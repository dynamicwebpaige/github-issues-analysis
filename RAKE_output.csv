/questions/34448582/how-to-input-data-into-keras-specifically-what-is-the-x-train-and-y-train-if-,124.2362702
"/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res



session_conf = tf",113.5324641
/questions/47981775/keras-prints-no-output-high-memory-and-cpu-usage-and-gpu-is-not-used-when-,97.33205037
/questions/44101692/implementing-a-multi-input-model-in-keras-each-with-a-different-sample-sizes-ea],96.27591215
io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development,94.92769619
/media/data/workspaces/git/master-thesis/python/thesis/absa/slot1/constrained/ffn,92.35644531
/questions/39782746/why-is-nvidia-pascal-gpus-slow-on-running-cuda-kernels-when-using-cudamallocmana,91.78822524
/questions/41191105/how-to-write-a-multidimentional-regression-predictor-using-an-rnn-in-tensorflow,91.1139562
/home/fxt120230/study/msp/research/visvad/samsung_vad/fusion_part/ete_vad/vadete_run,83.40153208
io/getting-started/faq/#how-can-i-save-a-keras-modelhi,81.11602462
/questions/47382952/cant-get-past-first-epoch-just-hangs-keras-transfer-learning-inception,72.3945898
/questions/47892072/keras-fit-generator-works-during-training-but-model-cant-predict-3d-cnni,72.06361536
/kyukon/home/apps/co7/haswell-ib/software/faceswap/20180212-foss-2017b-python-3,71.85243608
io/getting-started/faq/#how-can-i-save-a-keras-model,71.70689582
/questions/39921607/how-to-make-a-custom-activation-function-with-only-python-in-tensorflow,71.04780737
/questions/1324067/how-do-i-get-str-translate-to-work-with-unicode-strings,70.99279299
/data/sls/qcri/asr/sameer/vardial/languageid/vardial_2017/models/lstm,70.37025476
io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/,69.62145416
/questions/39124676/show-progress-bar-for-each-epoch-during-batchwise-training-in-keras,69.2954209
io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras,68.95934629
io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/,68.26185344
/opt/hdp/share/data/wertermittlung/newdata/ausbau/train/ausbau/gt12113,65.87622378
/university/django-and-bootstrap-template/mysite/rate/models/test/test,64.59128485
/users/charleschou/pycharmprojects/bigdata/prototypes/nlp/language_model/variational_asae/vae_example,63.00923382
/questions/49391097/many-to-one-recurrent-network-for-episodic-patterns-in-keras,62.93137983
/questions/41915862/theano-keras-set-the-k-first-values-of-tensor-to-a-,62.10955094
/aqibsaeed/human-activity-recognition-using-cnn/blob/master/activity%20detection,60.90498731
alt=media&token=11337eaa-4ffd-4dfb-b3ec-9c4ee6bd2f17,56.90365613
alt=media&token=39dd5e97-c411-43e9-9ba3-9f51a334c7c7,56.90365613
io/building-powerful-image-classification-models-using-very-little-data,56.87026074
/theano/theano/wiki/converting-to-the-new-gpu-back-end%28gpuarray%29,54.57096904
io/getting-started/functional-api-guide/#multi-input-and-multi-output-models,54.20801524
/kaggle/blob/master/state%20farm%20distracted%20driver%20detection/predictions,53.55296028
/~shervine/blog/keras-how-to-generate-data-on-the-fly,53.5230901
/@kuza55/transparent-multi-gpu-training-on-tensorflow-with-keras-8b0016fd9012,52.74535859
"/david-droz/d0edfc4ebd3fda09c13521ff515d8529#file-keras_theano_tf_issue-py-l89



average train time",52.51046087
/questions/46446670/keras-training-dies-when-running-more-than-1-process-simultaneously,52.05192243
"visualize_util import plot

/home/lcc/anaconda3/envs/sensequant/lib/python3",49.75831134
io/using-pre-trained-word-embeddings-in-a-keras-model,49.20014182
/cjfp6hjghfuvd01147d130984%2f5a7fdf5d-201a-40d0-bfef-c36d6ed02212%2fpeach8,49
/cjfp6hjghfuvd01147d130984%2f5a7fdf5d-201a-40d0-bfef-c36d6ed02212%2fpeach9,49
/apps/gent/co7/haswell-ib/software/python/3,47.47349253
/apps/gent/co7/haswell-ib/software/keras/2,46.86846229
/apps/gent/co7/haswell-ib/software/tensorflow/1,46.8228141
/data/sls/qcri/asr/sameer/anaconda3/lib/python3,46.67068594
/questions/49462794/keras-gets-none-gradient-error-when-connecting-models,45.84030505
/questions/44061208/how-to-implement-the-conv1dtranspose-in-keras,45.68649845
io/scikit-learn-api/#wrappers-for-the-scikit-learn-api,45.16486679
/jadore801120/attention-is-all-you-need-pytorch,44.78888889
"disable=g-doc-return-or-yield



~/anaconda3/envs/tensorflow/lib/python3",44.71982209
/home/spscup/cameraeye/large_dataset/part2_jpeg_pre_xception/trained_model/corrected_jpeg_xception_10-0,43.86307054
virtualenvs/deeplearning/bin/python /home/keo7/projects/agridoctor/classifier/test,43.74853174
using-pre-trained-word-embeddings-in-a-keras-model,43.68662831
io/blob/master/lesson%2021%20-%20generative%20adversarial%20networks,43.6182756
/questions/48192177/keras-with-tensorflow-runs-fine-until-i-add-callbacks,42.71627182
/rds/user/am2266/hpc-work/workspace/basic-yolo-keras/frontend,42.5546331
training/sgd/gradients/replica_0/model_1/reconst_layer_2/matmul_grad/matmul_1 = matmul[,41.77279681
/questions/46311506/feed-bson-files-directly-into-keras-pythonhi,41.55809149
/questions/41749398/using-keras-imagedatagenerator-in-a-regression-model,41.19297334
/home/claire/bureau/main/decibel-se/minimal_example,40.65936684
/eliotbarr/text-mining-with-sklearn-keras-mlp-lstm-cnn,40.24511131
/users/charleschou/anaconda/envs/ml-dev/lib/python3,40.17792687
replica_1/sequential_1/dense_1/truediv/_473 = _recv[client_terminated=false,39.80755095
/questions/49638685/keras-seq2seq-model-predicting-same-output-for-all-test-inputs,39.7395319
/questions/42156957/how-to-update-model-parameters-with-accumulated-gradients,39.70114765
/users/kathan/desktop/projectx/examples/frames/data_dir/test_dir,38.72256768
/keras-team/keras/blob/c8bef99ec7a2032b9bea6e9a1260d05a2b6a80f1/keras/utils/training_utils,38.57137724
/keras-team/keras/blob/45c838cc7a0a5830c0a54a2f58f48fc61950eb68/keras/utils/training_utils,38.57137724
training/adam/gradients/loss/td_loss/sub_3_grad/broadcastgradientargs = broadcastgradientargs[,38.44740277
training/rmsprop/gradients/loss/time_distributed_1_loss/add_1_grad/broadcastgradientargs = broadcastgradientargs[,38.38576707
pt/home/jlages/cdiscount_kaggle/venv/lib/python3,38.36312368
/users/kathan/desktop/projectx/examples/frames/data_dir/train_dir,38.35590101
/questions/47166191/extracting-bottleneck-features-using-pretrained-inceptionv3-differences-betwee,38.14295804
6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io,37.98489743
io/deep-learning-with-r-notebooks/notebooks/6,37.59084236
training/adam/gradients/loss/concatenate_1_loss/mul_grad/broadcastgradientargs = broadcastgradientargs[,37.5307361
/jacobgil/keras-grad-cam/blob/master/grad-cam,37.5216224
io/keras-as-a-simplified-interface-to-tensorflow-tutorial,37.49684438
/ppwwyyxx/tensorpack/blob/master/examples/resnet/cifar10-resnet,37.34634164
/questions/43839431/tensorflow-how-to-replace-or-modify-gradient/43948872,37.3382032
/divamgupta/image-segmentation-keras/blob/master/models/fcn32,37.16631206
/eppec/storage/sw/conda/envs/thibaultpython35/lib/python3,37.06370093
training/sgd/gradients/replica_0/model_1/reconst_layer_2/sigmoid_grad/sigmoidgrad,36.99501903
/users/david/pycharmprojects/deep-learning-with-keras/lib/python2,36.89431461
/andhus/extkeras/blob/master/examples/attention/graves_sequence_attention,36.71072415
/rossumai/keras-multi-gpu/blob/master/blog/docs/measurements,36.70132114
6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined,36.61951281
6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays,36.59403755
training/adam/gradients/model_1/conv2d_2/convolution_grad/conv2dbackpropinput = _mklconv2dbackpropinput[,36.5660283
/keras-team/keras/blob/cb6adf8da72c2d685b3a0a192165949c9da7b0e7/keras/backend/cntk_backend,35.84720225
/home/chris/developer/envs/keras_bug/lib/python3,35.82223488
/ning-ding/implementation-cvpr2015-cnn-for-reid,35.66669884
/home/ubuntu/efs/images/indexnew/tosep/kras_rn_multigpu,35.65030986
/tensorflow/models/blob/master/research/slim/preprocessing/inception_preprocessing,35.45432505
/keras-team/keras/blob/eb97bc385599dec8182963fe263bd958b9ab0057/keras/engine/topology,35.28177175
/ageron/handson-ml/blob/master/15_autoencoders,35.20732619
/questions/25227/fine-tuning-accuracy-lower-than-raw-transfer-learning-accuracy,34.93163175
moments_75/sufficient_statistics/shape/_1519 = _recv[client_terminated=false,34.85152539
/bvlc/caffe/blob/master/src/caffe/layers/base_conv_layer,34.84444369
/keras-team/keras/blob/632560d91286bf278228de72e7ce64f6c5aa530c/keras/engine/training_generator,34.5344239
/keras-team/keras/blob/3578599b6499eac4dc1f320ec5e7d96433777ee8/keras/engine/training,34.43951057
/keras-team/keras/blob/068a680480ebf27ecbe57f1406d60157b7d2df38/keras/engine/training,34.43951057
/keras-team/keras/blob/ab25382a2fe7c0684089918ae0fdbfcecd4065d4/keras/engine/training,34.43951057
/keras-team/keras/blob/35e10e91172c2fb716d5a6ec489ae71e0f488ca3/keras/engine/training,34.43951057
/keras-team/keras/blob/9a58f7b29026270afbec58c9255750b527ceff27/keras/backend/tensorflow_backend,34.38789993
/keras-team/keras/blob/af804d0a5db9a8f20fbb083b48655b2687ce89d9/keras/utils/conv_utils,34.333282
/home/lgy/anaconda2/envs/pycharm_tf/lib/python2,34.27378668
/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell_impl,34.24198968
/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl,34.24198968
/keras-team/keras/blob/3eab6103e0069d261c3e3586c12d5aaf0a331429/keras/engine/sequential,34.12157503
6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__,34.03866087
replica_0/sequential_1/dense_1/sigmoid/_165 = _recv[client_terminated=false,34.01255617
/andhus/extkeras/blob/master/extkeras/layers/attention,33.99737844
/fchollet/keras/blob/d5a242e9f6c17a60bbbc7bd114b34ba59dfcca29/docker/makefile#l7,33.74645433
/keras-team/keras/blob/3578599b6499eac4dc1f320ec5e7d96433777ee8/keras/applications/densenet,33.45999709
/home/ubuntu/notebooks/keras/fasterrcnn_keras/keras_frcnn/resnet,33.43355871
/keras-team/keras/blob/068a680480ebf27ecbe57f1406d60157b7d2df38/keras/utils/np_utils,33.38619205
/keras-team/keras/blob/b09ec1c9bf827622a5eebb94ba0af5bf202ca359/keras/layers/core,33.23227092
/keras-team/keras/blob/aedad3986200b825d94f847d52bd6b81f0419a06/keras/layers/core,33.23227092
/pablorr100/pruning-algorithm-method/blob/master/nn-comparison,33.20528556
/keras-team/keras/blob/05fe6076a117a184781c2c2dce087189995bf4d6/keras/layers/local,33.1471057
/taehoonlee/tensornets/blob/master/tensornets/resnets,33.10476209
il/home/hassner/projects/augmented_faces/masietal2016really,33.05537823
/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3,32.91820798
6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator,32.87877207
/assets/11470826/14587597/322ccb2e-04e8-11e6-8f82-b4759b5577fe,32.86666667
"io/applications/#usage-examples-for-image-classification-models

```",32.85152315
"> 

> /users/d069049/anaconda/envs/sapnlu/lib/python2",32.79257725
6/site-packages/tensorflow/contrib/learn/python/learn/estimators/__init__,32.67327626
/keras-team/keras/blob/6f3e6bb6fc97e706f37dc078ae821f490b78035b/keras/backend/__init__,32.6509657
/nvidia/nvidia-docker/wiki/frequently-asked-questions#platform-support,32.61003229
/keras-team/keras/blob/950e5d063320a72ca61f2082c154a65a48766239/keras/preprocessing/image,32.59097157
/keras-team/keras/blob/c476792e366626bec3b5a44b642c315239311516/keras/preprocessing/text,32.58333773
/fchollet/keras/blob/d5a242e9f6c17a60bbbc7bd114b34ba59dfcca29/docker/dockerfile#l33,32.57978767
"/sammy4321/networkinnetwork-using-keras-tensorflow  

openface",32.5797391
/use-different-batch-sizes-training-predicting-python-keras/,32.43473073
6/site-packages/tensorflow/python/keras/_impl/keras/engine/base_layer,32.34403755
/tensorflow/models/tree/master/slim#pre-trained-models,32.32828993
6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn,32.28617948
/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain,31.97991606
/andhus/extkeras/blob/master/examples/attention/readme,31.85358129
bag-of-words/bag-of-ngrams,31.83653846
/andhus/keras/blob/recurrent_attention_api_constants_support_before_removing_func_cell/keras/layers/recurrent,31.80656078
training/rmsprop/gradients/dense_1/add_grad/broadcastgradientargs = broadcastgradientargs[,31.72025394
/users/wil/projects/contrib/keras/keras/utils/generic_utils,31.70448481
io/datasets/#fashion-mnist-database-of-fashion-articles],31.56461896
/keras-team/keras/blob/master/examples/lstm_text_generation,31.31089694
/keras-team/keras/blob/master/examples/imdb_bidirectional_lstm,31.31089694
/fchollet/keras/blob/keras-2/tests/keras/legacy/interface_test,31.28652417
6/site-packages/tensorflow/contrib/factorization/python/ops/gmm,31.23659811
/keras-team/keras/blob/d3301fae7ef22801780d0f79a7a0a32c34507a09/examples/babi_rnn,31.2173528
org/versions/master/api_docs/python/tf/contrib/keras/layers/convlstm2d,31.21365353
/keras-team/keras/blob/master/keras/engine/topology,31.20864922
training/rmsprop/gradients/loss/time_distributed_1_loss/add_1_grad/broadcastgradientargs,31.10005279
/andhus/keras/blob/205d057b7078bfe885b967f39ab6324271c764fa/keras/layers/attention,31.07088827
[jalal@scc-c08 mhrn]$ cd test_mona/,31.05714286
/fchollet/keras/blob/bc9dbc5de0fec911ab8b6cae9696641da9c13d5c/keras/engine/topology,30.98905756
/aurora95/keras-fcn/blob/master/utils/transfer_fcn,30.95919302
/keras-team/keras/blob/fb1887d132a8ce8548ff53d868a6ba531cd63b34/keras/backend/tensorflow_backend,30.88789993
/keras-team/keras/blob/master/keras/utils/multi_gpu_utils,30.83158804
io/getting-started/sequential-model-guide/#examples,30.74884538
training/adam/gradients/loss/td_loss/sub_3_grad/shape_1,30.70930753
"io/getting-started/sequential-model-guide/#training



**binary_crossentropy**",30.70022225
training/rmsprop/gradients/loss/time_distributed_1_loss/add_1_grad/shape_1,30.64767184
"py

> /home/nrao/anaconda3/envs/tensorflow/lib/python3",30.64455554
/ahundt/keras-fcn/blob/master/utils/segdatagenerator,30.62585969
linear combination layer_i = a_1_x1+a2_x2+a3*x3,30.36805556
@fchollet @edersantana @abhaikollara @malaikannan @joshua-chin,30.34615385
6/site-packages/tensorflow/python/keras/_impl/keras/engine/training,30.276902
/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops,30.24198968
/home/hazem/pycharmprojects/optimizer-memory-network/optimzernet,30.23789847
/fchollet/keras/blob/master/keras/utils/training_utils,30.20554052
/keras-team/keras/blob/eb97bc385599dec8182963fe263bd958b9ab0057/keras/models,30.19181187
7/dist-packages/sklearn/externals/joblib/_parallel_backends,30.15457593
"n_train+n_val]

test_patient_ids = patient_ids[n_train+n_val",30.1456044
/keras-team/keras/blob/master/examples/lstm_seq2seq,30.11089694
/keras-team/keras/blob/master/keras/utils/data_utils,30.07071848
/keras-team/keras/blob/master/keras/engine/training,29.86638804
/keras-team/keras/blob/master/keras/backend/tensorflow_backend,29.8147774
/hironsan/anago/blob/master/anago/models,29.81276734
6/site-packages/sklearn/externals/joblib/_parallel_backends,29.80096459
training/adam/gradients/loss/concatenate_1_loss/mul_grad/shape_1,29.79264086
"/fchollet/keras/commit/b118cef26fae748d5ec23c33b29e9989a7abbe17#diff-4ea1eab272323ecb1f250db1b8d83443



@fchollet",29.76392991
/fchollet/keras/blob/a736c2632b315d8c6ee54369df89c31695c70591/keras/engine/training,29.64679638
/fchollet/keras/blob/6b106ab4ec9a1c0eb3e24ae590ce63f84022ad40/keras/backend/tensorflow_backend,29.59518574
"disable=g-import-not-at-top

-> 1046     save_model",29.51665976
/keras-team/keras/blob/master/keras/engine/saving,29.27241248
/hdd/rmk6217/imagenet/ilsvrc2015/devkit/data/,29.13294549
/keras-team/keras/blob/master/keras/wrappers/scikit_learn,29.1229348
/keras-team/keras/blob/master/examples/variational_autoencoder_deconv,29.11089694
training/adam/gradients/model_1/conv2d_2/convolution_grad/shapen,29.0660283
/keras-team/keras/blob/master/keras/applications/imagenet_utils,29.02973171
6/site-packages/tensorflow/python/data/ops/dataset_ops,29.00878593
/users/wil/projects/contrib/keras/keras/layers/__init__,28.9994051
"disable=g-import-not-at-top



typeerror",28.9701854
metrics/acc/mean_1/_2527 = _recv[client_terminated=false,28.95627199
/keras-team/keras/blob/a18aed4f8fcb8e4d6b4433fb56754a4a73f9224a/keras/callbacks,28.90343771
/fchollet/keras/blob/09e0044882f9311d5ea227e130209636defabfa7/examples/lstm_seq2seq,28.89130528
/keras-team/keras/blob/master/keras/layers/convolutional,28.8214291
/keras-team/keras/blob/master/examples/mnist_mlp,28.81089694
/keras-team/keras/blob/master/examples/cifar10_cnn_tfaugment2d,28.81089694
/keras-team/keras/blob/master/examples/deep_dream,28.81089694
/users/alex/anaconda/envs/keras/lib/python3,28.77566979
/keras-team/keras/blob/master/keras/layers/recurrent,28.70563962
/keras-team/keras/blob/master/keras/applications/xception,28.69639837
/keras-team/keras/blob/master/examples/variational_autoencoder,28.68589694
/users/ophir/miniconda3/envs/p3/lib/python3,28.66975841
/keras-team/keras/blob/master/keras/layers/core,28.6591484
/home/ubuntu/efs/images/indexnew/tosep/,28.65030986
io/layers/writing-your-own-keras-layers/,28.62802484
/fchollet/keras/blob/7610c55bdc046ff0b0d6300af5ea9dcfd0a427cb/keras/layers/convolutional,28.60183744
/fchollet/keras/blob/7af02c324004e6a743120c244101f44ce661dcdf/keras/layers/convolutional,28.60183744
training/adam/gradients/model_1/conv2d_2/convolution_grad/conv2dbackpropinput,28.5660283
/fchollet/keras#getting-started-30-seconds-to-keras,28.55720157
/home/yjy/anaconda3/envs/tensorflow/lib/python3,28.53533012
/farizrahman4u/keras-contrib/blob/master/keras_contrib/applications/densenet,28.472773
/keras-team/keras/blob/master/keras/applications/vgg16,28.42479343
/keras-team/keras/blob/master/keras/applications/mobilenet,28.32973171
/keras-team/keras/blob/master/examples/mnist_acgan,28.31089694
6/site-packages/tensorflow/contrib/learn/python/learn/__init__,28.28866087
/hdd/rmk6217/imagenet/ilsvrc2015/data/cls-loc/val/,28.15764628
/pdollar/coco/tree/master/pythonapi/pycocotools,28.12687747
/keras-team/keras/blob/master/examples/mnist_cnn,28.08867472
html#using-keras-models-with-tensorflow,28.07096114
/keras-team/keras/blob/master/keras/preprocessing/image,28.01784904
/theano/theano/blob/master/theano/tensor/nnet/abstract_conv,28.01210165
io/getting-started/functional-api-guide/,27.90674134
/fchollet/keras/blob/612f5307b962fb140106efcc50932c292630fda3/examples/variational_autoencoder_deconv,27.89130528
"runtime error

```

/nas/dft/ire/firdaus/",27.807824
/deep-learning-tools/keras/tree/keras2_mxnet_backend till,27.72232769
/keras-team/keras/blob/master/examples/imdb_cnn,27.71089694
io/#getting-started-30-seconds-to-keras,27.64103425
"2084             return output_tensors

   2085 



/home/claire/anaconda2/lib/python2",27.63601598
"ops import functional_ops



/opt/conda/lib/python3",27.55785277
/tensorflow/tensorflow/tree/master/tensorflow/core/distributed_runtime,27.55191734
/exdb/publis/pdf/hadsell-chopra-lecun-06,27.41904762
/share1/home/teeyo/anaconda3/lib/python3,27.4063055
/keras-team/keras/blob/master/examples/pretrained_word_embeddings,27.31089694
7/dist-packages/sklearn/externals/joblib/parallel,27.30609109
/users/wil/projects/contrib/keras/keras/models,27.21658611
/taolei87/sru sru recurrent neural networks,27.2090311
/home/roy/keras_tf/local/lib/python2,27.1746449
/keras-team/keras/blob/master/examples/image_ocr,27.12907876
@training/adam/gradients/loss/td_loss/sub_3_grad/reshape_1,27.0759742
/keras-team/keras/blob/master/examples/mnist_siamese,27.02518266
io/tensorflow/tf-slim/2017/01/23/fully-convolutional-networks-,27.01663897
"9456

/home/keo7/projects/agridoctor/classifier/test",26.99907709
/kuza55/keras-extras/blob/master/utils/multi_gpu,26.99252636
"inbound node



/disk/scratch_ssd/christian/lib/python2",26.95359004
6/site-packages/sklearn/externals/joblib/parallel,26.95247974
/home/pzw/venv2/local/lib/python2,26.95242268
/keras-team/keras/blob/master/examples/cifar10_resnet,26.8664525
/fchollet/keras/blob/master/keras/utils/generic_utils,26.81387385
io/getting-started/sequential-model-guide/,26.76510555
/snippet/913210/stacked-denoising-autoencoder-using-mnis,26.74084068
/users/ophir/dev/ophir/tensorboard_issue,26.68273155
/home/aditya/ocr-util/training_programs/data/test,26.64832294
/iamaaditya/vqa_demo/blob/master/models/cnn/vgg,26.62688145
/keras-team/keras/blob/master/examples/cifar10_cnn,26.59661123
/fchollet/keras/blob/keras-2/keras/legacy/interfaces,26.58943422
"py 

/usr/lib/python3/dist-packages/h5py/__init__",26.57999895
6/site-packages/tensorflow/python/keras/_impl/keras/models,26.52920329
/fchollet/keras/blob/master/examples/mnist_siamese_graph,26.51818275
/fchollet/keras/blob/master/examples/mnist_hierarchical_rnn,26.51818275
5/dist-packages/tensorflow/python/ops/functional_ops,26.40161296
/questions/48470539/keras-parameter-search-and-log-loss,26.38993108
org/versions/master/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits,26.38340543
/shuyib/projects/version_3_fashiondb/5/code/fashion-mnist-cnn,26.38164703
"validate state_spec



/home/tams/anaconda2/lib/python2",26.30315367
/glample/rnn-benchmarks/blob/master/theano/rnn,26.29897164
"methodtype] = _deepcopy_method

    252 



/nix/store/0ivvxa7gli2lhsxsscgvycbzsbjj5l8w-python3-3",26.26486447
6/site-packages/tensorflow/python/keras/_impl/keras/estimator,26.24712396
/coord-font-family /times-roman def,26.23165466
/keras-team/keras/blob/master/keras/models,26.11868934
/fchollet/keras/blob/130809e645e56d551250aef95c74f6f0f9463381/examples/pretrained_word_embeddings,26.09130528
/fchollet/keras/blob/8c8db2cd9ac263e082f8804899e97b7b7e910bda/examples/pretrained_word_embeddings,26.09130528
/fchollet/keras/blob/master/keras/engine/training,26.07367385
7/dist-packages/tensorflow/python/ops/array_ops,26.06827963
/fchollet/keras/blob/master/keras/backend/tensorflow_backend,26.02206321
/daemon2017/brumm-net/blob/master/train,25.89045009
/users/xxx/desktop/03_python/image_style_transfer/test,25.85175746
/fchollet/keras/blob/d5a242e9f6c17a60bbbc7bd114b34ba59dfcca29/docker/theanorc,25.74645433
6/site-packages/tensorflow/python/keras/_impl/keras/callbacks,25.74082913
6/site-packages/tensorflow/python/ops/gradients_impl,25.71466829
6/site-packages/tensorflow/python/ops/math_grad,25.71466829
7/site-packages/tensorflow/python/ops/array_ops,25.71466829
6/site-packages/tensorflow/python/ops/array_ops,25.71466829
6/site-packages/tensorflow/python/ops/nn_grad,25.71466829
7/site-packages/tensorflow/python/ops/gradients_impl,25.71466829
7/site-packages/tensorflow/python/ops/array_grad,25.71466829
5/site-packages/tensorflow/python/ops/array_ops,25.71466829
7/site-packages/tensorflow/python/ops/gen_state_ops,25.71466829
7/site-packages/tensorflow/python/ops/gen_logging_ops,25.71466829
/nukkung999/mybachelorfinalproject/blob/natkung/useexperimenttrain,25.67788462
6/site-packages/tensorflow/python/ops/nn_ops,25.51466829
7/site-packages/tensorflow/python/ops/nn_ops,25.51466829
"git --upgrade --no-deps

keras/keras/layers/merge",25.51297648
/keras-team/keras/blob/master/keras/optimizers,25.49670559
"/questions/46125848/modify-gradient-in-tensorflow-backward-pass

url 2",25.42884232
/keras-team/keras/blob/master/keras/callbacks,25.33031518
loss/mul/_179 = _recv[client_terminated=false,25.24999794
loss/mul/_193 = _recv[client_terminated=false,25.24999794
loss/mul/_515 = _recv[client_terminated=false,25.24999794
training/adam/gradients/loss/td_loss/sub_3_grad/shape,25.23446476
/mnt/hdd1/kevin/slu$ python lstm_imbd,25.21077944
training/rmsprop/gradients/loss/time_distributed_1_loss/add_1_grad/shape,25.17282907
/keras-team/keras/blob/master/keras/regularizers,25.16623964
/njwfish/mpra_yeast/blob/master/multigpu_failure,25.10476209
/aayushee/hwr/blob/master/ctc4d,25.10476209
/justm57/keras_add_features/blob/master/splitgenerator,25.10476209
/godfanmiao/mnist_cnn_centerloss_tensorflow/blob/master/mnist_cnn_bn_centerloss,25.10476209
/maciejkula/triplet_recommendations_keras/blob/master/triplet_keras,25.10476209
@training/rmsprop/gradients/loss/time_distributed_1_loss/add_1_grad/reshape,25.08127077
[jalal@scc-c08 test_mona]$ cd ~/,25.05714286
/deep-learning-tools/keras/tree/keras2_mxnet_backend,25.05566102
/fchollet/keras/blob/master/examples/imdb_fasttext,25.01818275
off-the-shelf resnet50 network trained,25.00353168
"keras



/home/tams/anaconda2/lib/python2",24.98411655
io/building-autoencoders-in-keras,24.94370716
/home/msid/thesis/pose_regression_using_cnns/helperfunctions,24.93449911
/fchollet/keras/blob/master/keras/layers/recurrent,24.91292543
/home/cxt/softwares/anaconda3/lib/python3,24.9063055
7/site-packages/tensorflow/python/framework/common_shapes,24.90282268
6/site-packages/tensorflow/python/framework/common_shapes,24.90282268
/fchollet/keras/blob/master/examples/variational_autoencoder,24.89318275
/assets/11470826/14587599/39d0fb2a-04e8-11e6-8300-be794b350bf2,24.86666667
/fchollet/keras/blob/master/keras/layers/core,24.8664342
roc auc/matthews correlation coefficients/cohen,24.83076923
6/site-packages/tensorflow/contrib/learn/python/__init__,24.83032754
"state_c]



/home/tams/anaconda2/lib/python2",24.80535147
7/dist-packages/tensorflow/python/framework/constant_op,24.80188856
/fchollet/deep-learning-models/blob/master/resnet50,24.7636205
7/dist-packages/tensorflow/python/framework/op_def_library,24.75643402
5/dist-packages/tensorflow/python/framework/op_def_library,24.75643402
7/dist-packages/tensorflow/python/ops/gen_math_ops,24.73494629
/fchollet/keras/blob/master/keras/applications/inception_v3,24.69156297
5/site-packages/requests/packages/urllib3/response,24.6913851
/nukkung999/mybachelorfinalproject/blob/natkung/trainexperiment,24.67788462
linux-x86_64/egg/keras/engine/topology,24.67708457
/7710032/34710793-f4a0abaa-f51c-11e7-865e-1f3a45cf198c,24.640625
/19284729/34156842-cefbe2bc-e4e0-11e7-83c6-3d96f45a9e2f,24.640625
/7592099/34078147-7aeaed4e-e2fb-11e7-9abd-7291a0d05528,24.640625
/23745991/33793851-fac96fdc-dcbf-11e7-916e-5b496d4e1524,24.640625
/5771169/33536259-a57d187c-d881-11e7-97ff-297ba8b50f04,24.640625
/20337365/33386584-8de5b8c6-d52b-11e7-8c2a-95b49e713648,24.640625
/939005/33294964-4c0890da-d3d3-11e7-9a7b-bfb38832b65f,24.640625
/643120/33247147-b6d72376-d2d0-11e7-8c94-364f40897816,24.640625
/643120/33247144-b350a312-d2d0-11e7-8baa-2b7c0fb73cd1,24.640625
/20726434/33110940-4fa3615e-cf71-11e7-8c21-9df69e2c82c3,24.640625
/31834007/33107116-d2618f2c-cf89-11e7-8cee-6ba1bb50d7ea,24.640625
/19515958/32816171-bc2dd530-c9b7-11e7-8ff0-bd360385ec65,24.640625
/1436271/32405436-5d9b8934-c1a8-11e7-99a7-86e32a869114,24.640625
/1436271/32405444-74cdb14a-c1a8-11e7-9a56-e8fb91e91d36,24.640625
/416585/32257791-5e1f46fc-be74-11e7-9bc1-547ac10e63fe,24.640625
/30388040/32235003-2eadc196-be56-11e7-9a07-1a9346cf66c7,24.640625
/416585/32200140-5bfca3e8-bd8d-11e7-86b8-f5fad6471f89,24.640625
/30106917/32187012-b61aecd6-bdc9-11e7-9ede-bc76ee8a1a66,24.640625
/4671752/32121045-4b16b5b8-bb31-11e7-86e0-8690ce9f867c,24.640625
/18151538/32105612-b9c52bec-bb46-11e7-8c55-ffa47db9c348,24.640625
/8509559/31753483-71d6e296-b4c3-11e7-8c4c-1f38a80623a2,24.640625
/495399/31577402-a4c70f0a-b0db-11e7-9b38-7d92fbb8a3c5,24.640625
/12878583/31319551-aae2e3f2-ac65-11e7-877f-afd744cb0fad,24.640625
/11304248/31310265-39bba3f6-ab95-11e7-8c1c-1b06ee23c77c,24.640625
/31940058/31058777-fa434b44-a701-11e7-8c1e-20d6f14cd26a,24.640625
/31940058/31058771-e978fb6a-a701-11e7-8b03-4fdac8ef9955,24.640625
/31940058/31018700-aa694f2e-a535-11e7-8b9a-9c81a65eb6db,24.640625
/17254532/30920739-b9d60156-a372-11e7-8b1e-3e5f8cddf709,24.640625
/22766463/30817715-e126c718-a219-11e7-84e7-0dd5f1632fb6,24.640625
/25488611/30604692-f7a4c85a-9d28-11e7-8e8c-c59cd9fcac78,24.640625
/8906088/30546485-651e4936-9c95-11e7-8d49-2c2122e124ee,24.640625
/3063343/30025150-1420004e-91b2-11e7-854d-5e0b8f22eea8,24.640625
/23259843/29837761-c7421ece-8d01-11e7-9e4d-40ad96f2f67b,24.640625
/7084539/29718695-856082f6-89ab-11e7-90b9-fd76cf9594f0,24.640625
6/site-packages/tensorflow/python/ops/gen_array_ops,24.63133495
7/site-packages/tensorflow/python/ops/gen_array_ops,24.63133495
5/site-packages/tensorflow/python/ops/gen_array_ops,24.63133495
/home/julian/kaggle/sbowl2018/saved_models/model,24.60394174
/fchollet/keras/blob/master/keras/applications/mobilenet,24.53701751
/3112825/41193236-f8df388a-6c3b-11e8-8ee7-2b7ac54a2c34,24.53333333
/11004307/39503488-d1151ff6-4df8-11e8-97f3-ce8b9e3fb719,24.53333333
/7721540/39447490-bfff1e48-4c76-11e8-96e3-b2a84bd9a300,24.53333333
/36124339/39165115-003ce400-47ad-11e8-9a95-17f2530bab9a,24.53333333
/26878250/38884164-02ed0f24-426f-11e8-8dc9-6532931145e0,24.53333333
/36965748/38779921-d5f4a920-40d7-11e8-8e82-6689b121aaaa,24.53333333
/36965748/38779922-d60fa2ca-40d7-11e8-92a1-8def824fbd93,24.53333333
/36965748/38779923-d62ee5c2-40d7-11e8-809f-df96b400d9f9,24.53333333
/19731019/38466105-58cafe76-3b24-11e8-9c24-893f16aa002e,24.53333333
/17986080/37650561-937dfcc4-2c35-11e8-967e-02541f2756db,24.53333333
/1201316/37323283-14f3a2b0-26c6-11e8-9fd5-24bd493abbc9,24.53333333
/13173000/37261825-360ae1d0-25da-11e8-909c-465441f6fffb,24.53333333
/11910731/37257080-893af836-253a-11e8-85ce-86bdaced45da,24.53333333
/11910731/37257438-bf2110ca-253f-11e8-9f98-b07f570be299,24.53333333
/11910731/37257184-f0484de8-253b-11e8-9a2c-b4fe48cecf89,24.53333333
/14579257/35983211-2d80a626-0cb7-11e8-806b-ea4e2286055a,24.53333333
/32168922/35532295-0d03ba34-053a-11e8-9dc9-8a841b149861,24.53333333
/fchollet/keras/blob/master/examples/mnist_acgan,24.51818275
mul_32/_721 = _recv[client_terminated=false,24.49303483
7/site-packages/tensorflow/python/framework/constant_op,24.44827722
6/site-packages/tensorflow/python/framework/constant_op,24.44827722
5/site-packages/tensorflow/python/framework/constant_op,24.44827722
7/dist-packages/tensorflow/python/client/session,24.4378809
5/dist-packages/tensorflow/python/client/session,24.4378809
"/keras-team/keras/issues/2280#issuecomment-306959926



import os

os",24.41081328
6/site-packages/tensorflow/python/framework/op_def_library,24.40282268
7/site-packages/tensorflow/python/framework/op_def_library,24.40282268
5/site-packages/tensorflow/python/framework/op_def_library,24.40282268
5/dist-packages/tensorflow/python/ops/nn_impl,24.40161296
6/site-packages/tensorflow/python/ops/gen_math_ops,24.38133495
/fchollet/keras/blob/master/keras/layers/wrappers,24.36984551
/assets/1304633/21485171/67371612-cb53-11e6-80f4-2d7ce1617d2b,24.36666667
/assets/15180702/18604772/1f107c00-7c81-11e6-8406-faaa467e4c5c,24.36666667
/assets/713026/15151640/491605d4-16d2-11e6-8844-768c4b509d57,24.36666667
/assets/17245428/14640043/e4cdf91c-063f-11e6-8844-c89a9e134339,24.36666667
/home/xenomorph/applications/anaconda3/lib/python3,24.35868645
7/dist-packages/zmq/eventloop/zmqstream,24.34014294
training/adam/gradients/loss/concatenate_1_loss/mul_grad/shape,24.3177981
/31110466/34079318-cf6c95f2-e33c-11e7-9b6b-1304337a0d4c,24.30729167
/31110466/34079319-cfaa0220-e33c-11e7-9e4c-bfaf843b1401,24.30729167
/fchollet/keras/blob/master/examples/mnist_cnn,24.29596053
/fchollet/keras/blob/keras-2/keras/layers/recurrent,24.23624161
/fchollet/keras/blob/master/keras/preprocessing/image,24.22513485
5/dist-packages/tensorflow/python/ops/gen_nn_ops,24.21113677
/19515958/32816345-730af72e-c9b8-11e7-98bc-83d7e2921856,24.140625
/19515958/32816356-7f3381d8-c9b8-11e7-9e9f-ac07ac9650a6,24.140625
/19515958/32816375-a81d2d2e-c9b8-11e7-999f-7342b0a7afe0,24.140625
/23259843/29837949-5f7cd684-8d02-11e7-923b-d36408d9ccff,24.140625
/home/xxx/project/keras/keras/engine/training,24.14059036
[jalal@scc-c08 test_mona]$ python resnet_50,24.10354321
"n_train+n_val]

x_test = data[n_train+n_val",24.09110613
"/fchollet/keras/issues/4865



/usr/local/lib/python2",24.09079647
/fchollet/keras/commit/edae1785327dd7a418ac06c2fe85a8c1f6ea05b7#diff-56dc3cc42e1732fdb3a3c2c3c8efa32a,24.08444273
7/site-packages/tensorflow/python/client/session,24.08426956
6/site-packages/tensorflow/python/client/session,24.08426956
5/site-packages/tensorflow/python/client/session,24.08426956
linux-x86_64/egg/keras/utils/generic_utils,24.07502339
"623           continue



/home/tams/anaconda2/lib/python2",24.0739229
7/dist-packages/tensorflow/python/ops/math_ops,24.06827963
7/site-packages/tensorflow/python/ops/nn_impl,24.04800162
/daemon2017/brumm-net/blob/flow/train,24.00411316
7/site-packages/zmq/eventloop/zmqstream,23.9865316
training/rmsprop/gradients/dense_1/add_grad/shape_1,23.9821587
/10016227/31258172-999520a6-aa67-11e7-9fc4-ffaa6d646994,23.97395833
2/api_docs/python/tf/contrib/layers/conv2d_in_plane,23.96272141
`/var/venv/tsats/local/lib/python2,23.93089254
7/dist-packages/tensorflow/python/framework/ops,23.92480137
5/dist-packages/tensorflow/python/framework/ops,23.92480137
4/dist-packages/tensorflow/python/framework/ops,23.92480137
@training_1/rmsprop/gradients/ctc_1/ctcloss_grad/mul,23.92105263
/fchollet/keras/blob/master/examples/imdb_cnn,23.91818275
5/dist-packages/tensorflow/python/ops/control_flow_ops,23.90161296
6/site-packages/tensorflow/python/ops/gen_nn_ops,23.85752543
/assets/3537118/25560256/935f61a0-2d04-11e7-8406-14281273edb4,23.840625
g-import-not-at-top,23.79101873
linux-x86_64/egg/keras/backend/theano_backend,23.77029285
"/0bserver07/one-hundred-layers-tiramisu  

vggface",23.75039413
6/site-packages/tensorflow/python/ops/math_ops,23.71466829
7/site-packages/tensorflow/python/ops/state_ops,23.71466829
/daemon2017/brumm-net/blob/flow_from_directory/train,23.69613076
/ahundt/keras-fcn/blob/master/evaluate,23.66328907
"enable=wildcard-import

     26 



/opt/conda/lib/python3",23.60377114
uk/media/uploads/documents/deng_marginal_loss_for_cvpr_2017_paper,23.58333333
6/site-packages/tensorflow/python/framework/ops,23.57119002
5/site-packages/tensorflow/python/framework/ops,23.57119002
7/site-packages/tensorflow/python/framework/ops,23.57119002
/fchollet/keras/blob/master/examples/pretrained_word_embeddings,23.51818275
5/dist-packages/theano/tensor/nnet/abstract_conv,23.50422469
org/api_docs/cc/class/tensorflow/ops/gather,23.45156765
/home/lpp/desktop/minion-basecaller/,23.42973721
"n_train+n_val]

y_test = targets[n_train+n_val",23.36702386
7/dist-packages/tensorflow/python/framework/tensor_util,23.36169718
/fchollet/keras/blob/master/examples/imdb_lstm,23.35151608
linux-x86_64/egg/keras/engine/training,23.33482339
/fchollet/keras/blob/0bc8fac4463c68faa3b3c415c26eab02aa361fd5/keras/metrics,23.28806212
"io/pkgs/pro/noarch

            config file",23.20033081
/home/am2266/venv/lib/python3,23.19645702
kr/static/docs/tr/snudm-tr-2015-03,23.1518797
/home/dr_aps/pycharmprojects/mnist/testmodel,23.08390387
6/site-packages/tensorflow/python/ops/gen_dataset_ops,23.04800162
6/site-packages/tensorflow/python/ops/clip_ops,23.04800162
7/site-packages/tensorflow/python/framework/tensor_util,23.00808584
6/site-packages/tensorflow/python/framework/tensor_util,23.00808584
5/site-packages/tensorflow/python/framework/tensor_util,23.00808584
loss/add/_153 = _recv[client_terminated=false,22.97925665
/eliorc/medium/blob/master/malstm,22.90476209
5/dist-packages/tensorflow/python/ops/variables,22.89180904
/users/hage581/envs/new_keras/lib/python2,22.88710462
"34 

     35 



/home/claire/anaconda2/lib/python2",22.84930751
"621 



/home/claire/anaconda2/lib/python2",22.84930751
ai steering angle predictor algorithm,22.79880952
"[dict] = _deepcopy_dict



/nix/store/0ivvxa7gli2lhsxsscgvycbzsbjj5l8w-python3-3",22.79861643
6/site-packages/tensorflow/contrib/factorization/__init__,22.76677032
7 /home/super/pycharmprojects/keras_tutorial/load_dataset,22.76608778
jung hyeong seok/keras/train_data_img/,22.75019365
jung hyeong seok/keras/train_data_txt/,22.75019365
carnd-behavioral-cloning-p3>python drive,22.72327944
/disk/scratch_big/cr_results/pwp3_jheat_sigma5_save2/pwp_model,22.64285714
/questions/50381504/use-intermediate-layer-values-to-fit-model,22.64146133
org/api_docs/python/tf/nn/fractional_max_pool,22.57319463
5/site-packages/tensorflow/python/ops/variables,22.5381977
7/site-packages/tensorflow/python/ops/variables,22.5381977
"pywrap_tensorflow_internal import __version__



/opt/conda/lib/python3",22.50689101
6/site-packages/tensorflow/python/framework/tensor_shape,22.40282268
7/site-packages/tensorflow/python/framework/tensor_shape,22.40282268
[jalal@scc-c08 models]$ cd_ml,22.39848144
[jalal@scc-c08 test_mona]$ ls ~/,22.39047619
7/dist-packages/zmq/eventloop/ioloop,22.34014294
/fchollet/keras/blob/master/keras/models,22.32597514
/home/tams/anaconda2/lib/python2,22.2339229
"1882 

   1883 



/home/tams/anaconda2/lib/python2",22.2339229
"181 

    182 



/home/tams/anaconda2/lib/python2",22.2339229
/lstm-neural-network-for-time-series-prediction,22.19277824
/vladimirdlc/universalmotion/blob/master/test,22.17923017
linux-x86_64/egg/keras/layers/core,22.12758374
/default-font-family /times-roman def,22.1263915
/opt/hdp/anaconda2/lib/python2,22.10904399
state-of-the-art implementation,22.03100064
7/site-packages/zmq/eventloop/ioloop,21.9865316
/keras-team/keras/issues/9321do keras,21.97258867
"/yoctol/yoctol-keras-layer-zoo

https",21.95623311
"keras



/home/user/anaconda2/lib/python2",21.93692447
/questions/48691449/typeerror-not-json-serializable-dimension2048,21.90944297
/fchollet/deep-learning-models/releases/download/v0,21.90248361
"/experiencor/basic-yolo-keras  

nin",21.86557826
/home/adhamija/anaconda2/lib/python2,21.84930751
"2113 

   2114     @property



/home/user/anaconda2/lib/python2",21.81173083
/home/david/downloads/seq2seq-master/seq2seq/model,21.79153349
/tflearn/tflearn/blob/master/tflearn/objectives,21.77142875
/fchollet/keras/tree/d5a242e9f6c17a60bbbc7bd114b34ba59dfcca29/docker,21.76856972
"2418 

   2419     @classmethod



/nix/store/0ivvxa7gli2lhsxsscgvycbzsbjj5l8w-python3-3",21.76486447
/home/antreas/anaconda2/lib/python2,21.73166045
/home/y0052080/pyenv/lib/python3,21.6813055
/home/rohan/anaconda2/lib/python2,21.64930751
out-of-the-box,21.58194444
/fchollet/keras/blob/master/keras/callbacks,21.53760099
6/site-packages/tensorflow/contrib/learn/__init__,21.47510366
3-dl-gpu-full/bin/python  7342mib,21.41587325
7/dist-packages/scipy/_lib/_ccallback_c,21.40136743
/fchollet/keras/blob/master/keras/regularizers,21.37352545
linux-x86_64/egg/keras/layers/__init__,21.36994367
tensors on-the-fly,21.33580247
/questions/27882261/mkdocs-and-mathjax,21.2308478
/questions/46259467/tensorboard-and-dropout-layers/49757651#49757651,21.21716969
"611             updates = []



/home/user/anaconda2/lib/python2",21.18673083
"/usr/bin/env python

import keras",21.16819977
/home/username/git/kerastests/testbug,21.161154
"/usr/bin/env python3

# vim",21.1207677
/fchollet/keras/blob/master/keras/losses,21.09713656
org/api_docs/python/tf/nn/atrous_conv2d_transpose,21.07319463
"git --upgrade --no-deps

wget -",21.07043933
3-advanced-usage-of-recurrent-neural-networks,21.04467925
5/site-packages/keras/utils/visualize_util,20.99096254
/src[tests] &&     pip install git+git,20.90295882
5/site-packages/conda/cli/main_install,20.88840076
"inbound node



/usr/local/lib/python2",20.88651247
/home/xzh/pycharmprojects/test/3dcnn,20.87503862
7/site-packages/theano/scan_module/scan_op,20.85816051
7/dist-packages/sklearn/model_selection/_validation,20.83878646
/home/ubuntu/code/dir/dir/datagen,20.82829958
7/site-packages/tensorflow/python/framework/errors_impl,20.81191359
5/site-packages/tensorflow/python/framework/errors_impl,20.81191359
6/site-packages/tensorflow/python/layers/convolutional,20.79037928
org/deeiip/keras/jobs/382610473#l1917,20.75405465
blog post [transparent multi-gpu training,20.74560412
/disk/scratch_ssd/christian/lib/python2,20.72819322
"347 

    348 



/disk/scratch_ssd/christian/lib/python2",20.72819322
io/preprocessing/image/#imagedatagenerator-class brightness_range,20.71187677
7/dist-packages/theano/sandbox/rng_mrg,20.71177186
/fchollet/keras/pull/8296/files#diff-9c4188ddc4dd173d80f64feed5b89412r19,20.68841099
/users/osama/pycharmprojects/untitled7/annmodel,20.64812271
4--generic-x86_64-with-linuxmint-18,20.63733766
"[list] = _deepcopy_list



/nix/store/0ivvxa7gli2lhsxsscgvycbzsbjj5l8w-python3-3",20.56914112
6/site-packages/tensorflow/python/estimator/estimator,20.56481946
5/site-packages/tensorflow/python/framework/device,20.56320004
7/dist-packages/theano/sandbox/cuda/__init__,20.52707376
tesla v100-sxm2-16gb major,20.52619048
6/site-packages/tensorflow/python/estimator/training,20.48842465
6/site-packages/sklearn/model_selection/_validation,20.48517512
"io/pkgs/pro/linux-64

                          https",20.47790015
/home/fractaluser/anaconda3/lib/python3,20.4063055
/home/edresson/anaconda3/lib/python3,20.4063055
/home/tthtlc/anaconda3/lib/python3,20.4063055
/home/jet/anaconda3/lib/python3,20.4063055
7/site-packages/theano/gof/cmodule,20.39870105
4/site-packages/theano/gof/cmodule,20.39870105
/home/pycharmprojects/mnist/data/lips,20.37802152
/caffe2/caffe2/wiki/model-zoo],20.35753786
/cluster/tools/python3/lib/python3,20.333509
"/titu1994/inception-v4/releases



full list",20.31257806
n14 default-font-family set_font,20.31140351
7/dist-packages/keras/backend/cntk_backend,20.28706557
[jalal@scc-c08 models]$ ls,20.23181477
5/dist-packages/keras/engine/topology,20.22163506
7/dist-packages/keras/engine/topology,20.22163506
"29     del swig_import_helper



/opt/conda/lib/python3",20.19291114
/flyyufelix/cnn_finetune/blob/master/densenet121,20.14642875
7/dist-packages/keras/legacy/interfaces,20.07181807
6/dist-packages/keras/legacy/interfaces,20.07181807
5/dist-packages/keras/legacy/interfaces,20.07181807
/users/osama/pycharmprojects/untitled7/prototxt,20.04812271
7/dist-packages/keras/utils/layer_utils,20.01124055
"tesla p100-pcie-12gb

major",19.99444444
7/dist-packages/ipython/core/interactiveshell,19.94597154
pyenv/versions/dir/lib/python3,19.91368951
/tensorflow/models/tree/master/object_detectioni,19.87276151
7/site-packages/keras/engine/topology,19.86802372
6/site-packages/keras/engine/topology,19.86802372
5/site-packages/keras/engine/topology,19.86802372
4/site-packages/keras/engine/topology,19.86802372
/home/ubuntu/miniconda2/lib/python2,19.85406699
/better-exploration-with-parameter-noise/,19.8539613
gh tickets suggested installing cython,19.8
12-intel/egg/keras/engine/topology,19.77599761
5/site-packages/conda/cli/install,19.77418756
io/bidirectional-lstms-with-keras/,19.75881793
6/site-packages/keras/legacy/interfaces,19.71820673
7/site-packages/keras/legacy/interfaces,19.71820673
5/site-packages/keras/legacy/interfaces,19.71820673
4/site-packages/keras/legacy/interfaces,19.71820673
building powerful image classification models,19.71540736
5/site-packages/keras/utils/layer_utils,19.65762921
7/site-packages/keras/utils/layer_utils,19.65762921
"zip

python faceswap/faceswap",19.65320368
7/site-packages/theano/gof/vm,19.64870105
4/site-packages/theano/gof/vm,19.64870105
7/dist-packages/keras/utils/generic_utils,19.61957388
5/dist-packages/keras/utils/generic_utils,19.61957388
5/site-packages/tensorflow/python/pywrap_tensorflow_internal,19.61772951
7/site-packages/ipython/core/interactiveshell,19.5923602
linux-x86_64/egg/keras/models,19.58712468
/keras-team/keras/wiki/keras-2,19.57258867
"[jalal@scc-c08 test_mona]$ 



```",19.55714286
8--generic-x86_64-with-ubuntu-12,19.54299804
6/site-packages/tensorflow/python/layers/base,19.53891729
"tesla p100-pcie-16gb

major",19.47063492
"org/api_docs/python/tf/set_random_seed



tf",19.40193203
io/callbacks/#usage-of-callbacks,19.35509052
tesla v100-sxm2-16gb gpu,19.35072873
/users/kain/miniconda3/lib/python3,19.33277924
7/dist-packages/keras/backend/theano_backend,19.31484334
/home/keo7/data/pvs/val/,19.30870334
6/site-packages/numpy/core/fromnumeric,19.30396959
5/site-packages/tensorflow/python/pywrap_tensorflow,19.29630094
tensorflow/core/grappler/clusters/utils,19.27018625
7/site-packages/keras/utils/generic_utils,19.26596254
6/site-packages/keras/utils/generic_utils,19.26596254
5/site-packages/keras/utils/generic_utils,19.26596254
/anaconda3/envs/proj1/lib/python2,19.23481524
/home/keo7/data/pvs/test/,19.23165627
/home/user/anaconda2/lib/python2,19.18673083
"456 



/home/user/anaconda2/lib/python2",19.18673083
"io/pkgs/free/noarch

                          https",19.18514653
org/api_docs/python/tf/nn/conv2d_transpose,19.17319463
net/wp-content/uploads/2012/03/bore_graf,19.13888889
6/dist-packages/keras/utils/data_utils,19.08370432
7/dist-packages/keras/utils/data_utils,19.08370432
virtualenvs/r-tensorflow/lib/python2,19.0591123
/tmp/roi/compile/tmptphsjtkt/mfb5a606d5cc1096c33f11985134ce267,19.00562372
5/site-packages/keras/backend/theano_backend,18.961232
7/site-packages/keras/backend/theano_backend,18.961232
4/site-packages/keras/backend/theano_backend,18.961232
/project/x_ray/model/xray_ver6_color/cc3,18.91229977
7/dist-packages/keras/engine/training,18.87937388
5/dist-packages/keras/engine/training,18.87937388
6/dist-packages/keras/engine/training,18.87937388
4/dist-packages/keras/engine/training,18.87937388
/home/rohan/pycharmprojects/comma,18.85057054
"device

    242 



~/anaconda3/envs/tensorflow/lib/python3",18.83263694
7/dist-packages/keras/backend/tensorflow_backend,18.82776324
5/dist-packages/keras/backend/tensorflow_backend,18.82776324
4/dist-packages/keras/backend/tensorflow_backend,18.82776324
org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits,18.82319463
"git --upgrade --no-deps

```

keras",18.82063298
7/dist-packages/theano/scan_module/scan,18.81177186
/home/keo7/data/pvs/train/,18.8039873
"845                     outs = [outs]



/usr/local/lib/python2",18.79444898
7/dist-packages/keras/utils/conv_utils,18.77314531
"big batch



/usr/local/lib/python3",18.76357253
"built = true

    103 



/usr/local/lib/python3",18.73754166
org/api_guides/python/image#image_adjustments,18.73436578
6/site-packages/keras/utils/data_utils,18.73009297
7/site-packages/keras/utils/data_utils,18.73009297
/flyyufelix/cnn_finetune/blob/master/resnet_50,18.67093856
6/dist-packages/keras/utils/vis_utils,18.64457388
/users/famil/desktop/numerai/example_model,18.61062271
6/site-packages/keras/engine/training,18.52576254
7/site-packages/keras/engine/training,18.52576254
5/site-packages/keras/engine/training,18.52576254
training/rmsprop/gradients/dense_1/add_grad/shape,18.50731593
7/site-packages/keras/backend/tensorflow_backend,18.4741519
6/site-packages/keras/backend/tensorflow_backend,18.4741519
5/site-packages/keras/backend/tensorflow_backend,18.4741519
tensorflow/core/common_runtime/9 evicted_count=1000 eviction_rate=0,18.46907396
tensorflow/core/common_runtime/5 evicted_count=1000 eviction_rate=0,18.46907396
"1885             return outputs[0]



/usr/local/lib/python2",18.46530663
7/site-packages/keras/applications/nasnet,18.4391062
7/dist-packages/cntk/ops/__init__,18.42142866
/questions/45020361/keras-callbacks-tensorboard-multi-output-error,18.41996551
6/site-packages/keras/utils/io_utils,18.41953397
6/site-packages/keras/engine/__init__,18.39666153
7/dist-packages/cntk/internal/swig_helper,18.38679787
12-intel/egg/keras/backend/tensorflow_backend,18.38212579
"/keras-team/keras/issues/5563



class customregularization",18.37456893
/workspace/hshu/anaconda3/lib/python3,18.34758279
"legacy_generator_methods_support



/usr/local/lib/python2",18.32778231
/keras-team/keras/commit/dec0c7b7aeddab2b31b55ccb015d7e0735206d59,18.30572835
"`pip install tensorflow-gpu tensorflow`



keras",18.30509349
/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/,18.27732416
"/keras-team/keras/issues/1675



```

src_model = sequential",18.2539906
%y-%m-%d-%h-%,18.25
"40x intel e5-2630 v4

    mem",18.23333333
/keras-team/keras/issues/2911hello,18.22239502
/keras-team/keras/issues/5031hello,18.22239502
/keras-team/keras/issues/1568i,18.22239502
7/site-packages/keras/engine/sequential,18.207827
6/site-packages/torch/autograd/__init__,18.20696171
5/site-packages/conda/cli/main,18.18469706
conda/envs/tensorflow-gpu/lib/python3,18.173667
conda/envs/architect/lib/python3,18.14458329
/home/pzw/keras_train/train_ir_01,18.14084832
7/dist-packages/keras/wrappers/scikit_learn,18.13592064
"/opt/conda/pkgs

           channel urls",18.10909176
"tesla p100-pcie-12gb



model",18.08531564
6/dist-packages/keras/applications/imagenet_utils,18.04271755
6/site-packages/tensorflow/contrib/__init__,18.01677032
"io/pkgs/free/linux-64

                          https",18.01123349
6/site-packages/keras/legacy/layers,18.00711939
7/site-packages/keras/legacy/layers,18.00711939
7/dist-packages/theano/sandbox/cuda,17.97331032
"git --upgrade --no-deps

```

theano",17.94206824
"error message



> /usr/local/lib/python2",17.94116187
7/dist-packages/keras/utils/__init__,17.89833732
5/site-packages/conda/cli/common,17.88840076
"/landmark-recognition-challenge/data

<img width=",17.86088124
topic/keras-users/pg5vr-obd_e,17.84970525
7/dist-packages/keras/layers/convolutional,17.83441494
/users/priot/tensorflow/lib/python2,17.83383757
3/tensorflow/contrib/keras/python/keras/backend,17.77881543
7/dist-packages/traitlets/config/application,17.76871437
"face-swap/data/trump/

```



error output",17.76362706
"224x224x3x30000 images

**theano outperforms tenserflow",17.75320786
/keras-team/keras/issues/3190#issuecomment-231699656,17.72239502
/keras-team/keras/issues/431#issuecomment-124175958,17.72239502
7/dist-packages/keras/layers/recurrent,17.71862546
6/dist-packages/keras/applications/xception,17.70938421
"__future__ import print_function



import numpy",17.69918306
"__future__ import print_function

import numpy",17.69918306
/parallelforall/scaling-keras-training-multiple-gpus/],17.68960764
7/dist-packages/keras/layers/core,17.67213424
5/dist-packages/keras/layers/core,17.67213424
"tree import decisiontreeclassifier



def create_dnn",17.66928586
"false







`$ /opt/conda/bin/conda install -",17.6637003
"__future__ import print_function

import keras",17.64334222
dynamic k-max pooling layer,17.62646993
"/rcmalli/keras-squeezenet

inception v4",17.62145802
5/site-packages/tensorflow/python/__init__,17.60006438
"__future__ import print_function



import tensorflow",17.59769403
7/dist-packages/numpy/core/numeric,17.58258094
7/site-packages/tensorflow/python/summary/summary,17.51465537
"nntools import helper

import numpy",17.48251639
6/site-packages/keras/layers/convolutional,17.4808036
7/site-packages/keras/layers/convolutional,17.4808036
5/dist-packages/theano/compile/sharedvalue,17.46739558
out-of-bound indices result,17.45995815
7/site-packages/traitlets/config/application,17.41510303
7/dist-packages/theano/gof/type,17.38967503
12-intel/egg/keras/layers/convolutional,17.38877749
5/site-packages/keras/layers/recurrent,17.36501412
7/site-packages/keras/layers/recurrent,17.36501412
5/site-packages/anago/models,17.36120352
6/site-packages/torch/autograd/variable,17.35605541
6/site-packages/keras/applications/xception,17.35577287
7/dist-packages/ipykernel/kernelapp,17.34014294
7/dist-packages/tornado/stack_context,17.34014294
7/dist-packages/ipykernel/kernelbase,17.34014294
7/dist-packages/ipykernel/ipkernel,17.34014294
7/dist-packages/ipykernel/zmqshell,17.34014294
7/dist-packages/theano/gof/op,17.33370774
5/dist-packages/theano/gof/op,17.33370774
6/site-packages/keras/layers/core,17.31852289
5/site-packages/keras/layers/core,17.31852289
7/site-packages/keras/layers/core,17.31852289
4/site-packages/keras/layers/core,17.31852289
7/dist-packages/numpy/core/include,17.31472379
00when sharing `dropout` layers siamese-style,17.30775046
/31110466/34079317-cf205ac0-e33c-11e7-8042-cf8fe5217784,17.30729167
6/site-packages/scipy/interpolate/ndgriddata,17.29775609
"n_train]

val_patient_ids = patient_ids[n_train",17.28846154
5/dist-packages/keras/layers/embeddings,17.28073073
/nix/store/0ivvxa7gli2lhsxsscgvycbzsbjj5l8w-python3-3,17.26486447
"generator_aug import loaddata_generator

import numpy",17.23251639
7/site-packages/numpy/core/numeric,17.22896959
7/dist-packages/h5py/_hl/group,17.22499143
/home/hpc/capn/mppi033h/,17.2202134
6/site-packages/h5py/_hl/files,17.21423723
"[dict] = _deepcopy_dict

    

    /usr/lib/python3",17.20152821
6/site-packages/dask/dataframe/core,17.18869141
7/dist-packages/keras/layers/wrappers,17.17554554
5/dist-packages/keras/layers/wrappers,17.17554554
"8 



~/anaconda3/envs/tensorflow/lib/python3",17.17225958
"621 



~/anaconda3/envs/tensorflow/lib/python3",17.17225958
~/anaconda3/envs/tensorflow/lib/python3,17.17225958
"261 



~/anaconda3/envs/tensorflow/lib/python3",17.17225958
"231 

    232 



~/anaconda3/envs/tensorflow/lib/python3",17.17225958
10-x86_64/egg/keras/preprocessing/text,17.15256359
/23259843/29838116-e2365be0-8d02-11e7-8953-219a8faaa2b0,17.140625
7/dist-packages/theano/compile/ops,17.13576292
/keras-team/keras/files/2068924/noreproducible_results_tensorflow_backend,17.13191883
"txt

pip install git+git",17.12507878
"/keras-team/keras/issues/1675

```

left = sequential",17.11673569
learning rate plateau adjustment callback,17.10793651
"import applications



/src/keras/utils/__init__",17.10219466
5/site-packages/keras/applications/vgg16,17.08416793
6/site-packages/keras/applications/vgg16,17.08416793
"org/~jm/demo/rnnoise/



loading",17.05609981
"/nyoki-mtl/keras-facenet  

googlenet",17.03590793
6/dist-packages/keras/preprocessing/image,17.03083488
7/dist-packages/keras/preprocessing/image,17.03083488
tesla v100-sxm2-16gb,17.02619048
4/site-packages/theano/gof/graph,17.01214643
"legacy_generator_methods_support



/opt/conda/lib/python3",17.00957781
7/site-packages/ipykernel/kernelapp,16.9865316
7/site-packages/tornado/stack_context,16.9865316
7/site-packages/ipykernel/kernelbase,16.9865316
7/site-packages/ipykernel/ipkernel,16.9865316
7/site-packages/ipykernel/zmqshell,16.9865316
"intel i7 4core/ht

gpu",16.98094851
7/site-packages/theano/gof/op,16.9800964
4/site-packages/theano/gof/op,16.9800964
/10016227/31258223-e7627d42-aa67-11e7-8810-723bd7a05391,16.97395833
/10016227/31258220-e31a4d32-aa67-11e7-8139-ae91968239ec,16.97395833
/users/firetiti/nn/keras/contributions_noise,16.94308586
"`





installed /usr/local/lib/python2",16.93889342
7/site-packages/keras/layers/embeddings,16.92711939
7/dist-packages/keras/layers/__init__,16.91449417
5/dist-packages/keras/layers/__init__,16.91449417
7/dist-packages/theano/gof/link,16.88252073
6/site-packages/h5py/_hl/group,16.87138009
generate reasonable-sounding midi tracks,16.87073171
6/site-packages/keras/preprocessing/__init__,16.85570608
/assets/11842615/25828679/df9dc5c6-3451-11e7-9792-c8fa32dd920f,16.840625
6/site-packages/keras/layers/wrappers,16.8219342
6/site-packages/keras/datasets/imdb,16.79794974
grayscale infrared imagery time series,16.795
tensorflow/core/common_runtime/gpu/pool_allocator,16.79361222
tensorflow/core/common_runtime/gpu/gpu_init,16.79361222
up-to-date software,16.74817759
7/site-packages/theano/gof/cc,16.68058025
4/site-packages/theano/gof/cc,16.68058025
5/site-packages/keras/preprocessing/sequence,16.67763325
7/site-packages/keras/preprocessing/image,16.67722354
6/site-packages/keras/preprocessing/image,16.67722354
"size



    /usr/local/lib/python3",16.64986738
/nix/store/3nvl1dwvb9n0715zflh7l81kimicpzx9-python3,16.64486447
"2697 



/nix/store/3nvl1dwvb9n0715zflh7l81kimicpzx9-python3",16.64486447
/23252616/34963761-97d02a88-fa8d-11e7-9587-b94b149ef0e6,16.640625
/35265385/34731359-75fa3760-f5a5-11e7-9041-1b0ae73477ba,16.640625
/35265385/34731364-79c9dcb0-f5a5-11e7-8594-af8948d317df,16.640625
/11025093/34558960-40043cda-f16a-11e7-8401-bc06a35aa368,16.640625
/29226171/34483160-b5bbc098-eff7-11e7-8976-94ffed66ee1a,16.640625
/23745991/33793855-06b43372-dcc0-11e7-8082-e7f6c4a87dc1,16.640625
/939005/33294699-12749bc6-d3d2-11e7-9795-0d6291ae4bd6,16.640625
/25509717/32843872-28b82af2-ca21-11e7-9055-3df74d266ce3,16.640625
/8632732/32103146-6bdf1b62-bb1f-11e7-9065-d66056d58fb5,16.640625
/31940058/31015242-c0ba6c6c-a527-11e7-9751-c072b40aafe7,16.640625
/8152811/30774060-e724436e-a04a-11e7-9019-1436bbb462a5,16.640625
/19523304/29341162-8b283c78-81d7-11e7-8706-52675853cade,16.640625
/5327989/29306472-17853336-819e-11e7-9f1b-c3c58b3ad005,16.640625
/24794718/29298283-40bf2a5e-8199-11e7-9f14-7924cfa62622,16.640625
/13865086/27340326-ce9256b6-560c-11e7-8452-daf55650e860,16.640625
/19548110/27017892-9a100f50-4f5e-11e7-9830-2e665c07df19,16.640625
6/site-packages/keras/datasets/__init__,16.63742747
on-they-fly generator,16.59570957
6/site-packages/keras/layers/__init__,16.56088283
7/site-packages/keras/layers/__init__,16.56088283
5/site-packages/keras/layers/__init__,16.56088283
"1257                 break

    

    /usr/local/lib/python3",16.5606812
/9593600/40618935-6423c596-6293-11e8-8fa5-dddb8d0c161a,16.53333333
/7151691/40524464-47238424-5ff8-11e8-86d2-0b56573865fd,16.53333333
/1832193/40192974-b8031054-59ba-11e8-9158-081bc3d1e830,16.53333333
/12259440/39555097-924d025e-4e6e-11e8-8579-3722ddba3e8e,16.53333333
/16248427/39394360-48ac1b08-4a86-11e8-8782-cbd9aa4f2ed5,16.53333333
/22906966/39133330-41525e64-4714-11e8-9c21-3964288ce4d1,16.53333333
/22906966/39133395-6059d4fe-4714-11e8-8d29-6308fca780a5,16.53333333
/3620404/38987680-39f51fb2-4403-11e8-8c82-54e795904e85,16.53333333
/12861981/38773885-ef225a10-404f-11e8-9818-030eea95fed7,16.53333333
/33388563/38238557-dcb35c9c-3732-11e8-9cc1-bc9702c5e4d9,16.53333333
/32168922/35532626-261c4602-053b-11e8-8654-33e8e77b777d,16.53333333
/4699179/35505604-91fb3bea-0521-11e8-8fb6-10aeee78e15c,16.53333333
7/site-packages/theano/gof/link,16.52890939
4/site-packages/theano/gof/link,16.52890939
3/tensorflow/python/ops/nn_ops,16.52813668
5/dist-packages/keras/layers/normalization,16.49798563
7/dist-packages/keras/layers/normalization,16.49798563
tesla p100-pcie-12gb,16.49444444
`keras-team/keras/docker/dockerfile`,16.44461724
6/site-packages/sklearn/metrics/classification,16.44338884
6/site-packages/dask/dataframe/__init__,16.43105135
"83s 370us/step

yy = model",16.43037737
/home/cadmus/desktop/ner,16.42973721
/fchollet/keras/issues/2397also fixes,16.42968083
[human activity recognition based,16.42117117
"1137       results = []



/usr/local/lib/python2",16.39215013
3-foss-2017b/lib/python3,16.38966353
#define ga_ulong unsigned long long,16.3748763
7/dist-packages/tornado/ioloop,16.34014294
"models import sequential



/src/keras/__init__",16.30184391
/opt/local/library/frameworks/python,16.30109907
7/site-packages/pil/tiffimageplugin,16.2865316
7/site-packages/pil/imagefile,16.2865316
"/fchollet/keras/tree/keras-2

note",16.27273162
"shape



/usr/local/lib/python3",16.2525051
"inputs



/usr/local/lib/python2",16.24899443
7/dist-packages/theano/compile/function_module,16.23662635
5/dist-packages/theano/compile/function_module,16.23662635
"2422 

       2423     @classmethod

    

    /usr/lib/python3",16.16777625
farther hidden statesfor train data,16.15758343
/home/****/miniconda3/lib/python3,16.15189374
5/site-packages/keras/layers/normalization,16.14437429
0/vc/bin/x86_amd64/cl,16.125
7/site-packages/theano/compile/pfunc,16.11378424
4/site-packages/theano/compile/pfunc,16.11378424
egg/keras/engine/base_layer,16.10087198
virtualenvs/py36/lib/python3,16.08746573
~/virtualenvs/tensorflowgpu/lib/python3,16.08746573
"+

~/virtualenvs/tensorflowgpu/lib/python3",16.08746573
"576

    577



~/virtualenvs/tensorflowgpu/lib/python3",16.08746573
"63

     64



~/virtualenvs/tensorflowgpu/lib/python3",16.08746573
git --upgrade --no-deps,16.07043933
git --upgrade --no-deps~~,16.07043933
git --upgrade --no-deps`,16.07043933
[slim/preprocessing/inception_preprocessing,16.06521739
org/keras-team/keras/builds/371831320,16.05958936
embedding_2/gather = gather[tindices=dt_int32,16.05291005
5/dist-packages/keras/layers/merge,16.03248645
/work/kaggle/input/idc_regular_ps50_idx5/9135/1/9135_idx5_x1701_y1851_class1,16.02285074
5/dist-packages/theano/tensor/sharedvar,16.00422469
"py



    /usr/local/lib/python3",16.00323995
62c    p0    86w / 150w,16
49c    p0    79w / 150w,16
% xcorner ycorner xsize ysize,16
"/dwin32 /d_windows /w3

                      h5_cflags",16
7/site-packages/tornado/ioloop,15.9865316
out-of-date tutorial,15.9826077
total in-memory usage,15.97632997
tesla p100-pcie-16gb,15.97063492
"1649 

   1650   @property



/opt/conda/lib/python3",15.96791114
6/site-packages/scipy/ndimage/__init__,15.93485287
implement data-parallel multi-gpu training,15.92965693
"base_layer import layer



import numpy",15.90739902
"tensorflow_backend import _to_tensor

    import numpy",15.89821407
ttext stringwidth pop width exch,15.89440994
/keras-team/keras/releases,15.88906169
7/site-packages/theano/compile/function_module,15.883015
4/site-packages/theano/compile/function_module,15.883015
6/site-packages/scipy/interpolate/__init__,15.85151953
conda/envs/tensorflow/lib/python3,15.84912874
pip install git+git,15.84600902
`pip install git+git,15.84600902
/home/rick/downloads/neural_talk/run,15.82783888
training utilizes multi-gpu callback,15.81875802
venvs/py361/lib/python3,15.81823496
"__future__ import division

import tensorflow",15.79769403
"py 

/usr/local/lib/python2",15.77034106
6/site-packages/scipy/misc/__init__,15.7681862
7/dist-packages/theano/gof,15.7523124
7/dist-packages/sklearn/cross_validation,15.71013149
applying routing-by-agreement mechanism,15.70321637
/fchollet/keras/issues/4056i found,15.69819935
6/site-packages/keras/layers/merge,15.67887511
7/site-packages/keras/layers/merge,15.67887511
5/site-packages/keras/layers/merge,15.67887511
/mnt/storage/home/username/,15.66512469
"318

    319



/mnt/storage/home/username/",15.66512469
"619



/mnt/storage/home/username/",15.66512469
io/keras-js-docs/conversion/,15.658444
@replica_0/model_1/reconst_layer_2/matmul,15.63638584
/keras-team/keras/files/2062968/slow_tensorflow_backend,15.63191883
/keras-team/keras/files/1603877/seis01,15.63191883
/keras-team/keras/files/1603878/xy_time01,15.63191883
embedding_1/gather = gather[tindices=dt_int32,15.61541005
"contrib import graph_editor

import keras",15.61527205
_one-to-one_ fashion,15.61135972
replica_0/model_1/custom_variational_layer_1/add_1 = add[,15.59535339
/keras-team/keras/compare/master,15.57784392
end-to-end visual odometry,15.5670201
"loss_functions = loss_functions



~/anaconda3/lib/python3",15.54323496
patchnotes didnt explicitly mention improvements,15.53571429
tensorflow/core/common_runtime/gpu/gpu_device,15.52088495
previous token language-model style,15.51186687
5/site-packages/requests/models,15.5015544
[screenshot_2017-12-17-15-05-30-239_ru iiec pydroid3],15.5
[screenshot_2017-12-17-15-04-36-922_ru iiec pydroid3],15.5
[screenshot_2017-12-17-15-04-20-194_ru iiec pydroid3],15.5
gov/pmc/articles/pmc5336098/,15.5
"sklearn-pandas

successfully installed sklearn-pandas-1",15.48997709
"/rcmalli/keras-squeezenet  

tiramisu",15.48352698
"get_config

    new_node_index = node_conversion_map[node_key]

keyerror",15.45169082
io/netscope/#/preset/alexnet,15.44208494
adding <code>encode_as_json=false</code> parameter,15.43987082
`tests/keras/legacy/interface_test,15.42876508
egg/keras/engine/topology,15.37599761
"load_cifar10 import load_cifar10_data



def identity_block",15.37313201
/usr/local/cellar/python3/3,15.34700599
"```python

import keras

import numpy",15.33793392
"estimators import dnn_linear_combined

  file",15.33229268
"pathlib import path

import pandas",15.32925969
"generic_utils import get_custom_objects



def relus",15.32761919
"plant species

            ys = labels[n_entries",15.31644144
"vis_utils import model_to_dot

import numpy",15.31029417
gpu support install nvidia drivers,15.30708711
high spatial resolution panchromatic image,15.29660957
"io/scikit-learn-api/



>",15.26928274
/oskarjonefors/130d13316c879d477df411fa9c6d848e#file-seq2seq-py,15.2365189
"```python

import keras

import tensorflow",15.23644489
tf slim function `preprocess_for_train,15.23141289
egg/keras/legacy/interfaces,15.22618062
"tensorflow_step_function import tf_stepy



    def buy_hold_sell",15.21928586
/usr/bin/env python,15.20476517
binary/multi-label classification examples,15.19547279
"blob

    blob = cv2",15.19250392
"topology import layer

import numpy",15.18252465
"626                 return true

    627 



~/anaconda3/lib/python3",15.17996406
inclib-vc14-x64/zlib,15.16666667
/inclib-vc14-x64/libsz,15.16666667
/inclib-vc14-x64/libaec,15.16666667
"/iwantooxxoox/keras-openface  

squeezenet",15.15019365
5/dist-packages/keras/models,15.13167518
7/dist-packages/keras/models,15.13167518
6/dist-packages/keras/models,15.13167518
deep recurrent convolutional neural networks,15.1024684
"pil import image

import matplotlib",15.10176281
6/site-packages/sklearn/metrics/scorer,15.08841048
"/conda/conda/issues







current conda install",15.06507849
/u01/anaconda3/lib/python3,15.04323496
ali cloud machine learning platform,15.00736434
"[list] = _deepcopy_list

    

    /usr/lib/python3",14.9720529
"utils import np_utils

import numpy",14.96823516
"utils import np_utils
import numpy",14.96823516
/keras-team/keras/files/1929703/v77,14.96525216
/deeplearning/learn/v4/overview,14.95833333
non-inception based nn1 model,14.95820633
tensorflow recently launched mirroredstrategy distribution,14.95454545
"dask_io import extract_dask_data

  file",14.9476773
7/dist-packages/theano/tensor/var,14.94172469
sequence one-dimense cnn model,14.9384537
"/keras-team/keras/issues/5640



apparently",14.93668073
ctc/ctcloss = ctcloss[ctc_merge_repeated=true,14.93253811
"inputs



/opt/conda/lib/python3",14.93078993
"utils import np_utils

import keras",14.91239433
"estimator import regression

import tflearn",14.90002688
/usr/local/lib/python3,14.89401453
"113 

    

    /usr/local/lib/python3",14.89401453
"179 

    180 



/usr/local/lib/python3",14.89401453
"359

        360



    /usr/local/lib/python3",14.89401453
"```

/usr/local/lib/python3",14.89401453
"308 

    309 



/usr/local/lib/python3",14.89401453
"677 

    678 



/usr/local/lib/python3",14.89401453
io/layers/core/#dense generated,14.89207841
org/install/install_sources#common_installation_problems,14.88964781
face recognition app ai based,14.86943124
"49536       first_item[0][0]                 

                                                                 second_item[0][0]                

__________________________________________________________________________________________________

distance_measure",14.86184211
virtualenvs/davidslater/lib/python2,14.85456684
"pil import image

import keras",14.85195646
/home/antreas/ndsb_2017/model,14.83629468
6/site-packages/scipy/ndimage/filters,14.79337013
"utils import plot_model

import numpy",14.78675368
"53 

     54 



/root/anaconda2/lib/python2",14.78623697
"]



/root/anaconda2/lib/python2",14.78623697
/root/anaconda2/lib/python2,14.78623697
7/site-packages/keras/models,14.77806383
6/site-packages/keras/models,14.77806383
5/site-packages/keras/models,14.77806383
4/site-packages/keras/models,14.77806383
egg/keras/utils/generic_utils,14.77393643
/labdata/tmp/to_tpc/scrwt_exd_train_skipped_0_frame,14.75
keras automatically downlodas pretrained weights,14.72165394
/pip-gkjbrkhs-build/h5py/h5f,14.70532244
load resnet50 pre-trained keras model,14.67984056
keras model  yolo detection network,14.67760331
time_distributed_1/keras_learning_phase = placeholder[dtype=dt_bool,14.67553734
robotworld 2013- fira robot soccer,14.66666667
7/site-packages/pil/image,14.6618125
/usr/local/lib/python2,14.66111564
"]

   2484 



/usr/local/lib/python2",14.66111564
"```

/usr/local/lib/python2",14.66111564
"100 

    101 



/usr/local/lib/python2",14.66111564
"> 

> /usr/local/lib/python2",14.66111564
"1359 

   1360 



/usr/local/lib/python2",14.66111564
"450 

    451 



/usr/local/lib/python2",14.66111564
"14 



/usr/local/lib/python2",14.66111564
"2227 

   2228 



/usr/local/lib/python2",14.66111564
"`

/usr/local/lib/python2",14.66111564
"1682 

   1683 



/usr/local/lib/python2",14.66111564
"177 

    178 



/usr/local/lib/python2",14.66111564
"+



/usr/local/lib/python2",14.66111564
"]

   1605 



/usr/local/lib/python2",14.66111564
"models import model_from_json

import tensorflow",14.66073804
io/callbacks/#learningrateschedulermodel accepts,14.65536683
7/dist-packages/keras/__init__,14.64410003
7/dist-packages/theano/tensor/type,14.64158732
"models import sequential

import numpy",14.63878388
typewhen loading raw image data,14.63830402
implement sequence-to-sequence transduction,14.61372133
/tensorflow/tensorflow/blob/r1,14.58697552
low resolution multi-spectral image,14.5864058
intel xeon e5-2680 v4 2,14.56666667
py#l1256the batch normalization epsilon values,14.56463456
non-training batch norm operator/layer,14.56004781
envs/py3keras/lib/python3,14.55040644
/ht93/05f07c4610df21964324e92555e00223#file-gist1-py,14.54366176
"15s 582us/step

test score",14.54104193
/oskarjonefors/5c1ee115fd20ef985089d1138787cda1#file-error-log,14.53010757
"/ikamensh/b2b2ff205e482b801dd0d284c86a2dd1



saved model file",14.52372024
replica_0/model_1/custom_variational_layer_1/mul_1,14.51315351
7/dist-packages/keras/optimizers,14.50969143
"topic/lasagne-users/l3ww51nlnx8

https",14.49971605
"# randomly flip images

                vertical_flip=false",14.49122978
"# randomly flip images

                                       vertical_flip=false",14.49122978
"# randomly flip images

        vertical_flip=false",14.49122978
ten minutes tutorial,14.46521739
uk/~szheng/papers/crfasrnn,14.45833333
tmc hage581$ python tm,14.43855721
tmc hage581$ python tc,14.43855721
"import imgaug

import augmentfunctions",14.42648191
state-of-art models,14.42253228
io/tutorials/keras/recurrent/,14.4216019
"io_utils import hdf5matrix

import numpy",14.41108782
# multi-spectral image shpape,14.40092192
7/dist-packages/keras/activations,14.37158659
5/dist-packages/keras/activations,14.37158659
"geforce gtx titan black

major",14.36471861
/ht93/05f07c4610df21964324e92555e00223#file-gist2-py,14.34366176
5/dist-packages/keras/callbacks,14.34330102
7/dist-packages/keras/callbacks,14.34330102
/keras-team/keras/issues/8018 https,14.33688518
/keras-team/keras/issues/8270 https,14.33688518
/keras-team/keras/issues/9245 https,14.33688518
"cross_validation import train_test_split

import h5py",14.32591098
"keras import sequential

import keras",14.29179812
6/site-packages/keras/__init__,14.29048869
out-of-box solution,14.27817086
"# randomly flip images

        vertical_flip=true",14.25124589
batch_normalization_1/keras_learning_phase = placeholder[dtype=dt_bool,14.24696591
5/site-packages/tensorflow/__init__,14.2448405
egg/keras/utils/data_utils,14.23806687
/fchollet/keras/pull/4429#issuecomment-261760721,14.20745861
/fchollet/keras/pull/5228#issuecomment-299611150,14.20745861
"image import imagedatagenerator



def segment_datagen",14.20025782
"learn_io import data_feeder

  file",14.1976773
7/site-packages/theano/compile/function,14.18002355
4/site-packages/theano/compile/function,14.18002355
7/dist-packages/keras/initializers,14.17922548
org/stable/modules/generated/sklearn,14.1713243
"git

pip install --user -",14.17106316
eval-in-training script,14.1675275
"preprocessing import image                  



def path_to_tensor",14.15978415
6/site-packages/keras/optimizers,14.15608009
5/site-packages/conda/fetch,14.13840076
tensorflow_backend import set_session` import statement,14.12894429
egg/keras/engine/training_generator,14.12864976
/documents/bachelor/imagemodels/weight_plots,14.125
/fchollet/keras/files/967876/word2vec_25_tar-category,14.11698242
"little-endian

                      libraries",14.11111111
"nvidia gtx 850m

enviroment",14.10132576
io/layers/core/#activityregularization,14.09531116
md#create-a-callback,14.09058608
7/site-packages/ipykernel/__main__,14.0833058
"utils import multi_gpu_model

import numpy",14.07008701
feed multi-channel word embedding layer,14.05835354
id=1wp7bbgpalbll9j-8pudmcyi_1-dfcgi8,14.04761905
egg/keras/engine/training,14.03373643
/broadinstitute/keras-rcnn/pull/41,14.02797143
6/site-packages/keras/activations,14.01797525
"keras import initializers

import keras",14.01575809
"1s 29us/step

test score",14.00979193
"14s 571us/step

test score",14.00770859
"14s 570us/step

test score",14.00770859
7/site-packages/keras/callbacks,13.98968968
5/site-packages/keras/callbacks,13.98968968
6/site-packages/keras/callbacks,13.98968968
egg/keras/backend/tensorflow_backend,13.98212579
"pandas import dataframe

import keras",13.97814615
tf ci builds started timing,13.97729478
"keras import initializations

def my_init",13.96947951
"/duggalrahul/alexnet-experiments-keras  

deepface",13.96081636
lstm training behaved completely differently,13.95575822
"/fchollet/keras/issues/6221#issuecomment-326733884



```",13.92968083
/fchollet/keras/issues/2317#issuecomment-307605458,13.92968083
/fchollet/keras/issues/369#issuecomment-147246435,13.92968083
/fchollet/keras/issues/1868#issuecomment-280373620,13.92968083
/fchollet/keras/issues/1872#issuecomment-212753159,13.92968083
/fchollet/keras/issues/1872#issuecomment-297162903,13.92968083
"np

import numpy

import matplotlib",13.92349291
"image import imagedatagenerator
import matplotlib",13.90745386
`sudo pip install keras`,13.90479765
"embeddings import embedding

#import tensorflow",13.89751859
-for-image-segmentation/,13.89501774
red�marrage du noyau,13.88888889
"io/layers/recurrent/#gru

https",13.87601086
/helvetica-oblique starnetiso def,13.87142952
/helvetica-bold starnetiso def,13.87142952
/helvetica-boldoblique starnetiso def,13.87142952
/courier-oblique starnetiso def,13.87142952
/courier-bold starnetiso def,13.87142952
/courier-boldoblique starnetiso def,13.87142952
replica_0/model_1/custom_variational_layer_1/mul,13.86609469
"models import model

import numpy",13.86472617
"models import model

    import numpy",13.86472617
"models import model



import numpy",13.86472617
"linux

    export keras_backend=theano

fi

```",13.85843015
/opt/conda/pkgs/requests-2,13.85550324
~/computer_vision/kaggle_distracted_driver$ python run_keras_simple,13.85522388
/explosion/spacy/issues/767#issuecomment-278651113,13.83333333
6/site-packages/keras/initializers,13.82561414
"get_index

    return _shared_sequences[uid][",13.81701149
"get_index

>     return _shared_sequences[uid][",13.81701149
keras handbook -_deep learning,13.81686032
"models import model



import keras",13.80888534
"models import model

import keras",13.80888534
/pip-gkjbrkhs-build/h5py/_objects,13.80532244
org/tutorials/deep_cnn#training_a_model_using_multiple_gpu_cards,13.803861
fan  temp  perf  pwr,13.78947368
proof-of-concept showing,13.7875
"/jihongju/keras-fcn



## questions",13.78558691
/rossumai/keras-multi-gpu,13.7670396
/tensorflow/core/util/cuda_launch_config,13.76594896
"models import model

import tensorflow",13.76323714
"models import model

    import tensorflow",13.76323714
~/heatmaps/examples $ python3 demo,13.75496625
proof-of-concept implementation,13.73730695
binary classification ml problem,13.72896226
"utils import plot_model

import os",13.71830785
egg/keras/engine/sequential,13.71580089
"image import imagedatagenerator

import numpy",13.71348835
gesture-based emotion recognition experiment,13.71283784
linux-x86_64 operating system,13.70108696
support none-sized inputs,13.67422417
mel frequency cepstrum coefficients,13.66666667
/daeun/kaggle/input/idc_regular_ps50_idx5/**/*,13.66604323
/dmitryulyanov/online-neural-doodle,13.66363636
bring last-turn metric history,13.64119952
multi-threaded `imagedatagenerator`-workalike,13.63133208
"video import fps

import numpy",13.62995229
"vgg16 import preprocess_input

import numpy",13.62757812
self-contained compact py-object,13.61861508
/nutstore_lab/rpm_project/code/try_it2,13.61411411
"callbacks import earlystopping

import sklearn",13.59387933
"resnet50 import preprocess_input



import tensorflow",13.58264027
/machinelearning/comments/6urcrl/is_windows_better_than_linux/,13.57142857
">

  </tr>

  <tr>

    <td>tensorflow 1",13.56168831
tensorflow/core/framework/op_kernel,13.53913737
"models import sequential

import lstm",13.5342146
multi-instance-multi-output cnn,13.51532944
/fchollet/keras/commit/5516c8fb42f01622c9a4a31c19cb46ae68cfa0f6,13.51301416
/keras-team/keras/pull/10082,13.5001728
/keras-team/keras/pull/10088,13.5001728
/keras-team/keras/pull/10093,13.5001728
/keras-team/keras/pull/9273,13.5001728
/keras-team/keras/pull/8021,13.5001728
/keras-team/keras/pull/9019,13.5001728
predicting time series data closer,13.49983193
one-hot encoded text data,13.48227753
one-hot encoded categorical variables,13.48125153
network produces unreproducible validation losses,13.48038767
mxnet backend implementing basic operators,13.46211359
7/dist-packages/theano/gradient,13.46177186
"optimizers import adam

import numpy",13.46056688
6/site-packages/h5py/__init__,13.44938595
7/site-packages/h5py/__init__,13.44938595
"callbacks import modelcheckpoint

import numpy",13.44844378
/farizrahman4u/keras-contrib/pull/28,13.43626489
/farizrahman4u/keras-contrib/pull/81,13.43626489
/farizrahman4u/keras-contrib/pull/80,13.43626489
"keras import  optimizers



import cv2",13.43276509
/times-roman starnetiso def,13.43037261
"keras import metrics

import numpy",13.41301307
/pytest-dev/pytest/issues/175,13.38321995
keras team no-doubt,13.360448
"models import model



def noop",13.35149564
/opt/conda/lib/python3,13.34291114
"15 



/opt/conda/lib/python3",13.34291114
non-fused batch norm api,13.33306996
"n_train]

x_val = data[n_train",13.33257919
reads incorrectly non-integer arrays,13.32518945
keras && pip install keras==2,13.32165797
edge_3032_replica_1/sequential_1/dense_1/truediv,13.31451613
tensorflow/core/platform/cpu_feature_guard,13.30988836
"models import model_from_json



def save_model",13.27463756
"model_selection import train_test_split

    text=list",13.26341706
/benoistlaurent/keras-example-wine,13.25019365
blas sgemm launch failed,13.25
"/opt/conda/envs

          package cache",13.23486963
"datasets import imdb

import os",13.22529505
/keras-team/keras/issues/3923,13.22239502
/keras-team/keras/issues/2826,13.22239502
/keras-team/keras/issues/1693,13.22239502
/keras-team/keras/issues/9459,13.22239502
/keras-team/keras/issues/2115,13.22239502
/keras-team/keras/issues/4871,13.22239502
/keras-team/keras/issues/6046,13.22239502
/keras-team/keras/issues/7632,13.22239502
/keras-team/keras/issues/5032,13.22239502
/keras-team/keras/issues/2594,13.22239502
/keras-team/keras/issues/7120,13.22239502
/keras-team/keras/issues/7497,13.22239502
/keras-team/keras/issues/7992,13.22239502
/keras-team/keras/issues/8802,13.22239502
/home/mazhar/downloads/sentiment,13.21883977
red hat enterprise linux 7,13.21497585
virtualenvs/r-tensorflow/ directory,13.20907034
"layers import lstm

import numpy",13.20437573
"0           batch_normalization_37[0][0]     

                                                                 reshape_6[0][0]                  

__________________________________________________________________________________________________

conv1d_31",13.19517544
[tensorflow cifar 10 multi-gpu tutorial],13.1913707
greedy layer-wise fashion,13.18370616
called multinominal logistic loss layer,13.17443302
/onlayer { curlayer ne {invis},13.16666667
custom_variational_layer_1/logistic_loss/mul = mul[,13.16042781
to_json/to_ymal/from_json/from_ymal,13.13636364
"/david-vazquez/keras_zoo

https",13.11449016
/fchollet/keras/blob/2,13.10756544
/ignaciorlando/cnn-dr-kagglei,13.09189189
"# cc



@dref360 @taehoonlee @davidariel",13.08187919
/programming/test/test_theano/test_concatenate,13.07446809
"time import time

import numpy",13.07251639
org/models/image/imagenet/inception-2015-12-05,13.06390603
batchsize*token length*embedding size,13.06130111
">

  </tr>

  <tr>

    <td>mxnet 0",13.05714286
"optimizers import adadelta

import numpy",13.00901409
venv/lib/python3,13.00005314
wilcoxon-mann-whitney statistic,13
/science/article/pii/s0893608015001847,13
egg/keras/layers/convolutional,12.98877749
"models import model

import time",12.97869169
"initializers import randomnormal





def expg_loss",12.97484142
keras community helped verify/fix,12.97120814
"contrib import factorization

  file",12.96960712
5/site-packages/conda/instructions,12.94395632
"start fine-tuning

# convolutional layers",12.94125979
score sklearn cross_validation/parameter search,12.9362989
arbitrary neural network based-cell,12.92015552
/gkalliatakis/keras-application-zoo,12.91686032
"initializers import constant

import numpy",12.90964057
"backend import clear_session



def dataset_fn",12.90130895
distributed multi-machine training capability,12.88809204
global spatial average pooling layer,12.87841798
/users/adamh/track_polynomial_detection/main_inception,12.87728938
egg/keras/layers/recurrent,12.87298801
"image import imagedatagenerator



def fixed_generator",12.86692448
"51136       input_title_column_first_item[0][

                                                                 input_title_column_second_item[0]

__________________________________________________________________________________________________

first_item",12.86184211
"plt

import pandas

import math",12.8493703
"return test_set





#fit model

input1=input_generator",12.84594042
"0           sequential_1[1][0]               

                                                                 sequential_2[1][0]               

__________________________________________________________________________________________________

second_item",12.84517544
io/layers/recurrent/#lstm,12.84326759
oil/gas data processing,12.83957219
tensorflow/core/kernels/logging_ops,12.82844896
egg/keras/layers/core,12.82649679
implemet pre-trained vgg16,12.80925157
***hdf5 library version mismatched error***,12.80096743
cross-platform front-end layer,12.79732066
io/models/model/ ->fit ->validation_split,12.74203873
/python/cognitive-toolkit/sequence,12.73091449
io/layers/core/#lambda,12.72077932
"/tensorflow/benchmarks/issues/157



thank-",12.70454545
test keras/tests/keras/test_multiprocessing,12.69787125
basic character-level seq2seq model [,12.67850485
google ml engine,12.65873694
/users/rajaramans2/codes/densenet_fb,12.64395604
5/site-packages/conda/exceptions,12.63840076
"/albertomontesg/keras-model-zoo

https",12.62222167
org/wiki/set_,12.603861
io/layers/core/#dense,12.58904811
~/anaconda3/envs/dev/,12.58825468
"n_train]

y_val = targets[n_train",12.58190883
pre-trained weights including resnet,12.57534255
4 vgg16when building keras image,12.54547455
x_train y_train scikit-learn api,12.54255925
"0           input_9[0][0]                    

                                                                 reshape_5[0][0]                  

__________________________________________________________________________________________________

conv1d_26",12.52850877
train framework-native data tensors`,12.52298456
"one-hot-encoded version



#train",12.49564055
penultimate training batch & stops,12.49359891
/tensorflow/tensorflow/commit/a94a333762b4d2c3fcae0a9e610d654bba6980de,12.49242424
io/backend/#backend-functions,12.48893867
face-swap/data/cage/ -,12.48642534
"vgg convolutional base model

    model_gen",12.47566652
variable loss_1/lambda_3_loss/map_2/,12.45285714
geforce gtx 950m major,12.44805195
"_pade import pade

>   file",12.4476773
"_pade import pade



  file",12.4476773
"loss



~/anaconda3/lib/python3",12.4472569
shuffle_batch = queuedequeuemanyv2[component_types=[dt_float,12.42
"sklearn import svm

#    



model1=svm",12.40558092
io/layers/core/#dropout,12.38266748
"metrics import log_loss





def get_im",12.38035812
mel filter bank / energy_,12.375
"_`import theano 

import keras",12.36537764
io/layers/core/#reshape,12.36224343
"2822729     input_10[0][0]                   

                                                                 input_11[0][0]                   

__________________________________________________________________________________________________

lambda_3",12.36184211
"```python

@threadsafe_generator

def mygenerator",12.36126879
7/dist-packages/ipykernel_launcher,12.34014294
5/dist-packages/ipykernel_launcher,12.34014294
/fchollet/keras/files/1252120/lstm_synthetic,12.33920464
making fit_generator support native-tensors validation,12.33267945
loss/time_distributed_1_loss/add_1,12.33259337
[keras fine tuning examples],12.33111493
"tesla p40



keras version",12.32852226
tensorflow/core/common_runtime/executor,12.32621682
dist-keras requires data,12.31995162
keras computes batch wise averages,12.31022783
run cuhk03 person re-id script,12.30330203
"/chen0040/keras-face  

densenet",12.2996442
"learn import estimators

  file",12.29062602
keras/keras/engine/training,12.28942459
5/site-packages/conda/plan,12.26340076
implementing _attention cell wrappers_,12.25714286
"keras import optimizers



def flatten",12.24848347
keras latest master `3b15ee6954b688b9490fd885d628939fd35f76ca`[],12.22401948
keras layer api design style,12.22251217
"models import *

import keras",12.21801414
ai/outputs/steering_model/steering_angle,12.19551282
"154368      input_6[0][0]                    

                                                                 input_7[0][0]                    

__________________________________________________________________________________________________

lambda_6",12.19517544
# randomly shift images horizontally,12.19343305
#define ga_bool unsigned char,12.18604651
#define ga_ubyte unsigned char,12.18604651
tensorflow/core/framework/allocator,12.15818499
up-to-date keras,12.14701989
/users/teo/obtrainv1/getdatafitkerasmodelv8,12.14395604
/19515958/32816271-28998034-c9b8-11e7-9902-d0c98fb43ff2,12.140625
~/code/tensorflow/lib/python3,12.13689453
"456 



~/code/tensorflow/lib/python3",12.13689453
"1463 



~/code/tensorflow/lib/python3",12.13689453
"62 



~/code/tensorflow/lib/python3",12.13689453
@athundt @dref360 @colinskow @timzaman,12.13333333
/2017/08/transformer-novel-neural-network,12.12517483
atkeras lacks augmentation layer,12.12488263
geforce gtx 1080 ti major,12.11471861
pre-trained inception-v3,12.11462087
conda install tensroflow-gpu,12.11219422
python processes accumulate memory leading,12.10522388
/times-italic starnetiso def,12.09703928
/times-bold starnetiso def,12.09703928
/times-bolditalic starnetiso def,12.09703928
weights/rot_lstm/cs/rot100/001_0,12.09267241
7/dist-packages/keras-1,12.09033659
7/dist-packages/keras-2,12.09033659
install gpu related stuff making,12.08313208
multiple layers stacked onb_featurer,12.08219398
volatile gpu utilisation stays,12.07453826
egg/keras/layers/__init__,12.06885672
"0           embedding_network_actor[1][0]    

                                                                 embedding_network_title[1][0]    

__________________________________________________________________________________________________

second_item",12.06184211
#define ga_byte signed char,12.06104651
keras generate tensorflow source codes,12.05390218
# randomly shift images vertically,12.04343305
"/rcmalli/keras-vggface  



deepid",12.01686032
"```

/usr/bin/python2",12.01286881
end-to-end memory networks,12.0045201
view incorrectly recognized texti,12
5/site-packages/ipykernel_launcher,11.9865316
training/adam/gradients/addn_5,11.97195226
/bhatabhijithn/car-behaviour-cloning,11.96321839
ctc_1/ctcloss = ctcloss[_class=[,11.93333333
randomly generated toy data set,11.93304689
3-foss-2017b-python-3,11.92665245
0-foss-2017b-python-3,11.92665245
"additional examples

     

## reference materials",11.89950071
"io_utils import ask_to_proceed_with_overwrite
>   file",11.87624873
"return avg_sum/number_of_record





lr_reducer = reducelronplateau",11.87534483
/src/keras/backend/tensorflow_backend,11.86599867
"time #helper libraries



def main",11.86123009
training/adam/mul_3 = mul[,11.84450128
_without similar side-effects_,11.84126984
"/flyyufelix/densenet-keras  

densenet",11.83947936
saving arbitrary user defined data,11.81201863
/src/keras/utils/conv_utils,11.81138074
case  restoring lr-schedular state,11.79400449
"22399800    masking_1[0][0]

                                                                 masking_2[0][0]

__________________________________________________________________________________________________

bidirectional_1",11.77850877
software versions easily,11.75849421
"py#l214-l215



1d",11.75208256
corrupt keras design principles,11.75019365
7/site-packages/keras-2,11.73672525
6/site-packages/keras-2,11.73672525
5/site-packages/keras-2,11.73672525
7/site-packages/keras-1,11.73672525
spatial pyramid pooling layer,11.73296344
passed non-serializable keyword arguments,11.73182778
ai/pythonwheel/gpu/cntk-2,11.72535985
decide not-trainable parameters,11.72244444
"ops import control_flow_ops

      5",11.71494163
recognize online handwriting strokes,11.71428571
/fchollet/keras/pull/8171 makes,11.70745861
recognizing handwritten digit sequences,11.70238095
tests/keras/layers/cudnn_recurrent_test,11.69915921
1 tests/keras/layers/cudnn_recurrent_test,11.69915921
"0           bidirectional_1[0][1]

                                                                 bidirectional_1[0][3]

__________________________________________________________________________________________________

concatenate_2",11.69517544
"vis_utils import model_to_dot

svg",11.69101873
# load imagenet pre-trained data,11.68677496
__future__ import print_function,11.67990762
"/emirceyani/281b7ce87e639ac1a67967585a512166

layer definitions",11.67488263
/usr/lib/python3,11.66777625
"58 



/usr/lib/python3",11.66777625
"519 



/usr/lib/python3",11.66777625
"252 



/usr/lib/python3",11.66777625
"layers import dense

import reader",11.66429721
tree import decisiontreeclassifier,11.66324095
"dev-c697eeab84e5b8a74908da654b66ec9eca4f1291

tensorflow",11.64332096
servers communicating web socket,11.64285714
[graph-with-bn],11.64185447
"shows

`     ==============    400s  290ms/step",11.63950617
io/papers/weneccv16,11.63851351
[pre-trained glove embeddings][1],11.63418984
replica_0/model_1/reconst_layer_1/sigmoid,11.62551803
[lasagne  3rd party implementation],11.62441012
/python2/lib/python2,11.6236636
data/predict/t160305m-0222c_5,11.6202046
"================code examples======================

import numpy",11.61712939
supports multi-label segmentation,11.61138351
"```

git clone git@github",11.59264285
"estimators import estimator

  file",11.59155194
"generate embeddings

        input_embed = embed_layer",11.59073171
define customers loss functionminimal,11.59006845
customized loss function called mbe1_4,11.58245638
"tools import freeze_graph



model_name =",11.58228857
org/tutorials/beginner/data_loading_tutorial,11.553861
tensorflow import set_random_seed & set_random_seed,11.54278641
"tensorflow import set_random_seed

set_random_seed",11.54278641
building triple siamese architecture,11.53567164
"plot_mo

del

    dot = model_to_dot",11.53402778
"119 # deconvolution layers



/home/captain_jack/",11.53346467
"0           bidirectional_1[0][0]            

                                                                 bidirectional_2[0][0]            

__________________________________________________________________________________________________

dropout_7",11.52850877
git &&     conda clean -yt,11.51423833
precious io bandwidth,11.51351351
empirical per-channel means,11.51298701
"disable=protected-access

   1405         count=",11.50987762
tf-idf weighing method,11.50961802
"random import random





    def get_single_min_max_sequence",11.50467399
blas gemm launch failed,11.5
pre-trained word embeddings,11.499025
io/models/model/#fit,11.4964247
french-to-english translation,11.49469306
"tmp$ python --version

python 2",11.48877637
"tmp$ python --version

python 3",11.48877637
/resnet_50/dbs2017/data/stage1_labels,11.48529412
modeling recurrent neural network,11.48306956
top shows rstudio cpu usage,11.47681057
"tf

import json





def remove_slice",11.47656469
3d convolutional neural network,11.47065391
"org/simple/scipy/

download error",11.46814759
data generators introduce side effects,11.4637605
basic neural network cells,11.45484515
existing pull requests related,11.45002658
"built = false



/home/captain_jack/",11.44658156
training large image data set,11.44432731
keras ml model,11.44362895
single keras training file/notebook,11.4403439
/usr/lib/python2,11.43487736
tensorflow/stream_executor/cuda/cuda_gpu_executor,11.43483392
"7524903     lambda_1[0][0]                   

                                                                 lambda_2[0][0]                   

__________________________________________________________________________________________________

concatenate_1",11.41898496
"siddharth



relevant code fragment",11.41411411
"/flyyufelix/densenet-keras

resnet-101",11.39697065
"import os

import csv

os",11.39256831
keras tensor board call back,11.39145486
multi-class classification outputting,11.38993615
[kuza55/keras-extras],11.38352698
/kuza55/keras-extras,11.38352698
kuza55/keras-extras,11.38352698
"/bzamecnik/92607207af912ae53dd2aa557631b977</del>



https",11.38115683
quadro m5000 gpu takes,11.36025254
"0           sequential_1[2][0]               

                                                                 sequential_2[2][0]               

__________________________________________________________________________________________________

sequential_3",11.34517544
paper [learning transferable architectures,11.33981481
/fchollet/keras/files/1524620/iou_test,11.33920464
/fchollet/keras/files/1097463/smoke_epoch_39,11.33920464
py <inputpath> <result_prefix>` checks,11.33144764
model recompilation step inside `fit`,11.33107877
ucf101 action recognition dataset,11.33035714
anaconda2/envs/myenv/,11.32538007
regular classification problems suchs,11.31212121
[tf image adjustments guide],11.30361237
fine-tuning inception v3,11.29761248
/fchollet/keras/files/713143/test_multiprocessing,11.28364908
/blob/nohistory/model,11.26875581
mercedes ml320 images classifier,11.25080972
#define ga_long long long,11.2498763
"disable=wildcard-import

---> 24",11.24657429
"```

import sys

import numpy",11.23251639
"misc import imresize



def preprocess",11.23010837
`zero_debias` optionally enables scaling,11.22222222
unreasonable effectiveness blog post,11.21256039
"2161984     input_actor_column_first_item[0][

                                                                 input_actor_column_second_item[0]

__________________________________________________________________________________________________

sequential_2",11.19517544
org/ftp/arxiv/papers/1604/1604,11.191361
pretrained neural network model weights,11.18750631
/model/dividedmaps/pointnet/weights,11.18354361
"967       results = []



/library/frameworks/python",11.18308824
"4                    py27_0    defaults

tensorflow-gpu            1",11.18292987
io/2015/05/21/rnn-effectiveness/,11.17480384
"existing model

##load model

#model=load_model",11.16376838
"2161984     input_actor_column_first_item[0][

                                                                 input_actor_column_second_item[0]

__________________________________________________________________________________________________

embedding_network_title",11.16184211
incorporate multi task learning,11.15241698
io/applications/#xception,11.13256113
/home/data/pretrained-model,11.12684726
"1162                 break



/library/frameworks/python",11.11872043
`python examples/mnist_cnn,11.1167415
positional/keyword argument conflict,11.11600221
end-to-end trainable model,11.1158913
auto-pruning takes place,11.10897436
update `keras/backend/theano_backend,11.10168453
io/layers/core/,11.09531116
"_check_p

ydot

    raise importerror",11.09174877
"sh cpu_config

$ sh run_tf_backend",11.09090909
"sh gpu_config

$ sh run_tf_backend",11.09090909
uknown word token,11.07392607
tesla k80 single gpu,11.07238772
"/abearman/916673e9a0f12bcf5ac2723b8b5eb819



run results",11.07080282
"utils import to_categorical

y_trn= to_categorical",11.05477983
"```

import theano

import keras",11.04830447
"0           bidirectional_1[0][2]

                                                                 bidirectional_1[0][4]

__________________________________________________________________________________________________

lstm_2",11.04811662
apply connectionist temporal classification,11.04650276
local/lib/python3,11.04447325
~/anaconda3/lib/python3,11.04323496
"115 

    116 



~/anaconda3/lib/python3",11.04323496
"]

    323 



~/anaconda3/lib/python3",11.04323496
"590 



~/anaconda3/lib/python3",11.04323496
"109 

    110 



~/anaconda3/lib/python3",11.04323496
"715 

    716 



~/anaconda3/lib/python3",11.04323496
"830 



~/anaconda3/lib/python3",11.04323496
"1027 



~/anaconda3/lib/python3",11.04323496
"/flomlo/234cca43fd213f37915fc28ba77074f9



    class wrapper",11.03813883
"deflate decode encode

                            mpe",11.03636364
non-fused batch norm,11.03563406
@loss/concatenate_1_loss/mul,11.00696311
"nvidia geforce gtx 1080

cudnn",11.00102181
158] retrieving cuda diagnostic information,10.99924338
abstract keras backend api,10.99435852
"layers import *



def make_model",10.98967999
_very_ redundant training matrix,10.96800501
"num_files_train_0]

list_validation_0 = list_files_0[num_files_train_0",10.96666667
unsigned long long int*,10.96382979
unsigned long long int,10.96382979
"cross_validation import train_test_split



    data_train",10.95357912
edge_869_replica_0/sequential_1/dense_1/sigmoid,10.94809277
support deep complex netowrk,10.9394318
"visualize_util import plot
```",10.92752667
[simple rnn benchmark test case],10.9249581
io/models/sequential/,10.91978101
#define ga_ushort unsigned short,10.88575916
"ops import tensor_array_ops



~",10.8816083
"ops import tensor_array_ops

      4",10.8816083
/keras/engine/topology,10.88149212
keras/engine/topology,10.88149212
current keras `recurrent` api,10.87920849
"7/dist-packages
> requirement",10.87860448
dose keras support map,10.87417344
geforce gtx titan black,10.86471861
keras faq https,10.86468381
optional argument named `recurrent_dropout_implementation`,10.85707364
building a3c model based,10.84870903
takes raw 1d signals,10.8452381
"disable=protected-access

   4218 

   4219   # pylint",10.84471925
cnn image classifier layerwise,10.83640356
includes fully convolutional networks,10.82571413
"sequence import _remove_long_seq

>   file",10.82336791
io-stream dump method,10.82069088
$homedir/lib/python3,10.81823496
largest positive representable number,10.81677019
local/lib/python2,10.81157436
applying one-hot encoding,10.80348765
/usr/lib64/python2,10.79695972
"-num_validation_samples]

    x_val = data[-num_validation_samples",10.79411765
ed 3rd class output,10.7882183
"disable=protected-access



invalidargumenterror",10.78712121
"disable=protected-access

> 

> invalidargumenterror",10.78712121
"1            py27h01caf0a_0    defaults

tensorflow-tensorboard    1",10.78696304
fully convolutional networks paper,10.78155458
"plugins import projector

  file",10.78101063
recurrent kernels match perfectly,10.76809589
366] error retrieving driver version,10.75837484
user defined cross entropy**,10.75695327
pre-trained keras model,10.75525468
"tmp$ pip list

backports",10.74901978
"mismatching environments

* importing h5py",10.74242424
"cost-masked objective function

    `fn",10.7418058
encountered unexpectedly high weighted accuracy,10.73976051
created dir structure correctly,10.73778419
# compute gen dice coef,10.73363095
/keras/legacy/interfaces,10.73167513
`keras/legacy/interfaces,10.73167513
decoder/tensorarrayunstack/range/delta,10.72647528
"layer_utils import layer_from_config

     46",10.71324095
keras sequential model comprising,10.70599375
io/layers/embeddings/,10.70390765
5000x1 time series vector,10.69272727
inverse dice-coefficient defined,10.69158879
working step function called `tf_stepy`,10.68258708
validation loss fluctuates randomly,10.6730189
nvidia tesla p100,10.67152778
pre-trained embedding vectors,10.66068107
"return steering_label



def read_images",10.65638973
"return shared_model



def get_auto_regressive",10.65638973
# perform piece-wise max pooling,10.65485528
"/opt/conda

       envs directories",10.64915534
"input video

clip1 = videofileclip",10.64681246
"utils import np_utils



np",10.63993624
install --upgrade keras,10.61878847
output dimension 3d [#filter image,10.61499398
/philipperemy/keras-visualize-activations,10.61477698
"misc import doccer

>   file",10.61434396
"misc import doccer



  file",10.61434396
"dnn import dnnclassifier

  file",10.61434396
pixel multinomial logistic loss,10.61235527
loss moves alike mse,10.61181415
/dogs-vs-cats/data,10.60522876
convert one-hot encoded,10.60051282
/aurora95/keras-fcn,10.60019365
"implementing 

spoken language understanding",10.6
caffe weight conversion utilties,10.59218352
"/data/table1

/data/table2",10.58823529
output_slack_sample_weights = placeholder[dtype=dt_float,10.58125162
`pip install keras`,10.57146432
length 1d convl window,10.56077883
function accepts single loss tensor,10.54945244
"models import load_model

simple_model",10.54938473
/cerndb/dist-keras,10.54583398
/fchollet/keras/issues/6462 https,10.54417099
/fchollet/keras/issues/5511 https,10.54417099
multi-label classification task,10.53960181
io/layers/merge/#add,10.53786325
/26558158/39282338-f0738c48-4943-11e8-8249-3125c5a1e19f,10.53333333
embedding_1_input = placeholder[dtype=dt_int32,10.53268019
end-to-end prediction task,10.53160094
`pip install tensorflow`,10.52581613
epoch started taking ~575 ms,10.50521688
wilcoxon-mann-whitney,10.5
back-ward calculation cost,10.49923946
steering angle model trainer,10.4908712
"return dataset



def print_weights",10.48674688
"engine import layer

  file",10.47873277
"4s 8ms/step

```



note",10.47680776
validation/ subfolders inside data/,10.47268908
including discrete wavelet transform,10.47268673
"image inputs

def input_generator",10.46920459
extra optional parameter in_place,10.46305221
"dev-f6f45e57a0151fa91b04de60b27f01eceaa0c17a

batch_size=256",10.45724842
io/preprocessing/image/,10.4540118
/home/ec2-user/,10.45049385
"tmp$ pip list

deprecation",10.44901978
discriminative feature learning approach,10.44665475
fused batch norm api,10.44150369
config=session_conf,10.42857143
pre trained word embedding,10.42551623
keras functional api tutorial,10.41284694
replica_0/model_1/lstm_2/,10.41154924
pre-trained vgg16 model,10.40012276
pre-trained vgg model,10.39394992
"topology import inputspec
>   file",10.38189384
clipping operation avoids overflow,10.38
/home/andreas/untitled9,10.36307054
/home/andreas/untitled0,10.36307054
/home/damiano/corrector,10.36307054
unknown token placeholder,10.35880355
newly computed moving average,10.35757576
"newly computed

    moving average",10.35757576
"models import sequential



os",10.3570971
"```python

image_mean = math_ops",10.35522388
2 output convolutional neural network,10.34601454
hot sized target sequence,10.34101217
multi class label support,10.33922393
[mscoco multi label segmentation],10.32877481
"training import collect_trainable_weights

importerror",10.32713989
data unlike recurrent layers,10.32240652
true avoids slower transformations,10.3197176
inception v3 fine-tuned,10.31684325
@farizrahman4u @fchollet @israelg99,10.31585082
pre-trained glove weights,10.30686225
nice high-level framework,10.3062595
"models import save_model

    save_model",10.30586159
"convolutional base

model_new = model",10.28677763
egg/keras/models,10.28603773
"`models=�lstm�`



models/lstm_benchmark",10.28414237
pytorch implementation [pytorch-t2t],10.28314028
create pr supporting cnn architectures,10.28244745
__future__ import absolute_import,10.27990762
keras/utils/generic_utils,10.27943094
fine-tuning learning code,10.27796223
data-parallel sgd algorithm,10.27593002
scikit-learn wrappers,10.27314815
"models import load_model

load_model",10.27276136
"one-hot

y_binary = to_categorical",10.27194139
start sharing pretrained models,10.27012646
multi-character handwriting problem,10.26623609
enable=wildcard-import,10.26086
"80s    

found 1000 images belonging",10.25009747
"return model





def split_validation_set",10.24726093
"return inputs



def get_shared_model",10.24426852
"```python

# current 

def _get_batches_of_transformed_samples",10.24404391
898] successful numa node read,10.2396304
892] successful numa node read,10.2396304
data/train/data/bad/bad,10.23503441
"tensorflow backend

```

keras-gpu                 2",10.22600633
py#l92-l98in https,10.22371557
/keras-team/keras,10.22239502
"ray van raamsdonk



#keras2",10.22222222
"std dev

        std_true =",10.22082679
pre-trained encoder network,10.21356614
"variable names

patient_ids = read_lines",10.20285714
"unclear error messages

running

```python",10.17934724
one-hot-encoded classes,10.16797045
>xeon e5-1650 v4 @ 3,10.16666667
zoo/visualizations/combinedcnn,10.16666667
"```



import sys

import os",10.16407056
/farizrahman4u/keras-contrib,10.15848711
io/keras-docs/1,10.158444
"py#l2443-l2451



check",10.14942642
model training update output reads,10.14787527
io/models/model/,10.14572329
english tokenization takes place,10.14468864
"clinical data

early_stop = earlystopping",10.14411765
ptb language modelling task,10.14344262
metrics current implementation averages metrics,10.14124008
"models import load_model

# construct",10.13867045
"# apply zca whitening

        rotation_range=20",10.13842196
"# apply zca whitening

                rotation_range=0",10.13842196
"# apply zca whitening

                                       rotation_range=0",10.13842196
"# apply zca whitening

        rotation_range=0",10.13842196
"4 

      5 



/src/keras/backend/__init__",10.12906444
full design review doc,10.12393162
original model takes multiple inputs,10.11892146
scy-py misc library,10.11848467
handcrafted feature vector representations,10.11793275
io/layers/noise/,10.11724098
@fchollet @dref360 @farizrahman4u,10.11585082
multi-output keras model,10.11386137
"neccessary columns

data = data[[",10.10997442
"/benchmark/#cifar10-train-time

https",10.10986071
"*nb_data]=weights

            inputs = [[x_train[batch]]",10.10898478
high-frequent dead lock,10.09935897
randomly sampled augmented images,10.09700448
user-defined function reshape_with_batch,10.09525141
input layer yields proper result,10.08475497
"```

keras invokes **sigmoid_cross_entropy_with_logits**",10.08352698
simple logistic regression model,10.08293469
roughly 1k data points,10.07189542
data server ip address,10.07189542
/usr4/cs542/jalal/,10.07142857
framework import graph_util,10.06976269
multi-dimensional lstm network,10.06364469
"0           embedding_network_actor[2][0]    

                                                                 embedding_network_title[2][0]    

__________________________________________________________________________________________________

siamese_network",10.06184211
"interface

```python

embedding_layer = embedding",10.05885797
$ python examples/mnist_siamese,10.05324943
pre-trained model weight,10.05179001
caffe pre-trained model,10.05051558
great deep learning frame work,10.05037012
"```python

import os

os",10.04364214
[multi-scale context aggregation,10.04209871
keras inception-v3 model,10.04149588
pre-trained weights provided,10.03912032
making documentation easy-to-read,10.0355933
"false

      conda-env version",10.03156593
200k 64x64x3 rgb images,10.02824561
"allocate as-needed

    config",10.02437562
stack multiple recurrent layers,10.01975905
io import bytesio,10.01246875
"models import model_from_json

print",10.00788272
"pfunc

    output_keys=output_keys",10
"code



```python

def mygenerator",9.9753829
org/docs/master/nn,9.974411487
not-trainable parameters,9.972444444
categorical cross-entropy loss,9.969172417
create pan-sharped image,9.968614232
node-type conv2dbackpropinput,9.962759463
"test data sequences

        output_dim=layers[1]",9.961731189
python process slowly increases,9.961284487
# cross-entropy loss score,9.959030783
keras framework hangs,9.940048721
layer requiring multiple inputs,9.939945883
standard pip install,9.938917732
/questions/tagged/keras,9.935586907
"sklearn import preprocessing



warnings",9.926224669
one-hot code labels,9.922735043
"0s 4ms/step

accuracy",9.92200173
keras imdb fasttext implementation,9.914286312
"neural network

simple_rnn_model = simple_model",9.910889111
tensorboard class inside callback module,9.905050231
data/train/data/good/good,9.888880565
screen-shot-2015-11-06-at-8 03 47-,9.883838384
__future__ import division,9.879907621
"env

> win7

> cuda9",9.875
/helvetica starnetiso def,9.87142952
/courier starnetiso def,9.87142952
"0           lstm_1[0][0]

                                                                 lstm_2[0][0]

__________________________________________________________________________________________________

dense_1",9.870208502
sequence-to-sequence lstm,9.864206142
`tqdm` module replace current implement,9.863255207
"```

/home/keo7/",9.863070539
/layerlen layercolorseq length def,9.861466592
time     calls       avg       min       max,9.859495798
batchwise averages,9.857142857
generalised dice loss implementation,9.853828888
tesla k80 major,9.85
"popped network



```

_________________________________________________________________

layer",9.838802043
underlying model output namesthis,9.838026696
"return model

```



__does saving",9.830104913
"test directory



```

import numpy",9.82903764
total minibatch size kn,9.824034661
id represent movie id,9.822510823
customized image preprocess function,9.814247488
optimizer updates providing evaluation points,9.813451811
replica_0/sequential_1/lstm_1/,9.812337662
#define ga_uint unsigned int,9.800332226
**introduction,9.8
"setarray failed

apply node",9.798667266
"model=save_weights

del model

tf",9.798267316
sequence tagging tasks inspired,9.785947018
deep learning network based,9.785796052
"@fchollet 

```



mona@pascal",9.779487179
"```

# coding=utf-8



import numpy",9.776851195
"/flyyufelix/7e2eafb149f72f4d38dd661882c554a6

squeezenet",9.775
time-delay neural networks,9.771136364
"single output

    stacked_ds = lambda",9.770473127
dogs/ subfolders inside train/,9.763465784
release complete notes covering,9.75974026
"#define function

def read_label",9.758330733
stacked bi-lstm layers,9.75647472
"return norm



def l2_output_shape",9.756389733
scikit-learn api,9.755769231
**sequence-to-sequence** model,9.753612136
sequence-to-sequence model,9.753612136
[keras faq][1],9.750193648
"models import model



# set",9.750015049
online handwriting recognition,9.75
simultaneous tensorflow initialization caused,9.747402597
/usr/include/python2,9.745011668
prepare many-to-,9.744693058
directly-converted file works fine,9.73793189
contrib import keras,9.735364427
padded label encoded fix vectors,9.732744773
editor import videofileclip,9.713240955
sklearn import model_selection,9.711884471
"learning phase

    model = keras",9.707731511
/fchollet/keras/pull/8572,9.707458606
/fchollet/keras/pull/7980,9.707458606
/fchollet/keras/pull/8276,9.707458606
models import save_model  # pylint,9.691985269
custom multiprocessing queue/pool combination,9.690240786
"0           dense_2[0][0]                    

                                                                 dense_3[0][0]                    

__________________________________________________________________________________________________

dense_4",9.687991531
tensor conversion requested dtype int32,9.684177088
/fchollet/7eb39b44eb9e16e59632d25fb3119975#gistcomment-2315777,9.679487179
"keras import backend



print",9.675094662
error selecting convolution algo,9.668379558
tf-slim],9.665173572
egg/keras/optimizers,9.664053982
input-output pair organization,9.663198725
"_make_callable

    callable_fn = session",9.661157025
include 3d image generation,9.659774183
"return content_loss





def get_style_loss",9.656389733
alexthe class function reset_states,9.646984658
"mathematically correct

  debiasing factor",9.644388398
conditional random fields],9.642694064
"test_multiprocessing_evaluating failed



call stack",9.640777708
installed tensorflow-gpu successfully,9.640194824
`     ==============    400s  290ms/step,9.639506173
"~/keras$ 

-------------------------



[installed versions]

scipy",9.639195916
"import logging





logger = logging",9.633409022
single layer encoder-decoder architecture,9.631504729
"advanced_activations import leakyrelu

model",9.624624971
"input_height= input_shape[1]

        input_width = input_shape[2]",9.621848739
single shot detector implementation,9.620383685
"return network







def similarity_network",9.617928194
"sampled input

        dw_model = [sequential",9.614305469
global max pooling operations,9.613708514
pr adds missing named arguments,9.613662542
"#adding custom layers 

    model_gen",9.611825396
input dimension mis-match,9.59284042
raw tensorflow loss function,9.591473375
"return lines



anim = animation",9.589369218
"respective cudnn library

conda 5",9.587014943
sklearn import cross_validation,9.5832295
system memory increase gradually,9.581818182
conv2d_1_input = placeholder[dtype=dt_float,9.581251621
output_power_sample_weights = placeholder[dtype=dt_float,9.581251621
add `class conv3dtranspose_ngroup` based,9.572211633
default keras `dense` layer doesn,9.572170761
/lasagne/lasagne/issues/167,9.571428571
/lasagne/lasagne/issues/730,9.571428571
"return 4d tensor

    return np",9.569833285
installed python-pip,9.568485529
"lstm cells

        fw_cell = keras",9.565944564
nature images classification app,9.557985874
running lstm keras default program,9.557139494
handles preloaded validation data,9.556022409
tensorflow object detection api,9.55303769
early stopping callback based,9.552123552
"35875       model_1[1][0]

__________________________________________________________________________________________________

reshape_1",9.549021592
installing collected packages,9.544502618
/keras/engine/training,9.539230938
4/keras/engine/training,9.539230938
keras/engine/training,9.539230938
"latest master code

backend",9.534668913
text topic classification task,9.528766449
exotic models/functions coming,9.523305796
"output shape              param  

-------------------------------------------------------------------------------------------------------

time_distributed_1",9.517733977
31k+ batches aka `steps_per_epoch`,9.51532567
**on_batch_end** enables access accuracy,9.515123762
global average pooling layer,9.514781619
"line-too-long



importerror",9.503981029
/verystrongjoe/a3c-sketch,9.5
############# core test code starts,9.499985708
"keras import optimizers





img_width",9.49754354
multi-label softmax classifier,9.491342136
/keras/backend/tensorflow_backend,9.487620295
"bottom networks

    top = get_part_model",9.4875
[char-level text generation,9.485702614
unreliable validation accuracy results,9.480563007
pre-trained model returns,9.480470869
"layers import dense



# initialising",9.47737204
keras functional api documentation,9.474296212
y_train[cmpt]=y_train_all[cmpt],9.469090909
achieve multi-gpus training,9.465648333
"error



undefind constraint constr",9.464740103
scikit-learn workflow,9.458333333
io/layers/merge/,9.455663373
pre-trained models],9.45552842
/home/*/similarity/cnn,9.454962431
/library/frameworks/python,9.452053761
"giving input throug computer

#",9.450134134
maximum recursion depth exceeded,9.44963145
[fully convolutional densenets],9.445906433
deepfakes/faceswap,9.444444444
keras/keras/layers/merge,9.442537156
keras model functional api,9.438500742
keras/utils/io_utils,9.433002365
"disable=protected-access

   1915",9.432954545
disable=protected-access,9.432954545
"disable=protected-access

--> 350",9.432954545
/fchollet/keras/issues/2822,9.429680828
/fchollet/keras/issues/2271,9.429680828
/fchollet/keras/issues/890,9.429680828
/fchollet/keras/issues/8121,9.429680828
/fchollet/keras/issues/3057,9.429680828
/fchollet/keras/issues/3358,9.429680828
/fchollet/keras/issues/2621,9.429680828
/fchollet/keras/issues/4365,9.429680828
/fchollet/keras/issues/5406,9.429680828
/fchollet/keras/issues/6261,9.429680828
/fchollet/keras/issues/7633,9.429680828
/fchollet/keras/issues/6142,9.429680828
/fchollet/keras/issues/5235],9.429680828
/fchollet/keras/issues/5235,9.429680828
/fchollet/keras/issues/1727,9.429680828
/fchollet/keras/issues/7632,9.429680828
/fchollet/keras/issues/1922,9.429680828
/fchollet/keras/issues/1920,9.429680828
/fchollet/keras/issues/7574,9.429680828
/fchollet/keras/issues/1627,9.429680828
/fchollet/keras/issues/6692,9.429680828
/fchollet/keras/issues/1868,9.429680828
/fchollet/keras/issues/4781,9.429680828
/fchollet/keras/issues/7379,9.429680828
/fchollet/keras/issues/7356,9.429680828
/fchollet/keras/issues/6334,9.429680828
/fchollet/keras/issues/2436,9.429680828
/fchollet/keras/issues/824,9.429680828
ml project,9.423992674
outperforms individual models,9.416338583
"org/simple/

download error",9.406923102
"1                         0    defaults

tensorflow-gpu-base       1",9.405152089
** intel i5-2500k,9.4
"tf-idf matrices

x_train =",9.397158402
up-to-date,9.396826244
stacked lstm regression model,9.391237497
multi-class classification,9.389936151
multi class classification,9.389936151
give big performance boost,9.389746777
keras training `sequential model,9.388858205
function expects complex input,9.382282542
"```python

import numpy",9.374499318
"```python



import numpy",9.374499318
"~~~python

import numpy",9.374499318
hadsell-et-al,9.371428571
accuracy started declines,9.366411641
fused batch norm happen,9.366290019
prefix/exec_prefix/home,9.363070539
facenet deep learning model,9.363005235
"2313        batch_normalization_35[0][0]     

__________________________________________________________________________________________________

reshape_5",9.361842105
"256         conv1d_26[0][0]                  

__________________________________________________________________________________________________

conv1d_27",9.361842105
"1052672     batch_normalization_42[0][0]     

__________________________________________________________________________________________________

reshape_6",9.361842105
"256         conv1d_31[0][0]                  

__________________________________________________________________________________________________

conv1d_32",9.361842105
"295936      dropout_7[0][0]                  

__________________________________________________________________________________________________

dropout_8",9.361842105
"```python

def preprocess_for_train",9.361268786
accelerometer x-axis,9.360599078
edge_2099_moments_75/sufficient_statistics/shape,9.358490566
recurrent ntm/dnc-,9.357894737
nvidia jetson tk1,9.34375
7/dist-packages,9.340142945
"return predicted

```

as-",9.339818512
/usr/local/cuda-8,9.337318032
pre-trained embeddings,9.334189837
i7-7700hq gtx1070,9.333333333
model_selection import train_test_split,9.33223409
fused_batch_norm` expects 1d tensors,9.328659612
"egg

processing dependencies",9.325674326
convolutional neural networks,9.324820574
save multi-gpu model,9.32447017
"return normalised_data





def build_model",9.323056399
"```python

import keras",9.318658484
"``` python

import keras",9.318658484
"0**



```python 

import keras",9.318658484
"```python

>>> import keras",9.318658484
simple recurrent submodel consisting,9.313617377
data-parallel sgd computation,9.313524003
repeatvector layer dynamically adjust,9.311246265
"learning rate

                old_lr = float",9.310727969
"utils import to_categorical

print",9.303837901
output shape         param #     connected,9.301706103
output shape         param      connected,9.301706103
output shape          param #     connected,9.301706103
"num_files_train_1]

list_validation_1 = list_files_1[num_files_train_1",9.3
python-dev,9.293999391
tensorflow/stream_executor/cuda/cuda_dnn,9.291976773
"placeholder

    return gen_array_ops",9.275344828
"placeholder

>     return gen_array_ops",9.275344828
"```python

import tensorflow",9.27301029
"```python



import tensorflow",9.27301029
sequential` class inherits `keras,9.267296471
"fit_generator



```python

class memorycallback",9.266281042
```imagedatagenerator``` randomly taking images,9.265195536
deeply nested error coming,9.263379558
pre-load data batches,9.263122366
y-hat,9.25
number marking time position,9.246803631
one-class classification,9.244295125
phoneme error rate decrease,9.230046225
"feedforward model

def get_combined_model",9.221916101
linear_model import logisticregression,9.213240955
neighbors import kneighborsclassifier,9.213240955
discriminant_analysis import lineardiscriminantanalysis,9.213240955
naive_bayes import gaussiannb,9.213240955
over_sampling import randomoversampler,9.213240955
phasedlstm import phasedlstm,9.213240955
signature_def_utils_impl import build_signature_def,9.213240955
session_bundle import exporter,9.213240955
cross_validation import train_test_split,9.203579119
learning rate multiplier applied,9.203174603
"# yields

            yields individual sequences",9.202380952
importing keras executes code,9.197641096
"optimizers import sgd

#model",9.196621352
"optimizers import sgd

model",9.196621352
"4160        batch_normalization_36[0][0]     

__________________________________________________________________________________________________

batch_normalization_37",9.195175439
"4160        batch_normalization_37[0][0]     

__________________________________________________________________________________________________

batch_normalization_38",9.195175439
faceswap/requirements,9.194444444
`make build gpu=1 python_version=2,9.194376831
million dollar questions,9.185393258
"x_arr_iobl[num_instances] = img_array_iobl



                    # prepare",9.181818182
dear keras team,9.178083723
dear keras-team,9.178083723
"### import

import keras",9.176675557
storage map footprint,9.165085389
topology import layer #,9.163249212
topology import layer,9.163249212
"return result



def mse_gmm",9.162718847
cifar10 keras examples,9.162504914
"```diff

diff --git",9.155226315
iso latin 1 character encoding,9.152761457
/tmp/saved_models/cifar10_resnet20v1_model,9.15
time series signal classifier,9.146373626
missing 1 required positional argument,9.143779993
io/callbacks/#progbarlogger,9.14147794
single data structure holds,9.138120956
**stateful** stacked rnn model,9.136776904
fully convolutional networks,9.133406433
[fully convolutional networks,9.133406433
recent semantic segmentation tasks,9.129980979
scalable image recognition],9.125280899
"/kadenze/siamese_net



papers",9.125
/~lsong/papers/liuwenyulirajson17,9.125
td_concat/concatenate_2/concat = concatv2[,9.121468927
post epoch tensorboard callback runs,9.118492493
keras blog][1] explains nicely,9.11830959
geforce gtx 1080 major,9.114718615
anaconda env,9.11380597
"counter = counter+1

    return counter*100/",9.110344828
write deep learning network,9.109930046
"return model



submodel = get_shared_model",9.109637077
single label classification fails,9.093367621
x_train[cmpt]= traces[cmpt],9.092699115
"image import imagedatagenerator

traceback",9.090439325
offending average pooling line,9.085476097
commit removes `func_reconstruct_closure,9.083333333
"]

        gradients=nb_data*numepoches*[",9.080392157
"top5 accuracies

def gettop1acc",9.072711572
ai/pythonwheel/cpu-,9.070329087
"return fc7



caffenet_inputs_1 = input",9.066388053
egg/keras/losses,9.057199143
"<module>
>     import h5py

originally",9.053779611
scikit-learn background,9.046568627
"install

        raise condasystemexit",9.046501088
layer gru_1 expects 1 inputs,9.04609475
_negative dimension size caused,9.044472698
models closer shows,9.041338583
feedforward neural doodle,9.038636364
"return resized





def load_train",9.037342114
multi gpu training,9.033043734
multi-gpu training,9.033043734
edge_8037_metrics/acc/mean_1,9.032934132
"optimizers import adam

model",9.032162642
keras models reproducible,9.029627469
sklearn import tranform,9.027673944
final average log files,9.02514881
"```

$ time python3 imdb_lstm",9.024559748
perform special image preprocessing,9.023831624
enhanced interactive python,9.021890547
nonlinear timeseries prediction similar,9.01955091
"ecah epoch

    datasize  = dataset",9.019286144
"cpickle

import numpy",9.019275437
"preamble

```
import numpy",9.019275437
"pywrap_tensorflow_internal import *

  file",9.019105869
cpu-based tensorflow backend,9.017774685
make multi gpu work,9.016077705
_conv import register_converters,9.013240955
conv2d_2/kernel_0_4 = imagesummary[,9.006896552
conda keras-gpu version,9.004929678
"0           dense_5[0][0]                    

__________________________________________________________________________________________________

time_distributed_1",9.004699248
org/get_started/os_setup,9.003861004
org/doxygen/classcaffe_1_1multinomiallogisticlosslayer,9.003861004
org/doxygen/classcaffe_1_1softmaxwithlosslayer,9.003861004
org/doxygen/classcaffe_1_1sigmoidcrossentropylosslayer,9.003861004
cam heatmaps,9
/p-baleine/e6f57dd6f89c932eccadec5d78fed0b5,9
1-cp36-cp36m-linux_x86_64,9
1-cp27-cp27m-win_amd64,9
deconv3d_1/deconv3d_1 = conv3dbackpropinputv2[,9
ning-ding,9
nisolatin1encoding 0 255 getinterval putinterval,9
ieee international conference,9
1-cp35-cp35m-linux_x86_64,9
"_v___v_             _v___v_ 

m_0 ->",9
fett ao   tatthet,9
"ant $

 ee tthrtit",9
"make_all

    impl=impl",9
"make_c_thunk

    output_storage=node_output_storage",9
"@fbranchaud-charron-miovision

>",9
/titu1994/snapshot-ensembles,9
3967s  21059291     921ns       0ns  4,9
16us       751     996ns     629ns  18,9
81672s  16619044     169ns     131ns  415,9
05ms   1995842     295ns     165ns  244,9
49ms   2492163     224ns     129ns  262,9
85us       830     275ns     189ns  3,9
02us       830     203ns     149ns  6,9
8410us        10     484ns     302ns  1,9
5860us         3     528ns     246ns  1,9
unnecessarily negatively impacted,9
/iamaaditya/vqa_demo,9
378] loaded runtime cudnn library,8.996256895
/dotdict 200 dict def,8.995840823
previous non-input layer,8.994396881
non-trivial generator based,8.991780341
"return train_function





def _swap_placeholder",8.989723066
site-packages,8.986531603
6/site-packages/,8.986531603
"site-

packages",8.986531603
"<module>
    import keras

  file",8.98646155
pretrained image net weights,8.98563008
"simple architecture





style   = input",8.976159312
"return data





def save_model",8.976148405
"/dist



    def get_config",8.975598275
"mse_nan

    y_true = y_true[index]

  file",8.971360036
"convolutional model

top_model = sequential",8.971150983
"gradientboostingclassifier

import keras",8.963434603
a-4,8.961538462
a-,8.961538462
one-hot encoding,8.961382386
3d cnn takes 40 frames,8.960939511
convert keras source codes,8.958625021
iostream/file/string-objects,8.954436343
"return list_of_all_indices





def main",8.952686029
utils import np_utils,8.948959724
"return tensor



def model_fn",8.948842563
geforce gtx 950m,8.948051948
faq section,8.947368421
#8253with pip installation,8.935483871
"image import imagedatagenerator



  file",8.928649254
3d weighted loss function,8.925389459
"dense layer

def get_feedforward_submodel",8.924664486
disable pytest-xdist,8.922222222
keras based inceptionv3 model,8.918033117
"plstm



import tensorflow",8.917786409
keras import applications,8.915815555
tensorflow_backend import set_session,8.915703335
16 tersor give memory error,8.90935657
recursive mutable structures,8.909090909
model end-to-end,8.907891298
"callbacks import modelcheckpoint

    parallel_model",8.907429214
"vgg16 network

model = applications",8.899852339
model_selection import stratifiedkfold,8.897451481
multi-gpu processing,8.89563383
give reproducible training model,8.891141229
pil import image,8.888521853
"read

        flush_decoder = true

      file",8.885054186
poly lr policy update,8.882539683
"]

        return proxy_of_class

    def compute_output_shape",8.878611955
"return ld





    def compute_output_shape",8.878611955
"convolutional base

model = model",8.877648825
diabetic retinopathy detection,8.875
"/diabetic-retinopathy-detection

  [3]",8.875
embedding layer non-trainable,8.870940122
neural network layer calculates,8.868239272
semi-supervised learning,8.866666667
compressed sparse row format>,8.863636364
/home/aditya/,8.863070539
deep face recognition,8.862060779
"768         lambda_1[0][0]                   

__________________________________________________________________________________________________

dense_5",8.861842105
"8320        batch_normalization_31[0][0]     

__________________________________________________________________________________________________

batch_normalization_32",8.861842105
"512         conv1d_24[0][0]                  

__________________________________________________________________________________________________

conv1d_25",8.861842105
"132096      batch_normalization_32[0][0]     

__________________________________________________________________________________________________

batch_normalization_33",8.861842105
"4096        conv1d_25[0][0]                  

__________________________________________________________________________________________________

max_pooling1d_7",8.861842105
"0           batch_normalization_33[0][0]     

__________________________________________________________________________________________________

dense_13",8.861842105
"524800      max_pooling1d_7[0][0]            

__________________________________________________________________________________________________

batch_normalization_34",8.861842105
"2048        dense_13[0][0]                   

__________________________________________________________________________________________________

dense_14",8.861842105
"131328      batch_normalization_34[0][0]     

__________________________________________________________________________________________________

batch_normalization_35",8.861842105
"1024        dense_14[0][0]                   

__________________________________________________________________________________________________

dense_15",8.861842105
"0           dense_15[0][0]                   

__________________________________________________________________________________________________

dot_5",8.861842105
"256         dot_5[0][0]                      

__________________________________________________________________________________________________

batch_normalization_36",8.861842105
"256         conv1d_27[0][0]                  

__________________________________________________________________________________________________

conv1d_28",8.861842105
"256         conv1d_28[0][0]                  

__________________________________________________________________________________________________

conv1d_29",8.861842105
"8320        batch_normalization_38[0][0]     

__________________________________________________________________________________________________

batch_normalization_39",8.861842105
"512         conv1d_29[0][0]                  

__________________________________________________________________________________________________

conv1d_30",8.861842105
"132096      batch_normalization_39[0][0]     

__________________________________________________________________________________________________

batch_normalization_40",8.861842105
"4096        conv1d_30[0][0]                  

__________________________________________________________________________________________________

max_pooling1d_8",8.861842105
"524800      max_pooling1d_8[0][0]            

__________________________________________________________________________________________________

batch_normalization_41",8.861842105
"131328      batch_normalization_41[0][0]     

__________________________________________________________________________________________________

batch_normalization_42",8.861842105
"0           dense_18[0][0]                   

__________________________________________________________________________________________________

dot_6",8.861842105
"4160        dot_6[0][0]                      

__________________________________________________________________________________________________

batch_normalization_43",8.861842105
"8320        batch_normalization_43[0][0]     

__________________________________________________________________________________________________

batch_normalization_44",8.861842105
"512         conv1d_32[0][0]                  

__________________________________________________________________________________________________

conv1d_33",8.861842105
"132096      batch_normalization_44[0][0]     

__________________________________________________________________________________________________

batch_normalization_45",8.861842105
"4096        conv1d_33[0][0]                  

__________________________________________________________________________________________________

max_pooling1d_9",8.861842105
"394240      dropout_8[0][0]                  

__________________________________________________________________________________________________

dropout_9",8.861842105
"98688       dropout_9[0][0]                  

__________________________________________________________________________________________________

dropout_10",8.861842105
"``` python

def get_vae",8.861268786
"```python

def get_model_simple",8.861268786
"```python

def loss_softmax_cross_entropy_with_logits",8.861268786
"```python

def test_normalize_training_input_has_channels_only",8.861268786
low-level tensorflow error,8.85757555
/pyannote/pyannote-audio,8.857142857
"sparse targets

                        acc_fn = metrics_module",8.850854701
"trainning methods

[useexperimenttrain",8.85
cudnn tests require gpu,8.845662879
nvidia-smi bounces,8.84375
library [extkeras],8.842592593
reading raw images straight,8.841256367
randomly occluding areas,8.840425532
"_check_p

ydot

    pydot",8.838709677
pandas import series,8.838240955
write keras custom metric,8.836859751
# store trainined weight,8.835461366
applications import xception,8.832288574
input_5 = placeholder[dtype=dt_float,8.831251621
"conversion

input_=converter_o_t # assign",8.830882353
model_selection import kfold,8.826022909
load traces data [training],8.82495507
one-hot encoded 1,8.820512821
"one-hot-encoded

#",8.820512821
one-hot encoded,8.820512821
"1

cuda compilation tools",8.818086081
export export keras_backend=theano,8.818057482
means cross validation technique,8.817226891
"get_index

    return ds[",8.817011494
conveniently switch format modes,8.816161616
multi-output models,8.814135108
code inside section #cleanup_code_construct,8.811482535
cross entropy functions,8.80990839
raw 1d signals,8.80952381
"return training_set

                                             



def test_generator",8.807904884
run 10-fold cross validation,8.800768124
separate function [`atrous_conv2d_transpose`],8.79957265
correct parallel sgd implementation,8.795787939
small dummy data set,8.795272872
binary cross entropy,8.793514947
well-defined initial state,8.793328456
model_selection import cross_val_score,8.792188323
/2017/04/03/pickling-keras-models,8.791532231
"del model
model = load_model",8.790833302
pick global average pooling,8.78989899
"/flyyufelix/65018873f8cb2bbe95f429c474aa1294

resnet-152",8.789634146
"# start fine-tuning

    model",8.788052641
[examples/variational_autoencoder_deconv,8.783739837
/weights/pretrain_weights-improvement-{epoch,8.781601415
"utf-8 -*-

import os

os",8.77932735
"models separately

>>> model_1",8.77851807
"shared library related

settings",8.77547713
attention based hidden states,8.769319319
utils import plot_model,8.767478243
dl models trained,8.765052229
prebuilt docker image,8.764169788
chris@skymind,8.761904762
"0           resnet_model[1][0]

                                                                     resnet_model[2][0]

    __________________________________________________________________________________________________

    neg_dist",8.761842105
multiple inbound nodes,8.760517799
in-,8.76
validation-based bottleneck features,8.758833509
subtensor{int64} [id bb],8.757033429
conv2d_2/kernel_0_4/tag,8.756896552
"return merge



def get_r",8.756716886
weight values setting constant initializer,8.755293888
seq2seq lstm autoencoder based,8.750342
"return model



def keras_weird_beh",8.747260929
"return model



def get_conv_pool",8.747260929
"return model





def read_data_file",8.747260929
"return model





def predict_point_by_point",8.747260929
models import model_from_json,8.74295163
randomly stretched horizontally,8.740425532
"tensorflow_backend import *

  file",8.738374972
categorical data classification task,8.736890784
keras handles **loss functions**,8.736182799
/keras/examples/vgg16_weights,8.733933486
recurrent import rnn,8.732426014
transferring weight values back,8.730631809
//keras-slack-autojoin,8.730430802
>xeon e5-1680 v3 @ 4,8.729166667
model expects 0 input arrays,8.727204277
"training import model

  file",8.721412944
dense prediction weight transfer,8.718746992
`embedding` layer calls `backend,8.718102829
"return input_shape



def build_generator",8.717314102
comprehensive state save-load,8.716753022
element-by-element function,8.716239316
"```

import keras

keras",8.713628251
single class label support,8.71143237
model_1/conv2d_2/convolution,8.707409372
stacked denoising autoencoder,8.702797203
add somes batchnormalization layers,8.702594016
1/keras/applications/imagenet_utils,8.702574601
implementing [re3 tracker],8.7
recurrent dropout versions compared,8.695251059
pixel-wise class labels,8.694105551
/p7w3m0d5be/*/face-swap,8.692307692
"make_node

    return gof",8.690885368
"attached zip file



[noreproducible_results_tensorflow_backend",8.688981798
good stable code merged,8.688405612
/warmspringwinds/tf-image-segmentation,8.685191313
tesla k80 gpu,8.674538259
"0           time_distributed_1[0][0]         

__________________________________________________________________________________________________

dropout_4",8.671365915
"squared error

trainscore = math",8.671071866
org/anthology/n16-1170,8.670527671
org/anthology/c16-1139,8.670527671
validation image folder separate,8.670518994
original attention api suggestion,8.66965812
tensorflow import keras,8.667980057
press/v28/goodfellow13,8.666666667
"808         timedistributed_31[0][0]         

____________________________________________________________________________________________________

timedistributed_33",8.666666667
"0           timedistributed_32[0][0]         

____________________________________________________________________________________________________

timedistributed_34",8.666666667
"1168        timedistributed_33[0][0]         

____________________________________________________________________________________________________

timedistributed_35",8.666666667
"0           timedistributed_34[0][0]         

____________________________________________________________________________________________________

timedistributed_36",8.666666667
"0           timedistributed_35[0][0]         

____________________________________________________________________________________________________

bidirectional_5",8.666666667
kernel reported driver version,8.662273566
image data augmentation module,8.65798915
/projects/glove/read,8.656541269
"train

    validation_steps=samples_per_validation/batch_size+1",8.654745708
pre-trained inceptionv3,8.653320272
real-time data augmentation,8.652212885
read numerous examples,8.647973414
10 runs handle identical mses,8.647058824
named entity recognition,8.645833333
/users/rajaramans2/codes,8.643956044
single callback works perfectly,8.643563748
"/titu1994/densenet  

facenet",8.642857143
multiple nonlinear regression,8.64147018
366s 2ms/step,8.639506173
363s 2ms/step,8.639506173
364s 2ms/step,8.639506173
27s 21ms/step,8.639506173
1254s 17s/step,8.639506173
71s 3ms/step,8.639506173
70s 3ms/step,8.639506173
69s 3ms/step,8.639506173
72s 3ms/step,8.639506173
68s 3ms/step,8.639506173
76s 304ms/step,8.639506173
72s 291ms/step,8.639506173
36s 6ms/step,8.639506173
16s 3ms/step,8.639506173
17s 3ms/step,8.639506173
15s 3ms/step,8.639506173
15s 2ms/step,8.639506173
functional api version doesn,8.634385199
"binary_crossentropy api

    test_loss2 = keras",8.633215131
"training labels



    text_steering = open",8.630102993
nasnet import nasnetlarge,8.629907621
recently rnn `cell` -> `rnn`,8.629723502
"#~ dummy generator

def train_generator",8.628648415
sgd scheduler callback function,8.625107964
model expects 3 target arrays,8.622636461
batch-wise confusion matrix,8.621365222
input_1 = placeholder[dtype=dt_float,8.620467308
applications import inception_v3,8.620167362
"binary accuracy

                        acc_fn = metrics_module",8.6198642
models import sequential,8.619508447
"models import sequential

      4",8.619508447
"models import sequential`



```",8.619508447
"convolutional import *



importerror",8.617959648
applications import resnet50,8.61723481
machine works perfectly fine,8.617109888
tf accepts sparse matrix,8.616980801
geforce gtx 1080 ti,8.614718615
geforce gtx 960m,8.614718615
geforce gtx 1060 3gb,8.614718615
/numpy/numpy/issues/6464,8.612068966
"0

nvidia cuda toolkit 9",8.605288462
"```console

$ python 3_wine_net_fit_generator_hdf",8.605223881
"bottom networks

    inp_top = input",8.603543225
"keras

center loss based",8.603164535
ml problems,8.602564103
named `conv_seq` sequential layer,8.602311539
convolutional neural network,8.598859036
data preprocessing steps required,8.597686293
sklearn import preprocessing,8.592891336
1435] adding visible gpu devices,8.588427147
1423] adding visible gpu devices,8.588427147
press many-time,8.586666667
fully-convolutional net,8.584795322
"vocab=vocab

        def fit",8.584019035
cnn_input = placeholder[dtype=dt_float,8.581251621
nvidia driver version,8.572078612
generated text flip,8.570677362
multiple custom loss functions,8.56571599
`logging` python interface,8.565307914
applications import vgg16,8.560683635
class labels mobilenet ssd,8.560282021
current custom layer doesn,8.559729902
"=32

nb_channel=3

nb_data=2

x_train=np",8.558675629
high spectral resolution,8.557692308
"import engine
>   file",8.553850137
"__init__

    fid = make_fid",8.553763441
scikit_learn import kerasclassifier,8.549273343
two-output lambda layer,8.547506293
xception import xception,8.546574288
multi-channel tensor,8.545366583
validation loss started,8.544714579
user global session,8.544034883
"return model



def main",8.543557225
research fields,8.538461538
conda install keras,8.537849609
training neural networks,8.534000814
keras examples folder,8.533933486
"image import load_img`



`load_img",8.529698324
"multiple gpu model



    # define",8.528640433
"201488      dense_4[0][0]                    

__________________________________________________________________________________________________

repeat_vector_1",8.528508772
"256         input_9[0][0]                    

__________________________________________________________________________________________________

batch_normalization_31",8.528508772
"1024        dense_17[0][0]                   

__________________________________________________________________________________________________

dense_18",8.528508772
"0           batch_normalization_40[0][0]     

__________________________________________________________________________________________________

dense_16",8.528508772
"0           bidirectional_4[0][0]            

__________________________________________________________________________________________________

time_distributed_5",8.528508772
"``` python



def generate_batches_from_train_folder",8.527935452
deep learning models,8.527758336
original implementation requires `decay`,8.52041301
handle large datasets quickly,8.514830932
"do_execute

>     res = shell",8.512820513
"do_execute

    res = shell",8.512820513
custom densenet-bc,8.50968523
"/program files/hdf5



compiling options",8.508928571
train entire deep network,8.508090665
"model_from_json

import numpy",8.50764753
"```python

class reduceonnan",8.507397794
"```python

class map_eval",8.507397794
pre-trained cnn,8.506081729
/nodecolor {nopcolor} def,8.506044905
/edgecolor {nopcolor} def,8.506044905
/graphcolor {nopcolor} def,8.506044905
"``` python
def step",8.500774958
cross entropy metric,8.500093075
"0   concatenate_921[0][0]   conv2d_1990[0][0]                

batch_normalization_1984",8.5
95857s   3050114     969ns     558ns  518,8.5
zoomed & translated equally,8.5
/azavea/raster-vision/,8.5
training progress bar,8.49536445
feed forward neural network,8.494405594
keras/layers/convolutional,8.494271993
"2 avx avx2 fma

traceback",8.49146451
"4



**deep learning ami",8.486419753
deep learning textbook,8.486419753
multi task learning,8.485750315
recurrent neural network,8.483069562
sub-batch inputs separately,8.481946584
memory allocation error occurs,8.481737046
re-installing tensor flow,8.481141519
_no additional parameters_,8.47826087
tower sub-batch slices,8.47740113
neural networks architectures,8.476136364
"0           resnet_model[1][0]

                                                                     resnet_model[3][0]

    __________________________________________________________________________________________________

    stacked_dists",8.47612782
"html#envvar-pythonhashseed

# https",8.47346452
io/losses/#categorical_crossentropy,8.473381935
#one-hot vector,8.473240093
standard python convention,8.472870939
support varying size inputs,8.471743679
io/applications/,8.465894466
keras slack channel],8.45770353
"ndgriddata import *

>   file",8.447677298
"enable=protected-access

    352",8.44724026
tensor conversion requested dtype %,8.445371118
scikit_learn import kerasregressor,8.444010185
"channel axis

        output = keras",8.44236381
including setting `allow_soft_placement=true`,8.44023042
tmp$ python lambdabug,8.438557214
"update training data

    encoder_func =",8.437299558
variable training data size,8.435692083
0s 4ms/step,8.434377968
collect intermediate layer output,8.43394289
"len = numpartitions

    

    def __len__",8.432224509
repository `fchollet/keras`,8.429680828
medium sized data,8.42745098
"514         dense_1[0][0]                    

__________________________________________________________________________________________________

lambda_1",8.426358234
dense cnn encoder depicted,8.423466682
keras block output_shape interface,8.422537971
`__init__` method takes 12 parameters,8.420588838
/dobiasd/frugally-deep,8.419753086
custom loss layer runs,8.41894694
simple rnn-wrapper layer,8.416582308
core import permute,8.413533352
user-defined rate argument,8.41247463
"test_model = model_1

test_model",8.41025641
keras import backend,8.410163575
line throwing error `pydot,8.409787555
/tensorflow/tensorflow/issues/4455,8.409090909
/tensorflow/tensorflow/issues/8604,8.409090909
/tensorflow/tensorflow/issues/15722,8.409090909
/tensorflow/tensorflow/issues/10642,8.409090909
/tensorflow/tensorflow/issues/3420,8.409090909
/tensorflow/tensorflow/issues/1122,8.409090909
fully convolutional network,8.407444894
63 character long decoder sequence,8.404760551
applications import inceptionv3,8.404752342
output 3d embedded sequences,8.404664657
proxy/strided_slice_1/stack_1,8.4
keras/engine/**init**,8.389699821
"return activations

 

    model = sequential",8.387394934
keras import optimizers,8.382789442
/keras/layers/recurrent,8.378482519
keras/layers/recurrent,8.378482519
src->ptr + srcoff,8.378378378
"np



import requests",8.377901679
weight saving fails silently,8.377284528
# original paper suggests performance,8.377033779
pre-trained network,8.375728299
image _per channel_,8.375280899
sklearn import datasets,8.37461272
on-line,8.374364986
module named tensorflow`_,8.372709229
variable length audio sequences,8.367802639
/home/david/,8.363070539
"256         conv1d_23[0][0]                  

__________________________________________________________________________________________________

conv1d_24",8.361842105
"0           batch_normalization_45[0][0]     

__________________________________________________________________________________________________

flatten_3",8.361842105
"288         masking_1[0][0]                  

__________________________________________________________________________________________________

time_distributed_3",8.361842105
"```python

def make_input_shape",8.361268786
overperform existing resnet50,8.360703812
hidden layers inputs activations,8.356189588
python program collapsed,8.355223881
normal python number arrays,8.35499802
makes models train faster,8.354804366
update `backend/theano_backend,8.351490877
"pretrained weights

_________________________________________________________________

layer",8.348723874
trained model form keras,8.342556269
3rd party implementation],8.338695839
sequence tag classification,8.33781182
"760s

user    25m50",8.337423313
# one-hot encode,8.336876457
minute,8.333333333
"dlimport

    rval = __import__",8.333333333
mac book pro,8.333333333
1 minute,8.333333333
"/mlakhal/deepface  

deepface",8.333333333
"__compile__

    keep_lock=keep_lock",8.333333333
pass attention vector back,8.325481842
define custom loss functions,8.324578035
hot encoded 2d array,8.323617321
calling keras layer module,8.320809739
/outputs/steering_model/steering_angle,8.320512821
"installed cudnn v4
3",8.320330969
"/emirceyani/2fdb11041760716cbb6dd86fc57b7c60

preprocessing",8.315217391
fashion-mnist dataset,8.313690476
2s 801ms/step,8.30617284
2s 812ms/step,8.30617284
2s 800ms/step,8.30617284
2s 836ms/step,8.30617284
2s 807ms/step,8.30617284
2s 591ms/step,8.30617284
2s 2ms/step,8.30617284
2s 884us/step,8.30617284
"__init__

    forward_model = keras",8.303957089
# additional sentence-level information,8.303465788
multi-label classifier,8.303268741
"make_fid

    fid = h5f",8.3
prohibiting simultaneous setting,8.3
vanilla logistic regression,8.297619048
return full output sequences,8.294325724
parametric rectifiers / optimization,8.294117647
/myupper exch def,8.291759191
/mylower exch def,8.291759191
"# create model

def baseline_model",8.290249435
happy long-time user,8.289338207
core import input_data,8.286549225
"audio track



model_arousal = sequential",8.286174331
automatically restore correct state,8.281671836
pre-trained architecture,8.279861479
multiple processes simultaneously,8.277184466
datasets import imdb,8.274465444
"samples/sec

keras-theano",8.272972614
recurrent import lstm,8.272600893
"decode_predictions

>     import numpy",8.269275437
"decode_predictions

import numpy",8.269275437
"apply_op

    op_def=op_def",8.266666667
models import load_model,8.263670446
"models import load_model

#",8.263670446
#NAME?,8.261971831
**cuda unknown_error** rises,8.261538462
pre-trained embedding,8.260681065
"linux-64

          conda version",8.256284727
same-size,8.255852843
/pavlosmelissinos/enet-keras,8.250193648
accumulates gradient calcs,8.25
bottleneck-features model ended,8.249962105
missing documentation makes learning,8.248888889
lazily created functions `model,8.248180875
input_dim=char_embedding_size*word�max_length,8.248168498
"73s 367us/step

```",8.239506173
73s 291ms/step,8.239506173
73s 293ms/step,8.239506173
73s 295ms/step,8.239506173
installing anaconda,8.23880597
3d cnn input shape,8.238220555
mnist data tensors built-,8.237062973
single unit output layer,8.236554258
gpu       pid   type   process,8.234628169
keras import layers,8.233828737
"66048       timedistributed_36[0][0]         

____________________________________________________________________________________________________

dense_1",8.231182796
numerically stable compare,8.228571429
multi label data,8.228155619
multi-label data,8.228155619
"0           input_2[0][0]                    

__________________________________________________________________________________________________

time_distributed_1",8.22692147
latest keras master,8.224019475
load nasnet weightsfixes #10091,8.222972973
preprocessing import labelencoder,8.22290279
model_1/conv_10/kernel,8.221124441
model_1/conv_13/kernel,8.221124441
"44400       embedding_2[0][0]

__________________________________________________________________________________________________

concatenate_1",8.218984962
keras import callbacks,8.21639903
non-slot variables,8.215095677
reduce training data set,8.214879746
sequential_1/dense_1/biasadd,8.214516129
interpnd import linearndinterpolator,8.213240955
imagenet_utils import preprocess_input,8.213240955
wide_resnet import wideresnet,8.213240955
multi-class version,8.206143551
centos linux release 7,8.204874835
install theano backend,8.204144684
"py



    imagenet pretrained weights 

    https",8.200670372
"return model





def gen",8.199641881
back prop algorithm,8.196125908
"original image

    result = cv2",8.195617434
"2048        dense_16[0][0]                   

__________________________________________________________________________________________________

dense_17",8.195175439
"0           bidirectional_3[0][0]            

__________________________________________________________________________________________________

bidirectional_4",8.195175439
"0           time_distributed_5[0][0]         

__________________________________________________________________________________________________

time_distributed_6",8.195175439
saved_model import utils,8.19475097
"```python

def custom_objective",8.194602119
neural network [learning,8.191841492
returns element-wise `max,8.191376223
put custom losses back,8.188640808
simple convolutional layers,8.188522789
access _beta[12]_power,8.1875
kim-2014 research paper,8.186609687
#define within_kernel extern,8.186046512
#define ga_warp_size warpsize,8.186046512
flow_from_directory & segmentation data generator,8.183788866
project [pyannote-audio],8.178571429
combine cross-entropy,8.177941176
keras master branch,8.177071119
tensor2tensor library [tensor2tensor],8.175925926
multi gpu node,8.17557611
"np

import glob



#functions",8.175373871
non-recurrent layer,8.174343631
generating train data generator,8.173881237
models import input,8.170622763
feed tensorflow data tensors,8.170363007
current reproduction steps don,8.170161501
convolutional import conv2dtranspose,8.169683786
fully connected layers,8.169445624
"0           timedistributed_30[0][0]         

____________________________________________________________________________________________________

timedistributed_32",8.166666667
progress bar logging,8.165441176
separate character based lstm,8.164528265
objective function / loss function,8.16150057
"master

tensorflow version",8.159751537
sequential keras models,8.156461141
io/search,8.156370656
"avg_sum=img

            number_of_record+=1

            #print",8.156332361
preprocessing import sequence,8.154148954
"preprocessing import image

>",8.153739245
preprocessing import image,8.153739245
preprocessing import image```,8.153739245
python import debug,8.151798169
"undefined_grad

    return undefined_grad_",8.150344828
"__contains__

      return wr",8.150344828
"compile_str

    return dlimport",8.150344828
"_prod

    return umr_prod",8.150344828
core import lambda,8.150112628
simply training theano longer,8.14919033
"training import moving_averages

      7",8.146105405
"training import moving_averages

      3",8.146105405
supports fixed length sequences,8.14596689
"output = new_state

            return output",8.144655826
"_ufuncs import *



importerror",8.144275437
fused batch norm,8.144067797
manually save-load-adjust,8.142106948
3d image segmentation,8.141812613
net&utm_source=pourover,8.138888889
implementing seq2seq models,8.134195726
"model=save_weights

del model",8.133093744
find nested embedding layers,8.132911003
loss = cross-entropy +,8.131963114
engine/topology,8.131298468
"win10 x64

pandas",8.125
learning rate scheduler,8.122222222
"custom number

char_embedding_size=len",8.121337574
"get_activations_and_weights

    layer_outputs = [func",8.120879121
custom lstm layer similar,8.120160045
dense_1/matmul = matmul[,8.120071685
"models

>>> model_1 = model",8.119389266
"resnet50 import resnet50

>",8.116466761
resnet50 import resnet50,8.116466761
general-purpose jpg evaluator,8.114809082
"33024       dropout_5[0][0]                  

__________________________________________________________________________________________________

dropout_3",8.111842105
"4224        dropout_3[0][0]                  

__________________________________________________________________________________________________

bidirectional_2",8.111842105
write batch-level performance,8.111819197
"utf-8 -*-

import numpy",8.110184528
"utf-8 -*-



import numpy",8.110184528
multi-gpu call,8.110004612
"built = true



    def call",8.109397356
"built = true

        

    def call",8.109397356
1s 746ms/step,8.108256173
1s 51ms/step,8.108256173
1s 39us/step,8.108256173
1s 55us/step,8.108256173
1s 40us/step,8.108256173
1s 553us/step,8.108256173
1s 77ms/step,8.108256173
14s 2ms/step,8.10617284
redirect keras logging,8.103134825
fully-defined `input_shape` argument,8.102642354
support multiple dimensions input,8.102263836
"validation sets

train_generator = datagen",8.101677489
"0           input_1[0][0]                    

__________________________________________________________________________________________________

lambda_2",8.101057792
0s 200ms/step,8.101044634
0s 2ms/step,8.101044634
0s 771us/step,8.101044634
0s 719us/step,8.101044634
0s 694us/step,8.101044634
0s 733us/step,8.101044634
0s 761us/step,8.101044634
0s 810us/step,8.101044634
0s 1ms/step,8.101044634
0s 887us/step,8.101044634
0s 926us/step,8.101044634
0s 983us/step,8.101044634
0s 868us/step,8.101044634
0s 791us/step,8.101044634
0s 829us/step,8.101044634
0s 964us/step,8.101044634
0s 965us/step,8.101044634
0s 906us/step,8.101044634
0s 907us/step,8.101044634
0s 996us/step,8.101044634
0s 848us/step,8.101044634
0s 713us/step,8.101044634
0s 3ms/step,8.101044634
0s 26us/step,8.101044634
0s 471us/step,8.101044634
0s 438us/step,8.101044634
0s 462us/step,8.101044634
0s 457us/step,8.101044634
0s 430us/step,8.101044634
0s 445us/step,8.101044634
0s 454us/step,8.101044634
0s 431us/step,8.101044634
0s 49ms/step,8.101044634
"0s 28ms/step

0",8.101044634
0s 14ms/step,8.101044634
0s 11ms/step,8.101044634
0s 10ms/step,8.101044634
"0s 5us/step

[2",8.101044634
"0s 3us/step

[2",8.101044634
functional programming api,8.097435897
"np array

    

    #valid_datagen = imagedatagenerator",8.096438738
"return lines



def animate",8.095414123
model runs significantly faster,8.095037863
self-supervised network,8.094871795
dataset classifying text document,8.091943596
nkeras cnn #1c,8.091891892
"generating layer names

        block",8.091624711
cnn mnist model proposed,8.091096422
ptb language model,8.090871196
time-series prediction problem,8.089841381
"0           input_2[0][0]

__________________________________________________________________________________________________

masking_1",8.084064327
"0           conv_23[0][0]

__________________________________________________________________________________________________

input_2",8.084064327
4s 68us/step,8.083950617
"4s 368us/step

```",8.083950617
"```python

def compute_output_shape",8.083491008
"variable `model`

```

__________________________________________________________________________________________________

layer",8.080453074
image data generator handle,8.078833607
"** amazon linux



**modifications",8.076086957
org/project/keras/,8.075483224
create multiple single outputs,8.072213416
"class index

    output = proxy",8.07160664
"function

    output_keys=output_keys",8.066239316
"dataset matrix



def create_dataset",8.065987055
#define ga_ssize ptrdiff_t,8.061046512
**cnn-rnn-ctc** network,8.060874522
datasets import make_blobs,8.06017973
random seeds,8.059360731
passing validation data parameter,8.058657951
org/versions/r1,8.053861004
keras import initializers,8.052323492
keras import regularizers,8.052323492
"0           input_1[0][0]                    

__________________________________________________________________________________________________

sequential_1",8.051057792
utils import multi_gpu_model,8.050811576
cifar10 small images dataset,8.049598428
resnet50 fine-tuning,8.048794348
dense_1_input = placeholder[dtype=dt_float,8.047918288
pci bus id,8.047619048
bus-id        disp,8.047619048
"2} [id bu]



 

backtrace",8.047619048
latest versiothe findings,8.046948357
"install

        raise condaruntimeerror",8.046501088
handle large data input,8.044719696
"autoencoder layers

model = sequential",8.044376058
excuting opt = optimizers,8.042161856
pre-trained model1,8.042096814
convolutional import conv2d,8.040116654
utils import to_categorical,8.038906814
"generating layer names

    note",8.038328007
wrong image dimension ordering,8.038116781
advanced_activations import leakyrelu,8.033753775
unsatisfied allocation rate=0,8.033333333
fundus photographs provided,8.032258065
"0           time_distributed_3[0][0]         

__________________________________________________________________________________________________

time_distributed_2",8.028508772
"0           lstm_3[0][0]                     

__________________________________________________________________________________________________

bidirectional_1",8.028508772
"``` python
def standardize",8.027935452
model_1/dense_2/biasadd,8.021662246
/keras/layers/convolutional_recurrent,8.020587782
convolutional import convolution3d,8.020258498
"considered



```

import numpy",8.019275437
core import dense,8.018381415
"ratio = ratio



    def call",8.015870233
medium sized images,8.014912281
overparameterized separable convolution,8.013333333
resnet fine-tuning,8.011815591
"prints

#40 suggests padding sequences",8.010790738
multi gpu device,8.010556643
gpu training bottlenecks,8.007402709
randomly accessed eliminating,8.007092199
pre-trained weights,8.006862251
pre-trained model,8.005061033
pytest-xdist supports,8.004830918
hash-based operations,8.004504505
validation loss stays constant,8.004161994
org/contents/convnets,8.003861004
vgg16 import vgg16,8.003364411
tensorflow fused_batchnorm api,8.001981352
"callbacks_list = [earlystop]



history=model",8.001585482
one-hot array,8.000283988
utility [keras-fcn],8.000193648
ca/misc_stuff/attnrnn,8
"120s

sys     1m18",8
"conv2d_backprop_input

    dilations=dilations",8
"separable_conv2d

    channel_multiplier * in_channels",8
tcurlayer mylower lt,8
"run_cell

>     interactivity=interactivity",8
te tie atn,8
te tent  ue,8
captura de pantalla 2017-12-09,8
"compile_cmodule

    preargs=preargs",8
simulated robotic gripper,8
"#plstm

reduce_lr_ema = reducelronplateau",8
cz/~imikolov/rnnlm/,8
unnecessarily consumes memory,8
"run_cell

    interactivity=interactivity",8
shape`  returning dynamic shape,7.993171608
fine tuning vgg16,7.992243173
datasets import cifar10,7.988751159
datasets import  cifar10,7.988751159
"```python

model = models",7.98743366
tf backend makes sense,7.986902544
deep reinforcement learning,7.986419753
examples/mnist_acgan,7.983739837
"layer_from_config

    return layer_class",7.983678161
convolutional inceptionv3 layers,7.983208779
embeddings import embedding,7.979732183
back-prop step,7.978489224
"bidirectional grus

gru_1 = gru",7.976861167
"shared

    allow_downcast=allow_downcast",7.976744186
core tf primitives,7.976577081
"258         dropout_10[0][0]                 

__________________________________________________________________________________________________

activation_1",7.972953216
2s 2s/step,7.972839506
"action placeholder

                called `action_one_hot`",7.970528455
"customized softmax

    model = model",7.969815787
vocab sizes ranging,7.969191919
rotation/flip/scale/,7.968181818
"one-hot

print",7.965443908
"seed = seed



    def __create_model",7.96099986
data batching parallelism,7.960784314
/unfilled { } bind def,7.96059036
/diagonals { } bind def,7.96059036
/tapered { } bind def,7.96059036
io/backend/,7.960242485
/ry exch def,7.958425857
"make_thunk

    keep_lock=keep_lock",7.958333333
org/performance/quantization,7.955473907
limited python skills,7.955223881
neural turing machine,7.954334038
currentdict end definefont,7.952830189
foggy river end,7.952830189
"classification

    pretrained_model = inceptionv3",7.951251647
convolutional import convolution1d,7.95008306
unnormalized probabilties/ logits,7.947368421
earth mover distance,7.947368421
linear chain crf layer,7.945715962
takes trainable weighted sum,7.942837093
multi-gpu model,7.941050481
"```

input shape



3d tensor",7.938781493
dev-ad1310c88830ed96119194c4f2da22b9b37c7622,7.93877551
randomly generated data,7.937573482
# randomly rotate images,7.936290194
accepts variable-size inputs,7.935477662
custom recurrent layer,7.935319739
"image type

    img = image",7.929325709
32bit floating point weights,7.928981938
convolutional import maxpooling2d,7.927148629
reuse stateful lstm layers,7.92640479
memory usage/allocation,7.925925926
layer naming conflicts,7.924882629
extract higher level features,7.923971861
apply supervised-learning,7.92327044
networks stop working correctly,7.922979798
"pd

import numpy",7.922501244
high spatial resolution,7.921328671
multivariate time series,7.92
"200         input_5[0][0]                    

____________________________________________________________________________________________________

timedistributed_31",7.916666667
imdb_fasttext implementation appears,7.916473616
conda github issue tracker,7.91451051
const ga_ssize stridesx0,7.914215686
const ga_ssize stridesy0,7.914215686
search layers recursively,7.913251277
fit finally invokes np,7.91009897
"return score



    def on_epoch_end",7.909383328
inception_v3 import inceptionv3,7.906916844
"learn import *

  file",7.906010631
native tensorflow runtime,7.905400155
"np

import matplotlib",7.904217469
generalised dice loss,7.904021938
preprocessing import minmaxscaler,7.903458346
keras + tensorflow backend,7.901468075
"0           input_1[0][0]                    

__________________________________________________________________________________________________

masking_2",7.901057792
3 864         input_1[0][0]                     __________________________________________________________________________________________________ block1_conv1_bn,7.901057792
"50547936    input_1[0][0]

__________________________________________________________________________________________________

conv_23",7.901057792
"1000        input_1[0][0]

__________________________________________________________________________________________________

embedding_2",7.901057792
pretrain pascal voc,7.9
python packages,7.899726498
"fully-trained

# classifier",7.898499971
un-intuitive behaviour,7.896551724
anaconda custom,7.891348343
training stacked autoencoder,7.885661653
core import flatten,7.884293586
xception import preprocess_input,7.879907621
keras import input,7.879477828
244     elif type_ == pkg_directory,7.878787879
* register sub-models,7.874671916
abstract base class,7.874396135
tensorboard start plotting values,7.873491215
"pickle

import numpy",7.872216614
"/aminought/9a78cf0573cd14ed43f97946753f1555

theano",7.87162891
simple 1-dim numpy array,7.86939903
"xx += grad

    return xx",7.868293546
"embedding



import numpy",7.865766665
convolution neural networks,7.864469697
current scope device placement,7.861334296
"```



```python

def savekerasmodelasprotobuf",7.861268786
"```python



def preprocess_input",7.861268786
"```python

def triplet_loss",7.861268786
"```python

def multi_gpu_test_simple_model",7.861268786
"```python

def _masked_objective",7.861268786
"```python

    def get_input_mask",7.861268786
# non-reproducible results,7.860695986
fully connected network,7.860589952
"+ 0x5e

[0x7f9764cd8441]    cntk",7.85915493
"+ 0x5e

[0x7f9764c6b7c8]    cntk",7.85915493
"+ 0x2a8

[0x7f9764c6eeea]    cntk",7.85915493
"+ 0x12a

[0x7f9764c71953]    cntk",7.85915493
"+ 0x243

[0x7f9764c71ee9]    cntk",7.85915493
training/adam/variable/read,7.858650822
vgg16 import decode_predictions,7.858302683
tcurlayer myupper gt,7.857142857
"predictions

import numpy",7.857113275
"assign

    return state_ops",7.856227181
gpu-util  compute,7.855788259
entire decoding sequence,7.855690608
`python deep_dream,7.855223881
python-novice conversion,7.855223881
"reproducibility

seed = 7

numpy",7.854940532
offset subsequent indexes passed,7.85
theano flag warn_float64={ignore,7.847819387
models import model,7.845450734
"models import model



#",7.845450734
"models import model

    

    #",7.845450734
<bound method _callable,7.844444444
datasets import mnist,7.843513063
dev set,7.843339826
"7539



keras cnn #1c",7.84208554
"total_words += sent_len
    return np",7.841321342
inception v3 net,7.839319923
_not reasonable_ predictions,7.837837838
high level library,7.8377849
"embedding_dim=64

lstm_dim=64



word = sequential",7.834111901
"input

import tensorflow",7.833829634
"truncated_normal

    normal_tensor = rng",7.833333333
"runsingleagentexperiment

    tmp_entity = entity",7.833333333
noise contrastive estimation,7.833333333
execute subgraphs conditioned,7.833333333
/raghakot/keras-resnet,7.831494461
const ga_size numrowsy,7.830882353
const ga_size numcolsy,7.830882353
process wide default device,7.827841473
convolutional import convolution2d,7.827770236
fully connected layer,7.82393412
fully-connected layer,7.82393412
attempting transfer learning,7.823809524
batch norm layers removed,7.822507907
resnet feature map model,7.821678564
final thesis,7.821428571
`pip install -,7.821270673
"last_index]

      return [batch_x[categorical]",7.820887463
varying length predict generator,7.818884881
"theano backend 





[lstm_synthetic",7.818357882
6/lib/python3,7.818234962
4/lib/python3,7.818234962
5/lib/python3,7.818234962
3/lib/python3,7.818234962
2/lib/python3,7.818234962
batch norm epsilon values,7.818154249
convolutional import conv3d,7.817359948
keras inbuilt function,7.816432965
ensemble import randomforestclassifier,7.813240955
"``` python



def get_model",7.808637207
"#shuffle=true

        train_scores = model",7.808024693
"batch_list_x=[]

                batch_list_y=[]







model = resnet",7.805505343
pre-train mobilenet,7.803941974
"csv files

    training_data = pd",7.803658707
"from_logits=false

`

   def binary_crossentropy",7.802847135
threaded video stream,7.802197802
stacked lstm cells,7.8003663
varying filter sizes,7.8
scalarfromtensor [id bj],7.797619048
scalarfromtensor [id bo],7.797619048
upsampling operation learnable,7.796666667
current learning rate,7.795906433
"/neil-119/0493832eb5ecb0387943d69e4691b859



works",7.793333333
/rx exch def,7.791759191
core import reshape,7.791576734
keras application models,7.791532231
explicitly _before_ shuffling,7.785714286
wrappers import bidirectional,7.785198627
write custom loss function,7.784775458
"pywrap_tensorflow_internal import *

     59",7.784669526
<ipython-input-237-a795cc722d43>,7.781896884
<ipython-input-1-d7f9f59b50e7>,7.781896884
<ipython-input-14-6e8f5dd35a11>,7.781896884
<ipython-input-374-85e2316f74b0>,7.781896884
<ipython-input-3-611aef6e5d2e>,7.781896884
<ipython-input-4-dd8f18b28a08>,7.781896884
<ipython-input-25-f29037b9f7ab>,7.781896884
<ipython-input-11-97045a1832d9>,7.781896884
<ipython-input-32-be01c033aa94>,7.781896884
<ipython-input-18-a1077a5b59f8>,7.781896884
<ipython-input-117-367a7aa16409>,7.781896884
<ipython-input-116-831b6ebc5733>,7.781896884
<ipython-input-45-ea9b2b461133>,7.781896884
<ipython-input-41-dda9b5eabd2f>,7.781896884
<ipython-input-40-6628e54f8c12>,7.781896884
<ipython-input-26-fe6240451925>,7.781896884
<ipython-input-39-f2f017d18837>,7.781896884
> <ipython-input-13-ff36de016442>,7.781896884
<ipython-input-3-cc3e34fe5d20>,7.781896884
<ipython-input-24-22d018627654>,7.781896884
<ipython-input-40-2755df92388f>,7.781896884
<ipython-input-13-94a747042e68>,7.781896884
<ipython-input-6-a81b83ffb149>,7.781896884
<ipython-input-1-a4f659c6409f>,7.781896884
<ipython-input-5-37356b91a563>,7.781896884
<ipython-input-2-c53988bad9f7>,7.781896884
<ipython-input-22-6a252d3d7102>,7.781896884
<ipython-input-62-33f9d3b67676>,7.781896884
<ipython-input-24-6d5b2f1a499c>,7.781896884
<ipython-input-23-a32d04236c16>,7.781896884
<ipython-input-81-8b2be3da305f>,7.781896884
> <ipython-input-5-da0151e53370>,7.781896884
<ipython-input-2-c7a6754e3cea>,7.781896884
<ipython-input-87-6048368f3789>,7.781896884
<ipython-input-1-6f1cfd260960>,7.781896884
<ipython-input-69-598bf1638a5a>,7.781896884
<ipython-input-26-83df9bd56477>,7.781896884
> <ipython-input-26-83df9bd56477>,7.781896884
<ipython-input-14-8a88bfa62905>,7.781896884
<ipython-input-2-9c5e0a19b646>,7.781896884
"```

<ipython-input-12-b3a9a7af6c69>",7.781896884
<ipython-input-23-49b663c22e29>,7.781896884
<ipython-input-1-4a6d30520120>,7.781896884
<ipython-input-2-3742075adf08>,7.781896884
<ipython-input-4-b0b480e25061>,7.781896884
<ipython-input-59-3f31b644b254>,7.781896884
<ipython-input-1-adb4191f7cba>,7.781896884
<ipython-input-2-0c0d80794c41>,7.781896884
<ipython-input-119-61165facbb5e>,7.781896884
> <ipython-input-37-cd6b49ad1258>,7.781896884
<ipython-input-18-0b2a968dbcfd>,7.781896884
<ipython-input-33-a3a0461bebd2>,7.781896884
<ipython-input-1-85df9e4ef9a1>,7.781896884
<ipython-input-23-cbcfc17289ab>,7.781896884
<ipython-input-13-e6afe0381572>,7.781896884
<ipython-input-6-72e860176cbd>,7.781896884
<ipython-input-7-a9899ee596df>,7.781896884
<ipython-input-37-894211790f97>,7.781896884
<ipython-input-2-c74e2bd4ca71>,7.781896884
<ipython-input-90-65016ddab3cd>,7.781896884
"3330048     embedding_1[0][0]

__________________________________________________________________________________________________

concatenate_1",7.781484962
"return reduced_loss



train_data = 10*np",7.781321342
pre-allocate memory,7.78021978
tensorflow benchmark test,7.77901354
"0           time_distributed_2[0][0]         

__________________________________________________________________________________________________

dropout_5",7.778508772
preprocessing import standardscaler,7.778458346
single thread generator yield,7.777956196
x-post,7.777777778
"44400       embedding_1[0][0]

__________________________________________________________________________________________________

lstm_2",7.777283282
"_extractimagepatchesgrad

        rows_out = int",7.775
subsequent 2nd/3rd/,7.774603175
single 3024x4032 image,7.773130361
multi label predictions,7.77187581
local packages,7.770740904
"output shape



3d tensor",7.769893767
directly write checkpoint model,7.76900682
"4 gpus



**virtual env",7.767857143
"convolutional layer

classifier",7.767797609
exponentially moving average,7.766666667
early stopping based,7.766409266
`tf_stepy` activation function created,7.763975254
"* decay

      return state_ops",7.763678161
"metrics import mean_squared_error





# convert",7.763543985
"query

generator = segment_datagen",7.762376238
"get_or_create_layer

    layer = layer_from_config",7.758215962
tensorflow library wasn,7.757664363
"```python

class customsequence",7.757397794
training loss fluctuates,7.753553055
nested time series,7.753333333
default initialization produces `filters,7.751461988
"4s 62us/step

```",7.750617284
matrix pretrained embeddings,7.750595108
day solar energy,7.75
load traces data [testing],7.747353778
"# standarization

                    img_array_iobl = preprocessing",7.747035573
ve started working,7.740128558
strict file format checks,7.739486848
varying batch sizes,7.735734463
takes 1 positional argument,7.735049834
conv_23/conv_23/kernel,7.733944954
"disk

evaluating loaded model",7.733728339
pseudo-attention mechanism,7.733333333
convolutional_recurrent import convlstm2d,7.733240955
"```python

def map",7.732236528
[info] starting video stream,7.731568432
tensorflow import losses,7.730286409
pre-trained part,7.729979311
creating update ops,7.728684807
stricter pep8 checks,7.722222222
user-defined lambda function,7.720719579
"optimizers import rmsprop



#",7.720315092
optimizers import rmsprop,7.720315092
keras python code,7.719531643
pre-processing part,7.718386876
hyper parameters tuning,7.717435897
sequence class accepted `epoch`,7.716793522
"<module>

    import dask",7.716117273
machine learning algorithm,7.714507198
/14anankkrohlijcpinqh-pitatdjo9uzsn6iz0mwcdhw/edit,7.714285714
/1z_2yd9n_vj7lh5zt2ftuj5d3_m5z6qqi-dsabxppd70/edit,7.714285714
/1psfxnmmlstg5japgzkz26ag-zbu3errxkkoeznpzl4w/edit,7.714285714
/1y85hat-brf6qh2urtwz8wfooalawebkhgzw96u1yvlm/edit,7.714285714
"kb

import keras",7.713434603
stats import norm,7.713240955
"managers import syncmanager

     55",7.713240955
lithological classification curve,7.712121212
"<module>
    import tensorflow",7.706377013
standard image classification,7.70504917
set tensornd descriptor,7.704564315
"plt

import seaborn",7.703437033
"plt

import matplotlib",7.703437033
open code jupyter notebook,7.703244549
nbatch end keras,7.703023837
"import utils

  file",7.701914586
directional recurring lstm,7.701465201
0s 945us/step,7.701044634
"allow_growth=true

sess = tf",7.69892626
understand transposed convolution correctly,7.697787929
"4608        masking_2[0][0]                  

__________________________________________________________________________________________________

dropout_1",7.695175439
image import imagedatagenerator,7.69421291
image import imagedatagenerator`,7.69421291
"top_k

    return gen_nn_ops",7.69320197
arbitrary input image,7.691324124
[`conv2dtranspose` layer mention `dilation_rate`],7.690974583
`keras/preprocessing/image,7.690691939
"epoch



verbosity-modes 0",7.688929001
#define lid_0 threadidx,7.686046512
#define lid_1 threadidx,7.686046512
#define lid_2 threadidx,7.686046512
#define ldim_0 blockdim,7.686046512
#define ldim_1 blockdim,7.686046512
#define ldim_2 blockdim,7.686046512
#define gid_0 blockidx,7.686046512
#define gid_1 blockidx,7.686046512
#define gid_2 blockidx,7.686046512
#define gdim_0 griddim,7.686046512
#define gdim_1 griddim,7.686046512
#define gdim_2 griddim,7.686046512
#define ga_half ga_ushort,7.686046512
"50d continuous

#vectors",7.685714286
"tf

import numpy",7.68444901
training successfully xception,7.68286445
calculate batch size based,7.682202922
mini batch size equal,7.68038041
t__device ga_double atomicexch,7.678571429
model predicts multiple values,7.675475448
"import multiprocessing

ls = [1",7.671574288
parallel multiple cnn,7.670591509
5th-8th layers,7.670394134
regular python logger,7.669509595
image data inputed,7.669398546
inception_v3 import preprocess_input,7.667786409
powerful,7.666666667
"model_to

_dot

    _check_pydot",7.666666667
m_ab = m_a + m_b,7.666666667
"model_from_config

    return layer_from_config",7.665496343
multi label results,7.665072455
resnet50 import preprocess_input,7.664853858
image classification tasks,7.664325188
deconv3d_1/deconv3d_1_w/read,7.664233577
">

6 #include <numpy/arrayobject",7.66317734
">

7 #include <numpy/arrayscalars",7.66317734
working download links found,7.661736412
simple 1 layer lstm model,7.661663471
"installed

         python version",7.66133027
923] device interconnect streamexecutor,7.660377358
911] device interconnect streamexecutor,7.660377358
/text exch def,7.65940625
## existing keras utilities,7.659284557
roc auc score,7.6578369
lower learning rate,7.655555556
"np

import keras",7.654411117
"np



import keras",7.654411117
keras expects probabilities,7.652757751
frequently occurring class,7.652173913
put set_learning_phase _before_ fit,7.651983454
"ctc_step

    return ctc_cost",7.650344828
"# fully connected 

    combined",7.649051491
"624

__________________________________________________________________________________________________

__________________________________________________________________________________________________

layer",7.64856684
core import activation,7.647037936
metrics import confusion_matrix,7.643543985
metrics import r2_score,7.643543985
1308s 18s/step,7.639506173
"create_node

    output_tensors = to_list",7.636363636
initializers import truncatednormal,7.635463177
"```python

def metric",7.633420684
"code





`import numpy",7.633389551
nvidia-smi command,7.633223684
"_clone_and_build_model

    model = models",7.632209779
"mask





**_the error occurs",7.630925561
"```python

# training

model",7.628959527
"tf

import keras",7.628608175
"tf

    import keras",7.628608175
"12480       dropout_4[0][0]                  

__________________________________________________________________________________________________

dropout_2",7.628508772
prepare mys data,7.62745098
"import np_utils

importerror",7.625756919
"```

conv_23/conv_23/bias",7.625
"return apply



input2 = input",7.622991826
sigmoid single class predictions,7.621437856
image preprocessing tests],7.619069719
"lstm network



model = sequential",7.618803769
"model_from_config

    return layer_module",7.617877295
existing keras `[max,7.616427415
geforce gtx titan,7.614718615
"store features

    x_dset =",7.61448997
excuse code quality,7.614114114
display import svg,7.613240955
"display import svg

     13",7.613240955
"model

import numpy",7.610146634
"np

import tensorflow",7.608762923
"np

    import tensorflow",7.608762923
vgg16 import preprocess_input,7.608302683
"return model



tmp_x = pad",7.606600639
14s 9ms/step,7.60617284
"norm]

    

def l2_output_shape",7.606044905
optimizers import sgd,7.605750156
"## proposed fixes



* gradients",7.605392157
0s 460us/step,7.601044634
non-linear activation function,7.601032387
start children sit,7.6
"repeatvector

import keras",7.599798239
"binary labels



validation_generator = test_datagen",7.599237434
nice data loading api,7.598337805
assure reproducible work,7.59490275
set variable `initing=true`,7.593805724
"create

    input_storage=input_storage_lists",7.593333333
processing variable size inputs,7.592043319
"data tensor

inputs = input",7.59049249
**global average pooling**,7.58989899
global average pooling,7.58989899
"lambda

import keras",7.588902768
"```

#breaks 

import keras",7.588434603
svm import svc,7.588240955
multi label outputs,7.587884126
/lib/python2,7.585336073
7/lib/python2,7.585336073
embedding_2/embeddings/read,7.584233577
ry = gen_array_ops,7.583333333
/microsoft visual studio 14,7.583333333
"text

import itertools",7.580888013
text import one_hot,7.580888013
const ga_ssize stridesindices,7.580882353
"call_with_requiring

    return call_cpp_shape_fn",7.578916256
"code



#import keras",7.577548717
1s 1s/step,7.577006173
"function



```

    def build_cnn",7.572284221
phd thesis,7.571428571
medical imaging application,7.571428571
cutting edge tech,7.571428571
"windows

                       byte sex",7.571428571
simple neural network,7.56961927
denoising autoencoder separately,7.568181818
callbacks import earlystopping,7.566205381
"trained model

score = model",7.565857042
"# standarization

                    img_array_dcc = preprocessing",7.565217391
"# standarization

                    img_array_icc = preprocessing",7.565217391
"# standarization

                    img_array_dobl = preprocessing",7.565217391
initial learning rate,7.563601533
started training,7.561652329
"```python



def data_gen",7.561268786
"```python

def data_generator",7.561268786
"random import seed

seed",7.560889973
progress-bar output,7.559655499
non-reproduciblity phenomenon,7.558232932
"input



```python

simple_model",7.556981392
tensorflow methods interchangeably,7.554545455
keras import model,7.554305799
"66048       dropout_6[0][0]                  

__________________________________________________________________________________________________

concatenate_1",7.552318296
"0           concatenate_1[0][0]              

__________________________________________________________________________________________________

bidirectional_3",7.552318296
keras-fcn performance,7.551806552
"514         dense_1[0][0]                    

__________________________________________________________________________________________________

dense_3",7.551358234
avoid inheriting `keras,7.550193648
keras` deeply compatible,7.550193648
100k images mixed,7.548245614
[dist-keras],7.545833975
dist-keras,7.545833975
deep neural network,7.544927912
unexpected keyword argument,7.544573643
"losses import binary_crossentropy

print",7.542924294
"```python 

    input = layers",7.54166124
maximum recursion exceed,7.540540541
installed cuda toolkit 7,7.539316239
generate chiense text,7.538378766
pull request adds,7.538281979
independent code branches handling,7.537923638
model_1_1/dense_2/biasadd,7.534482759
"code ===================

import tensorflow",7.531900523
tensorflow import graph,7.531231787
gup error recovered,7.530046225
core rnn cell,7.529836688
/utils/generic_utils,7.529237288
"np

import pandas",7.529217469
"```python

def dense_sum",7.527935452
multi class problem,7.526518109
maintain exponential averages,7.523809524
"kl

import keras",7.523434603
strength 1 edge matrix,7.5232358
continue training _as,7.52286445
"#feature extraction start

    input_shape =",7.522796516
reset encode hidden state,7.521082971
time fine-tuning,7.517181445
installed anaconda,7.516583748
load models sequentially,7.514311556
backend function `conv2d_tranpose`,7.512968288
keras` functionality seamlessly,7.51209841
validation-selection _after_,7.511904762
compute final gradients,7.511642157
output layer feeds back,7.511021179
"return loss

model = sequential",7.510166872
org/simple/scipy/,7.509529938
"plt

import numpy",7.509471516
"```python

class maxoutconv2d",7.507397794
"```python

class classsampler",7.507397794
tensorflow/stream_executor/dso_loader,7.506628788
"tensorflow_backend import *

     84",7.503938629
variable bn_conv1/moving_mean/biased,7.502857143
highlight=convtranspose2d#torch,7.5
shapes_mem_count + trainable_count + non_trainable_count,7.5
"turn

# `encoder_input_data` & `decoder_input_data`",7.5
#NAME?,7.5
taload pop sethsbcolor,7.5
"_main_

    yolo",7.5
"_check_array_lengths

    set_x = set_of_lengths",7.5
/nicolov/segmentation_keras/issues/14,7.5
pipeline import pipeline,7.49895524
replicate single data file,7.497832024
"_apply_op_helper

    op_def=op_def",7.497435897
"_apply_op_helper

>     op_def=op_def",7.497435897
training losses alternated,7.49536445
vgg16 keras codes,7.495255377
updates learning rates,7.495238095
realtime data augmentation,7.494117647
static fortran library,7.492592593
making depth recognition,7.492424242
tesla m60 gpus,7.49047619
model produces correct results,7.487661599
accuracy falls shrply,7.487623762
training runs fine,7.486776664
"documentation user-experience

**comment**",7.48582911
sutskevers seq2seq model,7.483728339
handle french tokenization,7.480392157
improve recurrent attention,7.480116959
summary ops created,7.477887028
summary` ops created,7.477887028
raw video dataset,7.47779304
1-percent/training-data,7.476982097
`channels_first` image data format,7.474749351
forward-backward algorithm,7.472527473
keras team,7.47220137
keras-team,7.47220137
"model_from_json

    return layer_from_config",7.472050254
training ignores pixels,7.468578736
y-axis,7.467741935
callbacks import reducelronplateau,7.466205381
callbacks import lambdacallback,7.466205381
clone model function doesn,7.465731202
keras calc auto,7.464479363
"0           input_1[0][0]

__________________________________________________________________________________________________

embedding_1",7.463557792
"import keras

warning",7.463434603
10-fold cross-validation,7.460999785
10-fold cross validation,7.460999785
ground truth positive boxes,7.460662526
next-step prediction,7.460644384
two-stream net,7.46031746
"running 



```

python seq2seq",7.458824825
//scikit-learn,7.458333333
scikit-learn,7.458333333
entire training data,7.456982097
dear keras fellow,7.456076001
4i found misleading `inf`,7.456018519
high memory usage,7.455840456
parallelize training process,7.455591723
neural machine translation,7.454334038
tricky programming question,7.453703704
medical tumor images,7.453007519
"0           time_distributed_4[0][0]         

__________________________________________________________________________________________________

lstm_1",7.452751196
t0 exch rlineto,7.452380952
"total_loss

```

import tensorflow",7.449701303
"gmm import *

  file",7.447677298
creating dummy variables,7.444362745
video import videostream,7.444010185
"title



`import numpy",7.44235236
optimizers import adam,7.441291445
numpy array sized,7.439138983
individually highlighted lines,7.43902439
top 2 inception blocks,7.437931034
building complex rnns,7.436666667
"timedistributed

import numpy",7.435942104
provide higher level features,7.434649328
0s 27us/step,7.434377968
`concatenate` layer requires inputs,7.431117581
"patient ids

targets = np",7.430720104
callbacks import modelcheckpoint,7.429168344
/text-datasets/imdb,7.428871549
statically linked executables,7.428571429
git clone https,7.426859333
"lambda layer

    loss_out = lambda",7.425818959
element wise operations,7.425490196
"model_from_json

    return layer_module",7.424431206
full training data,7.421426542
numpy import newaxis,7.419275437
data-parallel sgd,7.418787161
insufficient input dimension size,7.41765878
minimally trained state,7.41740734
developed individual models,7.416338583
assertion randomly fails,7.415425532
"160

keras-tf-keras_opt",7.415367221
"246

keras-tf-tf_opt",7.415367221
"run_internal_graph

    output_tensors = _to_list",7.414141414
"model architecture

model = sequential",7.412342944
many-to-,7.411359725
layers import layer,7.408517718
"input unchanged



trial_batch_2 = np",7.407019739
batch normalization learn,7.406322699
step activation function created,7.403481427
5 large numpy files,7.403058292
"validation set

preds = np",7.402900137
rum multiple times,7.402794222
fractional max pooling,7.401587302
fractional max-pooling,7.401587302
resnet50 implementation bundled,7.401419853
predict normal density function,7.401417182
"_buildloop

    body_result = body",7.4
272           cudaerror_t err2 = cudamemgetinfo,7.4
layers import input,7.399678314
original time series,7.397272727
"store labels

    y_dset =",7.396840502
similar topic disappeared,7.396825397
/usr/lib,7.396549831
"os import environ

environ[",7.395274052
callbacks import tensorboard,7.39477681
keras import metrics,7.393737633
simple recurrent model,7.393210378
keras api directly,7.391379546
glove word embeddings,7.384835165
nencodingvector 45 /hyphen put,7.384615385
fine tuning callback,7.38289573
"```python

def linear",7.382102119
slow learning rate,7.381045752
customized serialization function,7.380525031
requires scrolling horizontally,7.38
keras documentation misses,7.376860315
/flyyufelix/cnn_finetune,7.375
"getitem

oid = h5o",7.375
grid k520 gpu,7.374538259
deep complex networks,7.373919753
tensorflow ops,7.372912801
step function executes,7.372412156
turn calls [`tensorflow,7.371212121
current behaviour prevents,7.370235935
non-trainable layers,7.369960399
deconv3d_1/deconv3d_1/output_shape,7.369047619
restored recurrent connection,7.368883748
test data 41016x218,7.368585732
org/#home,7.366931543
latent layer + random var,7.366187804
perform cross-validation,7.364845938
"return outputs

m1 = u_net",7.364190981
multi-output model,7.363667721
"587 



/home/captain_jack/",7.363070539
/home/captain_jack/,7.363070539
"h5

import matplotlib",7.361628051
"```python

def slice",7.361268786
"test_multiprocessing_training failed

test_multiprocessing",7.361111111
"test_multiprocessing_training_fromfile failed

test_multiprocessing",7.361111111
"test_multiprocessing_predicting failed

test_multiprocessing",7.361111111
2 stacked lstm layers,7.35647472
"concatenate



import tensorflow",7.356142574
"toy problem

# input consists",7.355655486
"tensorflow-gpu

gpu",7.353621972
keras-gpu installed,7.352509685
non-trainable separately,7.349566265
multiple time series,7.347184466
keras import __version__,7.342744948
"model

model_callback = keras",7.341064845
conv import conv_2d,7.338240955
returning state _sequences_,7.336550837
bvh animation skeleton,7.333333333
1tera hdd,7.333333333
incorporate corrections outlined,7.333333333
bleeding-edge functionality,7.333333333
const ga_size numrowsx,7.330882353
layers import embedding,7.330126316
tesla p100,7.327777778
pretrained densenet 40-12 model,7.326801932
api version 0xb,7.325764509
allocator<wchar_t>> const&,7.324929972
previously choosen implementation,7.32480695
~/stock/src/feature,7.323583858
"corresponing position 

        vectors",7.323076923
session=session,7.32231405
learning rate recorded,7.322222222
increasing learning rate,7.322222222
* scaled learning rate,7.322222222
"loss

        import tensorflow",7.321808347
linear continuous target variable,7.320880172
"create_op

    op_def=op_def",7.319298246
"create_op

>     op_def=op_def",7.319298246
numpy import array,7.319046604
added l2-norm regularization,7.317824648
text import tokenizer,7.317730119
advanced_activations import prelu,7.317407621
examples/babi_rnn,7.317073171
end-to-end,7.317020102
featurewise_center flag subtracts,7.315018315
generic model class,7.314473681
#define ga_size size_t,7.311046512
"```python

        model = sequential",7.311023987
"```python

model = sequential",7.311023987
build keras bindings,7.310941312
pull request adding,7.30952381
updated nvidia-cuda 9,7.308992165
model definition examples,7.307944367
mixed precision training,7.30786445
#NAME?,7.307692308
cntk backend rises,7.305883902
77   cudnnstatus_t err = cudnnsetfilternddescriptor_v4,7.302325581
returning numa node,7.301587302
application exit/quit,7.3
"/dingchenwei/googlenet  

mobilenet",7.3
slightly modify `timedistributed` layer,7.299882629
support variable-size inputs,7.299600822
large negative log loss,7.298323408
"gradients

    return tf",7.295910557
"gradients

        return tf",7.295910557
loosing 2 data points,7.294117647
jointly learning pred,7.293333333
high-level api,7.292628205
simply 1*learning rate,7.291919192
/npages exch def,7.291759191
"make_thunk

    storage_map=storage_map",7.291666667
json format dataset support [,7.29163607
inception v3 model,7.291302231
loss function performing rmse,7.288443072
"convolutional base

model",7.286777629
"0           lstm_1[0][0]                     

__________________________________________________________________________________________________

dropout_6",7.28608453
broadcastgradientargs,7.285714286
callbacks import csvlogger,7.2843872
face localization model,7.283178889
multi-label problem,7.282741142
"return model



    model = get_model",7.279455641
largest individual loss,7.279021938
two-dimensional outputs,7.278846154
"```python

class normalize",7.276628563
"return model



dnn_model = kerasclassifier",7.27505061
/home/ubuntu/,7.268730917
2 parallel embedding layers,7.268400513
np_utils import to_categorical,7.266151007
"np_utils import to_categorical

#",7.266151007
"dll locally

x_train shape",7.26507857
full image produces,7.264169788
fine tuning vgg19,7.263848111
takes 2 positional arguments,7.262880562
pepper layer based,7.262720467
sparse categorical loss evaluation,7.26143326
"image encode

    flat = flatten",7.260182547
"maxpooling2d

import numpy",7.259498901
current callback implementaion,7.259398496
learn sentence representations,7.258333333
low learning rate,7.257706093
"12864       concatenate_1[0][0]

__________________________________________________________________________________________________

dense_2",7.253467721
sequential_1/conv3d_1/transpose,7.253448276
prepare time series,7.253333333
current keras version,7.252206471
callbacks import callback,7.251919667
"dummy losses

     keras",7.250193648
advancedear keras folks,7.250193648
ensure keras incorporates,7.250193648
replay memory considerations,7.25
gesture recognition,7.25
"swig_import_helper

    _mod = imp",7.25
t__device ga_half atomicexch,7.25
"set_shapes_for_outputs

    shapes = shape_func",7.25
const ga_ssize stridesx1,7.24754902
const ga_ssize stridesy1,7.24754902
tf core layers,7.246971215
"return perplexity





def crossentropy",7.246865923
computers run ubuntu 16,7.245428717
spatial dimension larger,7.242732409
gpu sync failed,7.241204925
"verbose = verbose



         def on_epoch_begin",7.240564478
non-trainable params,7.239693654
"917

non-trainable params",7.239693654
"169

non-trainable params",7.239693654
"105

non-trainable params",7.239693654
"680

non-trainable params",7.239693654
"600

non-trainable params",7.239693654
"722

non-trainable params",7.239693654
"0

non-trainable params",7.239693654
"130

non-trainable params",7.239693654
"116

non-trainable params",7.239693654
"165

non-trainable params",7.239693654
"925

non-trainable params",7.239693654
"385

non-trainable params",7.239693654
"931

non-trainable params",7.239693654
"698

non-trainable params",7.239693654
"104

non-trainable params",7.239693654
"230

non-trainable params",7.239693654
"798

non-trainable params",7.239693654
"656

non-trainable params",7.239693654
"972

non-trainable params",7.239693654
"751

non-trainable params",7.239693654
"903

non-trainable params",7.239693654
"729

non-trainable params",7.239693654
"141

non-trainable params",7.239693654
"351

non-trainable params",7.239693654
"514

non-trainable params",7.239693654
"870

non-trainable params",7.239693654
"42

non-trainable params",7.239693654
"1

non-trainable params",7.239693654
policy based rl,7.237837838
trx ry scale,7.234848485
gradient descent requires,7.23
t__device ga_double atomicadd,7.228571429
"import keras

print",7.22836569
set tf variable reuse,7.227140485
current keras experience,7.223877859
"`



cheers

kirill makukhin",7.222222222
`kerasclassifier` scikit_learn wrapper,7.221997301
keras training module,7.221648702
model_1/conv_11/kernel,7.221124441
model_1/conv_12/kernel,7.221124441
native tensorflow model,7.218493574
training large datasets,7.217303226
lambda layer inside timedistributed,7.217017461
"states

        gradients=cb",7.215841892
"return score





cache_path = os",7.215001149
early stopping callback,7.214285714
"> import sys

> #sys",7.213240955
"```python

vec = np",7.212867061
"2112        dropout_2[0][0]                  

__________________________________________________________________________________________________

lstm_3",7.211842105
handles english words,7.211538462
input + supplemental data,7.210160872
"history

def savemodel",7.208425857
tpop neg 0 rlineto,7.208333333
"3925        repeat_vector_1[0][0]            

==================================================================================================

total params",7.208309207
"0           max_pooling1d_9[0][0]            

==================================================================================================

total params",7.208309207
"1290        bidirectional_5[0][0]            

====================================================================================================

total params",7.208309207
softmax cnn layer shows,7.204847915
n_val = int,7.203571429
job engine managing,7.202947033
extracting image features,7.201038475
bi-cubic resizing,7.2
"94gib

free memory",7.2
"89gib

free memory",7.2
custom attention layer,7.199647224
updated learning rates,7.198941799
atis data set,7.198681962
training/adam/const,7.197442455
# start fine-tuning,7.197181445
keras/backend/common,7.19692262
medical image community,7.19670947
"816         dropout_1[0][0]                  

__________________________________________________________________________________________________

time_distributed_4",7.195175439
mini-batch training,7.193598913
works as-,7.193333333
states=nb_data*numepoches*[,7.192592593
keras model summary format,7.191403676
"predition

testset = np",7.190976514
geforce gtx1080 8gb,7.19047619
double gaussian function,7.18961594
requires comparing models,7.188005249
linear algebra operations,7.1875
gpuadvancedincsubtensor1_dev20{inplace=true,7.186384266
"_main

        exit_code = args",7.186335404
#define infinity __int_as_float,7.186046512
"categorical_accuracy

import numpy",7.185942104
layers import lstm,7.18510029
"layers import lstm



#",7.18510029
run nvidia-smi,7.18351834
sequential variantion autoencoder,7.183110728
"imread

import sklearn",7.181520098
preprocessing code touches,7.179331505
"1000        input_2[0][0]

__________________________________________________________________________________________________

lstm_1",7.174973418
current keras implementation,7.173684809
"list_classes





def convert_patterns_to_indices",7.172711572
open midi dataset,7.169487578
gaussian noise layer,7.167306872
"```

xxx lineno",7.166666667
"/bzamecnik/390d3802b31ce766fbf6fd6c9fd682d3



## problems",7.166666667
/tensorflow/benchmarks repo,7.166083916
embeddings_index[word] = coefs,7.164835165
started predicting,7.164502165
#define local_mem shared,7.162790698
"import imdb

>   file",7.161963012
"_error_catcher

        raise protocolerror",7.160714286
categorise prediction based,7.158976049
require special handling due,7.157142857
reducing learning rate,7.155555556
"top dense layers

model",7.155002282
"partitions = inputs

        return tf",7.153397188
deeplab v3+ model,7.153371196
# generate dummy data,7.152349354
#~ generate dummy data,7.152349354
"_make_callable_from_options

    return basesession",7.150344828
"preprocess_input

    return imagenet_utils",7.150344828
508             this->storage_v3 = storage_v3,7.15
509 this->storage_v5 = storage_v5,7.15
510 this->storage_v7 = storage_v7,7.15
511 this->storage_v9 = storage_v9,7.15
512 this->storage_v11 = storage_v11,7.15
513 this->storage_v13 = storage_v13,7.15
514 this->storage_v1 = storage_v1,7.15
/home/username/,7.148784825
cudnnrnn trained model,7.147918176
4/docs/templates/callbacks,7.147701269
embedding_1/embeddings/read,7.146733577
means custom models,7.146261908
dirt simple lstm,7.145909646
"keras



input_layer = keras",7.14324444
"activation



import numpy",7.14166891
"feature-wise normalization

    #",7.141283911
functional-style model,7.140871196
"# create model

model=sequential",7.140004636
generating image data,7.139986781
pre-defined model,7.139602839
"fine-tuning

top_model",7.138848111
unsupported operand type,7.137362637
"9851

    activation_3

    dropout_2

    dense_2

    -0",7.134482759
tensorflow source codes,7.132976827
original tensorflow implementation,7.131625132
adding gaussian noise,7.131313131
recently started,7.128787879
"py

import numpy",7.128500851
"py

      2 import numpy",7.128500851
"placeholder arrays

            y_true[start",7.127613087
"_uses_learning_phase = false

    320         return",7.126712987
layers import averagepooling2d,7.126492231
"support relu6



-------------------------------------------------------------------------

valueerror                              traceback",7.126302683
neural network depend,7.125174825
volta architectures / tensorcores,7.125
xlarge amazon instance,7.125
implementing custom layers,7.122936507
nvidia p100,7.121527778
"lp]



layer_outputs = [func",7.120879121
"#lstm

sgd_ema_plstm = optimizers",7.12082004
problem merging embedding layer,7.120077027
layers import repeatvector,7.119998725
"/stdcoutzyx/deepid_faceclassify

https",7.114490161
"/hqli/face_recognition

https",7.114490161
"/ozabluda/bbc6c84c0e69bfd9ca55170fd3ab040d

# https",7.114490161
"func_dump

    code = marshal",7.114114114
[backend function `conv2d_transpose`],7.112968288
tf backend issues,7.111902544
"return result

`lanes = lanes",7.111219396
"_fused_normalize_batch_in_training

>     data_format=tf_data_format",7.111111111
"separable_conv2d

    data_format=tf_data_format",7.111111111
optional pooling toggle,7.111111111
py#l48-l49shouldn,7.109225413
py#l1355-l1363,7.109225413
py#l56-l93,7.109225413
py#l440-l450,7.109225413
py#l947-l973,7.109225413
py#l459-l496,7.109225413
py#l1381-l1394,7.109225413
layers import lambda,7.109103253
#NAME?,7.108396947
astonishingly ugly manner,7.107142857
previous unit tests,7.107142857
checked similar questions,7.104082455
training time improves,7.10286445
ml,7.102564103
gpu memory allocation,7.102316036
initial _hidden_ state,7.101739671
module named keras,7.101284252
63350s 7s/step,7.101044634
60512s 7s/step,7.101044634
/encoding encodingvector def,7.100247804
step works till,7.099506173
"```python

def split",7.095643786
"processthread

    model = pluginloader",7.090871196
per-worker size,7.089186176
"shaun

feature request",7.088062622
"inputs[0]

    

        n_gr = tf_d_stepy",7.087878788
bi-cubic interpolation,7.0875
training loss decreases,7.086886388
locally connected layers,7.086112291
8s 4s/step,7.083950617
tfrecord dataset support,7.083369191
line opt = optimizers,7.083193509
numpy import zeros,7.083105225
cnn steering model,7.082763088
gtx 980m gpu,7.082114016
source activate tensorflow_p27,7.078431373
unroll=truestateful = false,7.078220011
totally wrong class labels,7.077355192
deep learning model,7.077290949
100k metadata files,7.076190476
recurrent layer works,7.076110699
learning rate 1e-3,7.075308642
highly varying size,7.075297287
makes iou test,7.074468085
"output_classes=4

batch_size=64



model=sequential",7.074273013
"french



train_sequences = tokenizer",7.070175439
shared fortran library,7.069336779
"```

main process trackback",7.069023569
keras/tensorflow code,7.068853217
13s 2ms/step,7.068077601
auto regression step,7.068077601
means cross validation,7.067226891
steering angle,7.066666667
"/marcellacornia/sam

filename",7.064516129
back past 500 steps,7.063445416
"<module>

>     import scipy",7.063056048
"<module>

    import scipy",7.063056048
<9516x28934 sparse matrix,7.06291834
zero-dimensional arrays,7.061956522
additional learnable transforms,7.061594203
image import load_img,7.059110089
imports keras slow,7.059017178
high dimensional sequence,7.058382915
"return loss

inputs = input",7.058288779
tensorflow-gpu version 1,7.057412325
tensorflow-gpu version 0,7.057412325
"null_wrapper

>     return fn",7.057321572
"null_wrapper

    return fn",7.057321572
trained autoencoders,7.05704698
"cntk backend

keras",7.05607755
1-percent/validation-data,7.056022409
module named tensorflow,7.055636059
"set_of_lengths

    return set",7.054909143
"early]

    

    train_generator = generate_batches_from_train_folder",7.053679654
ib,7.052631579
"epoch=epoch

        def on_batch_begin",7.050569574
2 layer neural network,7.050057454
mobilenet family,7.05
pyenv/versions/3,7.05
report kernel dies,7.048230668
keras application api,7.047629546
stacked lstm network,7.047619048
uggly/hacky ways,7.045454545
simple sentiment classifier,7.044444444
individual ops,7.043367347
steering data problem,7.042820817
auxiliary layer adds 0,7.042529688
pure tensor language,7.04245283
"<module>

    callbacks=[ffcallback]",7.041555031
keras [tensorflow_backend,7.040891323
long term dependencies,7.039851402
training vgg16 network,7.03946464
"<module>

    full_model = get_combined_model",7.038590604
# current_device takes precedence,7.035714286
highly regularized model,7.035315641
file lstm_seq2seq,7.034436343
simple python file,7.034104668
current time-step,7.033190383
language_model = sequential,7.031595577
raghakot resnet implementation,7.031107763
"convention `config` holds

            #",7.028571429
"py

    import tensorflow",7.027011823
generating validation data,7.026610644
simple custom layer,7.021869446
sentiment analysis model,7.021640427
/theano/theano/pull/5537,7.021035599
_several_ wrapped layers,7.020394134
providing inputs asynchronously,7.016450216
pandas import read_csv,7.014711543
subfolders representing classes,7.014124294
tensorflow resplease make,7.013636364
set batch size maximum,7.011692162
"cntk



class ksequence",7.011328843
"deserialization code

---------------------------------------------------------------------------

unicodeencodeerror                        traceback",7.010340529
lstm encoder decoder architecture,7.010237839
call` calls `keras,7.010018976
keras cifar10 dataset,7.00912222
x_train[counter%batch_size] = transform,7.008345934
validation_steps=samples_per_validation/batch_size+1,7.007946591
long-term support,7.007149164
"/norm



def ret_l2",7.006044905
"batch_labels





def get_compiled_model",7.006044905
support multiple gpu,7.004734773
3d tensor back,7.003230753
running keras models,7.002276033
train multilabel classification,7.001777472
global training process,7.001046268
"compute_output_shape 

keras version = 2",7.000744482
final keras v1,7.000193648
faq,7
"_fused_batch_norm_v2

>     is_training=is_training",7
activity regularisation,7
memory monotonically increases,7
categoryone[word2intclassvalue[lablevalue[,7
brown fox jumped,7
perhps expose `white_list_formats `,7
visual recognition],7
coco [pycocotools],7
set fileencoding=utf-8,6.995473406
classic cnn blocks,6.991891892
group deconvolution3d layer,6.991549296
found online added sigmoid,6.989274648
"<module>

    capsule = capsule",6.988590604
native-tensors validation,6.987450821
native-tensors validation`,6.987450821
negative dimension size caused,6.985649168
> negative dimension size caused,6.985649168
fine-tune resnet50,6.984691784
current mini batch,6.984418674
long long time,6.983829787
/examples/pretrained_word_embeddings,6.983739837
"dense layers

model1 = model",6.982909259
40milisecend time window,6.9825
backend-agnostic implementations,6.980062305
older keras version,6.97852226
"__call__

    return utils",6.978495159
3d numpy  array,6.977600522
layers import dense,6.97737204
high dimensional data,6.976809955
"gradient tensors

    trainable_weights = model",6.976673665
1-serena-x86_64-2,6.975
# add non-linearity,6.973766147
latest tf run time,6.971890269
model_1/conv_1/kernel,6.971124441
"full connection

classifier",6.967521368
current training batch,6.967283124
"documents

    def codedocuments",6.964378238
focussed early feedback,6.964285714
employed 3d cnn,6.963686764
bi-classification problem,6.960824382
"@staticmethod

    def sampling",6.96059036
tensor xxx,6.959119497
search function picks,6.959096459
correctly train models,6.958971033
"found ndim=4



keras couldn",6.957308658
python scripts giving,6.956622482
import theano & theano,6.956498776
simple deep cnn,6.956089423
"```pyhton

model= sequential",6.955800106
accumulated differences,6.955555556
4 class classification model,6.955166321
enforce serial execution,6.954545455
python3 training,6.954090865
anaconda spyder,6.953091684
virtual environments `old_keras`,6.952380952
"import data_utils

      5",6.952371389
cnn output softmax layer,6.952003415
misc import imresize,6.951336193
"_popen

    return _default_context",6.950344828
"_popen

    return popen",6.950344828
nested embedding layers,6.950218695
"usp=sharing



makes",6.95
**global max pooling**,6.947041847
cryptic keras error,6.94690654
io/metrics/,6.943816544
default keras api,6.942366388
load multiple models,6.941496022
`zx = zy = np,6.940976514
"gather

    validate_indices=validate_indices",6.940740741
advanced_activations import elu,6.940513682
saved_model import tag_constants,6.940513682
128-dimensional word vectors,6.939835165
"dtype=float32>



    encoded_vid

    <tf",6.939144492
image classification problem,6.936105281
"200960      input_1[0][0]                    

__________________________________________________________________________________________________

dense_2",6.93554055
[tf-image-segmentation],6.935191313
"multiple filters

    config = tf",6.933210169
rnn layers symbolically,6.931684456
dissimilar 2d datasets,6.930272109
providing residual connections,6.928571429
predicting 1 step ahead,6.925220459
inconvenience calling function,6.923382173
[google research blog],6.923244147
return additional data,6.922723344
cross validation loop,6.922538246
hit hit-rate,6.922222222
layers import concatenate,6.921991253
"conda_exception_handler

        return_value = func",6.920879121
optimizing classifier performance,6.920843672
#     optimizing classifier performance,6.920843672
multidimensional time series,6.92
#define kernel extern,6.919991466
"```python

optimizer = rmsprop",6.918732653
gradient ops,6.918367347
"# crop 48x48px

    desired_width",6.916666667
"softmax_cross_entropy_with_logits

  # expects logits",6.914035088
"softmax_cross_entropy_with_logits

# expects logits",6.914035088
training step `model,6.913241819
train  data fully,6.913138986
un-trainable variable,6.910857143
skeleton custom layer,6.910758335
data format convention,6.910279263
keras sets values,6.907613434
match core tf,6.907611564
integer positional arguments,6.907166276
"map_fn

    swap_memory=swap_memory",6.904761905
accepts multiple inputs,6.903952143
#NAME?,6.902857143
"hdf5 configuration

      =================================



general information",6.9024108
tensor variables manually,6.901696528
/width exch def,6.900454843
reads csv files,6.9004329
"load_dynamic

    return _load",6.900344828
layers import timedistributed,6.900301755
keras hard-codes,6.900193648
"func_load

    raw_code = codecs",6.9
`nxn` distance matrix `,6.89917565
multi-epoch fitting,6.898780553
trained keras-model,6.898111825
trained keras model,6.898111825
pooling import maxpooling2d,6.897908863
error text reads,6.897693284
"_apply_op_helper

>     param_name=input_name",6.897435897
ve added slicing functionality,6.895778464
"import backend

  file",6.89440627
"import pydot

pydot",6.890660309
"# input image dimensions

img_rows",6.889655913
1359         # prepare validation data,6.889355742
actuall speed differences,6.888888889
"main

    model = rnn_obj",6.887167493
"cases

pt_idxs = [all_patient_ids",6.884615385
upgrading/downgrading keras,6.883526982
"6           hidden[0][0]                     

____________________________________________________________________________________________________

output_slack",6.883333333
regularizers import l2,6.882775005
"cudnn_status_not_supporteddim=4

apply node",6.882000599
training data set,6.881546413
"```python

labels = input",6.879375214
tf graph inside `fit`,6.879320353
sentiment analysis context,6.879045093
started reimplementing,6.878787879
"test





def main",6.876809286
"0           time_distributed_6[0][0]         

==================================================================================================

total params",6.874975873
metrics import log_loss,6.874313216
dask works fine,6.874031261
initializers import randomuniform,6.873558415
#3 python script presented,6.872990378
permuting 4d arrays,6.872670807
"4096d activations
    model",6.872121196
several-epoch training,6.871793451
update `layers/convolutional,6.871062471
3s 48us/step,6.870275404
adds additional layers,6.866302062
distributed hyperparameter search,6.865079365
"** 



```bash

$ sh run_tf_backend",6.863636364
/home/rick/,6.863070539
bn-auxillary layer,6.862382629
model parses correctly,6.86170453
"py#l172_l177



reproduction",6.859225413
separate image folders,6.858614232
vgg pretrained model,6.858547964
lowest viable shape,6.858490566
"standardize

    whitex = np",6.857643181
">

  </tr>

  <tr>

    <",6.857142857
convert batchdescriptor {count,6.856923077
updated tensorflow backend,6.85497813
pickle noimplementedtype objects,6.852941176
improves performance significantly,6.851612903
"training

train_datagen = imagedatagenerator",6.851055507
"#error occurs



  lstm1=lstm",6.849868914
i-,6.846153846
i--,6.846153846
[i-1],6.846153846
"```pyhton

def mean_squared_error",6.846044905
predicts perfectly fine,6.84557888
layers import flatten,6.843284211
validation accuracy & testing accuracy,6.842415445
sample training image,6.841929133
"keras



    model schema",6.841064845
"lambda

import sys",6.838709119
"batchsize=500



#batch sized",6.838512241
current keras code,6.837991973
full devset passed,6.837301587
layers import conv2d,6.836826578
input time series,6.836043225
"loss

    opt = adam",6.835524608
simple mlp network,6.834554335
layers import batchnormalization,6.833635088
10% r-squared,6.833333333
pull request changing,6.832399627
const ga_size numcolsx,6.830882353
const ga_size offset_x,6.830882353
const ga_size offset_y,6.830882353
const ga_size numindices,6.830882353
const ga_size offset_indices_arr,6.830882353
famous [coco dataset,6.830357143
emnist byclass dataset,6.830357143
locally connected convolution,6.829051491
#define ga_double double,6.828903654
"# input shape required

                             tf",6.828596252
"sess = sess



    def on_epoch_end",6.826707673
gradients calculated/updates,6.826546003
works perfectly fine,6.826412214
"cnn

classifier = sequential",6.826051571
latest keras version,6.825470617
python tensor object,6.823733049
"import image

>   file",6.822958197
errno=connection timed,6.820512821
simple mnist cnn,6.81966967
--> 449       return gen_math_ops,6.817011494
"_maybecompile

    return grad_fn",6.817011494
"_maybecompile

        return grad_fn",6.817011494
# create scaling gammas,6.815555556
transfer learn,6.81547619
trained xception model,6.814584843
state non-identical,6.814426625
"arguments

data_gen_args = dict",6.81220029
model expects 5  arrays,6.811161051
run multiple models,6.808291388
3d cnn method,6.808131208
keras data generator,6.806687533
validation data separately,6.806022409
2d input `numpy,6.805411041
record logging history,6.805322129
large tests taking,6.803571429
default setting `orthogonal` doesn,6.803357532
"#build autoencoder

    var_auto_encoder = model",6.803134011
simply making [_reset],6.803030303
"network

def tower_network",6.8009167
found [docker/readme],6.80026455
t__device ga_half atomicadd,6.8
y_train[counter%batch_size] = np,6.79854033
"tensor 



```

 def loss_fn",6.798497735
"<module>

    _cardio_predictor = load_model",6.797681513
step function starting,6.79665458
original tensorflow code,6.795932296
high accuracy 0f > 0,6.79531607
load training config running,6.795152653
"import datasets

>   file",6.794616073
non-input parameters,6.794276157
bad marshal data,6.794117647
nasnet models,6.791338583
"weighted

    score_array = fn",6.790310078
custom image generator,6.790199509
fitting `imagedatagenerator` insists,6.789901583
"module_from_key

    module = lnk",6.788590604
"<module>

    norm_x = preprocess_input",6.788590604
discuss design decisions,6.785714286
error insertion rate,6.785601781
"900

_________________________________________________________________



```

learning log",6.784672619
simulate batch sgd,6.783888826
"inputs

    652                 feed_dict = dict",6.779802366
"5 lts

installed keras **",6.777971426
"sh multi_gpu_config

```



**results",6.776489028
time series length,6.775421687
"cnt=0

    ckvalue=int",6.775
<code>class_weight</code> parameter,6.77461377
"``` python 

score = model",6.773162746
"65          dense_1[0][0]

==================================================================================================

total params",6.772825336
"> original model

> <tensorflow",6.772689378
"dtype=float32>    



    encoded_frame

    <tf",6.772477825
fine-tune inceptionv3,6.772209315
entire input sequence,6.771733833
abandon embedding layer,6.771373857
embedding layer serves,6.771373857
"```python

input_l = input",6.771267106
layers import dropout,6.77099141
initializers import glorot_uniform,6.76879651
```keras requires `sample_weight`,6.768655187
allocator<int>> const&,6.766596639
"code

```

class model_keras",6.766288027
network runs fine,6.765450675
hyper parameter settings,6.763052209
"# previous transitions

    _p_prev =",6.761904762
`call` shows upthere,6.759825328
element-wise multiplication,6.758823529
paint_text function defined,6.757828101
"train_model

    model = multiimagemodel",6.757537863
painstaking labeling work,6.756807512
enable image summaries,6.75623328
"class_indices





def train_top_model",6.756044905
data/validation/dogs,6.756022409
pickle local object,6.755235801
entire model training,6.753735646
changed softmax classifier layer,6.752457063
"<module>

    initial_epoch=epoch_offset",6.752446026
layers import reshape,6.750567359
impose sparsity constraints,6.75
pre/post https,6.749410796
made time depending samples,6.749331873
ctc based tutorial],6.749209075
modelcheckpoint callback terminates,6.748677249
modelcheckpoint callback funtcion,6.748677249
/theano/theano/issues/5224,6.743257821
time series prediction,6.741138211
manual test invocation,6.741134752
"np

import cv2",6.740952163
"get_config

    function = func_dump",6.74015236
training data generator,6.739358335
"688

__________________________________________________________________________________________________

_________________________________________________________________

layer",6.739105687
truncated back propagation,6.738983051
param int batchsize,6.738675214
per-worker loss,6.737355271
"log_loss

def mlogloss",6.736814136
"dictionary

    

    vocabdic=dict",6.73659079
full input sequence,6.736178277
scalarfromtensor [id bn],6.735119048
inbuilt constraint nonneg,6.734693878
"shows 

kernel died",6.733944954
keras/examples/,6.733933486
keras examples,6.733933486
keras/examples,6.733933486
`keras/examples`,6.733933486
nvidia-docker,6.732638889
`nvidia-docker`,6.732638889
learning rate change,6.731860776
target time series,6.73147541
layers import conv1d,6.7308261
requires physical action,6.73
multi gpus job,6.729558076
reproduce imagenet training result,6.729341535
"import activations

  file",6.728927298
no_inplace} [id bf],6.727619048
no_inplace} [id bg],6.727619048
no_inplace} [id bt],6.727619048
ground truth data,6.72745098
clone object <keras,6.726249986
exclude top layer,6.724882629
layers import maxpooling2d,6.723858552
pr makes #9796 irrelevant,6.722222222
decreasing learning rate,6.722222222
disk file path list,6.718607175
feature vector standing,6.717932752
ith feature vector,6.717932752
export rnn layers,6.717398742
"`



```python

  input_img = input",6.71571155
automatically zero-pad,6.715384615
custom normalization layer,6.714679904
image import img_to_array,6.713521853
simple character sequence,6.712026944
"values

print dataset

# normalize",6.709438785
pretrained inceptionv3 model,6.70878951
"program runs correctly

2",6.708333333
"0           activation_1983[0][0]            

total params",6.708309207
layer outputs -> empty tf,6.708188069
"assign

    use_locking=use_locking",6.705882353
cuda kernel compile failure,6.705652592
"<module>

    _pywrap_tensorflow_internal = swig_import_helper",6.705257271
language code starting,6.705023205
negatively impact performance,6.701612903
02d}-10fol-lstm,6.701465201
"test_model = model_2

test_model",6.700854701
one-hot,6.700512821
normalization import batchnormalization,6.700495857
"normalization import batchnormalization

     44",6.700495857
/home/user/,6.700493852
`on_train_begin` methods conditional,6.7
dynamic system equation,6.7
32gb ram machine,6.699788584
reach 95% classification accuracy,6.699744974
svhn data set,6.698681962
examples/mnist_siamese,6.698025552
"interpolate import *



  file",6.697677298
"np



def test_loss",6.697021419
"model

def baseline_model",6.696916101
invalid argumenterror  error,6.696712892
artificial stopping point,6.693452381
"del model

gc",6.690871196
destroy cudnn handle,6.689612015
"```

import os

os",6.68841826
"import os

    os",6.68841826
functional api model,6.688307094
model functional api,6.688307094
"compute

    packed_fn_values = fn",6.688226744
simple segmentation problem,6.687884457
rectified linear unit,6.6875
/private/var/folders/,6.6875
convolutional import,6.686925165
reading training data,6.686659517
preprocessing_input function mentioned,6.685286935
validation_steps = testsetsize/batchsize,6.683918129
cnn model baed,6.682763088
global contrast normalization,6.682709447
jointly train classifier,6.682696553
activations import softmax  #,6.682564349
n2 errors detected,6.678571429
"input



generator = generate_batches_from_hdf5_file",6.678419463
`initial_state` keyword argument,6.677906977
blob,6.677884615
final density layer,6.674882629
tensorflow backend --> comment,6.673013557
reasonable upsampling approaches,6.672222222
max-pooling layers,6.671981435
max pooled anymore,6.671428571
"4s 62us/samples

```",6.671352075
"```python

x_tensor = input",6.671267106
common ops,6.668367347
summer ops,6.668367347
"```python

train = tf",6.66719657
data/validation/cats,6.66713352
1000 training examples,6.666604288
400 training examples,6.666604288
layers import inputlayer,6.66545327
image segmentation task,6.663460364
"imbalance data

                         validation_data=",6.663049686
separate zoom rates,6.661904762
"make random number generation

#",6.661067237
created word embeddings,6.660177631
"works fine

features_conv1_1 =",6.659745547
combined long sequence,6.657605501
apache v2 compatible,6.657142857
path + src[sr] +,6.656156156
theano officially supports,6.654237606
"standardize_weights
    raise exception",6.653672032
"fps counter

    fps",6.653333333
lstm performance decreases,6.653078105
gpualloc{memset_0=true},6.653050933
validation mlp network,6.652014652
code runs nicely,6.651614114
tensorflow backend worked,6.651274427
#define global_mem /* empty /,6.650332226
#define local_mem_arg / empty /,6.650332226
"sns

import cv2",6.649975648
highly dimensional dataset,6.649801587
"```python

history = model",6.648476029
"keras



def dump",6.647542901
img_data[index] = get_image_data,6.647277228
entire validation set,6.646469077
"```python

inp = input",6.646267106
generating layer names,6.645470864
mnist hierarchical rnn,6.644623656
metrics import top_k_categorical_accuracy,6.643543985
nlp task,6.643442623
"# skip transitions

    _p_prev =",6.642857143
zx=zy=random,6.642694064
3 time-distributed copies,6.642222222
"import io_utils

----> 6",6.641812383
"np

import os",6.641806121
"np

import os



#",6.641806121
"end batch

x_train shape",6.639754333
8s 8s/step,6.639506173
expects dimensions nchw,6.63935743
"_call_cpp_shape_fn_impl

    raise valueerror",6.637778506
"_fix_unknown_dimension

    raise valueerror",6.637778506
"user  system elapsed 

 14",6.637423313
"user  system elapsed 

 16",6.637423313
"dataset

trainpredict_extended = numpy",6.636391626
install keras,6.63598045
install keras 2,6.63598045
constant{-1} [id bq],6.635854342
cudnn tensor descriptor,6.635006022
` returning dynamic shape,6.634681042
"sxq3w4pzpeyi5th7ussq5tlk3fljlmw5grlphfwglum



predicted values",6.63439347
building auto-encoders,6.634285714
returning static size,6.632043319
"dataset

dataframe = pandas",6.631827731
"embedding_vecor_length = 26

def create_model",6.631044905
give intuitive names,6.629310345
custom evaluation function,6.627872598
/filled { } bind def,6.627257026
/rounded { } bind def,6.627257026
export keras model,6.62677913
kl-divergence function,6.626239316
latest versiohey guys,6.625895725
neural network putting,6.625174825
ga_ssize x_row = indices_arr[,6.625
layer / backend support,6.624623649
layers import convolution2d,6.624480159
"11 dimentions

target = target",6.62295082
_stdev_ prediction performed,6.621138211
"code



```

def read_and_decode",6.620159019
time series element,6.62
"epoch_counter = 0



  def __len__",6.617156016
layers import maxpool2d,6.616968422
basic lstm implemented,6.616849817
mnist import load_data,6.616574288
"lstm



# initialize loss function",6.6161709
"tf

import os",6.616003179
"py



    def get_initial_states",6.615270318
extern shared type,6.614106823
asked questions,6.613964687
multiple input layers,6.613621825
"x13]



sgd = sgd",6.612975391
deeper level layer,6.612382629
#5737 implement rnn decoding,6.612270715
triplet siamese network,6.611538462
keras 1 argument `samples_per_epoch`,6.611433958
basically wrap tf layers,6.60964178
2/frameworks/python,6.609461169
py#l255-l257,6.609225413
"inputs

```



```python

[<tf",6.608276241
previous feature vectors,6.607110241
backward propagation pass,6.606933911
3d structure required,6.606837607
keras framework,6.606715387
arbitrary loss tensors,6.606491074
layers import activation,6.606028561
conv2d_2/kernel/read,6.605075082
low-dimensional data,6.604601518
assume learning phase,6.601960784
treat `on_train_begin` event,6.6
"# inferencing

model = load_model",6.599962105
"get_config

    layer_config = layer",6.598795673
nlp problem,6.59870317
"layers import *

img_width",6.598389187
objective function `fn,6.59821606
allocate filter descriptor,6.598076923
single class weight,6.596752347
support multiple-input,6.596239739
"variable

    strict=false",6.595891969
"inf



    def on_epoch_begin",6.593544905
program raises `tensorflow,6.593434343
create incremental prs,6.593333333
32 bit floating point values,6.59148572
keras input layer,6.591119503
"argv[2]

model = load_siamese_network",6.590871196
install tensorflow,6.590332257
"download

        raise condaruntimeerror",6.589285714
"evaluate api

    test_logloss",6.589102564
"convolution descriptor

366       int",6.588333333
grid search/cross_val_score,6.587593985
"tensorflow

```

collected avg",6.586898396
implement weighted categorical_crossentropy loss,6.585704084
dimensional input data,6.585160872
"```

diff --git",6.583797744
off-by-,6.583333333
batch norm layers,6.581128597
"roc_auc_score

    preds_train = np",6.579865403
set filter descriptor,6.579564315
"ways people suggested



np",6.578097726
loss calc occurs,6.577934981
limit memory usage,6.576719577
similar directory trees,6.576563959
simple custom initializer,6.572396653
display import html,6.572215314
downloaded anaconda,6.572139303
"entire stack trace

     71",6.569285714
entire stack trace,6.569285714
support function paths_to_tensor,6.569251364
13s 9ms/step,6.568077601
"input_shape]



def build_generator",6.566969275
hardcoded batch size,6.566587306
"<module>

>     model_rmse = clone_model",6.566368382
odd input sizes,6.566043225
"flow_from_directory

    follow_links=follow_links",6.565891473
"%<-% imdb



x_train <- vectorize_sequences",6.565318163
all-zeros,6.563829787
layers import upsampling2d,6.563635088
ps level 1 devices,6.5625
test localization accuracy,6.562091847
multiple things ranging,6.56168739
"76532650    lstm_2[0][0]

==================================================================================================

total params",6.561250383
change local layer,6.56075947
"gather

    return tf",6.556259141
minimum size permited,6.555852843
adding m_a + m_b,6.555555556
"from_config

    layer = get_or_create_layer",6.555317412
loader imports backend,6.553871829
"__init__

    expected_shape=expected_shape",6.553763441
default classification block,6.5530119
"__newobj__

    return cls",6.55294223
"predict

    check_batch_dim=false",6.552455116
"```python

    w1=mdl",6.552193578
well-defined state,6.551949145
"desired shape

        piece_pool = flatten",6.551473022
[graph-without-bn],6.550945378
keras stable 2,6.550193648
"comparison`

setting `sys",6.55
"= net

    net = layers",6.548171912
explicitly called `keras,6.548103056
"]

dist = lab",6.545640327
incorrect classification assuming,6.545454545
adapting mnist mlp,6.545238095
"resnet50

#base_model = inception_v3",6.544712575
"```

fetching packages",6.544502618
n_train = int,6.544230769
upsampling* layers work,6.543868312
dropout rate signifies,6.542911877
[variational autoencoder demo],6.54040404
theano ops,6.539996257
step function execute,6.539078822
epoch*nb_data]=get_gradients,6.538929001
theano scan function,6.537868227
"```python

>>> model = model",6.536966273
"_standardize_args

    assert initial_state",6.53655914
problem gaining access,6.53620317
adding mxnet backend,6.535617861
computer 2= 16gig ram,6.534090909
zeroing negative weights,6.533848884
misc import imread,6.533753775
bounding box colors,6.533730159
full stack trace,6.533730159
"00gib

free memory",6.533333333
unbalanced data set,6.532015296
"_run_code

>     exec code",6.530780781
"_run_code

    exec code",6.530780781
/farizrahman4u/seq2seq,6.529220779
"sgd

#im = increasemomentum",6.528709918
model compilation annnnnnd,6.528371196
"run_internal_graph

    shapes = _to_list",6.527777778
verbosity levels exist,6.527472527
"keras 2 api

typeerror",6.526796212
core import,6.524644463
"simplernncell

ht --> yt",6.523076923
[keras contrib],6.522123473
[keras-contrib],6.522123473
keras contrib,6.522123473
elemwise{cast{int32}} [id,6.521719135
"embedding layer

keras",6.521567506
imagedatagenerator preprocessing steps,6.520370814
aforementioned time frame,6.52
simple test program,6.51891253
implement adversarial learning,6.517647059
achieved data parallelism,6.516339869
create custom layers,6.51626984
"layer

non_embed_model = model",6.515753825
allocate tensor descriptor,6.515529753
"tensorflow backend

      weights_path =",6.51491079
favourite nn architecture,6.514607812
"4492

> batch end keras",6.5137583
"4463

> batch end keras",6.5137583
"4609

> batch end keras",6.5137583
"4736

> batch end keras",6.5137583
high dimensional dataset,6.513049451
return-sequence=true,6.512419702
py --prototxt mobilenetssd_deploy,6.509225413
feature list bottleneck_features_train_v3,6.508741391
validation_steps=validation_samples / batch_size,6.507946591
validation_steps=validation_samples// batch_size,6.507946591
--> 151         validation_steps=validation_samples// batch_size,6.507946591
simple regression problem,6.507433329
custom metric functions,6.506661485
"# proposal

def _get_batches_of_samples",6.506044905
"maps = []



    def eval_map",6.506044905
"_predict_loop

    batches = _make_batches",6.505555556
started documentation,6.505454545
[elided 1 identical lines,6.50152439
"shape2 = shapes

    return",6.500344828
/shuyib/3cc4b59b8eb58513a3c3f887694bda59,6.5
{pop languagelevel}{1} ifelse,6.5
trained_model/corrected2_jpeg_xception_,6.5
"1170us  cudrivergetversion



```

titan",6.5
"create_node

    output_shapes = to_list",6.5
simple cnn network,6.497874798
sliding window approach,6.497282609
/home/kevin/,6.496403873
"inf detected

big",6.496323529
class weights dynamically,6.494846327
custom metric function,6.490933588
polygonical bounding boxes,6.489285714
accumulate true positives,6.486384266
# create numpy arrays,6.486324338
current allocation summary,6.485639203
mini-batch sgd,6.483888826
"== false

`

`def get_gradients",6.482413064
updated keras version,6.482225964
# image data generators,6.481898546
const int set_instead_of_inc,6.480882353
time series samples,6.480240964
logic started,6.478787879
"]

    y_val = labels[-num_validation_samples",6.478478478
"layer



class proxy",6.477056542
train reproducible model,6.475765551
04-precise-x86_64-2,6.475
augmented data generated,6.47214795
input lengths ranging,6.471598781
correct stepwise reduction,6.471311475
generate grid inside,6.470731707
projects page,6.47008547
inceptionresnetv2 pretrained model,6.469659075
resnet cnn network,6.4680645
"import utils

      4",6.467478243
"lambda



def weight_variable",6.464846403
class mode duality,6.464673913
"training

    ae = sequential",6.464460027
**api conversion decorators**,6.464102564
"batch

    class parameterhistory",6.462908376
keras blog post],6.462754035
doc proposes implementation,6.462627463
"= current

                    old_lr = float",6.462189958
"layers[1]



    expected_initial_normalization_scales = np",6.461370648
"layers[3]

    expected_initial_weights = np",6.461370648
original examples,6.461012565
dist = tf,6.460813899
validation data set,6.460586724
"normalize

mean_image = np",6.460207283
classic ocr task,6.46010929
_fn_cache[inputs] = theano,6.459507698
"# sample weights

                        [[y_train[batch]]]",6.45628157
constant/array initialized layer,6.455746233
"model

estimator = kerasclassifier",6.455393613
equivalent atrous dilation,6.454545455
keras_bug,6.454545455
implement conv1dtranspose,6.450980392
"backward compatibility

                bs =",6.448717949
total_loss = loss_weight * output_loss,6.44858156
total_loss += loss_weight * output_loss,6.44858156
"np_epoch_init=1
sgd = sgd",6.446308725
imagenet image preprocessing,6.445992796
static validation sample,6.445688546
`y_true[ind] = y_pred[ind] `,6.445174638
# convert 3d tensor,6.444247702
% layer color sequence,6.44343038
keras source code,6.442739135
"_make_batches

    num_batches = int",6.441666667
sequence length wasn,6.44163861
modified softmax weights matrix,6.440886371
facial point network,6.440705128
saved_model import builder,6.440513682
"registered kernels>                                                                        

[[node",6.437896825
batchnorm ops,6.437598116
"<module>

    shared_layers = nn",6.437526774
sequence2sequence model structure,6.437025042
tiff file dan,6.434436343
dummy lambda func,6.433847286
issue #511 keras runs,6.43243049
binary class matrices,6.432033398
save weight separatly,6.430148661
"data tensors

data_tensor",6.429920116
bad_color=tensor<type,6.429815468
/fchollet/keras,6.429680828
fchollet/keras,6.429680828
----> 1 tr = transformer,6.428571429
limit memory consumption,6.428571429
input mini batch,6.426777689
"dtype=float32>



    outputs

    <tf",6.426323979
two-part state,6.426149834
3x3x1x32 convolution filters,6.425614035
"6           hidden[0][0]                     

====================================================================================================

total params",6.424975873
custom stateful metric,6.424694272
ve installed keras,6.424665641
write generator extensions,6.424348069
model starts converging,6.42420453
transfer learning,6.423809524
"transfer learning

    #",6.423809524
distributed fashion,6.422222222
keras 2 argument `steps_per_epoch`,6.421204073
reset graph identifiers,6.421137686
[reset-graph-identifiers],6.421137686
`trainable=true/false`,6.420752425
write bidirectional clstm,6.419114688
dense layer claims,6.418619581
cell state evolves,6.417503218
character level encoder,6.41722973
"5



mac osx



keras 2",6.416860315
perform teacher forcing,6.416666667
identify dynamical systems,6.416666667
afaik inconsistent calculation,6.416666667
"get_resnet_single_image_model_no_softmax

    cnn_input = input",6.416043225
pre-trained,6.414189837
code variational_autoencoder_deconv,6.414114114
"func_load

    code = marshal",6.414114114
weights previous trained,6.411624156
option `collocate_gradients_with_ops=true`,6.410626691
simple feedforward model,6.410315641
code works seemlessly,6.407447447
feeding 1200 stroke sequences,6.406926407
framework/versions/3,6.406521739
framework/versions/2,6.406521739
shape [id bc],6.406109614
"#3rd layer

model",6.404642714
complex labeling information,6.404371585
"np

import collections",6.404217469
remaining top layers,6.403727467
importing module backend,6.401986243
keras lstm implementation,6.4014658
word attention code,6.401171501
multi-dimensional,6.400641026
simple sequential model,6.400244551
5/http/client,6.399932981
blank class id,6.399792961
12*12 array include unique index,6.399779487
recurrent models,6.39923332
selected implementation supports,6.399082312
multiple lstm layers,6.399043801
scripts>activate tensorflow,6.396853147
tensorboard scalars working,6.393217893
vanilla hidden layer,6.391549296
train image classifier,6.391310785
"expectation`

`loss3 = model",6.390871196
similarly nonsensical warning,6.388888889
"demo 

`

    base_model = nasnetmobile",6.388554217
default tensorflow module,6.387872901
stacked cnns,6.384615385
making keras compatible,6.383526982
generating test predictions,6.382894158
"rescaled images



``` 

    # inputimages",6.381578947
trainable parameter count,6.381308619
early draft branch,6.380952381
tensorconstant{2} [id ba],6.380952381
"weight[0] = weight_change

    model_base",6.380062305
moving average decay,6.38
accept multiple sequences,6.379565418
implement inception module,6.377502031
"reproducibility

numpy",6.377463054
"-num_validation_samples]

    y_train = labels[",6.377199017
keras documentation **content**,6.376860315
sample pnet model,6.37465498
user-level problem,6.373626483
human check,6.373534338
opt = keras,6.373000666
dense started,6.372524831
generate elements indefinitely,6.370731707
3s 51us/step,6.370275404
represent distinct color,6.37012987
draw items randomly,6.367788716
cpu supports instructions,6.366826672
batch size scheduler,6.366587306
conv1d_3/convolution/conv2d,6.366524823
conv1d_63/convolution/conv2d,6.366524823
simply packaged solution,6.365923385
losses import mean_squared_error,6.365740955
tensorflow session,6.365702479
"std

        zca_whitening=false",6.365562298
"std

                zca_whitening=false",6.365562298
"std

                                       zca_whitening=false",6.365562298
keras code briefly,6.364307762
/home/rockstar/,6.363070539
#/home/ga97beh/,6.363070539
/home/cdalmaso/,6.363070539
/home/pi/,6.363070539
/home/joe/,6.363070539
"> 

> /home/marcin/",6.363070539
/home/marcin/,6.363070539
/home/rajat/,6.363070539
/home/bparaj/,6.363070539
/home/glauco/,6.363070539
/home/kzh/,6.363070539
pr implements step 3,6.361728395
require explicit target,6.36147541
"<module>

    downsample_5 = deconv3d",6.360019175
adding extra layers,6.359283023
8 audio tracks,6.357142857
/titu1994/densenet,6.357142857
synchronize dropped units,6.356521739
latest versioplease make,6.356039266
muti-task network,6.354981084
label val data,6.354029745
created weights & json model,6.350991339
"# vgg16

    model = sequential",6.350861835
call model errorloss,6.350696524
standard `imagedatagenerators` `flow_from_directory`,6.350205198
multi-gpu,6.350179284
tesla k80,6.35
"0

__________________________________________________________________________________________________

model_1",6.349021592
training makes tf,6.348038022
single gpu multiprocessing,6.347387721
web traffic history,6.345238095
started working,6.343434343
time_distributed_1/reshape_1,6.342857143
keras test script,6.342428231
timedistributed layer distributes,6.341549296
data set consisting,6.341539105
defaults remain `interpolation=,6.341346154
"from_config

    layer = layer_module",6.341031697
consumer/gpu training,6.340736042
"* num_values





def sig_eq",6.339378238
previous hidden state,6.338931789
"match model input_shape dimensions

#",6.338854145
five-output model,6.338026696
"output

modelfinal = model",6.338026696
"# preprocess

min_max_scaler = preprocessing",6.337944664
break existing functionality,6.337662338
expect tensorflow backend,6.336459612
`sequential` instance directly,6.33367891
common entity pair,6.333333333
"run_local                      

    hooks=train_hooks",6.333333333
recurrently connecting,6.333333333
parameter `return_sequence=true`,6.332769808
# convert class vectors,6.332173913
"generate

        raise chunkedencodingerror",6.331445993
generate samples indefinitely,6.330972671
"dataset

scaler = minmaxscaler",6.330357143
additional callback function,6.330214472
"## code



<del>https",6.328604275
/home/super/,6.328587781
replace f_start = get_r,6.328571429
trained embedding layer,6.328420837
`max-pooling` layer,6.326469931
linux suse,6.326086957
linux pcs,6.326086957
linux partition,6.326086957
1d cnn model,6.325620231
# add gaussian noise,6.324624124
merge import concatenate,6.323352844
"_**



def ctc_path_probs",6.323118076
global logging option,6.322638146
code runs correctly,6.322447447
"function



```



def w_categorical_crossentropy",6.322284221
image channel axis,6.320295562
initial hidden state,6.318406337
# validation data generator,6.318398647
requires `unroll=true`,6.318236118
character-level information,6.31709681
sklearn cross_validate/gridsearchcv,6.31443299
total data matrix,6.314106694
single gpu model,6.313258917
training dataset divided,6.313221593
pr  #8178having model,6.313093419
git clone,6.312369172
cats data set,6.309793074
activity regularizer,6.307692308
"dataset

        samplewise_center=false",6.306725302
"dataset

        samplewise_std_normalization=false",6.306725302
"dataset

                samplewise_center=false",6.306725302
"dataset

                samplewise_std_normalization=false",6.306725302
"dataset

                                       samplewise_center=false",6.306725302
"dataset

                                       samplewise_std_normalization=false",6.306725302
output time step,6.306661672
"inverse_transform



defsgd=sgd",6.306487696
"y_holdout





def create_submission",6.306044905
dogs pictures index 12500-13499,6.305610561
"y_test]





def normalise_windows",6.304387446
"y_test





def split_validation_set_with_hold_out",6.304387446
backend framework,6.303250711
"dataset

testpredict_extended = numpy",6.303058292
[previous line repeated 970,6.302936415
timedistributed wrapper forces,6.302631579
combine word-level,6.302335165
recent pypi redesign,6.301178203
[dynamic routing,6.3
1120] creating tensorflow device,6.298256146
1195] creating tensorflow device,6.298256146
977] creating tensorflow device,6.298256146
1045] creating tensorflow device,6.298256146
1030] creating tensorflow device,6.298256146
975] creating tensorflow device,6.298256146
838] creating tensorflow device,6.298256146
latest versiovgg difference,6.296948357
"<module>

    callbacks=callbacks",6.294519458
"km





def concat",6.294180498
reconst_layer_2 = dense,6.293736952
xlarge aws machine,6.290697674
"```python

y_train = tf",6.289488362
potentially related issues,6.289473684
highly flexible method,6.288888889
session property,6.286157025
` image data format,6.285560162
weighted metrics correctly,6.284469697
"function

    return function",6.28282346
"function
    return function",6.28282346
breaking backward compatibility,6.282051282
custom built metric,6.281837129
"load_model

    model = model_from_config",6.281780287
previous target placeholder,6.281713505
decay = ops,6.28170068
processing image shape,6.27922601
custom lstm layer,6.278890203
losses import binary_crossentropy,6.277993207
inside bidirectional layers,6.277536991
gray scale image,6.27679605
turn current vae,6.276714514
ve started,6.275482094
"y_train





def load_test",6.275135814
true positive sequence,6.275118352
full inceptionv3 model,6.274446076
training huge model,6.273735646
convolutional `_conv`,6.273684211
slice operation index range [0,6.273489349
"inceptionv3

base_model = vgg16",6.27274638
improve metric flexibility,6.272151899
/roxana/python3,6.271226415
"binary_op_wrapper

    return func",6.271223948
"tf

import random",6.271108591
training time slowdown,6.269531117
support multiple inputs,6.268075302
alexnet/checkpoints/checkpoint-05,6.267651888
validation rate decreased,6.267460317
describing specific function,6.266239316
result element wise,6.265152643
"branches

processed_a = base_network",6.261660079
read large files,6.261257386
simple string parameter,6.260829987
pass training=true,6.260798012
#define ga_short short,6.260759155
low gpu memory,6.26002213
#define nan __int_as_float,6.258248678
full state sequences,6.257185757
"while_loop

    result = loop_context",6.256329114
"avg_fit = []



def road_lines",6.256044905
models import *,6.254579537
set parameter callbacks,6.253914284
classification models,6.253459795
"implementation

282           err = cudnngetconvolutionforwardalgorithm",6.252132531
small keras model `,6.250155754
> found 4485 images belonging,6.250097466
found 13581 images belonging,6.250097466
found 6000 images belonging,6.250097466
found 16 images belonging,6.250097466
> found 367 images belonging,6.250097466
"```

found 600 images belonging",6.250097466
found 91 images belonging,6.250097466
amazon ec2,6.25
"raise_exception_on_not_ok_status

    pywrap_tensorflow",6.25
"embedding



trainlabels = pd",6.249717035
"# exit early

  file",6.248722058
"# exit early

      file",6.248722058
saving bottleneck features,6.247979798
"attention

    att_vec2 = lambda",6.247690387
400 validation examples,6.245644599
use-case,6.244755245
seq-to-seq,6.244693058
# reshape training data,6.243914368
ops created,6.243709813
running **stacked lstms,6.24241801
stochastic optimization` section 3,6.241486068
"return model



rnn_model",6.241216024
45 pst return super,6.240862069
"__call__

    storage_map=getattr",6.24057971
"__call__



    storage_map=getattr",6.24057971
avoid float64 upcasting,6.24
trained cnn model,6.239810068
mnist sequential model,6.23913344
"30          main_input[0][0]                 

____________________________________________________________________________________________________

output_power",6.238095238
implementation training & testing,6.237934558
"np

    import pdb

    

    #",6.237550802
steps_per_epoch=trainsetsize/batchsize,6.237547893
match runtime version 3,6.237140872
map keras code,6.235275504
"layer duplication

shared=",6.234960148
"`

`#fit model`

`history= model",6.234824748
returning static shape,6.234681042
model2 refines output,6.233641986
`standardize` function applies,6.232905983
running python autogen,6.232634349
keras model compiler,6.229953734
mask binary crossentropy loss,6.229895334
copied keras source,6.228625021
js <code></code>,6.228228228
"return res

~~~~



shouldn",6.227267905
"stop_epoch = false

    break

```",6.226368159
open shared object file,6.226367302
affect learning results,6.226272578
"#layers

        model = sequential",6.22619424
"yield vect





ignores",6.22606383
build installs tf,6.225921236
ground truth tensor,6.225786164
propensity network shown,6.224696356
accuracy drops significantly,6.220957096
`input_length` keyword works,6.220869565
"print trainpredict_extended

print np",6.220838689
deep conv layer,6.219635716
shared hdf5 library,6.219336779
batch normalization layers],6.218383499
embedding layer produces,6.215818302
"__init__

    session",6.214920466
batch loss checkup,6.214756401
"408232

> batch loss checkup",6.214756401
"419726

> batch loss checkup",6.214756401
"448657

> batch loss checkup",6.214756401
"683458

> batch loss checkup",6.214756401
"771304

> batch loss checkup",6.214756401
"real features `

`return`",6.214197641
import matplotlib,6.213240955
"```

import tflearn",6.213240955
keras-provided metrics,6.212754743
1m images dataset,6.21193609
pure keras running,6.21093745
running pure keras,6.21093745
"autoencoder

sgd = optimizers",6.210691019
losses import mean_absolute_error,6.207559136
"__init__

    raise exception",6.207435473
autoencoder/u-net,6.207070707
global session,6.20661157
related weights variables,6.20567551
observed larger fluctuations,6.204761905
"tensorflow



    # tensorflow_step_function",6.204545455
custom lambda layer,6.202893167
basically steps_per_epoch = samples_per_epoch/batch_size,6.202317095
low frequency tokens,6.202150538
keras spec serve,6.200193648
"_do_call

    return fn",6.200178715
convert numpy code,6.200148597
alternate fashion,6.2
fine-tune vgg19,6.199745547
adding batch norm,6.199623352
"stop_epoch = true

            elif",6.198505478
/library/python/2,6.197816473
"np



def plot_results",6.197021419
supported inside `scan`,6.196153846
"__init__

    raise typeerror",6.193644393
auditing tf behavior,6.19295135
384       int filter_w = cudandarray_host_dims,6.191666667
"code

```

data = mnist",6.191565095
"maxpooling2d

import os",6.191053071
"training operation



> model1",6.190771427
parametric activation function,6.188632789
zero-padded inputs,6.187878788
"manipulation 



```

output = concatenate",6.185511664
questions incoming,6.185393258
compute mutlibox loss,6.185271938
"detected

nanguardmode found",6.185185185
adding dummy labels,6.184496997
suspected over-fitting,6.184210526
train simple cnn,6.183135453
memory problems training,6.18286445
find detailed explanations,6.182692308
imagedatagenerator specifies `featurewise_std_normalization`,6.182614134
"xception model   





layer",6.182420492
zca whitening,6.181818182
common num_words amounts,6.181818182
basic preprocessing,6.180602007
"inputs

        tuned_model = model",6.178749984
"print score

        print prediction



```",6.178068055
multi-class,6.177814939
param string filepath,6.177636566
keras master,6.177071119
__init__ function fixed,6.175558313
theano backend** leads,6.17550074
"0

________________________________________________________________________________

________________________________________________________________________________

layer",6.174882629
filter numby array,6.174771167
simply open ipython,6.174681063
model begin training,6.173735646
dummy loss functions,6.173489151
losses import categorical_crossentropy,6.173109376
[imdb bidirectional lstm,6.172893773
"] + inner_initial_input

    

        def _run_inner",6.172711572
"x_test_id





def cache_data",6.172711572
caused nan val loss,6.170596398
/bin/sh -,6.170454545
"features]

trainx = numpy",6.170253597
"script



```

class autoencodercreator",6.169940411
sequence labeling task,6.169133231
1912     pre_summaries = ops,6.168367347
1914     post_summaries = ops,6.168367347
_initial_value = ops,6.168367347
gaussian mixture model,6.166628772
validation set possession,6.166469077
lowest validation loss,6.1659267
import applications,6.165621907
applications import *,6.165621907
"active_class_ids 

pred_active = tf",6.165173572
numpy/python,6.161258363
# test initial values,6.160767182
active/nonactive pixels,6.160714286
large minibatch sgd,6.160654362
yield vectplease make,6.160154739
uncertain behaviour happening,6.159709619
2d convolution window,6.159166667
node connecting,6.158730159
"avx2 fma

traceback",6.158131177
"numpy arrays

print",6.157922092
predicts feature vectors,6.157705479
"wrapper

>     return func",6.157188861
"wrapper

    return func",6.157188861
"wrapper

        return func",6.157188861
keras checkpoint file,6.157043785
"prediction outcome + 2*lookback

2",6.154471545
full sequence processed,6.153468386
regularization multiple times,6.152794222
gather `total_loss` operation,6.152655634
parallel cnns,6.151515152
seperate data loader,6.151260504
set `keras_backend=theano`,6.151193226
modifying `step` method,6.150617284
"time step

    model",6.150377369
"num_partitions







dyn_partitions = dynamicpartition",6.15
customized versions,6.15
create validation data,6.149355742
custom metrics function,6.149084719
input sequence length,6.14715552
metric operates isn,6.147151899
3d input shape,6.146328663
multiclass single output,6.145004962
script documentation claims,6.144433164
backend completely breaks,6.143157543
loading model definiation,6.143110002
`load_model` command directly,6.142314593
data/train/dogs,6.140916764
"__iter__

    raise typeerror",6.139880952
recompilation step,6.139506173
/encodingvector 256 array def,6.139149405
keras docker,6.139082537
smaller physical batches,6.138888889
custom loss functions,6.138531524
deprecated public symbols,6.137931034
"theano backend

```bash",6.136539701
x_i = list_of_vectors/tensors[,6.135802469
"data

    return np",6.135438989
callback     **def on_batch_end,6.131759191
set `initing=false`,6.130932475
"activation



def mygenerator",6.128438377
"sequential





def perplexity",6.128116672
"1571 

   1572   return c_op



valueerror",6.127409048
simple cnn model,6.127207533
full cnn model,6.127207533
recently update keras,6.127177775
memory allocation problem,6.126480948
unicode char,6.125
building tensorflow,6.124545455
directory doesnt exists,6.124183007
bottleneck feature values,6.123458599
add 3rd class,6.123262684
custom **loss function**,6.122803627
custom loss function,6.122803627
gaussian dropout layer,6.12132986
network works fine,6.121284009
convert keras model,6.121064845
"layer_from_config

    custom_objects=custom_objects",6.119957537
compute updates based,6.119087838
vgg net model,6.118648974
"backends

    global bn_axis",6.118104118
linux machine,6.116784631
"run_cell

>     return super",6.115862069
"run_cell

    return super",6.115862069
remove pooling layers,6.114838578
"/baxter001/5b2bb9e65b587f893298f09102436ca1

https",6.114490161
"keyboardinterrupt

```



releated code",6.114114114
extremely high confidence,6.113247863
core model running,6.113018507
fixed validation data,6.111577965
"#fc layers

        model",6.11126533
####### test simple model,6.109783726
implementation=1 works fine,6.109552497
implementation works fine,6.109552497
attention location parameters,6.108888889
seq2seq model referenced,6.108728339
"= input_data  



   def on_batch_end",6.107949667
small data set,6.107772872
find matched layer,6.107574937
data sets due,6.106617647
"``

``batch_size=10``

``ada=rmsprop",6.106192205
manual experimenting process,6.106060606
"```python

keras",6.105417529
"```#python

keras",6.105417529
original lstm layer,6.103620558
10 consecutive time steps,6.102795699
nvidia gtx 970,6.101325758
nvidia gtx 1080,6.101325758
"model



    def __build_train_fn",6.096916101
ac-gan claims,6.095238095
"]

        epoch=0

        def on_epoch_begin",6.094973906
real simple thing,6.094304388
print correct output shape,6.091888628
"validaccuracy

}

model = keras",6.091064845
resulting weight matrix,6.089445292
detailed stack trace,6.089285714
set include_top=false,6.088678953
"<module>

    predictions = test_model",6.087966903
ground truth outputs,6.087179487
incorrect training loss,6.086886388
v-net code,6.086336336
half precision training,6.085642228
"_error_catcher

        yield

      file",6.085500173
"json_progress_bars

        yield

      file",6.085500173
"external data

model",6.084988843
launch keras 2,6.083526982
#aux channel size,6.08312557
cnn architecture proposed,6.082563534
"tf



keras = tf",6.080540793
unknown metric function,6.079770525
edit $home/,6.077356254
dense layers share,6.076631086
filter weak detections,6.075
lamda function doesn,6.074860006
toy examples,6.074648928
"return model



build_model",6.074549357
gpu memory allocated,6.074538259
performed training pass,6.074413746
"sgd

    early_stopping_m = earlystopping",6.073154362
loss ops,6.072389285
previous hidden states,6.071164021
"dense



#

# custom layer",6.071161954
lstm layer produces,6.070792275
additional forward-pass,6.069810165
general questions,6.0677462
time distributed layer,6.067104851
lstm keras code,6.065772964
native tf optimizer**,6.064039969
designed conv networks,6.0625
"0

__________________________________________________________________________________________________

lambda_2",6.061842105
core keras,6.061597157
steps_per_epoch=num_training_samples/batch_size+1,6.061576355
steps_per_epoch=training_samples / batch_size,6.061576355
n-percent samples,6.060240964
separate function call,6.059397977
"trainable = false

adversarial_model",6.059368159
removed long  ago,6.05900849
"fit_generator

    pickle_safe=pickle_safe",6.058883249
gpu op class,6.05810752
high validation accuracy,6.057220832
"py



euclidean distance",6.056593834
data/train/cats,6.052027875
16gb ram,6.051948052
total examples,6.051921656
issues opened/closed,6.051282051
train loss decreases,6.050821055
"save_model

    topology",6.050766654
generated output improving,6.050185802
"return

        return output *",6.047845155
d_input = d_input  # dimention,6.047619048
[analysis doc],6.046153846
"<module>

    model = train_model",6.046128467
scikit_learn wrappers,6.045584046
debugged packages,6.044502618
pretrained weights obtained,6.042888864
"keras lstm model

#",6.042530046
providing target tensors,6.042515974
resnet50 application model,6.0424841
#opt = optimizers,6.042161856
opt = optimizers,6.042161856
# opt = optimizers,6.042161856
"2]=testy

testy=scaler",6.041666667
kernel void k_vector_add_fast,6.041637262
current batch size,6.040271517
explicitly saving tf,6.039776747
"# attention

    att_vec0 = timedistributed",6.038888889
`# raises` section describing,6.03625731
notebook session,6.036157025
define complex transforms,6.036046512
hdf file descriptor,6.034436343
batch_normalization_1/cond/fusedbatchnorm,6.032967033
completely useless network,6.032967033
complicated data set,6.032015296
share layer works,6.030715962
function stack tracing,6.030525031
development version,6.028328612
make custom function,6.027872598
experiencing unexpected behavior,6.027777778
"score_array

            score_array *= mask

            #",6.026966292
"callbacks_list = [checkpoint]



parallel_model",6.025674663
"trainable = false



    model",6.025239356
"trainable = false

    model",6.025239356
"trainable=false`

`model",6.025239356
"trainable=false

model",6.025239356
"trainable = false



model",6.025239356
"trainable=false



model",6.025239356
"__init__

    constraint=constraint",6.023151196
batch normalization test,6.02245745
python shell,6.021890547
stateful rnn state,6.021650683
2d-convolution layer,6.021549296
nnvrtc compile log,6.021248722
import numpy,6.019275437
"```

import numpy",6.019275437
"`



import numpy",6.019275437
47 import numpy,6.019275437
1 import numpy,6.019275437
"**



import numpy",6.019275437
"5

    

    import numpy",6.019275437
"targets = []



    def on_batch_end",6.019121828
[ github jupyter notebook,6.017904509
fairly large dataset,6.017857143
dynamic axis makes,6.017741935
dummy input equal,6.017336329
"callbacks = [checkpoint]



model",6.016249416
3x speed increase,6.015151515
"allow_growth = true

config",6.014955695
3-neuron-dense-layers,6.014131086
2 dense fc layers,6.014131086
final dense layers,6.014131086
"0                                            

__________________________________________________________________________________________________

sequential_1",6.011842105
deprecated numpy function,6.010204833
`$ make notebook gpu=1 #,6.008629168
`$ make notebook gpu=0 #,6.008629168
medical images im,6.008563074
batches test data,6.007474621
architecture hidden layer,6.007220938
conv2d_2/kernel_0_4,6.006896552
run garbage collection,6.006435006
"```

   def mse_nan",6.006044905
"_uses_learning_phase = true

            

        print",6.001315354
created cnn successfully,6.000567691
similarly simple scenarios,6
"]=y_trainros

labros = dfros[",6
steering_label = text_steering,6
"internal_convert_to_tensor

    ret = conversion_func",6
development fork,6
development activities,6
"put_count=2141 evicted_count=

2017-09-12 12",6
hundred megabytes,6
upcoming development,6
highest validation accuracy,5.999528524
"`recurrentwrapper`



```

stateinput = input",5.999376559
explicit loss values,5.998941724
"import random

random",5.998629082
"# normalize



        adam = optimizers",5.99728126
"from_config

    function = func_load",5.996674099
1st input dimension,5.99513927
simple `lambda` layer,5.994795238
response = requests,5.993684211
45 pst encoded_vid = lstm,5.993131868
# handle dimension ordering,5.992821535
"class

mapload = open",5.991304348
"_**

def ctc_update_log_p",5.989784742
running keras version 2,5.989266062
str cvs show,5.989138671
restored correctly state,5.988336551
lambda layer runs,5.987850794
small data sample,5.98699234
stateful=true introduces,5.986384266
"print trainx



# reshape input",5.986368122
integrate tensorflow code,5.985326235
"logits



    epsilon = _to_tensor",5.984868421
"logits

    epsilon = _to_tensor",5.984868421
examples/babi_memnn,5.983739837
concrete examples,5.983739837
"_recursive_list

    return sorted",5.983678161
metrics import mean_squared_error,5.983543985
"model  

sgd = optimizers",5.983380397
function declared inside,5.982905983
function parameter **`from_logits`**,5.980806677
"exit code 1

```



**function",5.98035343
recurrent attention,5.980116959
trainable embedding layer,5.979373857
"ctc_path_probs

    mode=nanguardmode",5.979166667
"output video

vid_output =",5.97792473
script works perfectly,5.977766497
pretrained imagenet weights,5.976954798
input->output sets,5.975698725
# score trained model,5.974985845
"np



def create_dataset",5.974799197
h5` formatted model file,5.973694636
keras dot function,5.972682965
wrt total loss,5.972203756
ve accidentally created,5.972036681
shape-related variables,5.971493662
pretty simple things,5.970760234
loss function composition,5.970261254
contrastive loss function,5.970261254
"py



**basic issue",5.969346871
low level `add_weight`,5.966733871
input data size,5.966013715
"probability

p1all = decode_predictions",5.964285714
advancedsubtensor1 [id bs],5.964285714
padded vectorized sentences,5.964285714
"linux

> type",5.963449594
"```

import keras",5.963434603
import keras,5.963434603
>>> import keras,5.963434603
time distributed prediction,5.963360434
dense_1/kernel/read,5.96269466
adopt tf api,5.96260947
small cnn network,5.962521263
network parameter set,5.962488319
parameter server architecture,5.962057184
[errno 104] connection reset,5.961538462
#define ga_int int,5.961046512
optimizer internal api,5.960725371
recurrent concept**,5.957894737
"128-dimensional

    encoded_input = input",5.957709892
trainable weight variable,5.957586115
"batch_response



#%%

model = sequential",5.955800106
"<module>

    regr = nn_model",5.955257271
explicit target passed,5.954332553
`categorical_crossentropy` expects targets,5.953778677
"_dims[key]

indexerror",5.952272727
"trainable = false

    x_train",5.952067274
desired identity matrix,5.951807229
actual performance slows,5.951612903
theano optimization disabled,5.951460843
binary install,5.951360573
single input type,5.951255325
depending output data,5.950364056
saving state tp %,5.949249249
"rnn

    inputs = reverse",5.94916911
cnn framework,5.948413631
applies batch normalization,5.947989365
initialisation code embedded,5.947447447
cryptic error message,5.946712892
"convergence

    sgd = sgd",5.946308725
"numerator = y_true*y_pred

    numerator =",5.945174638
unknown function type,5.944981264
/bin/bash,5.943181818
"single gru layer

#",5.942450401
dropping entire words,5.941538462
"_do_call

    raise type",5.940934066
"```python

epoch 1/30

traceback",5.940379297
compute bottleneck features,5.940340909
1053] created tensorflow device,5.940265279
1041] created tensorflow device,5.940265279
# start increasing back,5.938983051
keras activation function,5.938826437
dev,5.93877551
"pass

        def on_batch_end",5.937594201
spyder-py3/ai_autodraw,5.936507937
`pip uninstall -,5.935483871
seq2seq models,5.934195726
multi-label,5.934037972
node [shape=record],5.933887391
user defined set,5.933576413
"_get_batches_of_transformed_samples

    ja = np",5.933400757
layer read directly,5.932866206
columna] = img_array_iobl[fila,5.931818182
giving varied scores,5.93083004
test set performance,5.930645304
output nodes names,5.930488833
return internal states,5.93043742
broadcast input array,5.930100107
"save_model

    dtype=val",5.930074465
keras config located,5.928765077
adding batchnorm layers,5.928513792
"clone_model              

    return _clone_functional_model",5.928122605
set default argument,5.927208134
interpret feed_dict key,5.92712766
show continue processing,5.925995086
varying sizes,5.925
negative examples,5.924916308
custom layer classes,5.924882629
cudnn auto-tune,5.923505572
reproducible training,5.920959688
models pretrained,5.920126461
pretrained models,5.920126461
vocab size & setting,5.919489206
"```

import tensorflow",5.917786409
import tensorflow,5.917786409
tensorflow import,5.917786409
----> 1 import tensorflow,5.917786409
"```

`import tensorflow",5.917786409
"all_text += tmp

    

raw_text",5.916666667
models serializable,5.916338583
"#5th layer

model",5.915753825
"return gbytes



print",5.915275915
custom ``lrn2d`` layer,5.910758335
"2048 inputs

single layer",5.910610879
"input=0

layer_h0 = dense",5.909780177
give incompability error,5.90935657
token,5.909090909
set `samples_per_epoch` correctly,5.908730982
model weight correctly,5.908433502
`weighted categorical accuracy`,5.908166398
support loss funcs,5.907033986
layer interfaces,5.906364111
display fps information,5.904371585
imbalanced loss contributions,5.904021938
constant trough epochs,5.903152421
explained multiple times,5.902794222
summary ops,5.902544562
"```sh

    def fit",5.902200853
"update

    numdigits = int",5.901984127
class weight variable,5.901760028
current master,5.900561681
obj2 original position,5.90034965
"load_module

    return load_dynamic",5.900344828
"out_channels]

            filter_shape = [filter_size",5.9
store center,5.899843505
tiled-fft implementation,5.89980695
**sigmoid_cross_entropy_with_logits** function,5.89957265
# fully connected 1024,5.899051491
fully connected,5.899051491
eager mode support,5.898845382
"np



def data_gen",5.897021419
"train_model

    base_model = model",5.89609208
accept lambda layers,5.895862299
"training phases



running",5.893608252
provide distinct datasets,5.893330528
seq2seq modeling,5.892857143
prints 5 random numbers,5.892694064
set write_images=true,5.890948582
"batch_index`

0



`submission_preds = model",5.890871196
get_config function return,5.890497187
dll load failed,5.88963964
multiple generator instances,5.889560704
"_conv2dgrad

    data_format=data_format",5.888888889
"return inputs



        return",5.888568443
model-persistence api,5.888307094
$ pipenv install -,5.885786802
"install

        execute_actions",5.885786802
preprocessing costs time,5.885217391
0  tesla m60,5.883333333
1  tesla m60,5.883333333
2d conv layer,5.883215962
sqrt returns type np,5.882696356
1-cnn-layer architecture,5.882446163
"memory

apply node",5.882000599
"py

index 34e3721",5.881502641
"py

index 7ef75b3",5.881502641
running time comparison,5.880743802
trainable layer output,5.880038128
"<module>

    model = resnet50_model",5.8794618
trained model results,5.878952659
docs examples,5.87847668
moving average momentum,5.877777778
cloud storage,5.87745098
provided output parameter,5.875799106
make learning worse,5.875757576
adding return_sequences=true,5.875273155
adding `return_sequences=true`,5.875273155
= classes_dest[wh]#filter,5.875
ai/train_steering_model,5.875
interpolation approach keras,5.872476257
cosine distance layer,5.87225105
txt --model mobilenetssd_deploy,5.869940964
setting `mask_zero=true`,5.8697176
setting mask_zero=true,5.8697176
measure propagation method,5.869444444
word=vocabdic[word],5.868131868
map output names,5.868123241
"<module>

    model = model_from_json",5.867833893
keras configuration file,5.866982933
supervised learning,5.866666667
back-propagation update,5.865967178
pr adding support,5.864123159
"np

    

    def stepy",5.863688086
unexpected behaviour appears,5.863218391
simple dense layer,5.863064026
gpu memory requirement,5.862999797
"0                                            

__________________________________________________________________________________________________

input_11",5.861842105
"0                                            

__________________________________________________________________________________________________

input_7",5.861842105
"0                                            

__________________________________________________________________________________________________

masking_1",5.861842105
"0

__________________________________________________________________________________________________

masking_2",5.861842105
"0                                            

__________________________________________________________________________________________________

input_title_column_first_item",5.861842105
"0                                            

__________________________________________________________________________________________________

input_actor_column_second_item",5.861842105
"0                                            

__________________________________________________________________________________________________

input_title_column_second_item",5.861842105
"0                                            

__________________________________________________________________________________________________

lambda_1",5.861842105
set shuffle=false,5.861701705
lstm works fine,5.861210749
individual loss functions,5.860989151
calculate custom metrics,5.860623181
"filters import *

>   file",5.859958
"filters import *



  file",5.859958
image file names,5.859717242
return network output,5.859038788
pre procissing,5.857142857
triplet architecture model,5.856542838
2d embedding layer,5.854707191
saved moving parameters,5.851746032
significantly worse performance,5.851612903
val = ratings[~msk],5.851515152
neural networks,5.851136364
neural networks 1,5.851136364
"]

partial_x_train <- x_train[-val_indices",5.851032448
label train data,5.849313711
"#1st layer

model",5.849087159
"`decoder_target_data`

model = model",5.848409059
"x13]



model = model",5.848409059
"6045

saved trained model",5.846330875
saved trained model,5.846330875
set reuse=true,5.845494036
"fit_generator

    callbacks += [cbks",5.845181009
"__call__

    return [func",5.845136992
nvidia-smi 384,5.84375
nvidia-smi,5.84375
`nvidia-smi`,5.84375
`nvidia-smi,5.84375
"np





class identity",5.843150427
convert sparse matrix,5.84291834
deepvo[1] combined cnn,5.841891892
computation graph construction,5.841515554
"cast_to_floatx

    return np",5.841321342
custom activation function,5.841175161
parallelised **stateful** model,5.840871196
parallelised stateful model,5.840871196
theano backend --> comment,5.840097013
embeddings=embeddings,5.84
run [cifar10_cnn_tfaugment2d,5.83976834
run mnist_mlp,5.83976834
"-------------------------------------

```

import pandas",5.838240955
import pandas,5.838240955
"```





import pandas",5.838240955
"```

import pandas",5.838240955
"output

        curr_layer_model = model",5.838026696
unicode inputs,5.837878788
"py

```

def compute_output_shape",5.837492541
encoder weight matrix,5.836374039
"get_model

    base_model = nasnetmobile",5.835922638
parallel training,5.834379602
d_latent = d_latent  # dimention,5.833333333
cloud vm,5.833333333
entire decoder output,5.832418657
"# add regularization penalties

        #",5.832199882
share layer weights,5.830055043
"1

_________________________________________________________________

_________________________________________________________________

layer",5.829644534
current block label,5.828235003
step activation function,5.828138961
make batch_size 45*gpunum,5.827563815
sample mlp code,5.826469326
input data format,5.826322488
default data type,5.826217127
program calls predict,5.826086957
"rescaling

test_datagen = imagedatagenerator",5.825691057
official deconvolution layer,5.824882629
rnn/lstm network,5.824293986
proper [palette handling,5.823809524
hidden state dimension,5.822789739
return [batch_x[categorical],5.820887463
[platform support],5.819678715
_uses_learning_phase = true          # add,5.818584148
rnn cell transformation,5.81843318
needed packages,5.817229891
learning keras,5.816860315
batch size inside,5.816587306
"single dense

# layer",5.816469043
select weights variables,5.816201826
kaggle tutorial,5.815217391
"optimizer configs

merge",5.814211866
batch_size * batch_len == data,5.812590553
progress bar,5.8125
progress-bar,5.8125
"`modelcheckpoint`



log messages",5.811921296
gradient-averaging properly,5.811538462
"items]

    132 

    133     def __len__",5.811185867
batchsizescheduler increasing batch,5.810734463
"```



```sh

    def fit_generator",5.810382699
tiff image file,5.809717242
"built = true

        super",5.809044365
"time

    att_vec9 = permute",5.808888889
initial batch size,5.807966616
unknown batch size,5.807966616
final dropout layers,5.807750456
"img_data]





  def on_epoch_end",5.806970831
create siamese network,5.804871795
loss function attempts,5.803594587
separate api suggestion,5.803496503
"create_group

    gid = h5g",5.803030303
literally copy-paste,5.802930057
effect training results,5.802787822
"embedding



model = sequential",5.802291334
"#2nd layer

model",5.801468111
"# input data

            model",5.801032069
"# input data

                     model",5.801032069
collected trainable weights,5.800672414
template describing,5.8
functional programming,5.8
one-time,5.8
"tensorflow



calling predict_generator",5.79978355
global random state,5.79850897
binary xor function,5.798479753
preparing embedding matrix,5.798298457
100x100 image size,5.797800408
creating inceptionv3 instance,5.797463768
input image dimensions,5.797348221
file keras/losses,5.797129992
"making

241         // cudnn time",5.795886525
"network



```

input = input",5.793624912
program simply throws,5.793226381
`tf dataset api`,5.792966613
spark dataframe format,5.792632204
text model loaded,5.791851588
keras models,5.791532231
keras/models,5.791532231
keras/models/,5.791532231
hidden state representation,5.791312741
"normal

    std = undefined_grad",5.791142191
"grid

grid = np",5.790976514
metrics import categorical_crossentropy,5.790912406
single random shuffling,5.790543526
split validation data,5.790397409
"cnn

rgb_model = sequential",5.790154135
"cnn

nir_model = sequential",5.790154135
write specific argument,5.789878808
neural architectures,5.788636364
conda install -,5.787655961
invalid argument exception,5.78753139
channel-wise,5.786096257
numpy integer array,5.78580565
"_standardize_input_data

    data = [np",5.785094161
recent time steps,5.784926283
word embedding vector,5.784053666
data = dict,5.783913565
x_sample = x_data[sample,5.783783784
1 extra batch index,5.783011691
class weight mapping,5.782236218
concatenate multiple input,5.781583856
"simplernncell

h_tm1 --> ht",5.78021978
initial research,5.779840849
correct apply reward,5.777915249
installed pydroid3,5.777777778
not-,5.777777778
theano  gpu op,5.777562518
"dimension 

```

threed_model = sequential",5.777358288
default api mapping,5.775506073
"<module>

    model = vgg16",5.774523529
code works fine,5.773859661
development process,5.772727273
fully functional,5.772222222
maximum sequence length,5.771652835
additional masking layer,5.771564551
forget gate layers,5.770394134
full model definition,5.768648974
corner case handling,5.768564769
"batch_size=32

nb_train_steps = train_images",5.768472906
"// batch_size

nb_valid_steps = valid_images",5.768472906
"get_lstm_resnet_batchnorm

    vision_model = get_resnet_single_image_model_no_softmax",5.766666667
final model layer,5.765753825
"num_partitions = num_partitions

        super",5.765517241
explains steps/functions,5.764762912
3d weights array,5.764238453
correspding target sequences,5.763856362
"<module>

    model2 = model_from_json",5.763449184
"single vector
model",5.761447931
sequence length error,5.761158519
numpy float array,5.760978064
"idx = 0

    

    def __getitem__",5.759606159
"<module>

    lm = vae",5.758287574
visualize layer names,5.758215962
gtx 980 ti,5.757575758
model zoo,5.757537863
test cnn model,5.757231173
entire output error,5.757201724
parameter server device,5.756762901
generating train batches,5.756276241
regression models,5.755624297
minimal modification required,5.755555556
cnn lstm network,5.754895555
cnn-lstm network,5.754895555
final output size,5.753008342
`dense` layer decorator,5.751952914
"fps counter

print",5.751597754
"add `training=true`

4",5.751448598
"dtype=float32_ref>]

[]

[<tf",5.751425193
classify timeseries data,5.751260504
cell state adapting,5.750836551
layers gradients,5.750786291
model works fine,5.750616743
variables connected,5.75035868
"dr

keras",5.750193648
installing keras,5.750193648
columna] = img_array_dcc[fila,5.75
columna] = img_array_icc[fila,5.75
columna] = img_array_dobl[fila,5.75
learn_io,5.75
bottleneck-features model,5.749962105
bottleneck features model,5.749962105
conv2d tutorial dataset,5.748766024
shared embedding layer,5.748118043
"trained

#



xpred = model",5.747918176
output = math_ops,5.747155499
inceptionv3 model input,5.746044856
"convolution

    return op",5.74507351
gray levels found,5.744708995
setting`include_top=true`,5.744130745
convolutional layers,5.744078344
"# residual

    rnn = add",5.743490204
disable cudnn,5.742553191
"unknown opcode

```



contrary",5.74137931
non-working cases,5.740828114
model/weights trained,5.74059059
full error log,5.740115669
"__init__

    epsilon_annealing_steps=args[",5.740098845
open source project,5.738990379
"_constant_tensor_conversion_function

    return constant",5.738580122
`fit` + array inputs reports,5.738351358
evaluation generator function,5.737706463
model train automatically,5.737670313
"losses

                    layer_loss_name = layer",5.737382629
layer-specific losses,5.737382629
simple lstm model,5.736780842
slightly modified version,5.736661945
# feature transform net,5.736268281
input sequence shifted,5.736178277
`fit_generator` returning tuples <,5.735073725
test set size,5.734885243
2d lstm implementation,5.734605485
original obj1 position,5.733682984
"np



model = resnet50",5.733460614
manually set `steps_per_epoch=5000`,5.733382049
horizontal flip,5.733333333
jointly learning,5.733333333
"optimizer configs

model",5.733327337
function incorrectly,5.732905983
monitor gpu utilization,5.728384412
original vae code,5.727750478
"= classes_dest[wh]

indexerror",5.727272727
additional loss values,5.727202594
non-lstm kind,5.7263648
similarly `nb_val_samples`->`validation_steps`,5.724516419
install pydot,5.724496479
"```



full error message",5.724490669
training models,5.724203033
single timestep seedvector,5.722173787
returned operation sets,5.721911765
normalization terms inside,5.720588235
"execute

        install",5.719120135
examples directory,5.719033955
"weights



    weight_1 = lambda",5.718140579
b4 flatten shape,5.718139689
> b4 flatten shape,5.718139689
conv-pool layers,5.716822705
computer vision model,5.715871196
cntk framework,5.715676669
"test image

print",5.714680071
`multi_gpu_model` utility results,5.714367816
"141     return arrays

    142 



valueerror",5.71436557
algorithm=algorithm,5.714285714
time_distributed_1/keras_learning_phase,5.714285714
"mapstar

    return list",5.713880739
import marshal,5.713240955
unknown loss function,5.711640564
"embedding



lang_model = sequential",5.711420138
"data

features = model",5.710746419
"`

`opt=rmsprop",5.710526316
virtual envs,5.710193452
"output2]

loss = keras",5.709771142
single core,5.709252971
[enter image description,5.708614232
slack channel,5.707509881
/tensorflow/benchmarks,5.704545455
installing `tensorflow`,5.704545455
/karpathy/char-rnn,5.702956989
keras applications,5.702574601
% draw text fitted,5.700980392
inception v3,5.700431034
inception-v3,5.700431034
generalized fashion,5.7
larger batch size,5.699920639
"trainable = false



print",5.699299246
"trainable = false
print",5.699299246
multi_gpu scenario throws,5.698529412
"upsampling3d

twod_model = sequential",5.698262243
invalid initialization error,5.696712892
extract bottleneck features,5.694805195
"constant

    tensor_util",5.693498452
output feature maps,5.692360979
non-functional,5.691566265
add validation datasets,5.691043419
"trainable = false



# compile",5.689991881
"__call__

    return super",5.689775112
padded input vector,5.688770498
detailed test code,5.688582199
lstm layer & cell,5.683490688
"theano backend

      weights_path =",5.681994246
"model

model = pretrained_model",5.681742393
"model

    model = resnet50_model",5.681742393
"model

    base_model = resnet50",5.681038316
`new_keras` environment,5.68
development environment,5.68
thxhi @fchollet,5.679487179
@patyork @fchollet,5.679487179
true source code,5.678929753
time steps depending,5.678553275
manually setting weights,5.6783867
"np



model = vgg16",5.676909439
pil image,5.675280899
concatenation layer `ae_input`,5.674882629
/str 10 string def,5.674643036
native keras,5.673270571
"vgg16



base_model = base_model",5.672170162
predict feature vectors,5.671292436
org/anthology/,5.670527671
"output index

    return",5.669777555
simply disable,5.66969697
multiple outputs/inputs,5.668909408
dense layer picks,5.668619581
final dense layer,5.668619581
"default values



compare",5.668228057
reset `reducelronplateau` state,5.668052668
"np



def f1_score",5.667609655
symbolic tensor instance,5.66745283
fit function inside,5.666940719
_recv,5.666666667
maximizing l_c + l_s,5.666666667
"# dcc

                    file_dcc = file_io",5.666666667
titan xp card,5.666666667
"argv[1]

dst = sys",5.666666667
"x_sample = x_data

y_sample =",5.666666667
incorrect validation loss,5.6659267
short resnet20v2 model,5.66558384
weight matrix wxh,5.665202868
weight matrix whh,5.665202868
non-integer `pool_size`,5.664589521
previously saved model,5.664283895
`output_shape` optional argument,5.663621262
batch begin/end,5.663564652
character embedding layer,5.663265749
aspect ratio constant,5.663235294
cat pictures index 0-999,5.661166117
cat pictures index 1000-1400,5.661166117
k_clean-session,5.661157025
import backend,5.659969927
multiple gpus instance,5.659327323
efficient cudnn implementation,5.659026808
[info] elapsed time,5.658461538
expecting gpu memory,5.657871592
**include trainable weights,5.657815271
"layers

    weights=[tensor",5.655519378
trace shows error,5.655046225
"#workaround

    def vae_loss_func",5.654854429
vgg16 weights frozen,5.654400809
python api,5.652659778
checkpoint model locally,5.652173878
current stage label,5.651311926
"sparse_categorical_accuracy

    elif metric",5.650939778
handle data reading,5.65085389
validation_steps=nb_validation_samples // batch_size,5.650803733
return initializations,5.650344828
"<module>

    processed_a = base_network",5.650250683
input image shape,5.64981469
debug compute_loss function,5.64957265
"np



model = sequential",5.64677662
ugly solution consists,5.646226415
"denominator = y_true+y_pred

    denominator =",5.645174638
keras segmentation,5.64493049
pickle module objects `,5.64153178
"pickle module objects

>",5.64153178
"_standardize_weights

    return np",5.641321342
return dict,5.640140746
"network

input_data = input",5.639486449
keras accepts,5.639082537
config reading portion,5.638248848
"_as_graph_element_locked

    raise valueerror",5.637778506
provided target tensor,5.636186305
constant{1} [id br],5.635854342
sparse label format,5.635669674
hdf5 file viewer,5.634436343
spent time verifying,5.634285714
multi-labels,5.633749134
# encode class values,5.633457336
multi gpus,5.632783883
optimizers import *,5.632595793
intel channels,5.631884058
simplified api,5.630769231
applying dropout selectively,5.629461585
total traing samples,5.628422782
recurrent layers,5.628288871
native tensorflow,5.627622378
reading training file,5.626978213
"1] interval

datagen = imagedatagenerator",5.626903178
separate activation layers,5.62612094
computer vision problems,5.625
"tensor

input = input",5.624539281
"# model

base_model = vgg16",5.624487142
efficient cnn architecture,5.6242302
time cost longer,5.621923077
set `shuffle=true`,5.621717812
"<module>

    input = input",5.620677055
read test images,5.620280609
shallow water end,5.619496855
model topology,5.615996824
"backward

    torch",5.615384615
cross validation,5.614845938
geforce gtx 1070,5.614718615
geforce gtx 1080,5.614718615
geforce gtx 1060,5.614718615
decay = math_ops,5.613333333
/home/**********/image_model,5.613070539
"tf_debug



sess = tf",5.612541993
tf backend due,5.611902544
simple type error,5.611853307
decode layer manually,5.610596915
"###error occurred

regr",5.60975637
"```python

callbacks",5.608188307
"apply_async

    result = immediateresult",5.606329114
"2]=trainy

trainy=scaler",5.605769231
complete input_shape argument,5.605498013
terrible time fitting,5.604210526
shared cluster,5.601744186
"deserialize

>     def deserialize",5.601283
tensor-train rnn,5.60054227
[keras-fcn,5.600193648
[keras-fcn],5.600193648
radial_1/truediv,5.6
"contrastive_loss

    }

    model = load_model",5.599962105
compiled multiple times,5.598872653
extract hidden values,5.597300738
fine-tuning,5.597181445
fine tuning,5.597181445
"}

opt = sgd",5.59596138
full tensor shape,5.595387841
single loss tensor,5.59432423
model weights files,5.59306742
keras library,5.592786241
user defined list,5.59254801
output specific values,5.592075285
lstm/gru layers,5.591577645
gpu resources immediately,5.591204925
fairly heavy model,5.590871196
"train_seq2seq

    model = s2s",5.590871196
"ratio}

        base_config = super",5.590517241
found keras depends,5.590140738
code produces error,5.588604784
multiple input case,5.587982936
pass training mode,5.586913746
gather` doc,5.586894587
waste time retraining,5.586666667
large scale dataset,5.586038961
questions/answers,5.585393258
"np



left = sequential",5.585317189
dense model conversion,5.584608148
resulting output dimension,5.583827302
"<module>

    validation_steps=validation_generator",5.583619844
warning messages totally,5.583333333
sequential model documentation],5.582466773
batch_normalization boolean argument,5.582452431
initial setup time,5.582431942
"tf



complex_tensor = input",5.581216797
text classification,5.579768271
simple lets put,5.579059829
import sequential,5.578169865
basic network,5.576923077
"bidirectional grus

    # gru",5.576861167
good validation accuracy,5.576451601
output dimension calculation,5.576251545
keras model file,5.575501188
keras 1 code running,5.575051564
"train

    initial_epoch=initial_epoch",5.57450996
"dtype=float32_ref>]

```



model2",5.572738108
"+testfile

images = np",5.572555462
recurrent matrices,5.572180451
edge detector,5.571428571
thesis,5.571428571
avoid embedding layer,5.571373857
resulting gradients,5.571301248
`load_weights` requires h5py,5.570909091
"code



```

 model = sequential",5.56991422
"code



model = sequential",5.56991422
keras image_ocr,5.568375467
bidirectional wrapper layer,5.567990399
define constant tensor,5.566734636
reinforcement learning,5.566666667
increasing batch size,5.566587306
binary treatment assignment,5.56557377
load validation  dataset,5.565234878
conv2d_4/kernel/read,5.564845197
ctc_batch_cost implementation code,5.563921064
model  computation cost,5.562531115
f-beta score,5.562361787
test accuracy remains,5.562091847
"#network fuse start

    #",5.561538462
keras calculate acc,5.560905558
# transform rnn output,5.560619735
"model

lm = vae",5.560568166
"crop_image_ratio



input_layer = input",5.558900368
padded target output,5.558630909
"*n_symbols*n_days_other

    print",5.556597754
default session,5.555893867
wrapped cell output,5.554298357
create full indices,5.55390681
constraint weightclip class,5.553534457
produces strange errors,5.553015873
end simultaneously,5.552830189
gaussian 1d,5.551948052
"model

    model=classifier",5.550973162
# count positive samples,5.550207519
totally implemented separately,5.55
proper warning message,5.55
raising memory requirements,5.55
middle conv layer,5.549882629
"shape]

        417     shape_size = np",5.54946708
"```

# create sequential model",5.54913344
"056

_________________________________________________________________

merge layer",5.549019307
"] * total

            gradients[",5.548573975
"= original_backend

 

 

 def load_weights_from_hdf5_group",5.547711572
implement 2d convolution,5.547647059
tensorflow library,5.547138047
conv layer output,5.547038128
3/lib/modelae,5.547008547
"lib

                       archiver",5.547008547
"model

model = sequential",5.546671303
"model

    model = sequential",5.546671303
"data-point

        index = ~",5.545561541
"layer2



    layer1_wt = layer1",5.545454545
constant_op,5.545454545
global definitions,5.545454545
"warning

420       chosen_algo = cudnn_convolution_fwd_algo_implicit_gemm",5.545454545
model generate sample,5.545386687
/users/davidslater/,5.543956044
pass actual sequences,5.543930248
evaluating model manually,5.543252149
--> m2 --> final output,5.542610045
"#model

rn = resnet50",5.5424841
lstm layer input,5.542391056
"```python

>>> # define",5.541270392
model parameters properly,5.539076325
"#training model 1

print",5.538666734
"#training model 2

print",5.538666734
documentation write formulas,5.538638498
modified inceptionv3 model,5.538334964
encountered multiple bugs,5.538295577
previous input shape,5.536438553
n_days_back+n_days_other*n_days_other,5.535714286
"train_model

    validation_data=[x_val",5.535598706
classic form `np,5.535420959
shared `dropout` layers,5.534494642
dog pictures index 13500-13900,5.53418199
normal validation generator,5.533371909
conv2d_4/convolution = conv2d[,5.533191489
keras supports,5.532802344
"integers

encoder = labelencoder",5.532282282
"+ b2

d2 = tf",5.531840239
error allocating 13366886400 bytes,5.530046225
means hidden state,5.529407979
plot sequential details,5.529214624
siamese network wrong,5.528611632
meta & data file,5.52855399
conv2d layers set,5.528149939
tensorflow variables,5.528074866
specific category varies,5.527777778
respective channel,5.527272727
<capsule object null,5.526056338
custom activation regularization,5.524935845
/opt/conda,5.524676176
input/labels transferred,5.524151333
output values match,5.523109768
"tf

    vec = np",5.522816753
"m2



doc link",5.521816725
python3 virtualenv,5.521226415
high classification,5.51981352
"pickle notimplementedtype objects



```",5.519607843
takes schedule function,5.518620269
stack auto encoder,5.516409266
"shared layer



code",5.515740929
"handle_metrics

    mask=masks[",5.515201586
io,5.513513514
"main

    foo = model",5.512167493
"reduction

                        new_lr = old_lr /",5.511904762
dummy variables,5.511029412
text model loading,5.510757061
variable length sequences,5.510659782
variable-length sequences,5.510659782
"np



class saltandpepper",5.509817094
keras `fit_generator` ends-,5.509076897
prior default boxes,5.509022556
validation_steps=n_images// batch_size,5.507946591
"label

            label = np",5.507770407
simple overfitting problem,5.507433329
"input

        hidp = model",5.506914422
"248 

    249 def _deepcopy_method",5.506044905
def tf_stepy,5.506044905
metric-defining function,5.505057882
"placeholders

inputs = input",5.503922013
unknown `implementation` mode,5.50368626
"<module>

    embedded_sequences = embedding_layer",5.502876318
"0

       requests version",5.502012822
limited timestep count,5.501247401
keras/keras,5.500387297
/keras/keras,5.500387297
op_def_library,5.5
study,5.5
build_fn=create_dnn,5.5
major contributors,5.5
undesired effects,5.5
action recognition,5.5
input2=input_generator,5.5
v4 onward,5.5
cxt,5.5
"func_load

    closure=closure",5.5
multigpu model fails,5.49920453
input batch index,5.499054916
`pip list`,5.499019783
predicting classification,5.497835498
low test accuracy,5.497575718
tf op inside,5.496568921
model_1 = load_model,5.496270396
training progress,5.49536445
learning rates,5.495238095
"max pooling

pool_size =",5.494610557
"import activations

      5",5.494490955
activations import *,5.494490955
longer input sequences,5.493424178
passes information back,5.493354636
unknown type code,5.492856062
computing predict differently,5.492753623
source code folder,5.492545487
"graph

   5652       elif original_graph_element",5.492233257
"graph

   5283       elif original_graph_element",5.492233257
# transforms rnn output,5.491779155
"12

    conda-build version",5.490945434
"total_loss += loss_tensor

        # modify",5.490248227
indices_char = dict,5.489795918
bounding boxes arranged [1,5.489285714
code previously worked,5.489114114
checking model input,5.488732603
current problematic code,5.487798325
supports tensorflow,5.48715415
deep learning,5.486419753
ctc_merge_repeated=true,5.486384266
"error

 

    model = sequential",5.485846331
predict works fine,5.485832504
embedding layer anymore,5.485659571
add custom constraints,5.484742255
solution / feature request,5.484289037
1403     return gen_dataset_ops,5.483678161
layers import *,5.483635088
layers import,5.483635088
calling lstm layer,5.483490688
rnn/lstm/gru,5.482473834
"train

    validation_steps=nb_val_samples",5.482426647
"gradients

    gate_gradients",5.480392157
"gradients

    grad_scope",5.480392157
"gradients

        grad_scope",5.480392157
* gradients aggregatin,5.480392157
"ctc_batch_cost

    mode=nanguardmode",5.479166667
set input arguments,5.476345246
small batch size,5.475678215
unit test file,5.475571095
specific requests,5.473684211
"#stateful=true

    model2",5.472870753
sample weights parameter,5.47284174
model_selection module,5.47280113
gpu 0% usage,5.472686407
decay=lrate/nb_epoch,5.471919192
specific loss function,5.470261254
random aspect ratio,5.467694064
`dataparalleloptimizer` wrapper class,5.466710254
"fit

    return super",5.466563472
import callbacks,5.466205381
"word_dropout}

        base_config = super",5.465517241
output include 30 state,5.464658717
"conv2d

    data_format=tf_data_format",5.4643026
paired input images,5.464288839
tensorflow estimator,5.463804714
sparse matrix untrainable,5.46291834
region proposal network,5.461538462
memory representation output,5.461441214
quick code-read,5.460165873
weight decay setting,5.460062305
assign boxes step,5.45967424
"py#l153



problem",5.457928583
"`



model trains fine",5.45728341
model worked fine,5.45728341
model loads fine,5.45728341
recent paper works,5.456945399
"nb_labels=6

    model = sequential",5.455800106
tensorflow keras,5.454739103
keras-tensorflow,5.454739103
keras & tensorflow,5.454739103
keras/tensorflow,5.454739103
direct correlation,5.454545455
good score gap,5.453990746
rnn/lstm model,5.45362672
model takes features,5.452343058
multiple path output,5.452117743
received 2 input tensors,5.451845694
stateless lstm converges,5.451465201
"cthunk_factory

    key=key",5.45
"dense



model = sequential",5.449537058
takes parameters `mask`,5.449347245
org/simple/,5.448305448
"batch size



    images = []",5.448166253
build main model,5.447915156
complete error message,5.446712892
"multiply



def l2",5.446690066
"```



weight dictionary defined",5.44665109
solve entering problem,5.446264146
change weight parameters,5.443034193
video classification,5.442890443
problem occurs time,5.442616214
sequence learning,5.442357274
checked code keras,5.441727117
car models,5.441338583
things added previously,5.441126856
input-output pairs,5.440976502
$ git status,5.440940601
"0         

_________________________________________________________________

model_1",5.43956044
"backward

    variables",5.438914027
nice examples,5.438285292
"ys

            augmented_generator = train_datagen",5.4375
provided weight shape,5.437477603
tf contrib,5.437103397
convolutional network,5.435222672
clear file buffers,5.434436343
normal gaussiannoise layer,5.433973538
learning fine,5.43307888
json string encoded,5.432105263
opt = adam,5.43150267
sentiment analysis,5.430769231
legacy metrics,5.43030303
unknown activation function,5.430012099
"``` python
# test",5.429691966
`tests`/`keras,5.428765077
early stopping,5.428571429
return_sequences=layer_number + 1 < config,5.428571429
ve successfully saved,5.428440247
master branch,5.42687747
branch master,5.42687747
origin/master,5.42687747
"0                                            

__________________________________________________________________________________________________

dense_1",5.426358234
quick question related,5.42499557
"0

__________________________________________________________________________________________________

embedding_1",5.424342105
remove validation generator,5.424281
spike/drop occurs,5.423913043
parameter service device,5.423429567
"0           reshape_1[0][0]

                                                                 input_2[0][0]

==================================================================================================

```",5.422222222
create generator function,5.421948887
python function,5.421463197
loss targets directly,5.420848861
pull request,5.420634921
pull-request,5.420634921
recurrent window,5.420394737
building deconvnetcurrently,5.42
reducing dataset size,5.419543319
## feature requests,5.41888969
feature requests,5.41888969
finally generated output,5.418606855
autoencoder parsing frame,5.418181818
window 10 python 3,5.417723881
sequence models,5.41702919
keras ocr,5.416860315
keras xception,5.416860315
"nasnet

    block_id=",5.416666667
raw jpegs,5.416666667
5 words long title,5.416530278
make keras work,5.416092069
"batch_generator

>     train_generator = zip",5.415151515
dummy channel,5.414772727
"<module>

    results = cross_val_score",5.414361929
vocab sizes 9,5.413636364
unused-import,5.413240955
predict data tensor,5.412657434
"4

windows 7





full traceback",5.412099431
layer model_1,5.412062116
"external parameter

https",5.410875703
`write_grads=true` option,5.410626691
test_y data format,5.410279263
tensorflow/tensorflow,5.409090909
flat output vector,5.408771661
latent_dim dimensional input,5.408690284
generate random values,5.408345557
"<module>

    gru_l = gru",5.408308914
lambda layer calling,5.407493651
input class info,5.406678677
recurrent weight,5.404623709
"label

    

    dataset = tf",5.403927662
"constant

    return tf",5.403753694
usage rate,5.403703704
saving weights correct,5.402872778
target critic model,5.402346606
conv2d_transpose dynamic,5.4
scroll horizontally,5.4
convolutional layer,5.39856684
"defined



```dear sir",5.397471138
successful train,5.396799117
thread `custom_objects` parameters,5.396645435
normalization layer scales,5.395470864
steps_per_epoch=train_samples // batch_size,5.394909688
`val_samples`->`steps` arguments,5.394088959
output label information,5.393257364
"batch size

         [[node",5.391984131
dense prediction tasks,5.39179824
param func,5.39010989
expected model argument,5.389745915
docker volumes,5.388888889
"<module>

    model = load_model",5.388552709
"<module>

    model=load_model",5.388552709
return uses_correlation[original_backend],5.388440066
+        return uses_correlation[original_backend],5.388440066
"labels

y_test = np_utils",5.387932131
#5731 add `return_state` flag,5.386961786
"map_fn

    return tf",5.386946971
# grab batch components,5.386492039
"correct values

```bash",5.38441308
empty string represents,5.384285714
cnn + lstm model,5.38422829
cnn+lstm model,5.38422829
cnn lstm model,5.38422829
checking model target,5.384164788
python version,5.383552492
**python version,5.383552492
"3

python version 3",5.383552492
bidirectional lstm layer,5.383490688
"=240

    nprobs=18+1



    probs_in = input",5.382709892
3 trained model file,5.382354519
"+ common_factor





apply node",5.382000599
"np

    np_stepy = np",5.381953028
"input unchanged



print",5.380974313
# reused auto monitor_op,5.380952381
major release,5.378787879
basic generator,5.377760853
client,5.376811594
output shape correctly,5.376479399
output vector length,5.375304459
variable input size,5.374753211
set kernel constraint,5.373203147
add machine translation,5.372897556
"0000e+00

    epoch 49/10000

    0s",5.372689685
"0000e+00

    epoch 50/10000

    0s",5.372689685
"0000e+00

    epoch 51/10000

    0s",5.372689685
"0000e+00

    epoch 52/10000

    0s",5.372689685
time-dependent sequences,5.372380952
sparse loss leads,5.372275906
/tensorflow/tensor2tensor,5.371212121
vertical_flip = false,5.369225302
word2vec model base,5.368648974
0 # learning phase,5.366666667
"```



full error dump",5.365795017
--> 204                                 training=training,5.3657289
2111                                       training=training,5.3657289
training=training,5.3657289
tensorboard images won,5.365705931
good research,5.365384615
2481         updated = session,5.364860728
1602         updated = session,5.364860728
"```python

load_model",5.36431479
classification class,5.364295125
4-class classification,5.364295125
"hidden

    outputs = dense",5.364249772
single printed document,5.363217428
final softmax layer,5.362956024
pass `custom_objects` argument,5.362768374
"0                                            

__________________________________________________________________________________________________

conv1d_23",5.361842105
simplified version,5.361661945
optimizer functions tensors,5.360225823
iterators implement `_get_batches_of_transformed_samples,5.360071301
passing padded sequences,5.358630952
validation dsc calculated,5.358058608
recurrent connections,5.357894737
"*frame_len

output_length = np",5.357643181
"adadelta

    reduce_lr_m = reducelronplateau",5.357142857
`regularizers/init/constraint,5.3569161
# loads rgb image,5.355280899
"```python

    losses_list = {",5.355223881
python processpoolexecutor,5.355223881
"oscar



python 3",5.355223881
python example_fit_gen_k2,5.355223881
"```

$ python example_fit_gen_k2",5.355223881
multilabel classification,5.354978355
models share,5.353838583
edge_697_loss/mul,5.352941176
multiply_1/mul,5.352941176
edge_4498_loss/mul,5.352941176
edge_5083_loss/mul,5.352941176
/mul_5 = mul[,5.352941176
elemwise{mul}[,5.352941176
setting pickle safe,5.352941176
"predict

    check_batch_axis=false",5.352455116
"as_graph_element
    raise valueerror",5.35206422
pretty bad loss,5.351390359
file layers/embedding,5.351321705
"10000

x_val <- x_train[val_indices",5.351032448
gestures recognition,5.35
embedding size dimension,5.348106783
network reuses parts,5.346153846
storing/loading works,5.345572139
simply square root,5.345168668
"negative]

    # outputs = [positive_d",5.345022624
standard vae model,5.344881892
nvidia titan,5.34375
cnns directly,5.34375
nvidia-gtx720m,5.34375
"convert_to_tensor

    as_ref=false",5.343584276
effective kernel width,5.342640606
hanging thread created,5.342009132
hand works fine,5.341563729
mobilenet models,5.341338583
657                             # infinite iterator/generator,5.341323606
experiencing similar problems,5.341269841
line `predictions = test_model,5.340407952
pydot/graphviz installation,5.338709677
max generator queue > 2,5.338566714
"# inputs

    x_in = input",5.337255346
"0s

---------------------------------------------------------------------------

valueerror                                traceback",5.334829097
"return model





# create",5.334549357
kernel dies,5.333944954
"/ batch_size

        valid_steps = len",5.3335414
"/ batch_size

        test_steps = len",5.3335414
intermediate supervision,5.333333333
@timzaman @athundt,5.333333333
self-explanatory,5.333333333
keep_lock=keep_lock,5.333333333
doubt regard pretraining,5.333333333
"break





train_images = tf",5.331840239
7s 3s/step,5.331813865
feed forward network,5.330769231
pre-load,5.33011583
layer weight shape,5.330102167
"fit

    validation_steps=validation_steps",5.329648771
"fit

        validation_steps=validation_steps",5.329648771
"fit



    validation_steps=validation_steps",5.329648771
"data

x_train = x_train",5.329515877
keras programs work,5.329223382
small dense layer,5.32771049
"activity_l2







importerror                               traceback",5.327260898
parameter tuning,5.327154773
session = tf,5.326330597
gpu communicating,5.324538259
training step,5.322370623
2*learning rate,5.322222222
learning rate = 0,5.322222222
learning rate,5.322222222
-- learning rate 0,5.322222222
# learning rate,5.322222222
learning rate**,5.322222222
learning-rate,5.322222222
defines output label,5.322219113
science project,5.321428571
compute output tensor,5.32085833
"net



  model = model",5.320631282
current doc,5.319838057
recurrent network,5.319433198
denoising autoencoder,5.318181818
"0065

    activation_1

    conv2d_2

    -0",5.318007663
load weights separately,5.315645387
keras tutorial,5.31541104
sequential model shape,5.314290672
max caption length,5.312564544
"# autoencoder

e_128 = dense",5.31191877
steps_per_epoch=nb_train_samples // batch_size,5.311576355
computed input tensors,5.309421452
complex models,5.308005249
predict separate output,5.306575789
assume weighted accuracy,5.306251213
"assign

    validate_shape=validate_shape",5.305882353
making code built,5.304590305
previous models,5.303243345
embedding_1/gather,5.303240741
random binary values,5.303187621
neural net,5.302525253
"parallel

-> 1283         return",5.301859979
"time

    predicted = model",5.300344881
create architecture similar,5.300274816
variable output steps,5.299475008
xent_loss = original_dim * metrics,5.296969697
metrics properly set,5.296405807
keras users,5.294149692
/data/table1,5.294117647
/data/table2,5.294117647
correctly address issue,5.293347953
make 50 examples,5.292830746
return -score/len,5.29248099
calculates true accuracy,5.292189847
exch def,5.291759191
models separately,5.291338583
gradients[batch+,5.29112662
auto encoding part,5.290944753
add bn layers,5.290094016
rmse loss function,5.288443072
opt=tf,5.28798059
"__call__      

    output = super",5.286585784
"__call__

    output = super",5.286585784
batch_normalization_1/keras_learning_phase,5.285714286
development machines,5.285714286
exact framework,5.285093168
"return lstm_x 



# put",5.284960212
learn features,5.284090909
create cudnn handle,5.282945348
recurrent layer,5.282777366
"num_filters]

            return tf",5.282185066
"np





model = inceptionresnetv2",5.281847711
images horizontally,5.281578947
concatenated encoder state,5.281531532
pretty good result,5.280620612
output deprecation warnings,5.280488833
create 2 timedistributed layers,5.280394134
error message bellow,5.280046225
"graph

tf_saver = tf",5.27861895
"fit

    initial_epoch=initial_epoch",5.278412246
[maxwell cards page,5.277777778
[word2vec_25_tar-category,5.277777778
binary classification,5.277694983
**binary classification**,5.277694983
normal batch_size inside,5.277563815
"fit_generator correctly



**output",5.276872081
"shape[1]

    img = image",5.275172739
recurrent_dropout works fine,5.275130162
# initialize sample weight,5.2749572
tensorboard images working,5.274796841
"trainable]

    optimizer=model",5.27466067
graph/session,5.274602403
recurrent input,5.273937962
raw signal,5.273809524
"negative dimensions

         [[node",5.272597392
"negative dimensions

     [[node",5.272597392
decoder remains untrained,5.271929825
3d-vectors,5.271794872
image segmentation],5.270017741
[image segmentation,5.270017741
image segmentation,5.270017741
error information shows,5.267751143
running data generator,5.267237686
--> 787                          op_def=op_def,5.266666667
-> 3392           op_def=op_def,5.266666667
op_def=op_def,5.266666667
template laid,5.266666667
"#4th layer

model",5.265753825
vgg model listed,5.265474371
"gamma

        masked = tf",5.265173572
"gamma

    masked = tf",5.265173572
"gamma



#         masked = tf",5.265173572
output layer weights,5.264710542
embeddings directly,5.26375
matrix size-incompatible,5.263215627
guide outlining,5.263157895
"#output layer

model",5.262909325
"layer

input_b = input",5.261978486
pretty good accuracy,5.26191526
"0                                            

__________________________________________________________________________________________________

embedding_network_actor",5.261842105
"expected`

`loss2 = model",5.261838938
input shape parameters,5.261200458
made backwards compatible,5.26
invalid kernel shape,5.259102187
intermediate layer,5.258215962
logistic layer --,5.258215962
validation accuracy doesn,5.258149214
"concatenate

    return tf",5.253874564
output result prefix,5.253484613
script takes ~ 20 minutes,5.253480783
"```

        # compute total loss",5.253453756
"grayscale

    img = cv2",5.253135968
embedded `dense` layer,5.251952914
running variational autoencoder,5.251147842
find input class,5.250909446
keras calls,5.250193648
keras automatically,5.250193648
keras starts,5.250193648
[enet-keras],5.250193648
nlp,5.25
//nlp,5.25
conditional weighting,5.25
full_model = get_combined_model,5.25
"3 lts

drivers",5.25
kaggle competition][2],5.25
language modelling,5.25
nnet,5.25
abstract_conv,5.25
black sweatshirt,5.25
nn simultaneously,5.24893617
loss function calculate,5.248039032
"len

    

    def on_epoch_end",5.247039324
"output

    net = flatten",5.245693511
epoch 00001 val set,5.245008468
cudnnlstm/cudnngru layers,5.241822705
reduced binary type,5.241397946
implementing models,5.241338583
#define ga_float float,5.241218925
"# label



sigmoid_x = tf",5.240237185
pip freeze,5.239831697
anaconda,5.23880597
2 anaconda,5.23880597
6 anaconda,5.23880597
"is_keras_tensor

    raise valueerror",5.237778506
[alt text],5.237212276
# generate random targets,5.236502694
core layer,5.236286138
"#%%

#read data

path =",5.236129001
log-loss function,5.235886254
test code attached,5.234036745
train dataset size,5.233009103
"stratifiedkfold

folds = list",5.230202578
large models,5.228838583
reaches >94% test accuracy,5.228758514
81                 driver version,5.228328612
local agent,5.226238286
/local/run_char_rnn,5.226238286
random horizontal flips,5.226027397
fully support,5.22523427
"y_train



model = sequential",5.224891015
feature vector dimensions,5.223956849
"py#l57 

https",5.223715574
current comparison,5.223684211
reproduce imagenet training,5.223012421
"# vocab_size

    mask_zero = true",5.221232751
hot representations,5.220512821
hot vectors,5.220512821
evaluate model based,5.220375701
"_set_inputs

    assert len",5.2182943
`conv2d` layer taking,5.215574118
"bias = bias

        super",5.215517241
<code>true</code>,5.214612494
code dies,5.214114114
"caffemodel



# import",5.213240955
import pprint,5.213240955
import statements,5.213240955
import dot_parser,5.213240955
"return gan

```

traceback",5.213237909
x_train = x_test = data[,5.213200845
1 #include <python,5.212366738
multiclass classification,5.212121212
classification curve,5.212121212
improving classification,5.212121212
compute accurate metrics,5.21155303
"batchnormalization layers`

`model",5.21126533
output labels length,5.210685294
wrong score function,5.210380156
hdf5 header files,5.20952381
masking layer input,5.209346907
final scalar output,5.209276711
"load_weights

    topology",5.20694381
conv2d_2/kernel_0,5.206896552
conv2d_2/bias_0,5.206896552
basic model,5.206255812
"#train data

print",5.205847851
org/external],5.203861004
org/external/,5.203861004
existing data,5.203208556
job engine,5.202947033
"_run

    allow_operation=false",5.202558635
showed worse performance,5.201612903
average=average,5.2
826                                                  average=average,5.2
reading->augmenting->writing,5.199873498
"dtype=float32>



    cnn",5.199196145
"build                        

    raise valueerror",5.198526169
"build

    raise valueerror",5.198526169
[keras backend],5.19692262
keras backend,5.19692262
"shape[1]

image_gray_test = cv2",5.19522526
mse loss weighted,5.195147479
break model compilation,5.195037863
"external loss

model",5.194893134
class weights `class_weight`,5.194846327
"target tensor

model",5.194799436
running examples,5.194483639
read train images,5.192611641
>     777                     feed_dict = dict,5.191923578
return models,5.19168341
388       int input_w = cudandarray_host_dims,5.191666667
template model,5.190871196
`del model`,5.190871196
"return loss





vae",5.190730402
pre-processed,5.19047619
"submodels

recurrent_model = get_recurrent_submodel",5.19047619
history=model_1,5.18956044
"[0]

    return classes[np",5.188778969
"#decoder

    decoder_input = input",5.18797305
"### decoder

decoder_input = input",5.18797305
default float type,5.187271893
embedding randomly,5.18691676
research paper,5.186609687
"fit_generator

>     initial_epoch=initial_epoch",5.186594092
"fit_generator

    initial_epoch=initial_epoch",5.186594092
observed error messages,5.18480813
"dense

training_data = np",5.184713466
"dense

      5 training_data = np",5.184713466
"output frame

    cv2",5.183890193
imdb_cnn sample,5.183783784
"weights

```

lstmweights=model",5.18354361
"from_config

    return cls",5.183377013
equal time steps,5.183255469
missing required information,5.182149362
venv,5.181818182
@fchollet due,5.179487179
existing layers,5.179485043
sample/task pair,5.177226407
native support,5.176088971
model output predictions,5.175864534
default float precision,5.174909256
classification network,5.173659674
/curlayer 0 def,5.172711572
"gradients

        np",5.171368671
/keras/optimizers,5.169548487
keras optimizers,5.169548487
default input shape,5.169270633
urllib3,5.166666667
"categorical_accuracy



                    masked_fn = _masked_objective",5.166666667
"x64

                     am_ldflags",5.166666667
"0                                            

____________________________________________________________________________________________________

timedistributed_30",5.166666667
find examples,5.166432145
3d data,5.165912519
variable_13/read = identity[,5.164233577
"get_bdclstm

    conv1 = bidirectional",5.163392857
"deserialize_keras_object

    return cls",5.161637882
rnn package,5.161290323
rnn toolkit,5.161290323
"_call

    session",5.161157025
"/initial_state]`



code snippet",5.160490926
"last_index]

    title = tokenizer",5.159919028
"1184      

_________________________________________________________________

conv2d_2",5.159277504
"2788      

_________________________________________________________________

conv2d_2",5.159277504
"320       

_________________________________________________________________

conv2d_2",5.159277504
theano + lasagne,5.157343196
kernel size 3x3,5.156464464
`shuffle`-option enabled,5.155011655
cpu cluster,5.15366242
validation loss/accuracy,5.153550462
generating training,5.153452685
identical model replicas,5.153371196
implement masking noise,5.152734778
"top5 accuracy

print",5.15255485
"0         

_________________________________________________________________

reshape_1",5.152380952
"trainable_weights[0]

    layer2_wt = layer2",5.151515152
tensorflow backend,5.151274427
"tensorflow backend

    #",5.151274427
backend tensorflow,5.151274427
tensorflow backend],5.151274427
"3

tensorflow backend",5.151274427
tensorflow backend-,5.151274427
tensorflow backend 1,5.151274427
**tensorflow** backend,5.151274427
**tensorflow backend,5.151274427
--> 281     return imagenet_utils,5.150344828
"slice

    return slice",5.150344828
return tf_stepy,5.150344828
"<module>

    d2 = dense",5.148994223
sentence labeling problem,5.14870317
usage/cap,5.148148148
memory-usage,5.148148148
unsafe usage,5.148148148
usage og,5.148148148
low classification,5.147605083
small reproducible,5.147186147
computing gradients,5.147058824
model compile phase,5.146494918
variable length inputs,5.146157617
gradients = tf,5.145565729
def step,5.145551078
"]

    

        def step",5.145551078
"```

def step",5.145551078
ctc loss computation,5.144912626
adam optimizer state,5.144845486
input sample patches,5.144271453
error prone code,5.144160339
python module,5.143814485
[api doc],5.143589744
"_get_conv_pool

             initializer=tf",5.140583408
randomly setting,5.140425532
** 9ms/step,5.139506173
> python sample,5.139007664
documentations mentioned batch_size,5.137520525
"test mode

            ]

    get_gradients =",5.136968085
"test mode

                     ]



    get_gradients =",5.136968085
assigning loss function,5.136927921
"# prediction

prediction = dense",5.136013375
embeddings matrices,5.134285714
143                                        custom_objects=dict,5.13310802
138                                        custom_objects=dict,5.13310802
toy models,5.132247674
sample weight array,5.130283923
latest commit,5.13028169
transfer process,5.12987013
control-flow construct,5.129826255
vertical_flip = true,5.129241409
vertical_flip=true,5.129241409
default file formats,5.129173185
verbose=1 properly displays,5.128798248
people report theano,5.127581291
full training,5.127308895
framework written,5.125752508
callbacks_list = [keras,5.125193648
neural network,5.125174825
single channel,5.12512219
"n_samples]



        # compute metric",5.12483047
`docker` directory,5.124183007
running test predictions,5.123049725
import h5py,5.122331864
store centers,5.122065728
handles mse equal,5.121585311
similar error message,5.121316066
remove pixel values,5.119919786
spatial size,5.119489206
keras classifier,5.119424418
raw lstm,5.118131868
python generator,5.117600118
gpu array exception,5.117267172
"features= 30

    

    inp = input",5.116800801
caffe2 [https,5.114490161
helps prevent overfitting,5.114285714
"~~



## update examples",5.110723964
total 11 models,5.109520401
num_files_train_0 = int,5.108333333
"@fchollet 



btw",5.108058608
recurrent constraints,5.107894737
"dtype=float32>]

```



```

loaded_simple_model",5.107304253
runs perfectly,5.104166667
identical models,5.103838583
"0         

_________________________________________________________________

sequential_1",5.102380952
gpu allocation,5.102316036
"evaluate_generator

    raise valueerror",5.10206422
"scale = scale

        super",5.101880878
"gen_model

    embedded = reshape",5.100265604
input_fn=dataset_fn,5.1
non-trainable,5.099566265
"window

    batch_size=batch_size",5.099445813
dtype=np float,5.099067216
awesome flow_from_directory function,5.098797456
optimizer=opt,5.098596491
"#execute init_op

        print",5.098264421
variable-size batches,5.097598875
"label



filename_list = glob",5.097586136
functional api**,5.097435897
functional api,5.097435897
multi-threading,5.097069597
returned batch size,5.095999071
var_pred + var_true + c2,5.095238095
"#model

inputs = input",5.094793209
"model

    inputs = input",5.094793209
keras directly,5.093943648
images classification,5.093700159
recurrent kernel,5.091839691
"starting clean



**",5.090909091
evaluating loaded model,5.090871196
separate submodels due,5.09047619
default batchnormalization values,5.089656628
python kernel,5.089168835
"maxlen=1000

# convert characters",5.089139785
2 based keras,5.088031486
keras user,5.087616961
"> memoryerror



flow variant",5.085995086
"evaluate_generator

    use_multiprocessing=use_multiprocessing",5.085907336
"##source code

note",5.08540263
word embeddings,5.084835165
"0                                            

__________________________________________________________________________________________________

input_2",5.084064327
"0

__________________________________________________________________________________________________

input_2",5.084064327
downgrading keras,5.083526982
audio=false,5.083511016
zca_whitening=false,5.083511016
weighted differently,5.083333333
"hidden

    d1 = dropout",5.082970357
"reshape

        return tf",5.082450671
1-hot encoding,5.081382386
hot encoding,5.081382386
output = clip_ops,5.080488833
intermediate output,5.080488833
# convert pil,5.08
"__call__

    dtype=dtype",5.079749619
keras_backend=tensorflow,5.079545455
model_1 = model,5.078050684
cuda samples compile,5.077403147
"prediction

        confidence = detections[0",5.076693767
separate library,5.075925926
cluster spec,5.075
layer sequential_1,5.074882629
keras-gpu=2,5.074731907
"1-gpu

keras",5.074731907
"shape



    model = create_model",5.074361762
"loop indefinitely

pyplot",5.074358974
existing word,5.073926074
"np



class mylayer",5.073919658
weights gradients,5.073064571
import cntk,5.072395884
unexpected edge,5.071428571
randomly shuffle,5.071194763
"log_action_prob * discount_reward_placeholder

        loss =",5.070688605
low train accuracy,5.06990675
basic question,5.069088319
add `by_name=true`,5.068584148
"input

    input_tensor=tensor",5.067871055
"input

>     input_tensor=tensor",5.067871055
effective learning,5.066666667
q-learning,5.066666667
separate dockerfile,5.066666667
learning progression,5.066666667
acc_fn = metrics_module,5.066666667
learning _something_,5.066666667
`import pickle,5.066182131
# calling fit leads,5.064987117
generic exception,5.064386318
"eye

    return variable",5.063728286
"eye

>     return variable",5.063728286
"expected`

`expectation = model",5.061838938
steps_per_epoch = num_images/batch_size,5.061576355
steps_per_epoch=n_images// batch_size,5.061576355
def __init__,5.059808346
"8 

      9     def __init__",5.059808346
"`

`      def __init__",5.059808346
"```

    def __init__",5.059808346
correct margin calculation,5.054644809
unknown `consume_less` mode,5.05387931
calls ``__init__,5.053763441
list/dict,5.05333183
training classifier,5.052095219
import pydot,5.051950632
"6     import pydot
----> 7",5.051950632
model names running,5.051614998
tensorflow datasets,5.05148423
lambda layer loads,5.050350794
keras clone,5.050193648
hard-coded amount,5.05
import cv2,5.049975648
expects input,5.049376559
expecting 5d input,5.049376559
model architecture & weights,5.049215252
core information,5.049108427
"np

x_bad = np",5.048619695
including segmentation,5.048582996
directly tensorflow,5.048295455
keras 2 api,5.047629546
keras api,5.047629546
keras 1 api,5.047629546
variable size inputs,5.046588774
activation function built,5.045775646
basic metrics,5.045687646
dir,5.045454545
global rotation,5.045454545
added dropout layers,5.044929943
keyword argument,5.044573643
/data/style,5.044117647
advanced users,5.043956044
tensorflow back,5.043528505
models/cityscape_model,5.041338583
models/basic_cnn_30_epochs,5.041338583
/models/lstm_ddqn,5.041338583
models serialized,5.041338583
models/shape_aware,5.041338583
models/test_keras,5.041338583
stateful models,5.041338583
models fairly,5.041338583
models/3rd_run_epoch_39,5.041338583
level=logging,5.040441176
encoded = embeddings,5.04
propagation step,5.039506173
"optimizer

optimizer = rmsprop",5.039298246
start outputting lines,5.03902439
tensorflow eager,5.037878788
"make_tensor_proto

    raise valueerror",5.037778506
semantic segmentation,5.037593985
semantic segmentation],5.037593985
single step,5.037355635
"150x150

        batch_size=batch_size",5.036945813
"environment



python 3",5.035223881
python environment,5.035223881
param log,5.034855769
encoder-decoder model,5.033972192
[keras mnist,5.033526982
%time scores = model,5.032610327
trainable variables,5.031529412
tensorflow-gpu 1,5.029083713
"0

tensorflow-gpu==1",5.029083713
"6

* tensorflow-gpu",5.029083713
tensorflow-gpu,5.029083713
tensorflow-gpu==1,5.029083713
"2

tensorflow-gpu==1",5.029083713
`tensorflow-gpu`,5.029083713
tensorflow gpu,5.029083713
tensorflow-gpu = 1,5.029083713
tensorflow-gpu=1,5.029083713
"np



train = np",5.028752145
learning properly,5.028205128
installed keras,5.027971426
installed keras 2,5.027971426
keras installed,5.027971426
input tensor dim,5.027644992
"concatenate

    return concatenate",5.027057156
"autoencoder





x_train = np",5.026857447
losses import *,5.025740955
"predict

    steps=steps",5.025011688
max decoder words,5.023944477
medium term,5.022222222
$ python theano_vs_tf,5.021890547
python floats,5.021890547
3048                 weights[1] = conv_utils,5.021243842
-> 2841             weights[0] = conv_utils,5.021243842
2843             weights[0] = conv_utils,5.021243842
lower level,5.020833333
"layers

[<keras",5.020587782
keras layers,5.020587782
vocabdic[word]=len,5.018365196
successfully training,5.016197783
"model



```

bid1 = bidirectional",5.01468072
proper broadcast,5.014285714
replace softmax layer,5.012956024
thankshi @fchollet,5.012820513
opt exists,5.011695906
"dense layer weights

    #",5.011291995
building model,5.010871196
> building model,5.010871196
performance-wise,5.010436433
`dense` layer model,5.009490777
gpu training,5.007402709
sort methods provided,5.007258065
"add

    output_tensor = layer",5.007082511
"return model
print",5.006147111
def get_recurrent_submodel,5.006044905
def resnet50_model,5.006044905
def rnn_model,5.006044905
def tf_d_stepy,5.006044905
def __iter__,5.006044905
"```

def read_lines",5.006044905
"```

def get_resnet_single_image_model_no_softmax",5.006044905
feature-wise,5.004029009
inception architecture,5.003602676
callbacks=[keras,5.003158075
4/keras/callbacks,5.003158075
run session,5.000925365
output shape computation,5.000382908
keras-tqdm,5.000193648
keras community,5.000193648
keras imports,5.000193648
keras recently,5.000193648
hyperopt package,5
ctc_1/toint64,5
ctc_1/gathernd,5
ctc_1/toint32_1,5
exceed norm 1,5
model_fn=model_fn,5
diagnostic plots,5
list_of_tensors = [path_to_tensor,5
#valid_generator = valid_datagen,5
residual blocks,5
/ deeplearning,5
volatile uncorr,5
scalar_output = bar,5
matplotlib inline,5
quadro k4000m,5
dilations=dilations,5
ml320 driving,5
use_locking=use_locking,5
lecun tu,5
casue issues,5
/flomlo/654a4f7121cf93ac6e1164492d4e7433,5
worse drivers,5
83 fields,5
fairly clean,5
segdatagenerator],5
all_patient_ids = read_lines,5
pressing issues,5
n-element array,4.999771167
normal vector representation,4.996103896
inception-v2,4.995073892
py install,4.995012215
good general direction,4.994990304
"control_dependencies

    return get_default_graph",4.994789272
"control_dependencies
    return get_default_graph",4.994789272
prepared session,4.994490358
"normalize_batch_in_training

>     epsilon=epsilon",4.991666667
initial loss calculated,4.991555094
"evaluate

    steps=steps",4.990591398
tensorflow explicitly,4.99025974
translate_table = dict,4.989795918
size 32x32 extracted,4.989186176
setting `device = cpu`,4.989039779
running mnist_cnn,4.988521579
model evaluation accuracy,4.987585868
"input2]

outputs = [output1",4.987179487
gmm parameters,4.986666667
"main path

        filters",4.986354776
randomly initialized,4.983282675
training phase,4.98286445
"gpus

partitions = lambda",4.982611022
installed tensorflow 0,4.982323232
paper ``efficient backprop``,4.981481481
variable timestep sequences,4.97956242
changing batch size,4.978352012
"__call__

    feed_dict=feed_dict",4.978168363
step-based,4.977344011
channel separately,4.977272727
training data,4.976982097
**training data**,4.976982097
change batch size,4.97622586
"column

x_test = test",4.975852168
strange predicted result,4.975802798
model stacked,4.975486581
image ordering,4.975280899
x86_64,4.975
traces[cmpt],4.975
current design,4.973684211
keras checks,4.972415871
scaling keras,4.972415871
png based labels],4.972261735
segmentation tasks,4.971659919
updating loss function,4.970261254
calling fit generator,4.970220498
python code,4.969337995
reproducible results,4.969129721
"labels



input_img = input",4.968595778
pass sample weights,4.968005493
implement center loss,4.966113441
tensorflow/cuda,4.966083916
3d cnn,4.963686764
"model methods

***comment",4.962610327
network = tflearn,4.961538462
network = similarity_network,4.961538462
local directory,4.961532404
} bind def,4.96059036
half steps completed,4.960573477
param np,4.960207283
learn efficiently,4.958333333
"# global_feature

    global_feature = maxpooling1d",4.956989247
return numpy,4.95637931
test_labels = cross_validation,4.955555556
start increasing lr,4.955555556
start python,4.955223881
pure tensorflow,4.954545455
tensorflow modules,4.954545455
"head

        v_conv1 = conv2d",4.953191489
performance issues,4.951612903
import os,4.950829607
"return model_gen



```",4.950344828
"appreciated

thanksplease make",4.95011655
trn = ratings[msk],4.95
usp=sharing,4.95
torch implementation,4.94980695
cnn algorithm,4.949034749
learning configuration,4.949019608
recurrent model,4.948765933
"model

test_input = np",4.948514377
model compiling time,4.948371196
sudo code,4.947447447
"section 

#cleanup_code_construct",4.947368421
medical image,4.94670947
give wrong gradient,4.946383516
"```python

model",4.946095077
loss function returns,4.94567109
split input tensor,4.942871055
"<module>

    verbose=true",4.942234657
"break

        batch_x_left = np",4.940976514
conv2d_2/kernel,4.940841506
hot encoded,4.940512821
1-hot encoded,4.940512821
`class_weight`dict,4.939795918
checked cpu statistics,4.939415109
`scan` back,4.938983051
"shape[0]

numdims = data",4.938322499
siamese networks,4.9375
generated pb file,4.937466646
--> 317     return layer_module,4.936059113
--> 346     return layer_module,4.936059113
--> 307     return layer_module,4.936059113
"# plot results

plt",4.935516275
non-cudnn,4.934119457
optimization step,4.93362382
"json

model_json = model",4.932976459
training processes,4.93286445
previously trained,4.93204698
upsampling+convolution,4.93
convolution + upsampling,4.93
local variable,4.929095429
undefined batch number,4.928746886
activityregularization layer,4.924882629
simplified model,4.92420453
text generation,4.923202614
epoch end compute,4.92300919
"process_layer

    custom_objects=custom_objects",4.92298784
custom layers,4.922936507
learn sentences,4.922619048
time series,4.92
embeddings * _dropout_mask,4.92
building capsules,4.92
involve building,4.92
convolutional block,4.919838057
read/write weights,4.918877821
"#wrong

model = load_model",4.917035276
importing keras,4.916860315
encoded_vid = keras,4.916860315
gradient clipping,4.916666667
interactive console,4.916666667
"```python

# build",4.915971544
wide resnet,4.914634146
1m files,4.90952381
give memory error,4.90935657
small benchmark,4.909090909
existing summarywriter,4.909090909
gradients turns,4.908963585
long sequence,4.907605501
local environment,4.906238286
ubuntu@insiscsdt-1997,4.905660377
custom callbacks,4.9055068
python `bool`,4.905223881
python bool,4.905223881
distributed training,4.905086672
loss = expg_loss,4.904021938
"```

resnet50 = resnet50",4.903225806
"json string
model",4.902976459
dense features concatenated,4.902827861
"convolution

    data_format=data_format",4.902222222
previous step,4.901410935
"0

__________________________________________________________________________________________________

input_1",4.901057792
anaconda2,4.900900901
pytest  tests,4.900793651
return keras,4.900538476
"model

    x_newfc = averagepooling2d",4.900395006
"py

line 165



`zx",4.900257066
pascal voc,4.9
pascal voc 2012,4.9
"np

x_train=np",4.899652143
"np

----> 2 x_train=np",4.899652143
models restored,4.89848144
test variables,4.897997497
"replacing 

`outputs = dense",4.897583106
embedding sizes,4.896491228
recursive=true,4.895475175
simply adding **kwargs,4.894784954
segmentation faults,4.894736842
data indefinitely,4.894117647
dense layer initializer,4.894029417
good learning,4.893589744
keras pipeline,4.893050791
2 numpy arrays,4.892991004
numpy arrays,4.892991004
numpy arrays --,4.892991004
"previous traceback]

  file",4.89256752
non-picklable,4.891566265
trained successfully,4.890380313
gradient step,4.889506173
3rd coumn,4.888888889
workspace == null && worksize,4.887681159
convolutional filters,4.885964912
"return f1_score 



print",4.88586415
"moving_variance+epsilon=1

bn",4.885714286
creating applications,4.885714286
cudnn library,4.885145784
loss + gradients,4.884414095
"model 

history = model",4.884123345
"0                                            

____________________________________________________________________________________________________

hidden",4.883333333
attention encoding,4.883091787
saved model weights,4.881956309
"np

x_good = np",4.881953028
optimizer weight shape,4.881009012
"gather

    params",4.880868129
dataset sizes,4.880357143
oom error message,4.880046225
"py



simple predict",4.879756814
add weight regularization,4.878928854
started,4.878787879
encoder-decoder approach,4.877883604
"added



    return tuple",4.877524315
csv class file,4.877519347
"get_config

    return copy",4.877187928
"shape[3]

x_trainflat = x_train",4.876189681
mask = tensor_map[str,4.875564423
"fit

    sigma = np",4.87501125
saliency detection,4.875
ga_ssize y_row =,4.875
large networks,4.875
anomaly detection,4.875
couple days ago,4.874231032
"model

hist = model",4.874050085
simple mlp,4.873015873
"# compile

adam = adam",4.873015026
python script,4.872990378
numpy function,4.872273799
"1] range



y_train = np_utils",4.871784512
2480         session = get_session,4.871683341
1601         session = get_session,4.871683341
convolution algorithm,4.87047619
"multiply

    return multiply",4.870344828
color channel,4.87012987
gpu processing,4.869992804
"7034500   

_________________________________________________________________

bidirectional_1",4.869047619
utils code,4.868351402
"# returns

        preprocessed tensor",4.867862666
"shape[1]

depth = x_training",4.867581475
"train_on_batch

>     check_batch_axis=true",4.866384266
architecture depicted,4.865671642
"model input shape

3",4.865404988
preprocessing phase,4.865217391
"247

    248         # early return",4.864630542
estimator = kerasclassifier,4.864522417
# spatial softargmax,4.863636364
**lstm + ctc** part,4.863408521
train input array,4.862613509
"tf

total_loss = tf",4.862262038
"tf

        total_loss = tf",4.862262038
8 i7 cpu,4.861995754
"0                                            

__________________________________________________________________________________________________

model_5",4.861842105
"0                                            

__________________________________________________________________________________________________

model_3",4.861842105
batch sizes > 1,4.860734463
data preprocessing,4.859335038
"object

            idx = int",4.858463745
cvn load put,4.857588358
machine learning,4.857364341
include benchmark,4.857142857
fresh algorithm,4.857142857
public interface,4.857142857
entire sequence,4.855690608
"```python

# x_enc",4.855223881
case image file,4.854472487
internal transformations,4.854166667
build lstm model,4.853084061
model called conv_model,4.853066318
h5 fortran flags,4.852932551
original image,4.852553626
word level,4.852335165
word-level,4.852335165
reproducible code,4.852209352
simplified script,4.851099831
key=lambda tpl,4.850468165
zip function isn,4.850330225
timedistributed layer doesn,4.850169985
minimum sizes,4.85
pascal card,4.85
data generation,4.849673203
training dnn,4.849531117
mnist tutorial,4.848550725
python exception,4.848181627
"epoch params

        batch_size =",4.847529296
temp = mapped[gt[,4.846616541
add `dense` layers,4.846330968
"] unit tests



~~",4.845238095
matmul function,4.844017094
marshal directly,4.84375
"main path

        stage",4.843304843
seq2seq implementation],4.842664093
sample-wise`,4.842607313
sample-wise,4.842607313
hyperopt library,4.842592593
libtiff library,4.842592593
downstream library,4.842592593
flexible library,4.842592593
tensor sizes,4.84245283
keras cnn,4.84208554
cnn = keras,4.84208554
layer bidirectional_1,4.841549296
upsampling layer,4.841549296
similar issues,4.841269841
categorical hinge loss,4.84123124
"concat

    dtype=dtypes",4.841053881
def build_model,4.839378238
copies back,4.838983051
"input tensor

        kernel_size",4.837528314
preprocessing layers,4.835611525
mask extracted doesn,4.835586982
numpy version,4.834363095
"timedistributed

encoded_frame = timedistributed",4.833333333
conversion decorator,4.833333333
non-negative,4.832742736
"expected behaviour



print",4.832450553
"```python

valueerror",4.832288101
conv2d_2/bias,4.831896552
"# check auc

         pred =",4.830970236
typing command line,4.830505337
resnet = resnet,4.829268293
"train

model = model",4.82854151
"train

    model = model",4.82854151
trained correctly,4.827880313
multiple branches,4.827184466
gradients calculated,4.826546003
lstm papers,4.826465201
extracting features,4.825757576
skip training,4.825721593
"<module>

    batch_size=batch_size",4.825536417
numa node,4.825396825
cudnn supports,4.825161887
->physical gpu,4.824538259
-> physical gpu,4.824538259
repeat model loaded,4.82420453
char_indices = dict,4.823129252
quick predict_on_batch loop,4.822843823
ci checks,4.822222222
bounding box,4.819444444
1 channel cnn,4.819164619
connect dense layer,4.818619581
actual batch_size implemented,4.818472906
parallel computing,4.818181818
learning procedure,4.816666667
keras function,4.816432965
function keras,4.816432965
height * width * depth,4.816294024
height * width*depth,4.816294024
#NAME?,4.816294024
train accuracy increase,4.816241061
global layers,4.815848679
early = earlystopping,4.814285714
simple classifier,4.813675214
"pooling

classifier",4.813675214
import codecs,4.813240955
"add_weight

    constraint=constraint",4.813137755
yields image,4.812780899
"0

    __________________________________________________________________________________________________

    resnet_model",4.811842105
org/abs/1602,4.810312617
org/abs/1705,4.810312617
org/abs/1603,4.810312617
org/abs/1505,4.810312617
org/abs/1408,4.810312617
org/abs/1707,4.810312617
org/abs/1706,4.810312617
org/abs/1412,4.810312617
org/abs/1409,4.810312617
org/abs/1503,4.810312617
org/abs/1605,4.810312617
org/abs/1511,4.810312617
org/abs/1512,4.810312617
org/abs/1611,4.810312617
--> 108       initializer = gen_dataset_ops,4.808743169
[densenet implementation],4.806949807
apply `keras,4.806797422
understand correctly basically,4.806147717
runs fine,4.803912214
dropout layer model,4.803110147
classification model,4.802992408
"shape[1] 

    n_channels  = rnn_x",4.80293501
"```python

sess =",4.802592302
def main,4.802341201
view=cntk-py-2,4.801713676
thread related issue,4.800877193
@kmader @dref360,4.8
reconst_layer_2,4.8
"output

    xx = flatten",4.799112314
handle list inputs,4.798473523
scalarfromtensor [id,4.797619048
api design,4.797435897
latest keras,4.797142005
latest keras 2,4.797142005
"vocabulary size

model",4.796724039
current project,4.795112782
regression tasks,4.791208791
"emotion

y_train = train[",4.790890026
execution hangs,4.787878788
3d input,4.787838097
"dtype=float32>

```

strange/",4.787304253
"__________________________________________________________________________________________________

layer",4.786724734
"```

__________________________________________________________________________________________________

layer",4.786724734
tensorflow functions,4.786512668
"2         

_________________________________________________________________

sequential_2",4.785714286
tfindfont exch,4.785714286
continuous improvements,4.785714286
web search,4.785714286
"45}

```



```python

    metrics ={",4.785526911
"```python

    metrics ={",4.785526911
"image files

#",4.784804708
# kernel sizes,4.783944954
conv1d takes care,4.782905297
passing sample weights,4.782706198
"device = cpu



```model",4.779910975
`keras_learning_phase` placeholder,4.779761905
double checked accuracy,4.779328832
keras version 2,4.77852226
keras version,4.77852226
"0



**keras version",4.77852226
**keras version,4.77852226
"0

keras version",4.77852226
"1

keras version",4.77852226
keras version 1,4.77852226
keras version %,4.77852226
training_generator = datagenerator,4.777777778
theano_backend,4.777777778
training_generator = data_genereator,4.777777778
"units]

                x_f = inputs[",4.77773386
"units]

                x_o = inputs[",4.77773386
python setup,4.776276512
sequence labeling,4.775690608
car image,4.775280899
[cnn-training],4.774756342
"input shape



`comb_model",4.774533791
"```

class attention",4.774396135
644] executor failed,4.773809524
resulting training,4.773773541
single sequence,4.77354007
single image,4.773130361
"model

    model = model",4.772613589
"additional data

6",4.772378517
function> const&,4.772121669
"made useless thing

[",4.771764706
differentiable loss functions,4.771703437
minimal reproducible,4.771428571
original data,4.771390374
tensorflow function,4.770784771
layers contained,4.770394134
underlying layers,4.770394134
tensorflow binary,4.770119225
"--------------------------------------------------------------------------------------------------------------------------------------

import keras2",4.76879651
"----> 1 import keras2



~",4.76879651
weird models,4.76861131
"batch_size=900

max_word_len=30

max_sentence_length=#",4.768472906
current data,4.767801858
native method,4.767521368
moving average,4.766666667
embeddings = embedding,4.766491228
reproducible behavior,4.765873016
ctc_1/log,4.765625
"num_class = num_class

        super",4.765517241
"state_spec

            super",4.765517241
"0 locally

x_train shape",4.76507857
generator=loaddata_generator,4.762376238
"avx2 fma

> 2018-05-22 09",4.761904762
"avx2 fma

1/1 [==============================]",4.761904762
"avx2 fma

2018-04-01 21",4.761904762
"expected

    normalization_layer = model",4.761838938
rescale pixel values,4.761586453
"shape[3]

x_testshape = x_test",4.759874649
keras load_model,4.759284557
"tf

 

config = tf",4.758918573
"tf



config = tf",4.758918573
8 gpus parallel,4.758658009
layer sequential_2,4.758215962
numpy matrix,4.757841712
model gan algorithms,4.757537863
dl model,4.757537863
subtensor{int64} [id,4.757033429
def paths_to_tensor,4.756044905
reproducible script,4.755861736
metrics `categorical accuracy`,4.755136095
"99997377e-01]]

predict generator",4.755129861
local cpu,4.754900707
neural model,4.75450756
3d images,4.753373819
files directly,4.75327381
multiple gpu,4.751722725
h5py library,4.751683502
latest tensorflow,4.751493811
"**

```python

traceback",4.751450296
horovod keras,4.750193648
keras loses,4.750193648
keras ruby,4.750193648
keras decipher,4.750193648
cloned keras,4.750193648
"crucially 

keras 2",4.750193648
shared_layer = keras,4.750193648
instruct keras,4.750193648
official keras,4.750193648
keras shows,4.750193648
keras contributors,4.750193648
@keras-teamhello,4.750193648
keras internals,4.750193648
keras repository,4.750193648
rom keras,4.750193648
[keras preprocess_input,4.750193648
keras learner,4.750193648
keras skillset,4.750193648
/dmlc/keras,4.750193648
keras refuse,4.750193648
"preprocess_input`



keras",4.750193648
keras devs,4.750193648
nonstateful_optimizer = keras,4.750193648
stateful_optimizer = keras,4.750193648
keras sees,4.750193648
keras displays,4.750193648
keras v1,4.750193648
0rc0 & keras 2,4.750193648
input_spec = [keras,4.750193648
actual_initial_normalization_scales = keras,4.750193648
actual_initial_weights = keras,4.750193648
actual_initial_bias = keras,4.750193648
branch `keras-2`,4.750193648
keras-2 branch,4.750193648
keras 2 branch,4.750193648
keras committee,4.750193648
keras facilitates,4.750193648
keras implements,4.750193648
"constraint = constraint

attributeerror",4.750089509
randomly change,4.750064086
base_layer,4.75
older versions,4.75
jupyter notebook,4.75
eeg signals,4.75
/emirceyani/7521a831be84e388af227d243dfdbb69,4.75
/emirceyani/d30284ea1c6dcd33442c57a9529af91b,4.75
regularization = customregularization,4.75
[aww-board],4.75
sound signals,4.75
connections sharing,4.75
factorization,4.75
lag operator,4.75
gradient descent,4.75
update=opt,4.749791145
training function,4.749103766
resnet bottleneck,4.74796748
error message appears,4.746712892
"```







```

def inceptionv3",4.74517534
found 1 input samples,4.744802708
image classifier,4.744511668
reproducible result,4.744424352
svm classifier,4.744230769
match kernels,4.743534483
lstm models,4.742803784
"target directory

        target_size=",4.741891479
randomly crashes,4.740425532
saved models,4.739751281
output includes timesteps,4.739463192
back propagation,4.738983051
back-propagation,4.738983051
"back-propagation

        *",4.738983051
produces data,4.738562092
find suitable distribution,4.738247863
windows 10 x64,4.738095238
_uses_learning_phase = true,4.736384266
text = text,4.735294118
"```
    text = text",4.735294118
1d cnn,4.734749035
custom functions,4.734509586
attention mechanism,4.733333333
unlike spacy,4.733333333
tensorflow version 1,4.732874066
`tensorflow version==1,4.732874066
tensorflow version,4.732874066
"14



**tensorflow version",4.732874066
"5

tensorflow version",4.732874066
**tensorflow version,4.732874066
"`



tensorflow version",4.732874066
"4

tensorflow version",4.732874066
"2

tensorflow version",4.732874066
"8

tensorflow version = 1",4.732874066
find index page,4.732747313
minimal debug code,4.730780781
seq2seq encoder,4.730694981
"nan

epoch 2/10

1s",4.729881167
"nan

epoch 3/10

1s",4.729881167
"nan

epoch 4/10

1s",4.729881167
"nan

epoch 5/10

1s",4.729881167
"nan

epoch 6/10

1s",4.729881167
"nan

epoch 7/10

1s",4.729881167
"nan

epoch 8/10

1s",4.729881167
"nan

epoch 9/10

1s",4.729881167
"nan

epoch 10/10

1s",4.729881167
inception model,4.728802231
"train

>     train_generator = zip",4.728617299
def compute_output_shape,4.728267127
"#model

input_shape=features",4.727553142
recurrent submodel,4.726315789
bi-gpu,4.724538259
"asarray

``

``

    return array",4.722843267
"asarray



    return array",4.722843267
"asarray

    return array",4.722843267
binary_crossentropy loss function,4.722513506
single gpu,4.722387721
input numpy,4.722077708
team,4.722007722
time running model,4.721614998
dimension mismatch error,4.720253381
"html



input_img = input",4.719462029
custom function,4.718781689
roughness values range,4.716131907
pooling layers,4.714838578
english sentences,4.714285714
automated stopping,4.714285714
"```

imdb = dataset_imdb",4.714285714
"<table>

  <tr>

    <",4.714285714
"```python

# shape",4.713714447
zero-center,4.711111111
seq2seq autoencoder,4.711038961
fixed length array,4.710748409
predict_generator > total number,4.710003764
"py

model=load_model",4.709187519
state_spec = [inputspec,4.709090909
gray image,4.708614232
cuda backend,4.708267434
vgg19 models,4.708005249
deploy models,4.708005249
full validation,4.706349206
"output_dim = output_dim

     super",4.706257982
"output_dim = output_dim

        super",4.706257982
add conv2d layers,4.705785505
step function,4.705745489
`step` function,4.705745489
function `step`,4.705745489
# force tensorflow,4.704545455
tensorflow counterpart,4.704545455
"0x118117320>

> <tensorflow",4.704545455
"0x1181173c8>

> <tensorflow",4.704545455
"0x111c23ba8>

> <tensorflow",4.704545455
"0x111f3acf8>

> <tensorflow",4.704545455
"**0x118109ef0**>

> <tensorflow",4.704545455
"0x118147390>

> <tensorflow",4.704545455
"0x118178d68>

> <tensorflow",4.704545455
"0x118178160>

> <tensorflow",4.704545455
"0x118178240>

> <tensorflow",4.704545455
"0x11818a1d0>

> <tensorflow",4.704545455
"**0x11818a160**>

> <tensorflow",4.704545455
"0x1181b59e8>

> <tensorflow",4.704545455
"0x11818a128>

> <tensorflow",4.704545455
"**0x11818a898**>

> <tensorflow",4.704545455
/tensorflow/lattice,4.704545455
tensorflow detects,4.704545455
tensorflow-aarch64,4.704545455
chaincrf tensorflow,4.704545455
tensorflow distribution,4.704545455
tensorflow repository,4.704545455
utils  class_weight,4.704237288
common stackoverflow recommendation,4.703211517
masking layer change,4.702942236
add batchnormalization layers,4.702594016
"output

f1_x = globalaveragepooling2d",4.701994209
"output

f2_x = globalaveragepooling2d",4.701994209
expected error stating,4.701013967
"```

resnet_model = keras",4.700193648
keras implementation,4.700000598
95% classification accuracy,4.699744974
custom weight,4.699271345
matrix 1 means present,4.698305828
"dtype=float32>

model",4.698175449
model performs great,4.698014053
numpy raises,4.694923372
adding numpy,4.694923372
grid search,4.692857143
projects,4.692307692
"shape[0]

        print total",4.691603472
objective function,4.691239316
"outputs = [outputs]



            # save",4.691111997
y_train_all=np,4.690976514
model compile method,4.690939363
adapting densenet,4.69047619
audio track,4.69047619
making averages,4.69047619
"4960        

________________________________________________________________________________

dense_1",4.689516129
### train models,4.6881377
unknown backend,4.688108282
composite networks,4.6875
resnet layers,4.68502828
keras blog,4.684976257
effecting training,4.68286445
training heavier,4.68286445
typical training,4.68286445
training begins,4.68286445
training program,4.68286445
actual training,4.68286445
"```



training & exporting",4.68286445
iterative training,4.68286445
training routines,4.68286445
"-1]

    x_test = result[int",4.682713197
simple flag,4.682539683
"sigma = args

        epsilon =",4.682168737
optionally increase,4.681818182
"<module>

    seq2seq",4.681447747
custom version,4.680870985
multiple callbacks,4.680148893
code provided acc -> 90-95%,4.67930631
"200 classes

predictions = dense",4.679032417
tensorboard = keras,4.678765077
keras tensorboard,4.678765077
black dog,4.678571429
performances tests,4.678571429
multiple processes,4.677184466
cpu usage,4.676810569
library loaded,4.675925926
network = regression,4.675824176
save lstm model,4.675756087
step takes,4.675220459
keras layer,4.675076277
"78 

         79     def on_batch_begin",4.672711572
def on_batch_begin,4.672711572
"76 

     77     def on_batch_begin",4.672711572
"+ b1

d1 = tf",4.672692369
expected conv2d_1_input,4.670967742
separate runs,4.670833333
"masks

train_generator = zip",4.670053476
time comparison,4.67
sequence data,4.669808255
easily obtain,4.669642857
training=true,4.669248716
ops,4.668367347
#NAME?,4.668367347
752       ops,4.668367347
1073       ops,4.668367347
xp = keras,4.666860315
teacher-forcing,4.666666667
ray van,4.666666667
storage_map=storage_map,4.666666667
"avx avx2

2017-11-19 17",4.666666667
bot = get_part_model,4.666666667
"38144     

_________________________________________________________________

batch_normalization_1",4.666666667
@rossumai,4.666666667
learning purposes,4.666666667
teacher forcing,4.666666667
language_model,4.666666667
language_model],4.666666667
valid_generator = generate_batches_from_train_folder,4.666666667
discrete curve,4.666666667
texch 0 rlineto,4.666666667
tlayercolorseq curlayer 1,4.666666667
cryptic stacktrace,4.666666667
robot driving,4.666666667
followlinks=follow_links,4.666666667
optional toggle,4.666666667
m_a = dot_product,4.666666667
"62us  cudamemset

  0",4.666666667
"]

            loss_weight = loss_weights_list[",4.666666667
scan function,4.666239316
input = keras,4.666236874
"``` python

input_shape =",4.66614825
input dynamically,4.666043225
"column

x_train = train",4.664498232
3d tensor,4.664247702
read online,4.664233577
word_index = dict,4.663708962
sequential api,4.662364807
"added

`model = multi_gpu_model",4.661384017
continuous image,4.660995185
"windows 10 build 17134

cpu",4.660838655
project based,4.659266409
"categorical accuracy/crossentropy

    #",4.658166398
y_valid = load_cifar10_data,4.657894737
"shape[0]

    labels = np",4.657575188
"_reconstruct

    state = deepcopy",4.657512259
1d convolution,4.656190476
"```python

array",4.654995048
tensorflow implementation,4.654352404
/outputs/steering_model,4.653846154
2928             swap_memory=true,4.653050933
custom objects,4.652542373
lithological class,4.652173913
loading `imagenet` weights,4.650405725
calls return,4.650344828
--> 343         return _load,4.650344828
-> 2226     return rng,4.650344828
"code

`x_train = x_train",4.649512344
trained cnn,4.648938872
re-initialisation,4.648148148
single neuron,4.647849462
preprocessing functions,4.647184604
mxnet backend,4.646728972
recurrent dropout,4.645251059
default [keras,4.64493049
keras docs,4.64493049
keras [docs],4.64493049
keras default,4.64493049
respective values,4.644919786
scheduler method,4.644444444
training network,4.644402912
input channel,4.643315953
cb=parameterhistory,4.642857143
web traffic,4.642857143
awesome library,4.642592593
classification metrics,4.642424242
"counter

        counter = 0",4.64
counter = counter + 1,4.64
shared config file,4.639751958
363us/step**,4.639506173
362us/step**,4.639506173
651us/step**,4.639506173
step began,4.639506173
reversed step,4.639506173
step functin,4.639506173
keras libraries,4.639082537
"optimizer

    grads=optimizer",4.639078947
model load fails,4.638844169
"90 seconds

* tensorflow",4.637878788
random error probability,4.637026003
"_add_inbound_node

    output_tensors[",4.636363636
keras wrapper,4.636158561
> tensorflow-tensorboard,4.633116883
"0

tensorflow-tensorboard==1",4.633116883
/models/model,4.632209779
model = models,4.632209779
"```

model = models",4.632209779
preprocessing function,4.631456708
def create_model,4.631044905
adam/beta_1/read,4.630823966
improve running time,4.630743802
training section,4.630232871
backward convolution,4.628717949
callbacks=callbacks_list,4.627964427
callbacks=[lr_reducer,4.627964427
callbacks = callbacks_list,4.627964427
unbalanced data,4.62745098
def func,4.626924026
simply removing line 257,4.626113238
test cases fail,4.625750136
multiprocessing issues,4.625
**pandas hdfstore**,4.625
"make_thunk

    on_unused_input=",4.625
"make_thunk

    no_recycling",4.625
32bit precision,4.625
"shape

print datagentrain",4.623421653
org/pdf/1603,4.622908623
org/pdf/1502,4.622908623
org/pdf/1707,4.622908623
org/pdf/1710,4.622908623
org/pdf/1709,4.622908623
org/pdf/1610,4.622908623
org/pdf/1408,4.622908623
org/pdf/1607,4.622908623
org/pdf/1503,4.622908623
org/pdf/1404,4.622908623
org/pdf/1512,4.622908623
org/pdf/1510,4.622908623
org/pdf/1611,4.622908623
attention mechanisms,4.622222222
theano->keras,4.621822559
creating networks,4.620833333
"```



```python

print",4.620154968
__init__ function,4.620002757
tensor_type=dt_float,4.62
tparams=dt_float,4.62
tools,4.619047619
"0         

_________________________________________________________________

dense_17",4.619047619
"3200      

_________________________________________________________________

time_distributed_2",4.619047619
"590080    

_________________________________________________________________

time_distributed_5",4.619047619
"1180160   

_________________________________________________________________

time_distributed_6",4.619047619
"327808    

_________________________________________________________________

dropout_4",4.619047619
def __len__,4.617156016
raghakot implementation,4.616473616
fine-tuned,4.616412214
classification loss,4.61614315
changing activation functions,4.616125391
backward compatiblitity,4.615384615
"shortcut

    arguments

        input_tensor",4.615112705
"shortcut

    # arguments

        input_tensor",4.615112705
weight file downloaded,4.614498649
"returna=[]

            returnb=[]

```https",4.614490161
"]



-----------------------------code---------------------

a2= separableconv2d",4.614114114
good idea start,4.613589744
registered kernels,4.6125
[dropout layer sources],4.612238951
sentence classification,4.612121212
feature extraction,4.611872146
keras built-,4.607336505
keras v2,4.607336505
geforce 1080ti,4.607142857
people mix tf,4.606840239
import random,4.605935019
classification task,4.605563835
"information

ipython 6",4.603558577
dummy input=0,4.603543225
dummy input,4.603543225
training time,4.60286445
time training,4.60286445
param gen_handle,4.602564103
gpu installed,4.602316036
build models,4.602086246
build_fn=baseline_model,4.6
mathjax extension,4.6
/capsule/_mnist_cnn_capsule,4.6
"start

>     ioloop",4.6
"start

    ioloop",4.6
tf `conv2d` op,4.59976041
**reproduction steps,4.599462366
data generated,4.59714795
hyper-parameter,4.596385542
operator __getitem__,4.596153846
slicing directly,4.59375
create issues,4.593333333
hot vector,4.593240093
related stackoverflow [thread],4.592685201
cudnn versions,4.592553191
import __version__,4.592551299
training depending,4.591955359
wrong input shape,4.591606962
"```

____________________________________________________________________________________________________

layer",4.591549296
"3

    

    base_model = applications",4.590935169
`base_model = applications,4.590935169
lazily computed,4.590909091
model = make_model,4.590871196
model = tflearn,4.590871196
shared_model = model,4.590871196
model = get_auto_regressive,4.590871196
language model,4.590871196
net = resnet50,4.590501792
"data 

data =",4.588235294
data = data,4.588235294
encoder stays,4.587837838
training set,4.587428765
"allow_growth = true

     

    #",4.586384266
allow_growth = true,4.586384266
allow_growth=true,4.586384266
callbacks=[lrate],4.58629776
gpu cuda 8,4.58607672
generator variables,4.585905649
imagedatagenerator requires,4.585691057
x_in = keras,4.583526982
tower separately,4.583333333
<timed exec>,4.583333333
param mode,4.581730769
def test,4.58051299
ga_double val,4.58008658
"-1]

    y_test = result[int",4.579671655
current imagedatagenerator,4.579375267
gpu support,4.577550307
mnist data,4.57745098
custom-layer,4.577425002
custom layer,4.577425002
custom  layer,4.577425002
translation tasks,4.576923077
tensorflow/theano,4.576174365
image augmentation,4.575280899
past 3 minutes,4.575
additional parameter,4.574646412
gpu utilization,4.574538259
test = read_data_file,4.574468085
] test improvements,4.574468085
pep8 test,4.574468085
keras throws,4.57372306
def masked,4.572711572
keyword arguments,4.572404372
vertical_flip=config,4.571428571
tidx=dt_int32,4.571428571
tensor_type=dt_int32,4.571428571
"call

    input_length=timesteps",4.570694893
keras autoencoder,4.568375467
keras calculates 0,4.568375467
/tmp/autoencoder,4.568181818
"shape[2]



#x_train = np",4.567166195
learning power,4.566666667
function increases,4.566239316
ctc_path_probs function,4.566239316
function differently,4.566239316
running python 3,4.565967682
"error 



> x_train = x_train",4.565444455
data_t1=preprocessing,4.565217391
data_x1=preprocessing,4.565217391
min_max_scaler = preprocessing,4.565217391
word vectors,4.564835165
"channels



img_input = input",4.56459395
single unit,4.564516129
dense_1/kernel_0,4.564516129
dense_1/bias_0,4.564516129
training images,4.564443397
10000 training images,4.564443397
sentiment corpus,4.564102564
issues list,4.563535912
"conv2d



layer1 = conv2dtranspose",4.563222837
training operation,4.56286445
"losses

    keras",4.562693648
def apply,4.562648679
calling `tensorflow,4.561688312
segmentation fault,4.561403509
classification problem,4.560824382
"sgd/momentum optimizer

#",4.560054947
bottleneck=false,4.559701493
2 classes classification,4.559578839
time step,4.559506173
time-step,4.559506173
previous api,4.559340659
"reshape

inp = input",4.557975496
extremely high,4.557692308
validation data,4.556022409
data/validation,4.556022409
data/validation/,4.556022409
/data/validation/,4.556022409
pthe `cifar10_resnet,4.555555556
"doc_vec = vects

    qry_vec =",4.555555556
`model_from_json` function,4.554611409
generated inside,4.553030303
keras tensors,4.552662784
"create_op

    set_shapes_for_outputs",4.552631579
"---------

                  parallel hdf5",4.551515152
object detection][2],4.551056338
object detection,4.551056338
"15 

     16 tbcallback = keras",4.550193648
upgrading keras,4.550193648
"```

tbcallback = keras",4.550193648
single class,4.550023375
ther versions,4.55
reading testing file,4.54937692
~100k images,4.548245614
images perfectly,4.548245614
callbacks_list = [checkpoint,4.547413793
"parallel_model = model



parallel_model",4.547392935
respective output,4.547155499
dynamic output,4.547155499
attention layer,4.547104851
global agent,4.545454545
imdb dataset,4.544642857
packages,4.544502618
data resolution,4.544117647
/users/olalonde/,4.543956044
instruct users,4.543956044
keras works,4.543526982
model = applications,4.543252149
repeat model loading,4.543110002
tensor-board,4.54245283
tensor board,4.54245283
function returning,4.542429792
complete image,4.541947566
produces nan val_loss,4.54147731
img = get_im,4.541401274
multitask models,4.541338583
gof,4.540540541
backward layer,4.540267244
generator=training_generator,4.540154015
generator = training_generator,4.540154015
keras module,4.538784252
continuous support,4.538726334
predict classification,4.538208169
"file

    file2=pd",4.53766215
native code,4.537191037
"dimension n_classes

model",4.536633908
word_dropout = word_dropout #kwargs,4.536199095
wrong state shape,4.535924097
kernel_regularizer=keras,4.535907934
keras callback,4.535907934
tensorflow dataset,4.534902597
hot representation,4.534798535
vgg16 net,4.533950617
"make_tensor_proto

    shape = [int",4.533490566
sub-directories,4.533333333
siamese/mnist,4.533333333
loss_weights coefficients,4.533333333
[mnist siamese,4.533333333
fine-tune,4.53307888
# fine-tune,4.53307888
fine tune,4.53307888
"# fit model

model",4.532443795
training steps,4.532326816
previous layers,4.532298896
real data,4.532212885
model merge stage,4.531857691
keras compute,4.531443648
simple arrays,4.531400966
directly access,4.53125
"# create loss

    total_loss =",4.529270165
keras page,4.527971426
sequence` class,4.527864521
"]      



        # check accuracy

         loss_tr",4.527824767
training     method,4.527308895
3d outputs,4.525641026
"/ 255



    return image",4.525625726
decoder embeddings,4.525263158
"]



num_files_train_1 = int",4.525
video data,4.524886878
correctly support `,4.523845382
continue training,4.52286445
face dataset,4.522664835
"mean_squared_error



model = model",4.521742393
class classifier,4.521404682
current weight,4.520413182
layers separately,4.520394134
final layers,4.520394134
"__init__

>     super",4.519280682
"__init__

    super",4.519280682
`optimize` param,4.519230769
trained network,4.518585441
x_train=read_images,4.517699115
"0         

_________________________________________________________________

dense_1",4.516897081
"53200

_________________________________________________________________

dense_1",4.516897081
"160800    

_________________________________________________________________

dense_1",4.516897081
data distributed,4.516339869
loaded training,4.516197783
obvious solution mentioned,4.515274034
def load_model,4.515135814
"0         

_________________________________________________________________

embedding_1",4.514880952
time_distributed_4/convolution,4.513333333
training dataset,4.513221593
backend function,4.512968288
"= 50

generator = build_generator",4.512376238
input_data = keras,4.51209841
validation folders,4.511904762
res = tf,4.511327418
queue size didn,4.511264098
"units]

                x_c = inputs[",4.511067194
mini-batch,4.510734463
generator returns 2 rows,4.510513346
call `keras,4.510018976
trained end,4.509877169
`pretrained_model = load_model,4.509090909
test_set = sequence,4.509023941
"05

gtx 1080ti",4.507575758
performance differences,4.507168459
global network,4.506993007
"1336 

   1337   def _extend_graph",4.506044905
"`



def getmodel_fcn",4.506044905
"1012 

   1013     def load_end",4.506044905
"```

def _preprocess_numpy_input",4.506044905
"```

def list_pictures",4.506044905
"```

def my_loss",4.506044905
"```

def cos_distance",4.506044905
`def cnn_3d,4.506044905
"= 100





def get_sub_model",4.506044905
def kl_divergence,4.506044905
def lstm_model_2d,4.506044905
def simple_cnn_network,4.506044905
def comapre_list_weights,4.506044905
10 @@ def _need_convert_kernel,4.506044905
def eucl_dist_output_shape,4.506044905
def contrastive_loss,4.506044905
"```

```

def create_base_network",4.506044905
def create_base_network,4.506044905
"```

def generate_data_generator",4.506044905
`def mycategoricalcrossentropy,4.506044905
def roc_auc_score_loss,4.506044905
def euclidean_distancex,4.506044905
def triplet_loss,4.506044905
def fake_loss,4.506044905
"**

```

def read_avg",4.506044905
> def my_loss,4.506044905
"```

def generalized_dice_loss_w",4.506044905
"258 

    259 def _make_iterencode",4.506044905
def ss,4.506044905
/showpage { } def,4.506044905
% /arrowlength 10 def,4.506044905
% /arrowwidth 5 def,4.506044905
def defmodel,4.506044905
def u_net,4.506044905
def outer_concat,4.506044905
def get_action,4.506044905
"0

def dice_coef",4.506044905
def decode_sequence,4.506044905
def get_img_from_gmm,4.506044905
"```

def get_weights_without_softargmax",4.506044905
def get_layer0_outputs,4.506044905
def get_content_loss,4.506044905
def get_nontrainable_model,4.506044905
def run_stuff,4.506044905
def _make_train_fn,4.506044905
"```

def special_loss_function",4.506044905
`def customlossfunction,4.506044905
def data_genereator,4.506044905
"``` 

    def preprocess_input",4.506044905
def _get_conv_pool,4.506044905
def compute_loss,4.506044905
def create_siamese_network,4.506044905
`def weighted_pixelwise_crossentropy,4.506044905
"```

def preprocess_train",4.506044905
def multi_gpu_test_simple_model,4.506044905
def get_r_i,4.506044905
def create_final_model,4.506044905
def predict_image_class,4.506044905
def make_lstm_input,4.506044905
def query_cnn,4.506044905
"```

def categorical_hinge",4.506044905
def kl_shape,4.506044905
def rel_shape,4.506044905
def get_deep_representations,4.506044905
"```

def test_metrics",4.506044905
def train_and_test,4.506044905
"201 

    202   def __repr__",4.506044905
"```

def create_base_network",4.506044905
def load_data_from_file,4.506044905
"[0]

    

    def stepygrad",4.506044905
def mapvaluescharlevel,4.506044905
def buildintmap,4.506044905
def padwordlevel,4.506044905
"1036 

   1037   def _extend_graph",4.506044905
"2



    def prep_model1",4.506044905
"```

def get_lstm_resnet_batchnorm",4.506044905
def read_model,4.506044905
"483 

    484 def asanyarray",4.506044905
"```
def batch_predict_generator",4.506044905
def computeppl,4.506044905
callbacks = callbacks,4.505928854
callbacks=callbacks,4.505928854
turn back,4.505649718
upgrading tensorflow,4.504545455
local path,4.504016064
train densenet,4.503941974
org/explore/,4.503861004
current version,4.502012822
training autoencoder,4.501046268
-> 1567     c_op = c_api,4.5
multi_gpu_utils,4.5
unexpected weighted_accuracy,4.5
/cuhk03/cuhk-03,4.5
demo codewhen,4.5
smaller fluctuations,4.5
"_addgrad

    rx",4.5
converter_o_t=lookup,4.5
indifferent wrt,4.5
slot fillings,4.5
tmp_x = tmp_x,4.5
model_new_predict_valid = model_new,4.5
/p7w3m0d5be/ -dcdn-0{1,4.5
layerlen mod,4.5
n2 lt {,4.5
pyenv,4.5
fb1887d132a8ce8548ff53d868a6ba531cd63b34,4.5
varied capacity,4.5
starts spewing,4.5
"0           batch_normalization_1984[0][0]   

max_pooling2d_52",4.5
output_height = input_height,4.5
"_feed_inputs[0]

    _swap_placeholder",4.5
bottleneck_features_train_v1 = pretrained_model,4.5
"3>

    inputimages = readalljpegsinfolderandmergeasrgb",4.5
bottleneck_features_train_v2 = pretrained_model,4.5
x_row += numrowsx,4.5
"ctc_cost

    log_probs",4.5
automatically interpolated,4.5
414     shape_size = nparray,4.5
serial comunication,4.5
behaving differently,4.5
vid_clip = clip1,4.5
bottle_feature = curr_layer_model,4.5
2225     rng = randomstreams,4.5
distinct phases,4.5
poses issues,4.5
sandbox,4.5
utilize `tf_stepy`,4.5
selectively dropping,4.5
expected_initial_normalization_scales == actual_initial_normalization_scales,4.5
expected_initial_weights == actual_initial_weights,4.5
0050us     558ns  529,4.5
"460us  cudevicegetname

  0",4.5
/nicolov/segmentation_keras,4.5
numerically instable,4.5
rnn based,4.49912816
tf builds,4.498506906
fcn paper,4.498148148
2d resnet,4.49796748
output = keras,4.497349148
#output = keras,4.497349148
numpy `np,4.497010997
base_model = densenet,4.495697074
data augmentation,4.494117647
**data augmentation,4.494117647
data-augmentation,4.494117647
fc7 = dense,4.493736952
training batch,4.493598913
batch training,4.493598913
global feature,4.490660025
validation_steps=valid_steps,4.489473684
layer dense_1,4.489398758
merged models,4.488707004
"output

    x1 = globalaveragepooling2d",4.487959121
layer named `,4.487382629
named layer,4.487382629
hidden layers,4.4870608
# hidden layers,4.4870608
hyper parameters,4.486666667
allow_soft_placement=true,4.486384266
"```

class recurrentwrapper",4.485507246
long sequences,4.484295846
fma instructions,4.484126984
seq2seq model,4.483728339
---> 52         return getattr,4.483678161
separate folders,4.483333333
randomly shuffled,4.483282675
[info] loading model,4.481571541
entire contents,4.48
"# returns

            scalar tensor",4.479983878
date compared,4.479890311
pretty long,4.479283315
trainable layers,4.478394134
additional complexity,4.47826087
step predictions,4.477344011
samplewise_center=false,4.476368159
samplewise_std_normalization=false,4.476368159
return_sequence = false,4.476368159
`return_sequence=false`,4.476368159
"]]



training works",4.476197783
"state_c]



# set",4.475992887
running tf natively,4.475917374
regular conv,4.475
average filter,4.475
current basis,4.473684211
channel dimension,4.473035439
"output

    x2 = globalaveragepooling2d",4.472364579
vanilla & variational,4.472222222
sub-batches,4.472222222
fully executable,4.472222222
v-net,4.472222222
upsampling approaches,4.472222222
pretrained weights,4.471460293
test_model = load_model,4.470629371
save/load code,4.470506776
pairs array passed,4.470406088
"```python

img_width",4.469977979
pretrained model,4.469659075
google drive link,4.469097222
global position,4.468531469
json serializable,4.467105263
metric_fn = metrics_module,4.466666667
larger corpus,4.466666667
training sample,4.466648234
utility function,4.466239316
generate data,4.464849354
small differences,4.464646465
"keras

 

edit",4.464479363
call tensorflow,4.464370782
single function,4.464088779
code block number 30,4.463994668
back-trace,4.463983051
trace back,4.463983051
tweets specifically,4.461538462
"cnn

classifier",4.461122661
local file,4.46067463
training pairs,4.460642228
current parameters,4.460350877
works perfectly,4.46
"feature dim = 1



    

  





target_size=",4.459476367
word data,4.458952812
"deepcopy

    rv = reductor",4.458713164
"deepcopy

>     rv = reductor",4.458713164
"```

def gen",4.458425857
modify highlight,4.458333333
param epoch,4.45815977
cnn = sequential,4.456820802
training process,4.455591723
"model throws



    line 360",4.455432261
"<module>

    train_model",4.455257271
tensorflow while_loop,4.454545455
updated keras,4.453897352
source image,4.453712271
def get_model,4.453413326
"`

def get_model",4.453413326
test_generator = test_datagen,4.453333333
keras `variable`,4.453050791
medical images,4.453007519
"compile

    total_loss = tf",4.452712188
"0         

_________________________________________________________________

time_distributed_3",4.452380952
vgg_model = applications,4.452380952
"204928    

_________________________________________________________________

time_distributed_3",4.452380952
"819456    

_________________________________________________________________

time_distributed_4",4.452380952
long time,4.451914894
keras lstm,4.45165885
lstm keras,4.45165885
resnet50 describes,4.451612903
obtain batches,4.451388889
adds noise,4.450980392
`return score_array`,4.450344828
keras instances,4.450193648
regular methods,4.45
y_ = helper,4.45
recently implementing,4.45
test image,4.449748984
great library,4.44973545
[densenet model],4.448014053
"densenet

model",4.448014053
> [id bi],4.447619048
backend maps,4.446728972
backend component,4.446728972
backend independent,4.446728972
backend engines,4.446728972
val data,4.445632799
return data[,4.444462475
simple magnification,4.444444444
alway full,4.444444444
simple subsampling,4.444444444
simple calculus,4.444444444
highly detailed,4.444444444
site,4.442028986
continue indefinitely,4.44
pos tagging,4.44
suggested step 2,4.439506173
"```

 offending lines",4.43902439
base_network = vgg16,4.438539989
custom callback],4.438256659
custom callback,4.438256659
"virtual class

487             //  2",4.437888199
train_datagen = image,4.437780899
runs smoothly,4.4375
"# compile model

model",4.437366115
"#compile model

model",4.437366115
res = model,4.437025042
accelerometer data,4.43697479
accelerometer data],4.43697479
takes 3 vectors,4.435714286
current network,4.435222672
binary classifier,4.43480454
labels_test = train_test_split,4.434782609
trainable = false,4.434368159
trainable=false,4.434368159
"trainable = false



#

#",4.434368159
trainable=false`,4.434368159
trainable == false,4.434368159
trainable = false`,4.434368159
`trainable=false`,4.434368159
reproduce theano behavior,4.434060154
user parameter,4.433808855
ground-truth,4.433333333
earlystop = earlystopping,4.433333333
ground truth,4.433333333
perform training,4.43286445
"training

num_gpu = 8 #",4.43286445
function fine,4.43265153
image_ocr code,4.432295932
rnn layers,4.431684456
"json

json_file = open",4.431235698
2d datasets,4.430272109
/keras environment,4.430193648
parameter noise],4.429718876
hot labels,4.428620929
"fetch_pkg

        download",4.428571429
status bar,4.428571429
"call_cpp_shape_fn

    debug_python_shape_fn",4.428571429
progbar averages,4.428571429
f_start = get_r,4.428571429
interactiveshell,4.428571429
source codes,4.428431373
"fit

    sample_weight=sample_weight",4.42762448
"fit
    sample_weight=sample_weight",4.42762448
multiple terminals,4.427184466
initializers based,4.426726727
object detected,4.426056338
callbacks = [checkpoint,4.42537822
callbacks=[checkpoint,4.42537822
consecutive cnn,4.425225225
lamda layer,4.424882629
calls `layer,4.424882629
layer flatten_3,4.424882629
custom metric,4.424694272
estimator = tf,4.424432831
tf estimator,4.424432831
172                     reductor = getattr,4.424242424
176                         reductor = getattr,4.424242424
seq-2-seq model,4.42420453
main argument,4.424203273
current implementation,4.42349116
output shape _,4.422719236
sigmoid activation function,4.422209431
data argument,4.422024624
"]

    merge = keras",4.421949374
`merge = keras,4.421949374
"categorical_accuracy

monitor = earlystopping",4.420512821
deep dream,4.419753086
"callbacks

regr",4.419631094
optimiz = optimizers,4.419354839
adadelta_ema = optimizers,4.419354839
adam_ema=optimizers,4.419354839
sgd_ema = optimizers,4.419354839
_optimizer = optimizers,4.419354839
shape wise,4.417314095
keras gave,4.416860315
plug keras,4.416860315
input_layer1 = keras,4.416860315
keras manage,4.416860315
actual_scales = keras,4.416860315
special calculation,4.416666667
weights variables,4.416201826
trainable=trainable,4.416
trainable = trainable,4.416
**backward compatible**,4.415384615
` def _get_batches_of_transformed_samples,4.415135814
"861 

    862     def _get_batches_of_transformed_samples",4.415135814
standard api,4.415082956
custom generator,4.414918611
partial networks,4.414772727
resnet v1,4.414634146
resnet variants,4.414634146
"requested

391       // convolution",4.413333333
resnet50 network,4.413151365
"valid characters

valid_chars = {",4.412162162
"time

        # remove padding",4.411743119
rnn separately,4.411290323
function directly,4.409989316
blacklisted files,4.40952381
program files,4.40952381
/program files,4.40952381
net = layers,4.409283023
state_c = encoder,4.409266409
small portion,4.409090909
"## existing workarounds

*",4.409090909
"`

`response = permute",4.408888889
variable const&,4.408739496
simple stack,4.408730159
label = read_and_decode,4.408396947
builds fails,4.408333333
string-level,4.4075
including support,4.406858202
simple network,4.405982906
outputs=keras,4.404039802
outputs = keras,4.404039802
dice loss,4.404021938
loss=[mse_gmm,4.404021938
loss aggregation,4.404021938
"sequence`



## version",4.40401922
"int64

label_length = input",4.403489643
#encoder =preprocessing,4.403055229
multiple times,4.402794222
custom constraints,4.402542373
class names,4.402173913
original layer,4.402155356
embedding generation,4.402046784
resnet_model = resnet50,4.401612903
`max-pooling`,4.401587302
max pooling,4.401587302
--> 243             return load_dynamic,4.400344828
return atomicexch,4.400344828
"gradient

            return",4.400344828
return moving_averages,4.400344828
//travis-ci,4.4
labeling granularity,4.4
travis ci,4.4
08 lagging significantly,4.4
bi-grams,4.4
significantly poor,4.4
shutdown requested,4.4
accumulated,4.4
forward propagation,4.4
vectorize_sequences <- function,4.39957265
"current layer

    165                     #",4.39856684
current layer,4.39856684
usage difference,4.398148148
single worker,4.397849462
list = ls,4.396869245
unexpected behaviour,4.396551724
"call

    output_tensors",4.396188964
/project/test,4.395896657
"window]

        normalised_data",4.395833333
callbacks=[cb],4.39582157
step-size,4.395359016
vgg16 upto,4.395061728
`lossmodel=vgg16,4.395061728
vgg_16 = vgg16,4.395061728
"```

def roc_auc_score",4.394933794
"**



```

def roc_auc_score",4.394933794
# def roc_auc_score,4.394933794
def roc_auc_score,4.394933794
additional input,4.394304095
simple implementation,4.394251394
full implementation,4.394251394
limited data,4.394117647
data backwards,4.394117647
original input,4.393315953
input_layer = keras,4.393050791
pretty simple,4.391812865
non-breaking,4.391566265
non-locking,4.391566265
functional model,4.390871196
"model 

    model_gen",4.390871196
mlp network,4.39010989
current input,4.389727436
entire ram,4.389090909
lstm networks,4.388965201
3rd column,4.388888889
u-net,4.388888889
avx instructions,4.388888889
avx2 instructions,4.388888889
[u-net],4.388888889
dll locally,4.388888889
multiple frames,4.388722928
"fit

    batch_size=batch_size",4.387647216
"fit
    batch_size=batch_size",4.387647216
custom constraint,4.38723625
test sets,4.386968085
keras vae,4.386557285
pickle_safe=true,4.386384266
saved networks,4.385912698
separate class,4.385507246
estimators,4.384615385
tensorflow environment,4.384545455
lstm training,4.384329652
training lstm,4.384329652
screen shot 2018-05-03,4.383838384
[screen shot 2018-03-20,4.383838384
screen shot 2017-11-22,4.383838384
[screen shot 2017-11-17,4.383838384
screen shot 2017-10-31,4.383838384
screen shot 2017-10-30,4.383838384
screen shot 2017-10-08,4.383838384
screen shot 2017-05-09,4.383838384
training instances,4.38286445
"convolution

classifier",4.382564103
weight = model_base,4.380062305
multiple sequences,4.379565418
layer custom_variational_layer_1,4.379428084
/src/train_all,4.378378378
"```

model1 = keras",4.378100625
2d data,4.37745098
[keras documentation],4.376860315
keras documentation,4.376860315
"623                 return false

    624",4.376712987
downgrading cudnn,4.375886525
sequence independently,4.375690608
padded sequence,4.375690608
longest sequence,4.375690608
sequence lengths,4.375690608
word_testtokenintpad = sequence,4.375690608
/image/image_vid_439_0115,4.375280899
image 192x192,4.375280899
"] = image

            batch_mask[",4.375280899
image retrieval,4.375280899
image datagenerator,4.375280899
8 bands image,4.375280899
actual image,4.375280899
test_batches = image,4.375280899
image descriptions,4.375280899
image captioning,4.375280899
trained autoencoder,4.375228798
individual contributions,4.375
visible devices,4.375
variational_autoencoder,4.375
#data_x1=scaler,4.375
varying speeds,4.375
worker devices,4.375
base class,4.374396135
correct custom,4.373853848
data source,4.37254902
gpu id,4.372157306
average metric,4.372151899
tensorflow summaries,4.371212121
adds support,4.370659107
list `[numpy,4.369570394
pooling layer,4.369327074
muticlass classifier,4.369230769
"flattening

classifier",4.369230769
make predictions consistent,4.369150969
validation_data=loaddata_generator,4.368932039
test data,4.368585732
explanatory text,4.367647059
chinese text,4.367647059
nietzche text,4.367647059
fine turning,4.366412214
# fine-turning,4.366412214
fine tunes,4.366412214
"stream

        data =",4.365546218
merging `sequential`,4.36492891
keras code,4.364307762
keras 1 code,4.364307762
"floatx=float32



theano",4.36394591
img_array_iobl = img_array_iobl,4.363636364
"flags
flags = flags",4.363636364
def vae_loss_func,4.363187762
home,4.363070539
/home/,4.363070539
"predict

    batch_size=batch_size",4.363032769
cnn layers,4.362286026
3 cnn layers,4.362286026
true sequence,4.362074874
functionality nicely,4.361904762
3 0                                             __________________________________________________________________________________________________ block1_conv1,4.361842105
triplet network,4.361538462
hierarchical rnn,4.361290323
full input,4.36048767
gripper state,4.36036036
subsequent call,4.359825328
#labels=keras,4.358301756
"```

encoder_input_data = np",4.357643181
decoder_input_data = np,4.357643181
decoder_target_data = np,4.357643181
simple snippet,4.357487923
easy interface,4.357142857
calling `remove_slice`,4.357142857
vectorized manner,4.357142857
units dead,4.356521739
"<module>

    input_dim=25

  file",4.356360281
weighted metric,4.355485232
"callbacks=[

                        earlystopping",4.352964427
callbacks = [earlystopping,4.352964427
earlystopping = callbacks,4.352964427
callbacks=[earlystopping,4.352964427
big data,4.352941176
gpu version,4.35286687
def __getitem__,4.352198751
blank class,4.352173913
class constr,4.352173913
vgg-16 network,4.35042735
"reverse

    return",4.350344828
`<start>` tag,4.35
gan training,4.349531117
steps=test_steps,4.349462366
trainable params,4.348127389
"817

trainable params",4.348127389
"169

trainable params",4.348127389
"729

trainable params",4.348127389
"368

trainable params",4.348127389
"600

trainable params",4.348127389
"722

trainable params",4.348127389
"256

trainable params",4.348127389
"130

trainable params",4.348127389
"116

trainable params",4.348127389
"165

trainable params",4.348127389
"925

trainable params",4.348127389
"463

trainable params",4.348127389
"385

trainable params",4.348127389
"931

trainable params",4.348127389
"698

trainable params",4.348127389
"104

trainable params",4.348127389
"878

trainable params",4.348127389
"798

trainable params",4.348127389
"656

trainable params",4.348127389
"972

trainable params",4.348127389
"751

trainable params",4.348127389
"903

trainable params",4.348127389
"0

trainable params",4.348127389
"197

trainable params",4.348127389
"415

trainable params",4.348127389
"150

trainable params",4.348127389
"514

trainable params",4.348127389
"870

trainable params",4.348127389
"42

trainable params",4.348127389
"2

trainable params",4.348127389
/datasets/dataset14-,4.346938776
users tensors,4.34642518
"```

def on_batch_end",4.346044905
def on_batch_end,4.346044905
test layers,4.344862219
method calls,4.344444444
require users,4.343956044
shipped directly,4.34375
multiple-input,4.343227691
/tmp/weights,4.342672414
keras model,4.341064845
# keras model,4.341064845
model keras,4.341064845
model = keras,4.341064845
----> 1 model = keras,4.341064845
keras-model,4.341064845
"```





def get_batches",4.339378238
"```

def get_batches",4.339378238
sample generation,4.339339339
installed scipy,4.339002268
merging back,4.338983051
communicated back,4.338983051
feed output t-1,4.338608491
inputs=[style,4.337878788
holds information,4.337704918
expected dense_16,4.337634409
user implemention,4.337423313
user waring,4.337423313
"710s

user",4.337423313
"736s

user",4.337423313
user mask_zeo,4.337423313
frames/sequence,4.337229069
feedforward network,4.336538462
"input_file

output_file = args",4.336335404
additional built-,4.335403727
gru cells,4.334004024
entity pair,4.333333333
memory duplication,4.333333333
3/plugins/model_lowmem,4.333333333
gradient calculation,4.333333333
"/1gcmwe4sef205fbklt3w1l3hl1ursyc7ljiz3agh3ea0



> inspired",4.333333333
nested cv,4.333333333
8gb memory,4.333333333
model_base = inceptionresnetv2,4.333333333
00gib freememory,4.333333333
x_row * stridesx0,4.333333333
y_row * stridesy0,4.333333333
test1=test_generator,4.333333333
win10 simulator,4.333333333
basic_string<wchar_t,4.333333333
char_traits<wchar_t>,4.333333333
rdn = recurrentwrapper,4.333333333
grad=stepygrad,4.333333333
red box,4.333333333
"27us  cudaconfigurecall

  0",4.333333333
prevent duplication,4.333333333
carefully review,4.333333333
pair construction,4.333333333
nn_impl,4.333333333
"processthread

    trainer",4.333333333
references deepface,4.333333333
fps = fps,4.333333333
train_target = load_train,4.333333333
add ctc loss,4.332375666
inceptionv3 cnn,4.331022327
imbalanced dataset,4.330357143
svhn dataset,4.330357143
artificial dataset,4.330357143
broadcasting add op,4.330261897
keras guys,4.329141017
write till,4.328638498
external argument,4.327906977
gen=image,4.327661851
"```

gen = image",4.327661851
warn_float64=raise,4.327380952
`history` property,4.327380952
f-score,4.327067669
avg]pooling[1-3],4.326797386
binary encoding,4.326443336
data provided,4.326375712
validate_indices=false,4.326368159
linux  3,4.326086957
linux,4.326086957
produces images,4.326023392
trainindex[idx*batch_size,4.325880314
remain features,4.325757576
input files,4.325567035
"<details>



---------------------------------------------------------------------------

    typeerror                                 traceback",4.325393082
"<details>

    ---------------------------------------------------------------------------

    typeerror                                 traceback",4.325393082
gpu memory,4.324538259
mono-gpu,4.324538259
gpu speedups,4.324538259
gpu memory**,4.324538259
gpu makes,4.324538259
"384gb

    gpu",4.324538259
"gpu memory
    #
```",4.324538259
def rmse,4.324226723
"```

def autoencoder",4.324226723
attention lstm,4.323687424
elif pooling ==,4.323232323
position vectors,4.323076923
single layer,4.322732091
"windows 10

keras",4.32162222
maskrcnn project,4.321428571
ios project,4.321428571
personal project,4.321428571
"preprocessing



    size",4.321070234
steps_per_epoch=training_generator,4.320881226
elapsed time,4.32
lower=true,4.3197176
early testing,4.319548872
1d object,4.318913481
tensorflow code,4.318659569
"tensorflow



code",4.318659569
batch_size scheduler,4.318472906
fully supported,4.318376068
theano backend,4.318357882
backend=theano,4.318357882
**theano backend,4.318357882
autoencoder = autoencodercreator,4.318181818
tensorflow graph,4.317990833
entire predictions,4.317837838
input car,4.316043225
input vectors,4.316043225
3 input vectors,4.316043225
le = preprocessing,4.315217391
redundant checking,4.315151515
"inputs

      channel",4.315151515
"1-channel]



inputs",4.315151515
2nd version,4.314042898
single-input,4.313892688
single input,4.313892688
list dynamically,4.313535912
** p3,4.3125
p3,4.3125
handles losses,4.3125
changed `models=,4.311608853
merge step,4.311261898
batch norm,4.310734463
variables added,4.310708899
"```

m1 = keras",4.310193648
cifar10 images,4.310150376
mask_zero=false,4.309701493
long post,4.309692671
multiple images,4.308763413
word indexes,4.307692308
exception_verbosity=high,4.307692308
deeply appreciated,4.307692308
"step

    f_active_next",4.30617284
"```

def _standardize_weights",4.306044905
cntk backend,4.305883902
base_model = xception,4.305220884
regression model,4.305156911
`return_state` flag,4.304761905
``trainable`` parameter,4.304385542
class <class,4.304347826
"1

* cuda / cudnn",4.304091653
current dataset,4.304041353
"__init__

    reduction",4.303763441
multiprocessing tests],4.303571429
featurewise_center=false,4.303291236
featurewise_std_normalization=false,4.303291236
"0

        featurewise_std_normalization=false",4.303291236
"0

                featurewise_std_normalization=false",4.303291236
"0

                                       featurewise_std_normalization=false",4.303291236
"0
        featurewise_std_normalization=false",4.303291236
gid = h5g,4.303030303
video stream,4.302197802
"return

    return",4.300689655
model summary returns,4.300458248
glove rathern,4.3
require `_get_batches_of_samples,4.3
equally divided,4.3
mobilenet modle,4.3
y_holdout = split_validation_set_with_hold_out,4.3
pretraining phase,4.3
predictions = test_model,4.299376299
`predictions = test_model,4.299376299
transposed convolution,4.299047619
support caffe,4.298466594
dense_1/kernel,4.298461083
directly reuse,4.298295455
advancedsubtensor1 [id,4.297619048
api enabled,4.297435897
api tracing,4.297435897
api philosophy,4.297435897
api transparently,4.297435897
bundle api,4.297435897
unified api,4.297435897
validation_steps=math,4.297165992
training code,4.296978564
main memory,4.296296296
main frustrations,4.296296296
m2 = keras,4.295648194
tensorflow model,4.295416651
1198] invalid argument,4.294573643
1192] invalid argument,4.294573643
1148] invalid argument,4.294573643
invalid argument,4.294573643
1152] invalid argument,4.294573643
975] invalid argument,4.294573643
optimization/orchestration,4.294117647
data talks,4.294117647
data formats,4.294117647
data/famfinal,4.294117647
data/seqfinal,4.294117647
fake data,4.294117647
"#

# sythetic  data",4.294117647
da data,4.294117647
/data/data40_new3,4.294117647
10x1024 data,4.294117647
"]

    batch_len = data",4.294117647
#temporary data,4.294117647
data succesfully,4.294117647
"```

seedvector = data[0]",4.294117647
`seedvector = data[0],4.294117647
data corruption,4.294117647
optimization instrumentation,4.294117647
telemetry data,4.294117647
data modality,4.294117647
nonsense data,4.294117647
keypoint data,4.294117647
data/train_s,4.294117647
data/val_s,4.294117647
data = min_max_scaler,4.294117647
converts data,4.294117647
data preprocessig,4.294117647
alexnet = sequential,4.293500339
tensorflow background,4.292780749
back-end,4.29181324
input sequence,4.291733833
n_symbols*n_days_other,4.291666667
input image,4.291324124
training labels,4.290972558
tensorflow_backend,4.290697674
machine translation,4.290697674
`tensorflow_backend,4.290697674
"```



changing `pretrained`",4.290552585
previous version,4.290233374
outputs=output_tensors,4.29020979
"```



sklearn returns",4.289842826
1] requested permute,4.288888889
"<module>

    runsingleagentexperiment",4.288590604
"<module>

    features_conv1_1 =",4.288590604
function `compute_output_shape`,4.288461538
seconds logging,4.28627451
"sentence

        merged = concatenate",4.285724585
manually separating,4.285714286
manually rebuild,4.285714286
manually carrying,4.285714286
pipeline = pipeline,4.285714286
current batch,4.284418674
3 convolution layers,4.283727467
reference doc,4.283653846
keras/**init**,4.283526982
checkpoint mechanism,4.283524904
stop iteration problem,4.283485779
test_y1 = mnist,4.283333333
test_y2 = mnist,4.283333333
mnist ccn,4.283333333
mnist tutorialhi,4.283333333
start training,4.28286445
ensemble training,4.28286445
> start training,4.28286445
arguments effect predict_generator,4.282721832
"0s

prediction",4.282676673
encoder = labelencoder,4.282282282
layer concatenate_1,4.282025486
activations interact,4.28125
true data,4.280501913
"error

[<keras",4.280239873
binary matrices,4.279859485
optimizers state,4.279715199
single images**,4.27942841
internal cnn,4.279391892
layer lstm_2,4.277823806
runtime matches,4.277777778
freshly installed,4.277777778
single release,4.276637341
extracted image,4.275280899
generic_utils,4.275
restore test,4.274468085
sequential components,4.274019819
hidden cell,4.273809524
model training,4.273735646
training model,4.273735646
training = model,4.273735646
state_c = lstm,4.272893773
single filter,4.272849462
shot clock,4.272727273
--> 243         model = model_from_config,4.272689378
"`

model = model_from_config",4.272689378
--> 233         model = model_from_config,4.272689378
entire tensor,4.27245283
python3,4.271226415
--> 432       return func,4.271223948
return func,4.271223948
---> 91             return func,4.271223948
---> 87             return func,4.271223948
--> 131         return [func,4.271223948
"return func

```",4.271223948
correctly afterward,4.270833333
correctly serialized,4.270833333
correctly aggregating,4.270833333
lattice layers,4.270394134
encoded_question] layers,4.270394134
downstream layers,4.270394134
layer_conv2d_2_shared_cc = layers,4.270394134
layer_conv2d_3_shared_cc = layers,4.270394134
layer_conv2d_4_shared_cc = layers,4.270394134
layer_conv2d_1_shared_obl = layers,4.270394134
layer_conv2d_2_shared_obl = layers,4.270394134
layer_conv2d_3_shared_obl = layers,4.270394134
layer_conv2d_4_shared_obl = layers,4.270394134
atomic layers,4.270394134
stack1_layer = layers,4.270394134
stack2_layer = layers,4.270394134
merge_layer = layers,4.270394134
layers=[stack2_layer,4.270394134
sequencial layers,4.270394134
broadcast pattern,4.26984127
doc title,4.269230769
y_train=read_label,4.269090909
"```

def generator",4.268421143
keras script 01,4.267960146
additional command,4.267734554
output response,4.267155499
"```

output response",4.267155499
"0391]

output response",4.267155499
"2871]

output response",4.267155499
"541]

output response",4.267155499
"8008]

output response",4.267155499
"0664]

output response",4.267155499
"335]

output response",4.267155499
"6074]

output response",4.267155499
"8838]

output response",4.267155499
backwards compatibility,4.266666667
files include,4.266666667
manual rescaling,4.266666667
backwards compatibility`,4.266666667
custom code,4.266656487
def call,4.265870233
"301 

    302     def call",4.265870233
>def call,4.265870233
classic architecture,4.265671642
tf ordering,4.265173572
answer online,4.263157895
directories named,4.2625
diff=np,4.262405086
text docs,4.262383901
generator=mygenerator,4.262376238
cats_and_dogs_small/validation,4.261904762
previous topics,4.261904762
previous da,4.261904762
cuda installation,4.261538462
weight matrices,4.261014686
state vectors,4.26036036
current callback,4.259398496
high performance,4.259305211
"_fit_and_score

    estimator",4.259259259
cifar10 dataset**,4.258928571
cifar10 dataset,4.258928571
keras doesn,4.258814338
# keras doesn,4.258814338
"cnn



# importing",4.258558559
lstm trained,4.258512181
bottleneck layer,4.258215962
noise layer,4.258215962
1st layer,4.258215962
imagedatagenerator class,4.25786497
training fails,4.25786445
xception model,4.257537863
model = densenet121,4.257537863
model = xception,4.257537863
model parallelism,4.257537863
`kerasclassifier` class,4.257437071
general feedforward,4.257352941
"```



def w_categorical_crossentropy",4.256044905
def subtract_mean_gen,4.256044905
`def caffenet,4.256044905
def train_top_model,4.256044905
def create_pairs,4.256044905
repetition rate,4.255555556
full batch,4.255178908
"0

__________________________________________________________________________________________________

```



note",4.254699248
"inputs]

        graph_editor",4.254545455
test_set = test_datagen,4.253333333
"support nchw

    283",4.253012048
support `known_grads`,4.253012048
official support,4.253012048
support dilation,4.253012048
support collapse,4.253012048
officially support,4.253012048
support desired,4.253012048
callbacks=[check_point,4.252964427
"fit_loop

    callbacks",4.252964427
callbacks = [metricscheckpoint,4.252964427
callbacks=[mycallback,4.252964427
callbacks=[lrmodifiy],4.252964427
callbacks=callback_list,4.252964427
callbacks= [mcp,4.252964427
callbacks=[log_callback,4.252964427
callbacks= [checkmodel,4.252964427
callbacks=[reducelr,4.252964427
callbacks=model_callbacks,4.252964427
callbacks=[lc],4.252964427
callbacks=[ival],4.252964427
callbacks=[tfckptcb],4.252964427
models running,4.252082384
hdf5 file format,4.250597959
"num_samples = 50000`



**command ran",4.250574253
form `numpy,4.250478927
keras pushing,4.250193648
"```

vgg_model = keras",4.250193648
merged_layer = keras,4.250193648
submodel1 = keras,4.250193648
submodel2 = keras,4.250193648
b_output = keras,4.250193648
"```   

    r_new1 = keras",4.250193648
actual_weights = keras,4.250193648
actual_bias = keras,4.250193648
characters till,4.25
"get_gradients

    norm =",4.25
objects inside,4.25
memory utilization,4.25
replay memory,4.25
637             loss_functions = [loss_function,4.25
apparent resolution,4.25
extremely tedious,4.25
ann comparison],4.25
2 objects inside,4.25
handily picks,4.25
gradient updates,4.25
calls _test_loop,4.25
dissimilar shapes,4.25
play-ground,4.25
calls `get_gradients,4.25
implicit gemm,4.25
precomp gemm,4.25
"]

            output_loss = weighted_loss",4.25
"unicode
```",4.25
mobilenet implementation,4.24980695
make `multi_gpu_model` work,4.249231754
average nn,4.24893617
global variable,4.248311688
`input_1` placeholder,4.24754902
shared layers,4.24713832
# shared layers,4.24713832
avoid backend,4.246728972
keras_backend=theano,4.24662891
entire log,4.245625
make things work,4.244845789
"```

class cnn",4.244065805
dense = keras,4.2439306
dense=keras,4.2439306
segmentation problem,4.243440012
low >= high,4.243176179
low >= high`,4.243176179
52 training samples,4.243105414
1000 training samples,4.243105414
explicit exception,4.242957746
hdf5 library,4.242592593
entire generator,4.242376238
"conv2d

    data_format=data_format",4.242080378
adding logging,4.241830065
func = func,4.241758242
initial daemon,4.24137931
moment calling `fit_generator`,4.241026106
"works

backend",4.240062305
char = sequential,4.23992891
multiple losses,4.239684466
validation_steps=nb_valid_steps,4.239473684
installed properly,4.239316239
"```

    base_model1 = inceptionv3",4.239130435
base_model2 = inceptionv3,4.239130435
inceptionv3 specifications,4.239130435
tmp_model = model_from_json,4.238372093
"71024



real    18m4",4.238095238
compiled models,4.237417014
share layer,4.237382629
# pooling tensor,4.236897275
model2 = keras,4.236680135
return_sequence=true,4.236384266
samplewise_center=true,4.236384266
"205         

________________________________________________________________________________

activation_1",4.236111111
expected dense_1,4.235483871
backend module,4.235319576
embedding_2/cast,4.235294118
linear regression,4.235119048
y_holdout = train_test_split,4.234782609
h_tm12=numpy,4.234605911
theanorc file,4.234436343
temp = full[,4.233918129
separate backpropation,4.233333333
separate validation_batch_size,4.233333333
separate terminals,4.233333333
original size,4.23312557
ctc_update_log_p function,4.232905983
sequence length,4.231112294
20 sequence length,4.231112294
sequence length = 64,4.231112294
unexpected results,4.231034483
log_loss/neg_log_loss,4.230769231
video clips,4.230769231
current size 0,4.229537053
older version,4.228328612
complex network,4.228205128
adam = optimizers,4.228050491
"1 channel

y_train_arousal",4.227272727
entire output,4.227155499
200k samples,4.226907631
"-> 1894                 is_training=false

   1895",4.226368159
nesterov= false,4.226368159
shows false,4.226368159
ignore_longer_outputs_than_inputs=false,4.226368159
preprocess_collapse_repeated=false,4.226368159
save_weights_only=false,4.226368159
stateful = false,4.226368159
return_sequences=false,4.226368159
sstateful = false,4.226368159
stateful=false,4.226368159
nesterov = false,4.226368159
amsgrad=false,4.226368159
nesterov=false,4.226368159
back_prop=false,4.226368159
write_grads=false,4.226368159
preprocess_collapse_repeated=false],4.226368159
transpose_a=false,4.226368159
transpose_b=false,4.226368159
error_bad_lines=false,4.226368159
`by_name = false`,4.226368159
blit=false,4.226368159
set_instead_of_inc=false},4.226368159
loadweights=false,4.226368159
only_supporting = false,4.226368159
write_images=false,4.226368159
enqueue_many=false,4.226368159
log_device_placement=false,4.226368159
as_text=false,4.226368159
return_sequences = false,4.226368159
zero_debias=false,4.226368159
input_binary=false,4.226368159
false negatives,4.226368159
by_name=false,4.226368159
`return_sequences=false,4.226368159
optimizer=keras,4.225983122
optimizer = keras,4.225983122
keras optimizer,4.225983122
test_datagen = imagedatagenerator,4.225691057
"```

test_datagen = imagedatagenerator",4.225691057
"```
test_datagen = imagedatagenerator",4.225691057
initializer=keras,4.225603484
initializer = keras,4.225603484
average precision,4.225
1536                 # clone layer,4.224882629
facing strange issue,4.224736842
gpu system,4.224538259
additional dimension,4.224023581
"line 44

    model = model",4.222774046
"line

model = model",4.222774046
statement checks,4.222222222
distributed filesystem,4.222222222
fully describe,4.222222222
topic=head_lstm,4.222222222
adding noise,4.222222222
vgg loaded,4.222222222
sequential built-,4.222071767
image embedding,4.221772127
custom_variational_layer_1/log,4.220170455
//user-images,4.21900226
single prediction,4.218987674
# extract training,4.218578736
dummy error,4.217546225
"return masked

```",4.217011494
appears keras,4.216860315
#NAME?,4.216666667
additional information,4.215965788
callbacks=[modelcheckpoint,4.21592739
6           callbacks=[modelcheckpoint,4.21592739
callbacks=[modelcheckpoint],4.21592739
modelcheckpoint = callbacks,4.21592739
gray images,4.214912281
keras working,4.214840113
ios app,4.214285714
aggregate matrices,4.214285714
"launch_instance

>     app",4.214285714
"624 

625 double __dummy_1",4.214285714
"627 

628 double __dummy_3",4.214285714
"630 

631 double __dummy_5",4.214285714
"633 

634 double __dummy_7",4.214285714
"636 

637 double __dummy_9",4.214285714
"639 

640 double __dummy_11",4.214285714
"642 

643 double __dummy_13",4.214285714
"launch_instance

    app",4.214285714
utm_medium=app,4.214285714
validation performance,4.213517665
tensorflow doesn,4.213166144
training error,4.212910675
main input,4.212339522
scalar coefficients,4.212121212
keras repo,4.21173211
previous implementation,4.211711712
"previous implementation

222         //",4.211711712
siamese network,4.211538462
network = conv_2d,4.211538462
running pretrained_word_embeddings,4.210743802
input data,4.210160872
"input data

            #",4.210160872
"input data

                #",4.210160872
"## input data

```",4.210160872
full log,4.210069444
h5py/h5f,4.209090909
single batch,4.208583926
# single batch,4.208583926
total params,4.208309207
"505       

=================================================================

total params",4.208309207
"0         

=================================================================

total params",4.208309207
"88408     

=================================================================

total params",4.208309207
"66048     

=================================================================

total params",4.208309207
"2050      

=================================================================

total params",4.208309207
# total params,4.208309207
"404

=================================================================

total params",4.208309207
"0           

================================================================================

total params",4.208309207
"3838593   

=================================================================

total params",4.208309207
"811       

=================================================================

total params",4.208309207
"804       

=================================================================

total params",4.208309207
"93670     

=================================================================

total params",4.208309207
"91        

--------------------------------------------------------------------------------------------------------

total params",4.208309207
"0         



total params",4.208309207
"55489     

=================================================================

total params",4.208309207
"771       

=================================================================

total params",4.208309207
"3999      

=================================================================

total params",4.208309207
"150       

=================================================================

total params",4.208309207
"2052      

=================================================================

total params",4.208309207
"1         

=================================================================

total params",4.208309207
"2         

=================================================================

total params",4.208309207
"1290      

=================================================================

total params",4.208309207
collected trainable,4.208
remains trainable,4.208
bn layers,4.207894134
ga_double* address,4.206349206
ga_double *address,4.206349206
encoding feature,4.206075045
image dataset,4.205638042
dataset = scaler,4.205357143
binary net,4.204462659
creating layers,4.203727467
architecture based,4.20350948
encoder = sequential,4.202766748
"224256    

_________________________________________________________________

lstm_3",4.202380952
"33024     

_________________________________________________________________

dropout_5",4.202380952
"z_log_var = args

    epsilon =",4.20177658
"z_log_var = args

        epsilon =",4.20177658
"]

    image = features[",4.201038475
training script,4.200630948
keras spec,4.200193648
usp=sharinghello,4.2
validate_indices=validate_indices,4.2
feedforward_model = get_feedforward_submodel,4.2
"_predict_loop

    batch_outs =",4.2
weak detections,4.2
external memory,4.2
augmentation variant,4.2
fromnumeric,4.2
slightly older,4.2
assets,4.2
implementation selection,4.19980695
class id,4.199792961
data set,4.198681962
"data

  set",4.198681962
applying sigmoid activation,4.198075378
commit https,4.197823494
sess=keras,4.197562069
exception tensorflow,4.197503201
data = pd,4.197343454
"```

data = pd",4.197343454
layers[layer],4.195276763
feature selection,4.195205479
multi_gpu feature,4.195205479
"0

    __________________________________________________________________________________________________

    input_pos",4.195175439
"0

    __________________________________________________________________________________________________

    input_neg",4.195175439
compatibility version 7100,4.194995279
compatibility version 7000,4.194995279
trainable parameters,4.194666667
batch_x_middle = keras,4.194638093
trainable = true,4.194384266
trainable=true,4.194384266
"trainable = true

```",4.194384266
"trainable = true



#",4.194384266
entire control,4.194285714
`y_val `variables,4.193899782
length based,4.193259525
video frames,4.192307692
full output,4.191599944
complex layer,4.191549296
training doesn,4.19148514
low rate,4.191039427
non_trainable_count = np,4.190976514
gbytes = np,4.190976514
zy = np,4.190976514
num_values = np,4.190976514
"train_and_evaluate             

    executor",4.19047619
"chosen

300         // algorithm",4.19047619
single tensor,4.190302293
explicitly set,4.190278601
manually set,4.190278601
gpu-architecture,4.1902099
dense_1/bias,4.189516129
training imagenet,4.188358956
subsequent inputs,4.187878788
individual losses,4.1875
[tests]` doesn,4.187192118
previous layer,4.186787391
"extra parameters

    #",4.186666667
input layers,4.186437359
reverse=true,4.186384266
inplace=true},4.186384266
required api,4.186324786
#define local_barrier,4.186046512
#define load_half,4.186046512
#define store_half,4.186046512
#define ga_decl_shared_param,4.186046512
#define ga_decl_shared_body,4.186046512
extremely low,4.185483871
questions,4.185393258
/ questions / 43196636 /,4.185393258
keras approach,4.184976257
"```



yields output",4.184655499
images generated,4.18460925
"num_instances = 0

                    yield",4.184397163
over-fitting,4.184210526
include_top=false,4.184114638
base network,4.183760684
resume training,4.18286445
training triggers,4.18286445
stop training,4.18286445
training datas,4.18286445
training captions,4.18286445
validation time,4.181904762
quick readability,4.181818182
img_array_iobl[fila,4.181818182
img_array_iobl = min_max_scaler,4.181818182
monotonically increase,4.181818182
## quick outline,4.181818182
"tensorflow

```

valueerror",4.181609675
callbacks=[tensorboard],4.181535855
callbacks=[tensorboard,4.181535855
15     callbacks=[tensorboard,4.181535855
`tensorboard` callbacks,4.181535855
reuse = false,4.180913614
metrics=[keras,4.180496679
simulated environment,4.18
"205 

    206     def get_config",4.179957948
def get_config,4.179957948
"56

         57     def get_config",4.179957948
"213 

    214     def get_config",4.179957948
tutorial code,4.179331505
"]

    f_end = get_r",4.178571429
f_end = get_r,4.178571429
consecutive method,4.177777778
# multiple threads,4.177184466
multiple graphs,4.177184466
multiple digits,4.177184466
multiple threads,4.177184466
input encoding,4.17691279
spark dataframe,4.176470588
# custom handling,4.176351897
data/images,4.175696594
registered devices,4.175
final layer,4.174882629
layer names,4.174882629
# fix random seed,4.174519367
0 internal parameters,4.174166667
"continue



                    num_instances += 1",4.173333333
character activations,4.173141892
result perfectly,4.172995781
"]





def multiple_inputs_generator",4.172711572
"```

def init_stuff",4.172711572
scipy sparse,4.172335601
loaded back,4.172316384
fully clear,4.172222222
network wasn,4.172064777
imagedatagenerator function,4.171930373
3d array,4.171566039
setup keras 1,4.17124628
generate paraphrases,4.170731707
single vector,4.170576735
single process,4.170576735
training accuracy,4.170488213
single metric,4.170001361
top classifier,4.169230769
char data,4.169117647
taking video,4.168269231
`train_datagen = imagedatagenerator,4.168191057
train_datagen = imagedatagenerator,4.168191057
"```

train_datagen = imagedatagenerator",4.168191057
image tensor,4.167733729
[directly writing,4.167279412
tensorboard flag,4.166666667
mapfull = mapload,4.166666667
coding skills,4.166666667
"51us  cudagetlasterror

  1",4.166666667
checkpoints/dermatology_v1_i-20180324_230205/,4.166666667
silently ignoring,4.166666667
complete removal,4.166666667
performs perfectly,4.166666667
optional boolean,4.166666667
silently overwritten,4.166666667
robot drove,4.166666667
log_b_next = ctc_update_log_p,4.166666667
new_model = xception,4.166666667
pytorch/torchvision,4.166666667
worked perfectly,4.166666667
build_fn=dnn,4.166666667
invalid initialization,4.166666667
complete article,4.166666667
fish moving,4.166666667
validation set,4.166469077
validation set**,4.166469077
unknown layer,4.166261939
community input,4.166043225
calls tf,4.165173572
mnist images,4.164912281
3 # mnist images,4.164912281
5 #include <math,4.164835165
longest word,4.164835165
single thread,4.164516129
simple string,4.164444444
stateful rnn,4.161290323
stateless rnn,4.161290323
"rnn

    # tend",4.161290323
rnn flavors,4.161290323
x13 = dense,4.160403619
single generator,4.1602257
works fine,4.159745547
style change,4.159638554
"3720        

________________________________________________________________________________

dense_2",4.159482759
sample sequence,4.159474392
remaining features,4.159090909
bottleneck features,4.159090909
# final evaluation,4.159090909
"bottleneck features

    #",4.159090909
equivalent tensorflow,4.159090909
prediction based,4.158976049
"fit_generator

>     class_weight=class_weight",4.158883249
individual sample,4.158783784
simple convnet,4.158730159
full logger,4.158730159
dynamic shape,4.158490566
single call,4.15767479
steps = math,4.157154673
horizontal_flip=false,4.154939588
"py

model=unet",4.154642064
prediction outcome,4.154471545
loss=keras,4.154215586
keras loss,4.154215586
loss=[loss_1,4.154021938
"1            py27hf484d3e_0    defaults

```",4.153846154
205                                      argdefs=defaults,4.153846154
"orig_function

    defaults",4.153846154
"20 

     21 def train",4.152844022
def train,4.152844022
"```

   def train",4.152844022
class batchsizescheduler,4.152173913
attnrnn class,4.152173913
`class mycallback,4.152173913
"```

class lrmodify",4.152173913
actual class,4.152173913
class customconstraint,4.152173913
specific class,4.152173913
"```

class auccallback",4.152173913
"```

class oracle",4.152173913
class bboxutility,4.152173913
"```

class truemetrics",4.152173913
"```

class modelwrapper",4.152173913
simplernncell class,4.152173913
class prediction_history,4.152173913
`multilayerwrapper` class,4.152173913
class skillmodel,4.152173913
class nonneg,4.152173913
class tfcheckpointcallback,4.152173913
class granularity,4.152173913
class lstmlm,4.152173913
x_test = keras,4.151577731
autoencoder attempts,4.151515152
1st autoencoder,4.151515152
val-20news,4.151515152
ga_half val,4.151515152
introduce data,4.151260504
433     return tf_decorator,4.150344828
788       return output_structure,4.150344828
return image_resized,4.150344828
110     return iterator_ops,4.150344828
1680         return _clone_sequential_model,4.150344828
-> 1682         return _clone_functional_model,4.150344828
1822             return _broadcast_normalize_batch_in_training,4.150344828
return modelhttps,4.150344828
251         return _forkingpickler,4.150344828
756       return identity,4.150344828
"self_outer

    return",4.150344828
return custom_vgg_model,4.150344828
--> 257         return _iterencode,4.150344828
322     return cv_results[,4.150344828
"dispatcher

>     return",4.150344828
"__str__



    return",4.150344828
return log_probs,4.150344828
"return get_r_i

```",4.150344828
"query_cnn

    return",4.150344828
1077       return identity,4.150344828
"dispatcher

    return",4.150344828
return modeli,4.150344828
carriage return,4.150344828
"```

vgg16_model = keras",4.150193648
keras complains,4.150193648
"validation_data = val_ins



https",4.150088867
relevant codes,4.15
trained weights,4.149719394
weights trained,4.149719394
data length,4.149539334
training appears,4.149531117
"padding = padding

        super",4.14900348
"0



test = test",4.14893617
#test = test,4.14893617
vector sequence,4.14841788
re-initialise,4.148148148
re-initialised,4.148148148
re-shaping,4.148148148
image + vector,4.148008172
image vector,4.148008172
net=load_model,4.147979798
trained model,4.147918176
model trained,4.147918176
10-dimensional vector,4.147727273
7 dimensional vector,4.147727273
image index,4.147558127
training working,4.147510915
policy output,4.147155499
files = os,4.147112462
variational layer,4.147104851
data = pickle,4.147058824
"```

video  = input",4.146812456
video = input,4.146812456
train = read_data_file,4.146799117
"_make_batches

typeerror",4.145833333
obtain benefit,4.145833333
5th dimension,4.145762712
"1 samples

epoch 1/500

traceback",4.14539638
conv layers,4.145394134
single output,4.145004962
allocator<cntk,4.144869215
gradient computation,4.144736842
box = detections[0,4.144444444
keras document,4.144133042
batch statistics,4.144067797
1st batch,4.144067797
optimization steps,4.143580013
validation images,4.143483709
create versions,4.143333333
cost function,4.143162393
gen_nn_ops,4.142857143
"call_cpp_shape_fn

    require_shape_fn",4.142857143
web server,4.142857143
587         cb = batchcompletioncallback,4.142857143
multilabel-indicator,4.142857143
skip ahead,4.142857143
"tuple

`

removing dropout",4.142740937
"bash]`



gpu=0",4.142720077
"optimizer configs



`",4.14245614
time-distributed,4.142222222
hidden layer,4.141549296
hidden layer 1,4.141549296
hidden layer 2,4.141549296
avg_sum+=img,4.141401274
main method,4.140740741
test function,4.140707401
<400k params,4.140127389
false positive ->,4.139411637
false positive,4.139411637
"2]





testy_extended = numpy",4.139367816
# forward net,4.138888889
xnor net,4.138888889
fortran compiler,4.138888889
fortran 2003 compiler,4.138888889
zf net,4.138888889
similar api,4.138705739
input term,4.138265447
sequence generator,4.138066845
image generator,4.137657137
type conversion,4.137362637
output_tensors[tensor_index],4.136363636
remaining tensors,4.135802469
"```

checkpoint = modelcheckpoint",4.135376756
checkpoint = modelcheckpoint,4.135376756
`checkpoint = modelcheckpoint,4.135376756
"exist 



keras",4.134809033
relevant statistics,4.133333333
kevin@juang003,4.133333333
test_set = test_gen,4.133333333
single directory,4.13314358
"config

> <tensorflow",4.133116883
10 nature images,4.131578947
50 nature images,4.131578947
categorical data,4.131326949
working perfectly,4.131313131
image size,4.131133742
39 features generated,4.128787879
final release,4.128787879
frequent words,4.128205128
`output_length` argument,4.127906977
data types,4.12745098
replace = false,4.126368159
tensor=data_tensor,4.125786164
train_test_split = np,4.125759123
dyn_partitions = lambda,4.125468165
norm = lambda,4.125468165
original paper,4.125420875
original [paper],4.125420875
keras codebase,4.125193648
combinedx=keras,4.125193648
keras isn,4.125193648
keras dependency,4.125193648
keras 1 codebase,4.125193648
6/multiprocessing/managers,4.125
h0 = layer_h0,4.125
computer vision,4.125
higher resolution,4.125
"205         

________________________________________________________________________________

activation_2",4.125
build_fn=create_model,4.125
bin,4.125
lock objects,4.125
individual digits,4.125
38/bin/,4.125
lock objectstoday,4.125
train_datagen = train_datagen,4.125
"lock objects

```",4.125
theano support,4.124640959
gpu setting,4.124538259
dataset = data,4.12447479
output sequence,4.122846107
output image,4.122436398
1-dimensional output,4.122155499
3 dimensional output,4.122155499
sample-based,4.121621622
present weights file,4.121226404
high losses,4.120192308
time implementing,4.12
sparsely encoded,4.12
callbacks=[checkpointer,4.119631094
callbacks = [checkpointer,4.119631094
callbacks=[checkpointer],4.119631094
"9248      

_________________________________________________________________

conv2d_4",4.119047619
"93670     

_________________________________________________________________

conv2d_4",4.119047619
x_train[cmpt],4.117699115
text rnns,4.117647059
standard deviation,4.117647059
embedding layers,4.116885362
16 embedding layers,4.116885362
64 embedding layers,4.116885362
200k vocabulary,4.116666667
dnn implementation,4.116473616
classifier output,4.116386269
model1 = model_from_json,4.11627907
--> 500             return super,4.115862069
-> 1011         return super,4.115862069
--> 499             return super,4.115862069
siamese architecture,4.115671642
optimizer step,4.115295647
"```

    combined = sequential",4.11492891
"```



    combined = sequential",4.11492891
code snapshot,4.114114114
code = marshal,4.114114114
mnist dataset,4.113690476
correctly applying,4.112938596
complex structure,4.112820513
internal layer,4.112382629
data = wholesequence[,4.112299465
tf backend,4.111902544
return network,4.111883289
solve 2 classes selected,4.111685269
finished training,4.111435879
>> 60 validation steps,4.111367127
validation steps,4.111367127
highly unintuitive,4.111111111
1893                 data_format=tf_data_format,4.111111111
data_format=tf_data_format,4.111111111
"2s 



`gen_submission_test_batches",4.111111111
automatic sparse,4.111111111
"timesteps = input_shape[1][1]

        child_input_shape =",4.11092437
final state,4.11036036
theano flag,4.109724149
5 times larger,4.108943089
"shape





keras",4.108684214
blank label,4.108396947
"model_fn              

    labels",4.108108108
regression task,4.107728337
volta gpus,4.107142857
data generators,4.106617647
engine,4.10617284
engine=,4.10617284
def texts_to_sequences_generator,4.106044905
109     def apply_async,4.106044905
def reconstruct,4.106044905
numpy array,4.10580565
probleminside imagedatagenerator,4.105691057
test_gen = imagedatagenerator,4.105691057
val_datagen = imagedatagenerator,4.105691057
imagedatagenerator objects,4.105691057
image_datagen = imagedatagenerator,4.105691057
tensors generated,4.105499439
--> 163       tensor_util,4.105263158
--> 102       tensor_util,4.105263158
tensor_util,4.105263158
--> 165       tensor_util,4.105263158
decoder symbolically,4.105263158
loaded correctly,4.104166667
training setup,4.103917082
2nd autoencoder,4.103896104
return gen,4.10272578
sequential information,4.102633828
initial state,4.101739671
#NAME?,4.101739671
mnist autoencoder,4.101515152
bi-lstm,4.101465201
generator based,4.100214075
lstm_2 output,4.100096676
limited memory,4.1
stop_train = earlystopping,4.1
nicely pack,4.1
nicely sorts,4.1
grid = grid,4.1
grid=grid,4.1
slice_i = remove_slice,4.1
#early_stopping_ema = earlystopping,4.1
previous predictions,4.0997426
kernel_initializer=keras,4.098817502
#                  # kernel_initializer=keras,4.098817502
kernel_initializer = keras,4.098817502
call back,4.098808378
current scenario,4.098684211
categorical encoding,4.098078868
single element,4.097849462
relevant api,4.097435897
def model,4.096916101
2d convolution,4.096666667
tensors=[data,4.096586783
data tensors,4.096586783
meta-parameter,4.096385542
iter_size parameter,4.096385542
`mastk_zero` parameter,4.096385542
parameter server,4.096385542
save_best_only parameter,4.096385542
structure separately,4.096153846
generator=test_generator,4.095709571
generator=batch_generator,4.095709571
gradient values,4.094919786
highest values,4.094919786
data/ folder,4.094117647
multiple tables,4.093851133
machine generated,4.093727977
automatically create,4.093333333
validation dataset,4.092261905
cnn = inceptionvis,4.091891892
save_model` function,4.091880342
---> 31         raise importerror,4.091748768
---> 72   raise importerror,4.091748768
--> 693             raise importerror,4.091748768
original code,4.091386841
mill/sec,4.090909091
lstm_1/transpose_1,4.090909091
branch starting,4.090909091
lstm_1/tensorarrayreadv3,4.090909091
underlying `model,4.090871196
[model conversion],4.090871196
rl model,4.090871196
"multiimagemodel

    model",4.090871196
model composition,4.090871196
"resnet50_model

    model",4.090871196
model improves,4.090871196
model design,4.090871196
model = get_compiled_model,4.090871196
model = km,4.090871196
vision model,4.090871196
run keras,4.089961988
single defined,4.089438247
save/const,4.089302042
stack trace,4.089285714
remaining == size,4.089186176
size 8gb,4.089186176
09792when saving,4.088888889
net = resnet_model,4.088888889
extra libraries,4.088888889
16 residual background,4.088235294
feature request,4.088062622
"**feature request**



[",4.088062622
# final predictions,4.087837838
current code,4.087798325
sentence-level,4.0875
boolean arrays,4.086956522
training loss,4.086886388
**training loss**,4.086886388
data tensor,4.086570477
validate_indices=true,4.086384266
callbacks=[model_checkpoint],4.08629776
dtype=float32_ref>,4.086251621
layer = rnn,4.086172952
rnn-layer,4.086172952
predicting distributions,4.085714286
def iterator,4.084992273
"<module>

    main",4.0848869
main module,4.0848869
"error 

__init__",4.083809666
"predicted data

3",4.083591331
keras#description,4.083526982
input_layer2 = keras,4.083526982
m2_loaded = keras,4.083526982
y_category=keras,4.083526982
a_input = keras,4.083526982
r_new = keras,4.083526982
lower approx,4.083333333
wrappers found,4.083333333
converges quickly,4.083333333
y_arr[num_instances] = 0,4.083333333
y_arr[num_instances] = 1,4.083333333
2d-specific,4.083333333
complicated formulas,4.083333333
input_dim=char_embedding_size,4.083333333
"bug



```

---------------------------------------------------------------------------

valueerror                                traceback",4.083167178
augmentation configuration,4.082352941
"97 

98         pyobject* storage_v3",4.082352941
99 pyobject* storage_v5,4.082352941
100 pyobject* storage_v7,4.082352941
101 pyobject* storage_v9,4.082352941
102 pyobject* storage_v11,4.082352941
103 pyobject* storage_v13,4.082352941
104 pyobject* storage_v1,4.082352941
pyobject* storage_v3,4.082352941
pyobject* storage_v5,4.082352941
pyobject* storage_v7,4.082352941
pyobject* storage_v9,4.082352941
pyobject* storage_v11,4.082352941
pyobject* storage_v13,4.082352941
pyobject* storage_v1,4.082352941
generate_data_generator functions,4.081967213
document-level,4.081439394
multiple outputs,4.08103062
word input,4.08087839
l2 norm,4.080645161
def __call__,4.079957948
"129 

    130     def __call__",4.079957948
"53

         54     def __call__",4.079957948
model = model_from_json,4.079243289
`model = model_from_json,4.079243289
current testing,4.078947368
unroll=false,4.078220011
`unroll=false`,4.078220011
"```

sample data",4.077901431
data sample,4.077901431
separate method,4.077777778
"0         

_________________________________________________________________

dense_3",4.077380952
`layer` class,4.077056542
class layer,4.077056542
hidden state,4.077027027
memory cost,4.076923077
## motivating tasks,4.076923077
yields batches,4.076388889
training task,4.076307073
"```

keras predict",4.076280605
convolution window,4.075833333
features separately,4.075757576
"ipynb`>` ---------------------------------------------------------------------------

typeerror                                 traceback",4.075393082
`load_model` function,4.075330225
load_model` function,4.075330225
latest version,4.075276969
aspect ratio,4.075
test curve,4.074468085
test multi_gpu_test_simple_model,4.074468085
steps_kt/test,4.074468085
validation losses,4.074404762
validation generators,4.074404762
read files,4.073757386
current prototype,4.073684211
funcs] <- throws,4.073529412
sess property,4.072368421
good link https,4.071621571
stream->parent,4.071428571
completely undesirable,4.071428571
key doc,4.071153846
callbacks=[csvlogger,4.071146245
expected policy,4.070967742
weighted accuracy,4.070957096
cudnn version 5110,4.070881803
cudnn version 6021,4.070881803
cudnn version,4.070881803
model requires,4.070871196
entire model,4.070871196
top layers,4.070394134
* setting layers,4.070394134
back results,4.070017534
original weights,4.069945141
`mask_zero=true`,4.0697176
mask_zero=true,4.0697176
main process,4.069023569
shared cnn,4.068636078
input class,4.068217138
"0

total memory",4.068181818
total%thr == 0,4.068181818
original model,4.068143924
requires inputs,4.067878788
implementation adds,4.067454009
standard implementation,4.067454009
**manually** compute,4.066964286
optimization process,4.06684492
# preprocess data,4.06684492
"0]]



# preprocess data",4.06684492
def build,4.066792569
322     def build,4.066792569
"```
def build",4.066792569
desktop,4.066666667
significantly slower,4.066666667
broader group,4.066666667
samples_per_epoch=train_samples,4.066666667
patient ids,4.066666667
data[index,4.066394875
module installed,4.066368382
function  troublehi,4.066239316
decode_batch function,4.066239316
function `comapre_list_weights,4.066239316
<function gauss2,4.066239316
generate_data_generator function,4.066239316
`preprocess_input` function,4.066239316
k_rnn function,4.066239316
function cast_to_floatx,4.066239316
preprocess_input function,4.066239316
read_hdf` function,4.066239316
conpile function,4.066239316
function accepting,4.066239316
function useless,4.066239316
identity function,4.066239316
traces= np,4.065976514
saved fine,4.064824912
works correctly,4.064166667
calculate manually,4.063492063
manually calculate,4.063492063
`model_from_json` fails,4.063372093
featurewise_center=true,4.063307343
featurewise_std_normalization=true,4.063307343
regression problem,4.062988884
main thread,4.062962963
`sparse matrix`,4.06291834
1460     inf = _to_tensor,4.0625
634             loss_functions = [losses,4.0625
"epoch 1/1



---------------------------------------------------------------------------

valueerror                                traceback",4.062219636
"gpu

os",4.062126911
long error,4.061961119
validation folder,4.061904762
hidden values,4.061586453
"current inputs

236",4.061562998
final batch,4.060734463
class label,4.06057086
restore state,4.06036036
state-tiled,4.06036036
samples contained,4.060240964
ocr task,4.06010929
sorted=false,4.059701493
make keras,4.059284557
full code,4.058558559
"```



full code",4.058558559
generating inputs,4.058467023
dense_1 dense,4.058253081
regularizer=keras,4.057885956
score = log_loss,4.0578369
score log_loss,4.0578369
"165         return fn

    166",4.057321572
"trained

q_approximator",4.05704698
quick sense,4.056818182
apply __arg_max,4.056603774
apply punishment,4.056603774
custom loss,4.056564311
data generator,4.056493885
data generator**,4.056493885
rnn computation,4.056027165
installation instructions,4.055555556
xtest = testset[,4.055555556
"installation 



> instructions",4.055555556
net = input,4.054932114
lstm_2 = lstm,4.054406378
cnn network,4.053430353
tensor encoding,4.053322395
return_state=true,4.053050933
`return_state=true`,4.053050933
single float,4.053021876
tbcallback = callbacks,4.052964427
callbacks=[early_stopping,4.052964427
callbacks=[tbcallback],4.052964427
callbacks=[early_stopping],4.052964427
function parameters,4.052905983
"tensors 



funcs = [",4.052469136
"45200     

_________________________________________________________________

dropout_2",4.052380952
"52224     

_________________________________________________________________

dropout_2",4.052380952
"3096704   

_________________________________________________________________

dropout_2",4.052380952
"262656    

_________________________________________________________________

dropout_2",4.052380952
"1179776   

_________________________________________________________________

dropout_2",4.052380952
sequence` object,4.051746946
code runs,4.051614114
trained dense,4.050783932
keras implemented,4.050193648
output generated,4.050185802
"batch_index`

0



`tmp=",4.05
avoid slicing,4.05
data size,4.04997049
"```

```

________________________________________________________________________________

layer",4.049882629
attention mask,4.049188514
real batch,4.048829701
y_test = keras,4.04853619
3+ dimensional targets,4.048076923
internal state,4.04786036
id=sy2fzu9gl,4.047619048
[download pdf],4.047619048
slowly increased,4.047619048
transformations applied,4.047619048
id=1s3_lynh1lrn4u2icyehzxewnnh5sp0-,4.047619048
inesc-id,4.047619048
id=1xxezv3ylcp45aqfevf8pll3kgn9quypk,4.047619048
> [id bd],4.047619048
} [id bh],4.047619048
} [id bk],4.047619048
0 [id bl],4.047619048
} [id bm],4.047619048
unbalanced representation,4.047619048
latest versioi,4.046948357
latest versi,4.046948357
latest versiopython 2,4.046948357
latest versioas,4.046948357
weight updates,4.046728972
weight involved,4.046728972
from_logits=false,4.044549977
optimization/speedup,4.044117647
optimization procedure,4.044117647
users dig,4.043956044
recent version,4.043792529
base_network = create_base_network,4.043478261
"0         

_________________________________________________________________

lstm_1",4.043290043
"0

_________________________________________________________________

lstm_1",4.043290043
internet search,4.042857143
disk space,4.042857143
resulting matrix,4.04271632
print model_to_dot,4.042708865
cudnn autotuner,4.042553191
resnet50 model,4.0424841
model = resnet50,4.0424841
# model = resnet50,4.0424841
symbolic tensor,4.04245283
#im1 = image,4.041947566
im1 = image,4.041947566
batch auc = %,4.041503694
output data,4.041273146
output data**,4.041273146
sequential object,4.040985248
numpy file,4.040470826
"]

    image = tf",4.040454471
image = tf,4.040454471
variational autoencoder,4.04040404
batchnorm layers,4.039624903
def init,4.039378238
def **init**,4.039378238
return roc_auc_score,4.039233716
global dense,4.039191497
callbacks=[callback,4.038678713
python2,4.038327526
`wrapper` class,4.038138825
epsilon = _to_tensor,4.0375
use_multiprocessing=false,4.03717897
merge = sequential,4.036684635
[char-rnn],4.036290323
char-rnn,4.036290323
encoded input,4.036043225
latent layer,4.03599374
sparse layer,4.03599374
allowing keras,4.035907934
178                                          as_ref=false,4.035891969
--> 676       as_ref=false,4.035891969
174                                          as_ref=false,4.035891969
history = cbks,4.035714286
validation_data=fixed_generator,4.035598706
random search,4.035551207
"full model

#",4.035315641
simple model,4.035315641
2d matrix,4.035140562
dense_2/kernel_0,4.034482759
dense_2/bias_0,4.034482759
multiple gpus,4.034327323
loaded_model = model_from_json,4.033826638
"```

base_model = vgg16",4.033615945
"41]= 4





base_model = vgg16",4.033615945
base_model = vgg16,4.033615945
weight parameters,4.033395639
mnist digits,4.033333333
"mnist





train_x1",4.033333333
output manually,4.032869785
gan = sequential,4.031595577
compute gradient,4.03125
keras logs,4.030681453
stack function,4.030525031
assertion error,4.030046225
unexpected error,4.030046225
modelcheckpoint function,4.029202279
user-defined,4.029012098
user defined,4.029012098
alessandrokeras version,4.028328612
newest version,4.028328612
newer version,4.028328612
[factorized version],4.028328612
compiletime version 3,4.028328612
version implements,4.028328612
n_entries + batchsize],4.027777778
"n_entries + batchsize]



            #",4.027777778
calculate gradient,4.027777778
`batches = vgg,4.027777778
custom scoring,4.027542373
test sequences,4.026849037
1521             check_batch_axis=false,4.026368159
1357             check_batch_axis=false,4.026368159
1237                                     check_batch_axis=false,4.026368159
nb_epoch=np_epoch_init,4.025252525
shape operations,4.025157233
topology,4.025125628
[topology,4.025125628
names[int,4.025
"shape

print x_test",4.024805736
color images,4.02443609
ja = np,4.024309848
x_arr_iobl = np,4.024309848
validation generator,4.024281
work perfectly,4.023474178
check output rank,4.022650622
default argument,4.022643819
training run,4.02263279
docs_word_lstm = attention,4.022222222
distributed setting,4.022222222
final metric,4.022151899
previous call,4.021730089
"map

    return",4.02131257
executed correctly,4.020833333
gru_1 = gru,4.01971831
sparse label,4.019508058
y_train = keras,4.019284557
unexpectedly found,4.018518519
run tests,4.018339768
tests run,4.018339768
keras github,4.018098158
output correctly,4.017988833
large dataset,4.017857143
dynamic axis,4.017741935
output layers,4.017549633
auto-generated,4.017316017
cnn layer,4.016774521
manually shuffle,4.016483516
iterator yields,4.016447368
restarted training,4.016197783
training speed,4.016197783
"# training



multi_modal",4.016197783
layer lstm_1,4.01579172
console log,4.015625
print keras,4.015124736
multiple inputs,4.015063254
larger images,4.014912281
nn = sequential,4.01386508
weighted metrics,4.013636364
1x1 convolution,4.013333333
attentive convolution,4.013333333
image type,4.012643536
generator=customsequence,4.012376238
git,4.012369172
"sequence

    # encode",4.012054244
validation dsc,4.011904762
perform validation,4.011904762
subsequent set_session,4.011764706
standardize method,4.011111111
return state,4.010705188
deep model,4.010624283
original implementations,4.010606061
"```

_model = load_model",4.009090909
`best_model = load_model,4.009090909
loaded_simple_model = load_model,4.009090909
normal density,4.009090909
previous output,4.009060261
saving time,4.008888889
rnn = embedding,4.007781551
class length,4.0075956
bias_initializer=keras,4.007336505
#                  # bias_initializer=keras,4.007336505
bias_initializer = keras,4.007336505
current implementations,4.007017544
dataset = dataframe,4.006827731
--> 111         result = immediateresult,4.006329114
result = normalise_windows,4.006329114
"```

def apply_softmax",4.006044905
def proc_images,4.006044905
def runkerascnnaugment,4.006044905
def set_model,4.006044905
285   def _device_function,4.006044905
"`



    def _build_residual_block",4.006044905
"```

def get_model_memory_usage",4.006044905
def apply_n_times,4.006044905
`def get_slice,4.006044905
"858 

    859     def __next__",4.006044905
def l2norm,4.006044905
def mean_pos_dist,4.006044905
def mean_neg_dist,4.006044905
def train_test_separation,4.006044905
"7

```

def init_gan",4.006044905
"```

def custom_loss",4.006044905
def _body,4.006044905
def reg,4.006044905
>>     def noised,4.006044905
def my_r,4.006044905
def __build_network,4.006044905
def generate_arrays,4.006044905
def l1_distance,4.006044905
"```

def foo1",4.006044905
def foo2,4.006044905
"```

def loss_transformed",4.006044905
def gettop5acc,4.006044905
def ctc_interleave_blanks,4.006044905
def gen_min_max_sequences,4.006044905
def read_data,4.006044905
def relative_distance,4.006044905
def noised,4.006044905
def get_initial_state,4.006044905
def get_p_net,4.006044905
"#%%

def batchgenerator",4.006044905
def keras_nn_opt,4.006044905
def validate_holdout,4.006044905
"#####################

def generator_from_array",4.006044905
"```
def translate_non_alphanumerics",4.006044905
model = resnet,4.005505343
resnet 50 model,4.005505343
resnet model,4.005505343
/users/aaron/,4.005494505
gpu environment,4.004538259
selected based,4.004504505
expected input_6,4.004301075
current error,4.003730435
input arrays,4.002999747
"_fit_loop

    callbacks",4.002964427
"<module>

>     app",4.002876318
"<module>

    app",4.002876318
weights files,4.002196223
encoded images,4.001578947
placeholder tensor,4.000786164
generating error,4.00063446
trainable tensor,4.00045283
keras forced,4.000193648
legacy,4
903       is_training=is_training,4
-> 3774         is_training=is_training,4
3775     _result = _op,4
"]

   3776     _inputs_flat = _op",4
coimpare docu,4
specific application,4
902         proto_data = tf_session,4
development,4
weight_gru1 = weight_1,4
vector_assembler = vectorassembler,4
dataset_train = vector_assembler,4
user_matrix = gettrainmatrix,4
/0lw6i0yc9xmctrn/soe4630,4
78gib freememory,4
`new_keras`,4
new_keras,4
/predict_ulos/ridup,4
s0=s0,4
pool3d funtion,4
run_meta=run_meta,4
"_call_model_fn                

    model_fn_results =",4
_op = _op_def_lib,4
57     _result = _op,4
"]

     58     _inputs_flat = _op",4
/keras_models/model_fold_,4
/temp_data/fold_at3_history_data,4
realize,4
sub_model2 = get_sub_model,4
fx=x_change,4
y_trainros = ros,4
//hager-richter,4
expressed idiomatically,4
tightly coupled,4
pcap_z/all_data_amount_7,4
clipping terms,4
bad eng,4
30k records,4
ralph@r4robotics,4
2175                                                  wait_time=wait_time,4
7353mib /  7613mib,4
/atr1an/9a2f4ceb2ca830ce7344ebe6544cea05],4
/atr1an/9a2f4ceb2ca830ce7344ebe6544cea05,4
many-,4
91gib freememory,4
/firefoxmetzger/44e9e056e45c1a3cc8000ab8d6f2cebe,4
output_sequence = lstm_network,4
relation extraction,4
a3,4
amazon aws,4
softwares,4
remotemonitor sends,4
modern clients,4
tr_pair0=tr_pair0,4
tr_pair1=tr_pair1,4
classical recurrence,4
/jonas1312/7c2d35a02c9d624cb8fada9317dfa22a,4
performing aggregations,4
threshold levels,4
4568     _result = _op,4
"]

   4569     _inputs_flat = _op",4
actual accelerometers,4
/hechtlinger/graph_cnn,4
competition hosted,4
"```

ncce = functools",4
164   dtype_value = attr_value_pb2,4
/hbredin/89b2249504a62712441e7ffec7de9518,4
elemwise{composite{,4
[[gpuincsubtensor{inplaceset,4
[mnist_acgan,4
"_output_tensor_cache[cache_key]

   2082",4
92gib freememory,4
"720s

sys",4
"884s

sys",4
raspberry pi,4
"```

pi@raspberrypi",4
petri leskinencurrently,4
rel-win,4
/miyosuda/disentangled_vae,4
decode_content=decode_content,4
"execute_actions

        inst",4
"fetch_cmd

        fetch_pkg",4
"1

makefile",4
strategydqn_multi-instrument_0123,4
/kmcnaught/a335bb26afa66677d8dff9abbf8af138,4
/mitkeyastromouse/5ae860cbc569c12b9125d5903c4a1827hi,4
frontend,4
/tuyki/tt_rnn],4
dmt/_187,4
prompt break2,4
rows_in / stride_r,4
quotation marks,4
1026     present_labels = unique_labels,4
mutually exclusive,4
padded spots,4
tcoordfont setfont,4
t0 0 moveto,4
tscalefont setfont,4
tmatrix currentmatrix,4
n1 setmiterlimit,4
references deepid,4
stateful=stateful,4
kde neon 5,4
/stoney95/9c71bb7f7008b7d01dcf8f6bf3afaeff,4
ian goodfellow,4
/ilkarman/deeplearningframeworks,4
/anonymous/8871bec87bcdd5375326e9511cec0718,4
/matthewwilletts/7eef6a201413f936dff55378b4a14ecf,4
/matthewwilletts/0c4332d6f7092a7acfa5fff5a29e868c,4
gpuelemwise{composite{,4
/sdrobert/10297a006c02593b40ab7528652f51a0,4
computational standpoint,4
trainlabel = trainlabels,4
updates oneself,4
uxxxxxxxx escape <,4
"my_r

    r1 =",4
updates=updates,4
>     891         proto_data = tf_session,4
"execute_request

>     user_expressions",4
store_history=store_history,4
silent=silent,4
l_c + l_s,4
"```

        x_0__               x_1__",4
/mul_5/enter,4
"anticipation

thomas",4
fri mar 03 10,4
"raise_with_op



    storage_map_item",4
"_clone_functional_model

>     merge_config =",4
typical experiences,4
/akababa/chess-,4
"1168        concatenate_922[0][0]            

activation_1983",4
/115ixotqbktbmeew0_wlnj2y5s9f-bf7ysqc5akz9nuy/,4
lcpl=lcpl,4
/geeksiddharth/9d23bedc8f6370b5578067757af11463,4
preallocated memory,4
achive combining,4
cammera sensor,4
inferences side,4
storing waveforms,4
dilation makes,4
math_ops,4
/afs/l2f,4
3-64/tmpcrjeyz/b8e34ea4363b3812bd111a731cb835f81ccc84235ec10367467e6198f7abc278,4
basketball possession,4
/joemarshall/338b0f0c0741408d044f3104b0d3b91d,4
val_output-0_func,4
"cpu_feat

ure_guard",4
ad hoc,4
---> 24                 _mod = imp,4
/alekseynp/1bb6cbe4ee7fb6e8ea46d68c675b934dsuppose,4
casting rule,4
/aelphy/c73aa56bf2f410b1423c63bd7087142ei,4
l707  lies,4
memory leak,4
"14*14

    loss_sum = get_content_loss",4
improper sizing,4
img_array_dcc[fila,4
img_array_dcc = min_max_scaler,4
img_array_dcc = img_array_dcc,4
img_array_icc[fila,4
img_array_icc = min_max_scaler,4
img_array_icc = img_array_icc,4
img_array_dobl[fila,4
img_array_dobl = min_max_scaler,4
img_array_dobl = img_array_dobl,4
[lower_slices] + [upper_slices],4
698             # unsafe deserialization,4
swmr=swmr,4
sblock->base_addr = 0,4
imagenet_models/resnet50_weights_tf_dim_ordering_tf_kernels,4
trend continued,4
17gib freememory,4
77gib freememory,4
gradient = get_gradients,4
mem = get_mem_usage,4
/sandeepnmenon/023495c69a877980535a7bf2da1389fa],4
[benjamin graham,4
/diogo149/theano_fractional_max_pooling,4
reduce_lr_m_adadelta = reducelronplateau,4
pool_3/_reshape,4
#ifdef infinity,4
#undef infinity,4
"```

callback_list = [prediction_history",4
"ctypedescr objects

```",4
#policy head,4
neg_pos_ratio=neg_pos_ratio,4
negatives_for_hard=multiboxloss_negatives_for_hard,4
`mnist_acgan,4
/dslituiev/740813f65c785c13ae294ec5d46bfb17,4
/sachinruk/deepschool,4
wa recommanded,4
normalizer=preprocess_train,4
_functional api_,4
boiler-plate,4
/roya0045/94817bf98449111a002c1c05b3a83862,4
lc = lambdacallback,4
elemwise{lt,4
updates = scan_utils,4
merge_tensor = merge_layer,4
/p16/p16-1100,4
steadily increasing,4
architecturte prestented,4
fairly accustom,4
fairly trivial,4
103   dtype_value = attr_value_pb2,4
/dslituiev/4633acda282f3434265dbe7ca9c959ed,4
elemwise{sgn,4
suplying outputshape,4
delayed startup,4
clusterprobability_18879-19379_1000clusters,4
+ tgt[tg] +,4
nutts[nutt],4
capacity=capacity,4
enqueue_many=enqueue_many,4
_1_shuffle_batch/random_shuffle_queue,4
[fariz rahman,4
multilradam = multilr,4
lr_multiplier=lr_multiplier,4
/jjakimoto/dqn,4
sum_{ij},4
# viz_cb = vizcallback,4
tags=[tag_constants,4
lane drawing,4
junyoung park,4
memory checker,4
m_b = dot_product,4
"dennis



remarque",4
recurrent_constraint=nonneg,4
_maxlen_ updates,4
design preferred,4
simple pattern,4
/ajk4/789437a8f74b7058ee2bbfafde23b27f,4
/anonymous/03801941c2ccb77242faa21f793daf28,4
kamran janjua,4
#NAME?,4
arthur szlam,4
jason weston,4
rob fergus,4
_recurrent setting_,4
_return_sequence =true_,4
_mast_zero=true_,4
--> 200           expected_shape=expected_shape,4
kzh@otter,4
/rtao/50eb8c96b06f4deddec2b7888da1d062,4
/rtao/c6773e7e430552a54a3812d5fae91bfe,4
chasing segfaults,4
-dcuda_ndarray_cuh=c72d035fdf91890f3b36710688069b2e,4
#NAME?,4
12-64/tmpafu_ee/ea4e203b6529466794536f8a1bfa77ae,4
pinning memory,4
tensorflows queues,4
memory insufficiency,4
expected_initial_bias == actual_initial_bias,4
166   dtype_value = attr_value_pb2,4
`on_train_reset` + `on_train_continue`,4
"256ms  cudathreadsynchronize

 11",4
7900us     698ns  3,4
"0919ms  cudalaunch

 10",4
"0050ms  cudasetupargument

  8",4
190us     838ns  14,4
"014ms  cudamalloc

  4",4
149us     769ns  654,4
"71ms  cudafree

  3",4
"472ms  cudamemcpy

  1",4
"8696ms  cudagetdeviceproperties

  0",4
747us     768ns  425,4
"4768ms  cudabindtexture

  0",4
7240us     698ns  406,4
"34us  cudaunbindtexture

  0",4
4970us     698ns  218,4
"33us  cudevicegetattribute

  0",4
"17us  cudevicetotalmem

  0",4
0180us     628ns  15,4
"645us  cudadrivergetversion

  0",4
"648us  cudaruntimegetversion

  0",4
"655us  cudevicegetname

  0",4
"1200us  cudaeventdestroy

  0",4
"5840us  cudaeventcreatewithflags

  0",4
7790us     838ns  7,4
"0540us  cudagetdevice

  0",4
1360us     978ns  1,4
"9560us  cudadevicegetattribute

  0",4
3350us     768ns  2,4
"0950us  cudeviceget

  0",4
5190us     768ns  3,4
"4000us  cudagetdevicecount

  0",4
76us     900ns  171,4
"24ms  cudamemcpy

 23",4
"029ms  cudathreadsynchronize

 13",4
"3525ms  cudalaunch

  6",4
"1770ms  cudamalloc

  3",4
"08ms  cudafree

  2",4
"93us  cudasetupargument

  0",4
"3401ms  cudagetdeviceproperties

  0",4
"31us  cudamemsetasync

  0",4
"619us  cudamemset

  0",4
"59us  cudabindtexture

  0",4
"245us  cudaeventquery

  0",4
2140us     889ns  14,4
"869us  cudaeventrecord

  0",4
0580us     483ns  105,4
"42us  cudaunbindtexture

  0",4
"95us  cudevicetotalmem

  0",4
0690us     155ns  72,4
"302us  cudevicegetattribute

  0",4
"2550us  cudadrivergetversion

  0",4
"3840us  cudaruntimegetversion

  0",4
2260us     886ns  4,4
"3770us  cudaeventdestroy

  0",4
0090us     479ns  7,4
"2680us  cudaeventcreatewithflags

  0",4
"193us  cudasetdevice

  0",4
3270us     497ns  6,4
"8900us  cudagetdevice

  0",4
"3930us  cudadevicegetattribute

  0",4
1250us     514ns  1,4
"9080us  cudagetdevicecount

  0",4
"0050us  cudevicegetcount

  0",4
"]

            weighted_loss = weighted_losses[",4
tfckptcb = tfcheckpointcallback,4
8080/leaderboard/displaylb,4
challengeid=11&compid=6,4
companion repository,4
masked_metric_fn = _masked_objective,4
flying blind,4
/survival/target_probs,4
/survival/target_patient_ids,4
var_names = read_lines,4
char_testtokenintpad = padwordlevel,4
/~jonlong/long_shelhamer_fcn,4
769         proto_data = tf_session,4
"execute_request

    user_expressions",4
/feynman27/77e94295eb386abec9cc67a6f5ae47e0,4
industry standards,4
strong rationale,4
noredirect=1#comment70692649_41749398,4
winpython-64bit-3,4
768         proto_data = tf_session,4
david,4
penn treebank,4
/phipleg/adfccb0ad96b777eecc9bb0f16ab54fc,4
trailing spaces,4
cpp#l117,4
/reesepathak/118c5573e320c82cf99d1bec26dc6366,4
common appraoch,4
"batch_size_init=30
momentum_init=0",4
esp beginners,4
a_1 a_2,4
/janenie/lstm_issu_keras,4
blonde horse,4
fisherman fishes,4
scikit,4
2d input `,3.999376559
2d input,3.999376559
input 2d,3.999376559
index=false,3.998645387
weight matrix,3.998536201
grad = tf,3.998506906
test_loss2 = tf,3.998506906
epochs training,3.997781577
"read

        n_entries = 0

        #",3.99756691
network takes,3.997252747
final output,3.997155499
output gradient,3.997155499
output inside,3.997155499
"n_samples]

        y_pred = y_pred[",3.997131383
class values,3.997093699
time cost,3.996923077
"__getitem__

    return",3.996498674
"__getitem__

>     return",3.996498674
generate features,3.996489283
case keras,3.994948893
keras issue,3.99493049
tensorboard function,3.994810745
input source,3.994474598
test time,3.994468085
data directories,3.994117647
def accuracy,3.993668667
model1 = sequential,3.992835887
kerasclassifier wrapper,3.99122807
gpu computing,3.991204925
# transform back,3.991156964
model representations,3.990871196
model branches,3.990871196
training loop,3.990556758
"```

adversarial_model = sequential",3.98992891
tf-gpu,3.989711831
tf-gpu -,3.989711831
past https,3.989490161
validation_steps = val_batches,3.989473684
validation_steps=val_steps,3.989473684
updated manually,3.989417989
partial validation,3.989177489
replacing inceptionv3,3.989130435
nb_val_samples=nb_validation_samples,3.989010989
">   nb_val_samples=nb_validation_samples

>",3.989010989
vgg16 weights,3.987734142
large gap,3.9875
multiple samples,3.98742543
"0         

_________________________________________________________________

dense_2",3.986863711
sole parameters,3.986666667
nework parameters,3.986666667
performing parameters,3.986666667
shows true,3.986384266
return_sequences=true,3.986384266
add_shapes=true,3.986384266
as_text=true,3.986384266
save_best_only=true,3.986384266
"167                     set_inputs = true

    168",3.986384266
concentrate=true,3.986384266
colocate_gradients_with_ops=true,3.986384266
ignore_index=true,3.986384266
#save_best_only=true,3.986384266
allow_pickle=true,3.986384266
stateful = true,3.986384266
write_grads=true,3.986384266
"supports_masking = true

--> 300",3.986384266
nesterov=true,3.986384266
return_sequences = true,3.986384266
save_weights_only=true,3.986384266
write_images=true,3.986384266
show_accuracy=true,3.986384266
decode_content=true,3.986384266
urlstxt=true,3.986384266
stateful=true,3.986384266
use_cudnn_on_gpu=true,3.986384266
"_iterating = true

    781",3.986384266
"stateful = true



#",3.986384266
`return_sequences=true`,3.986384266
by_name=true,3.986384266
force=true,3.986384266
by_name = true,3.986384266
one_hot=true,3.986384266
binary_mode=true,3.986384266
transpose_a=true,3.986384266
return_state_sequences=true,3.986384266
unit_forget_bias=true,3.986384266
nan_is_error=true,3.986384266
inf_is_error=true,3.986384266
supports_masking = true,3.986384266
best_model = true,3.986384266
`stateful=true`,3.986384266
drop_last=true,3.986384266
zero_debias=true,3.986384266
clear_devices=true,3.986384266
vgg16 model,3.985932925
model = vgg16,3.985932925
"vgg16

    model",3.985932925
minutes ago,3.985714286
long question,3.985618597
correctly recognize,3.985119048
"```

data = np",3.985094161
data = np,3.985094161
"1]]

data = np",3.985094161
gpu device,3.984915617
gpu device 0,3.984915617
gpu device 1,3.984915617
file record,3.984436343
examples,3.983739837
5008 examples,3.983739837
return var_auto_encoder,3.983678161
default initializers,3.983625731
test evaluation,3.983558994
samples_per_epoch=nb_train_samples,3.983333333
multi_gpu_model utility,3.983333333
varying strides,3.982843137
h5 file extension,3.98282344
upgrade,3.982808023
original imagenet,3.982767233
individual gpus,3.982142857
checking total_batches_seen,3.981818182
vgg-16 weights,3.981561303
interfaces,3.981481481
"1418 

   1419     @interfaces",3.981481481
"1122 

   1123     @interfaces",3.981481481
"1157 

   1158     @interfaces",3.981481481
testing sequence,3.980953766
internal works,3.980833333
"1

       root environment",3.98
vgg model,3.979760085
test set,3.9790324
50% test set,3.9790324
-> 1705                               validation_steps=validation_steps,3.978947368
> --> 960                               validation_steps=validation_steps,3.978947368
> -> 1657                               validation_steps=validation_steps,3.978947368
test = pd,3.977693892
weird stuff,3.977272727
"# predictions



    # net",3.976726727
% width text,3.976342711
cuda-convnet,3.975824176
optimizer=ada,3.975789474
classify sequence,3.975690608
# net = cv2,3.975623583
`output_maxlen`times,3.975609756
image transformation,3.975280899
previously stated,3.975
model2 = model_from_json,3.97485858
model h5 file,3.973694636
h5` model file,3.973694636
current epooch,3.973684211
compilation takes,3.973214286
dataset consisting,3.973214286
sgd optimisation,3.973154362
files list,3.973059721
files = list,3.973059721
testx = numpy,3.972701149
happen keras 1,3.972415871
model3 = keras,3.972415871
regularization term,3.972222222
lstm layers,3.971859335
re-writing,3.97167756
miniconda3,3.970588235
"```

decoder = sequential",3.970192068
simply forwards,3.96969697
simply magnify,3.96969697
simply adopting,3.96969697
output term,3.969377722
x_train = resnet50,3.969312018
/src/model/,3.969249575
test-docs,3.969204927
output_shape=l2_output_shape,3.969047619
"return autoencoder

```",3.968526646
"shape[3]

img_rows = x_train",3.968497373
expected api,3.968403639
cudnn layer,3.967435821
> ----> 6                     callbacks=[logger],3.967250141
sequence model,3.966561804
image = model,3.966152095
"model



[image",3.966152095
virtual environment,3.965714286
localhost/replica,3.965246788
recently spent,3.964285714
stack-distances_target,3.964285714
"api

                bs =",3.964102564
api cleaner,3.964102564
dataset/test_set,3.963690476
"scan

    condition",3.963636364
convolution implementation,3.963140283
`save_best_model = modelcheckpoint,3.962962963
"+ 1

    

    checkmodel = modelcheckpoint",3.962962963
main concern,3.962962963
tf api,3.96260947
full script,3.962210942
simple script,3.962210942
checkpoint related,3.961887477
connection reset,3.961538462
customize network,3.961538462
properly padded,3.961538462
network invariant,3.961538462
network behaves,3.961538462
underlying backends,3.961538462
deeper network,3.961538462
running keras,3.96093745
running keras 2,3.96093745
data faster,3.960784314
# reshapes data,3.960784314
def sampling,3.96059036
`def batch_normalization,3.96059036
"]

    datagen = imagedatagenerator",3.960236511
datagen = imagedatagenerator,3.960236511
"```

datagen = imagedatagenerator",3.960236511
"```



datagen = imagedatagenerator",3.960236511
custom regularizer,3.960234681
classifier model,3.960101966
keras bug,3.960070192
"```

unlike m1",3.96
unlike m1,3.96
# read data,3.958351224
read data,3.958351224
"read

        data =",3.958351224
require_flatten=include_top,3.957746479
cnn architecture,3.957563534
shuffle=false,3.95713739
shuffle = false,3.95713739
`shuffle=false`,3.95713739
queue user,3.956470932
test images,3.956047032
dear community,3.955882353
sequential model,3.955800106
model = sequential,3.955800106
`model = sequential,3.955800106
1 model = sequential,3.955800106
"8]



```

model = sequential",3.955800106
"```

model = sequential",3.955800106
"```

model= sequential",3.955800106
```model = sequential,3.955800106
"`

`model = sequential",3.955800106
>       1 model = sequential,3.955800106
model=sequential,3.955800106
"]





    model = sequential",3.955800106
"6]





model = sequential",3.955800106
"**



`model = sequential",3.955800106
model= sequential,3.955800106
"sequential model

----------------------------------------------------",3.955800106
"> 

> model = sequential",3.955800106
"]

model = sequential",3.955800106
sequential model],3.955800106
"```

        model = sequential",3.955800106
#model=sequential,3.955800106
"-

-------------------------------------------------------------------------------------------------------------------

model = sequential",3.955800106
"```

   model = sequential",3.955800106
"+= 1



model = sequential",3.955800106
"```

    model = sequential",3.955800106
"```
    model = sequential",3.955800106
"```
model = sequential",3.955800106
changing users,3.95572075
takes time,3.955714286
input_1 = input,3.955258912
"<module>

    regr",3.955257271
roc_auc_score function,3.955128205
worth including,3.953846154
ve trained,3.953741195
question evolves,3.953703704
variable inside,3.952857143
nepoch end,3.952830189
"_slicehelper

    end",3.952830189
barrel end,3.952830189
pond end,3.952830189
"sequences

max_length = 12",3.952380952
"0         

_________________________________________________________________

conv1d_1",3.952380952
"7212      

_________________________________________________________________

max_pooling1d_1",3.952380952
partitioning sequences,3.952380952
"0         

_________________________________________________________________

lambda_4",3.952380952
"0         

_________________________________________________________________

conv1d_15",3.952380952
"256       

_________________________________________________________________

batch_normalization_21",3.952380952
"256       

_________________________________________________________________

conv1d_16",3.952380952
"4160      

_________________________________________________________________

batch_normalization_22",3.952380952
"256       

_________________________________________________________________

lambda_5",3.952380952
"0         

_________________________________________________________________

conv1d_20",3.952380952
"4160      

_________________________________________________________________

batch_normalization_28",3.952380952
"256       

_________________________________________________________________

conv1d_21",3.952380952
"8320      

_________________________________________________________________

batch_normalization_29",3.952380952
"512       

_________________________________________________________________

conv1d_22",3.952380952
"132096    

_________________________________________________________________

batch_normalization_30",3.952380952
"4096      

_________________________________________________________________

max_pooling1d_6",3.952380952
"0         

_________________________________________________________________

conv2d_5",3.952380952
"18496     

_________________________________________________________________

conv2d_6",3.952380952
"0         

_________________________________________________________________

conv2d_7",3.952380952
"73856     

_________________________________________________________________

max_pooling2d_3",3.952380952
"0         

_________________________________________________________________

flatten_1",3.952380952
"45408

_________________________________________________________________

conv1d_1",3.952380952
"3104

_________________________________________________________________

max_pooling1d_1",3.952380952
verify explicitly,3.952380952
"1640      

_________________________________________________________________

max_pooling1d_42",3.952380952
"0         

_________________________________________________________________

dropout_39",3.952380952
"0         

_________________________________________________________________

conv1d_48",3.952380952
"640040    

_________________________________________________________________

max_pooling1d_43",3.952380952
"0         

_________________________________________________________________

dropout_40",3.952380952
"0         

_________________________________________________________________

lstm_19",3.952380952
"86528     

_________________________________________________________________

lstm_20",3.952380952
"131584    

_________________________________________________________________

flatten_19",3.952380952
"0         

_________________________________________________________________

conv7",3.952380952
"93670     

_________________________________________________________________

spatial_soft_argmax_1",3.952380952
"2359808   

_________________________________________________________________

time_distributed_7",3.952380952
"2359808   

_________________________________________________________________

time_distributed_8",3.952380952
"2359808   

_________________________________________________________________

time_distributed_9",3.952380952
"4719616   

_________________________________________________________________

conv_lst_m2d_1",3.952380952
"2507008   

_________________________________________________________________

conv_lst_m2d_2",3.952380952
"110720    

_________________________________________________________________

conv2d_10",3.952380952
"289       

_________________________________________________________________

flatten_1",3.952380952
smaller sequences,3.952380952
"903749    

_________________________________________________________________

sequential_5",3.952380952
"0         

_________________________________________________________________

radial_1",3.952380952
"1000000   

_________________________________________________________________

conv1d_1",3.952380952
"75050     

_________________________________________________________________

global_max_pooling1d_1",3.952380952
"1         

_________________________________________________________________

collect_avg_1",3.952380952
wrapper function,3.952204229
class folder,3.952173913
code based,3.951951952
identity matrix,3.951807229
aggregate matrix,3.951807229
"matrix



bid1_step_1",3.951807229
rectangular 0 matrix,3.951807229
length parameter,3.951807229
bad performance,3.951612903
performance improvement,3.951612903
poor performance,3.951612903
lstm inside,3.951465201
lstm neuron,3.951465201
set weight,3.951293287
graph based,3.951283216
image created,3.950623365
def get_activations,3.950489349
"```

def get_activations",3.950489349
65   return return_value,3.950344828
keras `sparse_categorical_crossentropy`,3.950193648
extra threads,3.95
tiled-fft,3.95
implementation side,3.94980695
implementation coincides,3.94980695
independent implementation,3.94980695
tensorflow [issue],3.949282297
batch normalization,3.947989365
compute capability,3.947916667
"training

print",3.947795537
decorator code,3.947447447
pretty common,3.947368421
sess = tf_debug,3.947368421
section _using,3.947368421
pretty solid,3.947368421
cosine distance,3.947368421
pretty clumsy,3.947368421
pretty helpless,3.947368421
important step,3.947198481
extra output,3.947155499
tensoflow backend,3.946728972
sgd= sgd,3.946308725
sgd = sgd,3.946308725
"`



`sgd=sgd",3.946308725
"001

    sgd = sgd",3.946308725
calling `regularizers,3.946031746
extra dimension,3.945762712
#NAME?,3.945454545
worthy feature,3.945205479
feature extensively,3.945205479
full power,3.944444444
decoder back,3.944246209
include_top=true,3.944130745
/users//cnn_model,3.943956044
"main

    train",3.943095413
setting color,3.942857143
1d array,3.94262831
wrong objective,3.942073171
batches generated,3.941919192
generated batches,3.941919192
training `fit_generator`,3.941747699
predicted class,3.941647597
gradient defined,3.941588785
defined separately,3.941588785
vgg loading,3.941127695
reuse=true,3.940929721
data/train,3.940916764
train data,3.940916764
data/train/,3.940916764
/data/train/,3.940916764
sec/steps`,3.940371457
`sec/steps`,3.940371457
generate probabilities,3.939962477
custom dropout,3.939898695
"]

    return temp`",3.939818512
"epoch 1/2

---------------------------------------------------------------------------

invalidargumenterror                      traceback",3.939322083
keras epoch,3.93912265
fall back,3.938983051
5     # fall back,3.938983051
image list,3.93881681
gpu code,3.938652373
significantly reduced,3.938461538
convolution layer,3.938215962
# callback class,3.937888199
callback class,3.937888199
class callback,3.937888199
theano function,3.937868227
cudandarray *var,3.9375
yields minibatches,3.9375
word index,3.937112393
shortcut_layer = layers,3.9370608
ga_uint *base =,3.936507937
image samples,3.935521863
pip,3.935483871
> pip,3.935483871
blog showing,3.934782609
constraint constr,3.934693878
successfully classify,3.933333333
enqueue nodes,3.933333333
nodes disposition,3.933333333
episode concept,3.933333333
multiple dimensions,3.933208562
finish training,3.93286445
"```

 def on_epoch_end",3.931970831
"] `

`      def on_epoch_end",3.931970831
def on_epoch_end,3.931970831
gpus={gpu,3.931681116
inputs directly,3.931628788
data type,3.931480284
`sequence` won,3.931246163
limited dataset,3.930357143
distinct metrics,3.93030303
entire vocabulary,3.93
3rd line,3.929920542
cnn encoder,3.92972973
custom_objects=dependencies,3.929026388
user pass,3.928972609
model based,3.928709034
screwing tensorboard,3.928571429
compare timings,3.928571429
callback=cb,3.928571429
kfold = stratifiedkfold,3.928571429
tensorboard/esc_example/,3.928571429
friend asked,3.928571429
single error,3.927895687
text samples,3.927888023
1703                               initial_epoch=initial_epoch,3.927710843
-> 1417             initial_epoch=initial_epoch,3.927710843
-> 1121                                         initial_epoch=initial_epoch,3.927710843
>     958                               initial_epoch=initial_epoch,3.927710843
>    1655                               initial_epoch=initial_epoch,3.927710843
-> 1156                                         initial_epoch=initial_epoch,3.927710843
--> 871                               initial_epoch=initial_epoch,3.927710843
--> 863                               initial_epoch=initial_epoch,3.927710843
--> 845                               initial_epoch=initial_epoch,3.927710843
-> 1485                               initial_epoch=initial_epoch,3.927710843
-> 1143                               initial_epoch=initial_epoch,3.927710843
save users,3.927375733
multiple cores,3.927184466
mask = ctc_path_probs,3.926966292
saving predictions,3.926726727
proper documentation,3.926666667
documentation suggests,3.926666667
single cpu,3.926511883
**regular predict**,3.926086957
object names,3.926056338
weights successfully,3.926005747
"```

modelcheckpoint = modelcheckpoint",3.925925926
separate scripts,3.925641026
validation_generator = test_datagen,3.925555556
return int,3.925344828
concatenation layer,3.924882629
layer conv_lst_m2d_4,3.924882629
layer chopped,3.924882629
identity layer,3.924882629
-> 1537                 new_layer = layer,3.924882629
"2493 

   2494             layer = deserialize_layer",3.924882629
layer timely,3.924882629
layer lstm_10,3.924882629
specific layer,3.924882629
layer lstm_5,3.924882629
adaptivegaussiannoise layer,3.924882629
layer periodically,3.924882629
adaptive layer,3.924882629
flattening layer,3.924882629
"2474 

   2475             layer = deserialize_layer",3.924882629
timedistribution layer,3.924882629
fcl layer,3.924882629
layer concatenate_3,3.924882629
layer permute_1,3.924882629
nonlinearity layer,3.924882629
desired layer,3.924882629
layer time_distributed_19,3.924882629
globalmaxpooling layer,3.924882629
segmentationtop layer,3.924882629
class index,3.924451141
"layers

# outputs",3.924240288
multigpu model,3.92420453
model construction,3.92420453
model = build_model,3.92420453
win10 model,3.92420453
test steps,3.923930451
imagedatagenerator calculates,3.923872875
axis>> const&,3.923624288
incsubtensor{inplaceset,3.923076923
allocate memory,3.923076923
targets separately,3.923076923
file-level,3.921936343
device cuda,3.92191582
"shape

print y_test",3.921764195
# prepare inputs,3.921212121
deserialization time,3.92
time freezes,3.92
estimated time,3.92
time distribution,3.92
468         score_time = time,3.92
time serie,3.92
encoded = encoder_model,3.92
time stamp,3.92
><img src=,3.919779652
bidirectional rnn,3.91843318
rnn = bidirectional,3.91843318
cnn features,3.917649468
correctly train,3.91763245
cell state,3.917503218
cell state**,3.917503218
full = load,3.917417417
takes images,3.917293233
img = image,3.916682173
"]        

        img = image",3.916682173
"execfile

>     exec",3.916666667
easier reproduction,3.916666667
"execfile

    exec",3.916666667
titan xp,3.916666667
>titan xp</,3.916666667
"execfile

exec",3.916666667
"**



titan xp",3.916666667
press `ctrl +,3.916666667
resnet_input = input,3.916043225
incoming input,3.916043225
input queues,3.916043225
query = input,3.916043225
cudandarray *input,3.916043225
#NAME?,3.916043225
cnn_input = input,3.916043225
input=cnn_input,3.916043225
input x_t,3.916043225
vector consisting,3.915584416
replicate directly,3.915178571
skip metric,3.915009042
support write,3.914983879
horizontal_flip=true,3.914955695
#horizontal_flip=true,3.914955695
horizontal_flip = true,3.914955695
tensorflow bug,3.914421998
feel free,3.914285714
"exit code 1

```",3.914114114
exit code -1073740791,3.914114114
`input_layer = layers,3.913251277
layers initialized,3.913251277
return generator,3.912721065
write formulas,3.911971831
potential source,3.911764706
limited target,3.91147541
trainable variable,3.910857143
>     601             # raise exceptions,3.910714286
m2 = sequential,3.910383455
data format,3.910279263
"call

    return",3.910170155
"call

             return",3.910170155
def loss,3.910066843
change pred_active,3.909638554
principal components,3.909090909
program giving,3.909090909
4 gig ram,3.909090909
11 gig ram,3.909090909
reuse=reuse,3.909090909
squential components,3.909090909
input_spec = [inputspec,3.909090909
input_spec = inputspec,3.909090909
state_input_spec = inputspec,3.909090909
action_input_spec = inputspec,3.909090909
_hl,3.909090909
evaluate_generator produces,3.908730159
"disk

print",3.90778823
tokenizer generate,3.907573813
identical values,3.907419786
"orig_function

    fn =",3.906976744
repeatvector layers,3.90675777
discrete tuple,3.906666667
top_model = sequential,3.906595577
initial = tf,3.906552883
reshape step,3.906438444
def decode,3.906044905
gpu op,3.905933607
"image

----- error -----",3.905327124
dimensional error,3.905046225
test = dataset[0,3.904825228
flag = flag_train,3.904761905
input_spec set,3.904564315
set pythonhashseed,3.904564315
`write_grads` set,3.904564315
shuffling set,3.904564315
set stateful,3.904564315
quick pr,3.904040404
loss=loss_fn,3.904021938
contrastive loss,3.904021938
loss=test_loss,3.904021938
lowest loss,3.904021938
outputs=loss_out,3.903846154
dfros = pd,3.903225806
prediction_data = pd,3.903225806
rain = pd,3.903225806
"shape[1]

img_cols = x_train",3.902856348
additional option,3.902503294
class `validaccuracy`,3.902173913
class dynamicpartition,3.902173913
`hdf5matrix` class,3.902173913
/conda/activate,3.901869159
conda-bld,3.901869159
internal representation,3.901785714
shared layer,3.901626815
test score,3.901535754
val = subtract_mean_gen,3.901515152
hierarchical lstm,3.901465201
file path exists,3.90110301
previous batches,3.900793651
validation batches,3.900793651
csv files,3.9004329
inputs share,3.900378788
"]

        return initial_states",3.900344828
return kb,3.900344828
`metric` argument,3.900058875
callbacks handle,3.90002325
extra element,3.9
early_stopping = earlystopping,3.9
system memory,3.9
ndotdict begin,3.9
flip,3.9
"generate_hard_negatives

    vectors =",3.9
theano version %,3.899957522
"2

theano version 1",3.899957522
theano version,3.899957522
"code

```

dependencies = {",3.8998284
including dimension 0,3.899608866
softmax_cross_entropy_with_logits** function,3.89957265
true positive,3.899427745
testing data,3.899380805
directly suitable,3.899305556
target arrays,3.898431932
checking input,3.897861407
return output,3.897500327
shuffle settings,3.897435897
elegant api,3.897435897
def dump,3.897349253
"py

    z_mean = dense",3.897080012
feature matrix,3.897012708
surprising behaviour,3.896551724
incorrect behaviour,3.896551724
desired behaviour,3.896551724
hacky solution,3.896226415
windows-gpu,3.89596683
"video

    <tf",3.895942803
lambda layers,3.895862299
run [cifar10_resnet,3.895323895
optimizer=optimizers,3.895144312
"```

optimizer = optimizers",3.895144312
"0001

optimizer = optimizers",3.895144312
optimizer = optimizers,3.895144312
true label,3.894781213
logits=logits,3.894736842
[official docs,3.894736842
grid_search/cross_val_score,3.894736842
data field,3.894117647
"nan problem

                # load",3.893878309
running training,3.893608252
x_train = sequence,3.893389723
"]





x_train = sequence",3.893389723
convolution operation,3.893333333
fixed_cnn_model = keras,3.893050791
include_distance=false,3.893034826
"shape

    print y_train",3.892512562
"shape

print y_train",3.892512562
"thread lock

   1282         #",3.891666667
thread-lock,3.891666667
weight values,3.891648758
multiple sentences,3.89147018
# multiple sentences,3.89147018
gru layers,3.890112444
tokenizer class,3.889016018
locally atleast,3.888888889
memory required,3.888888889
statistically significant,3.888888889
batches inside,3.888888889
drive/interact,3.888888889
multiple backends,3.888722928
negative section,3.888544892
negative-distance,3.888544892
model api,3.888307094
api model,3.888307094
return [os,3.88793348
9% top5 accuracy,3.887623762
3% top5 accuracy,3.887623762
"featurewise normalization

            #",3.887254902
"featurewise normalization

    #",3.887254902
"main

    model",3.887167493
keras didn,3.886557285
`timedistribution` wrapper,3.885964912
`wrapper` objects,3.885964912
kerasregressor wrapper,3.885964912
install,3.885786802
install/,3.885786802
**2nd elements,3.885714286
explicitly stated,3.885714286
cnn works,3.885225225
"data

model",3.884988843
functions/tensors,3.884436349
shapes larger,3.883333333
general guideline,3.882352941
pyobject* __error,3.882352941
collected avg,3.882352941
"```

collected avg",3.882352941
"]

collected avg",3.882352941
data/masks,3.882352941
apply node,3.882000599
300 thousand images,3.881578947
#images=load_images,3.881578947
feeded images,3.881578947
distorting images,3.881578947
rescaled images,3.881578947
transforming images,3.881578947
1024x1024 images,3.881578947
10k images,3.881578947
/imagefilter/images/,3.881578947
default parameters,3.881403509
preprocessing part,3.881006865
nadam  =  optimizers,3.8808933
training_set = train_datagen,3.880681818
sorting operation,3.88
class lanes,3.87944664
simple approach,3.879227053
release-win,3.878787879
weights manually,3.8783867
keras understand,3.878100625
json` manually,3.877819549
base_model = inceptionv3,3.877684652
"```

base_model = inceptionv3",3.877684652
network input,3.877581687
returning `x_test,3.877574559
"0

____________________________________________________________________________________________________

```



running",3.877410468
## previous experiments,3.877289377
"```

_________________________________________________________________

layer",3.877263581
"_________________________________________________________________

```

layer",3.877263581
"_________________________________________________________________

layer",3.877263581
explicitly pass,3.877263581
batch function,3.87697378
# export model,3.876585482
simple_model = model,3.876585482
cifar10_cnn model,3.876585482
"export model

3",3.876585482
2d tensor,3.875786164
sequence due,3.875690608
word_traintokenintpad = sequence,3.875690608
result = classifier,3.875559883
"``

``loss_out = lambda",3.875468165
"`

`loss_out = lambda",3.875468165
loss_out = lambda,3.875468165
image num,3.875280899
distorted image,3.875280899
image_save = image,3.875280899
img_dcc = image,3.875280899
img_icc = image,3.875280899
img_dobl = image,3.875280899
img_iobl = image,3.875280899
image belongs,3.875280899
required=true,3.875273155
output argument,3.875062476
makes sense,3.875
identical losses,3.875
tern generates,3.875
filter maps,3.875
"conv

        dilated_kern[",3.875
lr_multiplier = {conv,3.875
apply autoencoder,3.874785592
kernel_regularizer=regularizers,3.874603175
`kernel_regularizer=regularizers,3.874603175
**test** folder,3.874468085
encoder takes,3.873552124
task requires,3.873442623
train=false,3.873167276
extra **targets**,3.873076923
end = time,3.872830189
img_array_iobl = np,3.872794696
cntk convolution,3.872488263
distance layer,3.87225105
theano/compiledir_linux-3,3.87162891
theano upcasts,3.87162891
theano 8s,3.87162891
theano/compiledir_linux-4,3.87162891
"startidx=1

    map = {}",3.870967742
correctly  reconstruct,3.870833333
validation labels,3.87001287
"```

def euclidean_distance",3.869681269
def euclidean_distance,3.869681269
`def euclidean_distance,3.869681269
big batch,3.869557993
y_train[cmpt],3.869090909
complete history,3.869047619
error back,3.869029276
input sequences,3.868424178
sequences = input,3.868424178
encoded_vid = lstm,3.868131868
input matrix,3.867850454
callback functions,3.867681499
standard rnns,3.867647059
"get_combined_model

    batch_shape=",3.867647059
user error,3.867469538
generated list,3.866566215
trains fine,3.866412214
worked fine,3.866412214
calling load_model,3.866233766
multiple lines,3.866208856
runs fast,3.866071429
"[0]

        tiled = tf",3.865173572
new_model = sequential,3.86492891
"```

    new_model = sequential",3.86492891
"]



currmodel = sequential",3.86492891
"as_graph_element

    return",3.864630542
float placeholder,3.863505747
squared error,3.863379558
"221 

        222 def _deepcopy_tuple",3.863187762
"221 

    222 def _deepcopy_tuple",3.863187762
rnn = lstm,3.862755524
lstm rnn,3.862755524
lstm/rnn,3.862755524
rnn/lstm,3.862755524
correctly pass,3.862382629
model correctly,3.86170453
processed_a = base_network,3.861660079
model layers,3.86126533
input feature,3.861248705
label sequences,3.860777899
positive-distance,3.860411899
inital state,3.86036036
estimated state,3.86036036
authors state,3.86036036
great support,3.860154905
"py



keras `2",3.859419062
def conv2d,3.859236394
cntk backendhave,3.85915493
shared_ptr<cntk,3.85915493
dense_3/kernel,3.858944954
width < desired_width,3.858695652
width-desired_width,3.858695652
csv text,3.85855615
shape=filter_shape,3.858490566
shape=make_input_shape,3.858490566
compilation time,3.8575
multiple metrics,3.857487496
batch weight,3.857463435
"2581 

       2582     def save_weights",3.857396256
"1047 

   1048   def save_weights",3.857396256
negative = input,3.857219696
kfold = kfold,3.857142857
saturation threshold,3.857142857
tnpages 1 gt {,3.857142857
twidth 0 gt {,3.857142857
calling reduce_prod,3.857142857
globs=globs,3.857142857
incorrect manner,3.857142857
sound signal,3.857142857
"<pre>

1",3.857142857
"0  

</pre>",3.857142857
pre,3.857142857
tensorboard = tensorboard,3.857142857
h_tm1 * rec_dp_mask[0],3.857142857
h_tm1 * rec_dp_mask[1],3.857142857
h_tm1 * rec_dp_mask[2],3.857142857
h_tm1 * rec_dp_mask[3],3.857142857
val_generator = val_datagen,3.857142857
h_tm1 * b_u[0],3.857142857
h_tm1 * b_u[1],3.857142857
h_tm1 * b_u[2],3.857142857
h_tm1 * b_u[3],3.857142857
d_input=d_samples,3.857142857
latent dimension,3.856873823
framework,3.856521739
2d vector,3.856060606
"2s     

epoch 1/1

5002/5002 [==============================]",3.855595668
2s/epoch,3.855595668
rate = min,3.855555556
* frame rate,3.855555556
glove + word2vec,3.855555556
nrow = length,3.855421687
initial graph,3.854824688
previous states,3.854497354
data samples,3.854358611
data=samples,3.854358611
metric functions,3.854119112
2483         return updated[,3.854048531
1604         return updated[,3.854048531
lstm class,3.853639115
`lstm` class,3.853639115
support natively,3.853012048
callbacks=[reduce_lr,3.852964427
naively pickle,3.852941176
pickle _thread,3.852941176
pickle _cffi_backend,3.852941176
callback function,3.851953602
246           int count,3.851923077
num_instances < batch_size,3.85180624
train_samples/batch_size,3.85180624
model2 = sequential,3.851415396
multiprocessing = false,3.851368159
bias=false,3.851368159
"<module>

    train_datagen",3.851090604
yield this_x,3.85106383
steps_per_epoch = math,3.850795756
steps_per_epoch=math,3.850795756
simple passing,3.850694444
asynchronous methods,3.85
negative-label,3.849573417
write access,3.849471831
keras don,3.847208574
lstms/grus,3.847058824
restore train,3.846799117
embedding initialization,3.846491228
override embedding,3.846491228
"```

char_em = embedding",3.846491228
"+= 1



    embedding_layer = embedding",3.846491228
"```

embedding_layer = embedding",3.846491228
embeddeding=embedding,3.846491228
build dependencies,3.846461949
regularization parameter,3.846385542
loading data,3.846356453
rigid structure,3.846153846
ctc/toint64,3.846153846
ctc/toint32_2,3.846153846
ctc/squeeze_1,3.846153846
ctc/**toint64**,3.846153846
"__getitem__

    negatives =",3.846153846
nb_val_samples=test_batches,3.846153846
trained `concat,3.845182573
validation_labels = np_utils,3.845117845
q-values,3.844919786
values=x_square,3.844919786
incoming values,3.844919786
pass callbacks,3.844513723
method gettrainmatrix,3.844444444
initialization method,3.844444444
#vdeostream method,3.844444444
method infers,3.844444444
query_cnn method,3.844444444
effective method,3.844444444
`save_callbacks_state` method,3.844444444
clone_model function,3.844017094
fileio directly,3.84375
built = true,3.843527123
final states,3.842592593
cudnngru layers,3.841822705
loss runs,3.841521938
unknown entry,3.84137931
return np,3.841321342
`return np,3.841321342
similar occurrences,3.841269841
input layer,3.840925854
**input layer,3.840925854
layer input,3.840925854
# input layer,3.840925854
#input layer,3.840925854
zx=rand,3.840909091
siamese model,3.840871196
parallelised model,3.840871196
final model,3.840871196
model inside,3.840871196
matrix required,3.840696118
full traceback,3.84067086
simple solution,3.84067086
pr adds,3.839869281
automatically run,3.83976834
---> 42     result = getattr,3.839662447
multiple filters,3.839465168
def get_data,3.839378238
def _parse_function,3.839378238
"21 

     22     def clone_keras_model",3.839378238
"405 

    406     def _recv_bytes",3.839378238
"```

def mean_squared_logarithmic_error",3.839378238
def _cond,3.839378238
def get_output_shape_for,3.839378238
"```

def load_train_data_traces",3.839378238
def load_test_data_traces,3.839378238
def kl_distance,3.839378238
def d_stepy,3.839378238
def sparsify,3.839378238
"```

def assign_moving_average",3.839378238
def merge_average,3.839378238
def restore_data,3.839378238
"6]


    def max_1d",3.839378238
back propagate,3.838983051
hear back,3.838983051
preprocess function,3.838966589
detections = net,3.838888889
counter%batch_size == 0,3.838472906
metric function,3.838391215
unroll=true,3.838236118
makes predictions,3.837837838
predictions = fit1,3.837837838
_reasonable_ predictions,3.837837838
conv3d_transpose_ngroup` based,3.837837838
actual predictions,3.837837838
rms = rmsprop,3.837719298
user warning,3.837423313
user wishes,3.837423313
user unaware,3.837423313
extra = repeatvector,3.836363636
code base,3.836336336
x_test = train_test_split,3.836166692
data flow,3.834658188
originally defined,3.834445928
support op,3.834407397
initial weights,3.834051724
layer depth,3.833973538
layer depending,3.833973538
control_flow_ops,3.833333333
images_to_read[n_entries,3.833333333
"corpus



datafile",3.833333333
sigmoid_cross_entropy_with_logits,3.833333333
bottleneck = vgg_model,3.833333333
train_docs=codedocuments,3.833333333
test_docs=codedocuments,3.833333333
] + sm_model + dw_model,3.833333333
spikes/drops,3.833333333
w_conv1 = weight_variable,3.833333333
batch_x[continous],3.833333333
troubles moving,3.833333333
251 _deepcopy_dispatch[types,3.833333333
horizontal slider,3.833333333
lose track,3.833333333
val_batches = get_batches,3.833333333
debug console,3.833333333
potential predecessors,3.833333333
"bid2_last_step

bid1_step_2",3.833333333
"bid2_last_step

bid1_step_3",3.833333333
"bid2_last_step

bid1_step_4",3.833333333
"bid2_last_step

bid1_step_",3.833333333
"bid2_last_step

bid1_step_n",3.833333333
numbers representing,3.833333333
output1 = make_encoder,3.833333333
log_f_next = ctc_update_log_p,3.833333333
fucntion get_batches,3.833333333
"bias_i

                x_f =",3.833333333
"bias_c

                x_o =",3.833333333
worker computes,3.833333333
"b_i

                x_f =",3.833333333
"b_c

                x_o =",3.833333333
greatly improved,3.833333333
training item,3.83286445
initial model,3.832250507
def predict,3.832131862
input = input,3.832086451
input=input,3.832086451
"**





`input = input",3.832086451
>input = input,3.832086451
```    input = input,3.832086451
"```

input = input",3.832086451
"= 2



input = input",3.832086451
log function,3.831864316
sample id,3.831402831
true values,3.831304052
method parameters,3.831111111
working fine,3.831058678
147k dataset,3.830357143
dataset/single_prediction/1,3.830357143
storing dataset,3.830357143
sentiment_analysis dataset,3.830357143
smaller dataset,3.830357143
dataset dropped,3.830357143
dealt dataset,3.830357143
flickr8k dataset,3.830357143
return integer,3.830344828
test size,3.830320928
model = inceptionv3,3.830001631
inceptionv3 model,3.830001631
`    model=inceptionv3,3.830001631
#checkpointer = modelcheckpoint,3.82962963
checkpointer = modelcheckpoint,3.82962963
positive = input,3.829086704
full desc,3.829059829
generator function,3.828615554
earlier version,3.828328612
compatible version,3.828328612
incsubtensor{set,3.827641238
"--> 383                     raise eoferror

    384",3.827380952
network architecture,3.827210103
multiple pages,3.827184466
reconst_layer_1 = dense,3.827070285
curve score,3.827067669
score = mean_square_error,3.827067669
# score = mlogloss,3.827067669
score += yk/,3.827067669
good candidates,3.826923077
good afternoon,3.826923077
calls predict,3.826086957
call-function,3.826064644
function call,3.826064644
call function,3.826064644
inputcols=features,3.825757576
= training_data[features],3.825757576
32 flatted features,3.825757576
latent representation,3.825396825
deconvolution layer,3.824882629
`deconvolution` layer,3.824882629
gpu cycles,3.824538259
/test/tmp_model,3.824468085
label = input,3.824440172
separate model,3.82420453
total size,3.824034661
current problem,3.822387381
validation samples,3.822145726
small snippet,3.822134387
encoded = lstm,3.821465201
"```

dt = decisiontreeclassifier",3.821428571
bad prediction,3.821138211
prediction-delay,3.821138211
prediction = predict_image_class,3.821138211
kernel arrays,3.820901476
# set input,3.820607541
"html



specifically",3.820512821
shifted sequence,3.820135052
"```

train_gen = image",3.819725343
#train_gen = image,3.819725343
image patches,3.819725343
keepdims=true,3.8197176
weight vector,3.819456245
inputs=[video],3.818648019
window size,3.818352843
autoencoder independently,3.818181818
val lost,3.818181818
adversarial-autoencoder,3.818181818
`csvlogger` makes,3.818181818
_ = make_blobs,3.817073171
"][0]=1    

            

        return [batch_x1",3.817011494
return f_active_next,3.817011494
return wrapper_output,3.817011494
additional info,3.816722408
"_fit_loop

    outs =",3.816666667
"_fit_loop



    outs =",3.816666667
executed function,3.816239316
wrapped function,3.816239316
`conv4d` function,3.816239316
"edge

    778             # case",3.816183816
9�9 feature map,3.816173221
feature map,3.816173221
tiff `format,3.816161616
return tf,3.8155184
#         return tf,3.8155184
-> 1358     return tf,3.8155184
1462     return tf,3.8155184
1879         return tf,3.8155184
-> 1881         return tf,3.8155184
--> 358     return tf,3.8155184
1679         return tf,3.8155184
-> 1681         return tf,3.8155184
rnn outputs,3.815136476
train_labels = np_utils,3.814814815
dummy_y = np_utils,3.814814815
train_target = np_utils,3.814814815
"read

        return",3.814578404
code describing,3.814114114
logits=d2,3.814035088
latent variable,3.813968254
small set,3.813655224
components set,3.813655224
"base model

#",3.813093419
label set,3.812961262
max length,3.812564544
--> 636             loss_function = losses,3.8125
x_train = data[,3.811816762
considered batch,3.810734463
batch-restricted,3.810734463
gig = 4 batch,3.810734463
batch renormalization,3.810734463
original discussion,3.810606061
test directory,3.809762203
use_bias=false,3.809701493
use_bias = false,3.809701493
generate batches,3.809620596
hdf5 files,3.80952381
hidden states,3.809259259
adam optimiser,3.808695652
updates = adam,3.808695652
runtime error,3.807824003
"0



runtime error",3.807824003
network structure,3.807692308
testscore = math,3.807692308
true prediction,3.807522478
layer configuration,3.80723557
match filter,3.806034483
data_generator = imagedatagenerator,3.805691057
validation_generator = data_genereator,3.805555556
y_val = train_test_split,3.805152979
required input,3.804932114
set `num_partitions=2`,3.804564315
return outputs #,3.804190981
[triplet loss],3.804021938
patient number,3.803726708
network similar,3.802808303
` collects tensors,3.802469136
single number,3.80157617
fine approach,3.801194822
trainable weights,3.800672414
hierarchical bilstm,3.8
size_hidden_layer=hidden_layer,3.8
"runfile

>     execfile",3.8
worth mentioning,3.8
travis side,3.8
worth accepting,3.8
meaningless setting,3.8
num_partitions=num_partitions,3.8
earlier submission,3.8
"create_network

    plot_model",3.8
"runfile

    execfile",3.8
"batch_list_x=[]

    batch_list_y=[]",3.8
/ globalmaxpooling / flattened,3.8
ctcloss,3.8
setting lahead=2,3.8
temporary folder,3.8
states_value = encoder_model,3.8
max_pooling2d_1/maxpool,3.8
resizing externally,3.8
generally relevant,3.8
elemwise{minimum,3.8
cmpt<nb_traces_train,3.8
worth noting,3.8
shuffle_batch/random_shuffle_queue,3.8
259] raising pool_size_limit_,3.8
@dapid suggested,3.8
"runfile

execfile",3.8
word_test_label = nnu,3.8
conv layer,3.799882629
3 conv layer,3.799882629
# conv layer,3.799882629
function received,3.79957265
encoder network,3.799376299
return nn,3.799280998
model trainable,3.798871196
title = sequence,3.798767531
completely represent,3.798701299
400 train 200 val,3.798314269
embedding matrix,3.798298457
"embedding matrix

     [[9",3.798298457
embedding_1/cast,3.797794118
"1706 

       1707     def evaluate",3.797711572
"872 

    873     def evaluate",3.797711572
"864 

    865     def evaluate",3.797711572
"846 

    847     def evaluate",3.797711572
"1486 

   1487     def evaluate",3.797711572
"665 

    666     def evaluate",3.797711572
"1144 

   1145     def evaluate",3.797711572
"<module>

    load_model",3.797681513
input images,3.797622173
10 input images,3.797622173
french sentences,3.797619048
stack overflow,3.797619048
methods section,3.797368421
use_multiprocessing=true,3.797195077
use_multiprocessing = true,3.797195077
return train,3.797143945
keras provide,3.796585401
test_image = image,3.79633353
model_checkpoint = modelcheckpoint,3.796296296
high accuracy,3.79531607
validation_steps=validation_generator,3.79502924
validation_steps= validation_generator,3.79502924
re-train,3.794947265
default deconvolution,3.794736842
scale=false,3.794549977
downloading data,3.794117647
coordinate data,3.794117647
data formulation,3.794117647
data overwriting,3.794117647
feeding back,3.793528505
cnn-lstm,3.793357093
cnn + lstm,3.793357093
cnn lstm,3.793357093
pytorch documentation,3.793333333
works fines,3.793333333
checking target,3.793293592
steps_per_epoch=nb_train_steps,3.793103448
outputs=[net],3.792735043
outputs=net,3.792735043
32x1x3x3 tensor,3.79245283
allocating tensor,3.79245283
symoblic tensor,3.79245283
on_batch_begin=lambda,3.792134831
"```

    def _make_train_function",3.791759191
remove padding timesteps,3.791743119
layer ```d2```,3.791549296
loading inceptionv3,3.791369241
yy = model,3.790871196
"```

yy = model",3.790871196
`gist1` model,3.790871196
generator version,3.79070485
2xlarge machine,3.790697674
24core machine,3.790697674
small images,3.790669856
argument epsilon,3.790406977
type <class,3.78953655
type `<class,3.78953655
closely related,3.789473684
default=default,3.789473684
return batches,3.789233716
store,3.788732394
"<module>

    mybdc",3.788590604
"<module>

    myunet",3.788590604
"<module>

    run_ete_exp",3.788590604
"<module>

    get_weights_without_softargmax",3.788590604
distribution module,3.788590604
"<module>

>     multi_gpu_test_simple_model",3.788590604
class vae,3.788537549
unused inputs,3.787878788
combine user,3.787423313
taking `809 steps`,3.786962366
model_2 = load_model,3.786868687
gru-unit,3.786384977
-> 1636             check_batch_axis=true,3.786384266
negative values,3.786096257
define `epsilon_std`,3.786046512
"21900     

_________________________________________________________________

dropout_1",3.785714286
tesnorboard callback,3.785714286
autotuner disabled,3.785714286
manually click,3.785714286
"0         

_________________________________________________________________

dropout_1",3.785714286
"112600    

_________________________________________________________________

dropout_1",3.785714286
2000x2000 pixels,3.785714286
months ago,3.785714286
kernel_regularizer = ortho,3.785714286
"26112     

_________________________________________________________________

dropout_1",3.785714286
performance gains,3.784946237
labeling = df[,3.784615385
seq = text,3.784313725
run produces,3.784212784
sparse targets,3.784188034
small filter,3.784090909
batch-sgd,3.783888826
5m sample,3.783783784
113526 sample points,3.783783784
choose training,3.78286445
proper conv2dtranspose,3.782758621
approximation based,3.782282282
expected activation_1,3.782078853
seq = sequential,3.781595577
kerasclassifier object,3.781319496
rnn = gru,3.781008632
grad = sess,3.780701754
internal weights,3.780172414
y_test = np_utils,3.779824023
"func_load

typeerror",3.779166667
image number,3.779007607
6/multiprocessing/connection,3.778846154
train_generator = imagedatagenerator,3.77841833
large model,3.778371196
"<module>

>     validation_steps=50",3.778064288
installed `graphviz`,3.777777778
sample_weight_model=temporal,3.777777778
temporal ensembling,3.777777778
compiler=compiler,3.777777778
model_clone = clone_model,3.777777778
pairs/triplets,3.777777778
mnist_cnn,3.777777778
"```

## mnist_cnn",3.777777778
class  precision,3.777173913
default configuration,3.777089783
x_test = sequence,3.777074691
hidden = kl,3.776666667
real requirement,3.776556777
parameters related,3.776140351
predicted parameters,3.776140351
return lambda,3.775812992
desp = sequence,3.775690608
created external,3.775342466
recent call,3.775289245
[fw_cell] * num_layers,3.775
num_rows = int,3.775
"2

    val_words = int",3.775
n_test = int,3.775
network predicts,3.774038462
current solutions,3.773684211
prediction performance,3.772751115
vector assembler,3.772727273
mask_datagen = imagedatagenerator,3.772357724
toposort index,3.772277228
scanning index,3.772277228
"index 0
        img_channel_index =",3.772277228
estimated metric,3.772151899
metric involving,3.772151899
contrib,3.771929825
contrib`,3.771929825
unit testing,3.771929825
input length=1,3.771464912
input length,3.771464912
xent_loss + kl_loss,3.771428571
unknown error,3.771425535
initial error,3.771425535
# initial error,3.771425535
embedding layer,3.771373857
`embedding` layer,3.771373857
# layer = embedding,3.771373857
fold layer,3.771036475
layer structure,3.771036475
remember correctly,3.770833333
generate histograms,3.770731707
larger type,3.770695971
layers arise,3.770394134
maxout layers,3.770394134
layer_conv2d_1_dcc = layers,3.770394134
layer_maxpool_1_dcc = layers,3.770394134
layer_conv2d_2_dcc = layers,3.770394134
layer_conv2d_3_dcc = layers,3.770394134
layer_maxpool_2_dcc = layers,3.770394134
layer_conv2d_4_dcc = layers,3.770394134
output_dcc = layers,3.770394134
layer_conv2d_1_icc = layers,3.770394134
layer_maxpool_1_icc = layers,3.770394134
layer_conv2d_2_icc = layers,3.770394134
layer_conv2d_3_icc = layers,3.770394134
layer_maxpool_2_icc = layers,3.770394134
layer_conv2d_4_icc = layers,3.770394134
output_icc = layers,3.770394134
layer_conv2d_1_dobl = layers,3.770394134
layer_maxpool_1_dobl = layers,3.770394134
layer_conv2d_2_dobl = layers,3.770394134
layer_conv2d_3_dobl = layers,3.770394134
layer_maxpool_2_dobl = layers,3.770394134
layer_conv2d_4_dobl = layers,3.770394134
output_dobl = layers,3.770394134
layer_conv2d_1_iobl = layers,3.770394134
layer_maxpool_1_iobl = layers,3.770394134
layer_conv2d_2_iobl = layers,3.770394134
layer_conv2d_3_iobl = layers,3.770394134
layer_maxpool_2_iobl = layers,3.770394134
layer_conv2d_4_iobl = layers,3.770394134
output_iobl = layers,3.770394134
merge_branchs = layers,3.770394134
layer_dense_1 = layers,3.770394134
layer_dropout = layers,3.770394134
layer_dense_2 = layers,3.770394134
output_final = layers,3.770394134
`get_weights/set_weights` doesn,3.769585602
time steps,3.769462366
1000 time steps,3.769462366
time-steps,3.769462366
time steps 1,3.769462366
500 time-steps,3.769462366
1 time steps,3.769462366
9 time steps,3.769462366
force batchnorm,3.769230769
function_module,3.769230769
reconstruction probabilities,3.769230769
nb_train_samples // batch_size,3.768472906
dense_2/kernel,3.768427713
test_label=train_test_split,3.768115942
random image,3.767974963
elif resultfinal == 1,3.767676768
elif resultfinal== 2,3.767676768
elif resultfinal== 3,3.767676768
elif resultfinal== 4,3.767676768
elif resultfinal== 5,3.767676768
elif resultfinal== 6,3.767676768
elif resultfinal== 7,3.767676768
**graph connection,3.767291532
load data,3.76709062
"create_op

    original_op=",3.766917293
vision_model = get_resnet_single_image_model_no_softmax,3.766666667
decoder rnn,3.76655348
step [update,3.7664903
ncompile log,3.765625
typicall -log,3.765625
elemwise{log,3.765625
log informaiton,3.765625
test = np,3.765444599
current workaround,3.765350877
"class_indices

print",3.764931087
"continue



        layer",3.764882629
word tokens,3.764835165
validation_steps=int,3.764473684
net = lambda,3.764357054
4 dense layers,3.764131086
dense layers,3.764131086
additional syntax,3.763975155
identical lstm,3.763965201
neg term,3.763888889
# creating dataset,3.763690476
batch end,3.763564652
end batch,3.763564652
conv2d_1/convolution,3.763333333
model checkpoint,3.763284989
shown prior,3.763157895
embedding_1/random_uniform,3.7625
genx1 = generator,3.762376238
preparing generator,3.762376238
fake = generator,3.762376238
---> 33 fake = generator,3.762376238
#generator makes,3.762376238
generator routine,3.762376238
generator fills,3.762376238
generator=batch_predict_generator,3.762376238
called inside,3.762195122
accompanying functionality,3.761904762
hack/modification,3.761904762
new_lr = old_lr *,3.761904762
previous efforts,3.761904762
desired functionality,3.761904762
initial_state argument,3.76124031
`initial_state` argument,3.76124031
385                     raise oserror,3.760714286
class labels,3.760282021
"call

      x_expanded =",3.759825328
"call

    proxy_of_class =",3.759825328
call succeeds,3.759825328
weights=[vec],3.75933908
convolution dimension,3.759096045
return width,3.75904048
lstm cell,3.758608059
"```

def binary_crossentropy",3.758297157
layer numbers,3.758215962
apply lstm,3.758068975
positive values,3.757963264
net/pdf,3.757936508
complete model,3.757537863
"input



==========================================

similar",3.757313067
invoking `bidirectional,3.757142857
augmented images,3.756578947
9 grayscale images,3.756578947
single shape,3.756340028
final result,3.756329114
"664

    665     def compute_mask",3.756044905
def compute_mask,3.756044905
def root_mean_squared_error,3.756044905
size 60x80,3.755852843
size 15x128,3.755852843
"compile

    handle_metrics",3.755623722
w_regularizer = regularizers,3.755555556
works properly,3.754871795
current = logs,3.754172015
"]

#test_data=scaler",3.753378378
"model_from_json



print",3.75330318
decay_init=1e-2,3.75308642
support ring,3.753012048
mscoco support,3.753012048
callbacks=[tb],3.752964427
dtype=variant,3.752918288
dtype=np_dt,3.752918288
dtype=_convert_string_dtype,3.752918288
makevector{dtype=,3.752918288
dtype=tf_dtype,3.752918288
dtype=_floatx,3.752918288
dtype=subfeed_dtype,3.752918288
variable grid,3.752857143
"9248      

_________________________________________________________________

max_pooling2d_1",3.752380952
extract hidden,3.752380952
"221440    

_________________________________________________________________

max_pooling2d_1",3.752380952
"18496     

_________________________________________________________________

max_pooling2d_1",3.752380952
rnn = model,3.752161519
rnn model,3.752161519
highly appreciated,3.752136752
confusion matrix,3.751807229
unlike `fit,3.750701403
y_train = np_utils,3.750572391
"/ 255

y_train = np_utils",3.750572391
return active_next,3.750344828
"return dense3

```",3.750344828
image patch,3.750280899
util,3.75
perform exceptionally,3.75
coded bellow,3.75
"]

distros = lab",3.75
rendered bigger,3.75
"_test_loop

    batch_outs =",3.75
internally converted,3.75
492x1100k approx,3.75
webcam watching,3.75
start_x+desired_width,3.75
stateful rnns,3.75
middle samplehello,3.75
p5all = decode_predictions,3.75
reduced_representation =mid,3.75
decreased efficiency,3.75
magnitudes bigger,3.75
ga_int *indices_arr,3.75
experiencing exceptions,3.75
reversed shapes,3.75
lstm_x = make_input_lstm,3.75
acceptable procedure,3.75
application continues,3.75
news article,3.75
override `get_gradients,3.75
fft tiling,3.75
patient_ids,3.75
3 model_loaded = get_custom_cnn,3.75
model_loaded = get_custom_cnn,3.75
conv2d_1/kernel_0,3.75
conv2d_1/bias_0,3.75
validation accuracy,3.749528524
80% validation accuracy,3.749528524
75% validation accuracy,3.749528524
callback modelcheckpoint,3.748677249
modelcheckpoint callback,3.748677249
feeding data,3.748663102
single `fit,3.748550865
459             # collecting output,3.747155499
padded output,3.747155499
453             # collecting output,3.747155499
actual output,3.747155499
output = identity,3.747155499
collecting output,3.747155499
output=conc,3.747155499
"848s

```



output",3.747155499
"708s

```

output",3.747155499
representative output,3.747155499
output _z_,3.747155499
`output-n_func`,3.747155499
"increasing

```



output",3.747155499
renames output,3.747155499
1 output weather,3.747155499
output=encoded_imgs[1],3.747155499
visible output,3.747155499
cudandarray **output,3.747155499
feedbackthe output,3.747155499
output=decode_music,3.747155499
desired output,3.747155499
fourth dimension,3.745762712
tow-dimension,3.745762712
n-dimension,3.745762712
accept 4 dimension,3.745762712
ncol = dimension,3.745762712
outer dimension,3.745762712
class weights,3.744846327
target nodes,3.744808743
"{

325       case cudnn_convolution_fwd_algo_implicit_gemm",3.744755245
model including,3.74471735
directly instantiate,3.74375
tf source,3.743604945
feedforward submodel,3.743421053
# feedforward submodel,3.743421053
/theano/theano,3.743257821
linear combination,3.743055556
class model,3.743045109
"--> 558         return weights

    559",3.743017241
# return states,3.74293742
"entry 

            # consisting",3.742857143
sets metrics,3.74280303
2696         return json,3.742450091
"_get_batches_of_transformed_samples

>     batch_x[",3.742424242
function object,3.742295654
loss based,3.741859776
input features,3.741800801
features = input,3.741800801
turn fails,3.741666667
"return model

`",3.741216024
"return model

#",3.741216024
return model`,3.741216024
return model,3.741216024
"return model



#",3.741216024
"return model 





`",3.741216024
"return model`

```",3.741216024
"return model

```",3.741216024
"`

  return model",3.741216024
grid = np,3.740976514
total >= train_generator,3.740909091
def split,3.740419905
1 background class,3.740409207
background class,3.740409207
`get_config` function,3.74015236
logits tensor,3.739821251
"adam



importerror",3.739730135
default values,3.739656628
small dataset,3.739448052
data_utils,3.739130435
"```

--- data_utils",3.739130435
"746278926 -0500

+++ data_utils",3.739130435
[data_utils,3.739130435
required steps,3.738351254
return inputs +,3.738223615
flag=flag_val,3.738095238
`merge` function,3.737995041
temporary information,3.737704918
detailed information,3.737704918
memory information,3.737704918
highest accuracy,3.737623762
mac os,3.737588652
untar_fpath = os,3.737588652
macbook os,3.737588652
loss=custom_objective,3.737355271
lower loss,3.737355271
loss drops,3.737355271
test_sequences = tokenizer,3.736842105
`tokenizer` fixes,3.736842105
modified version,3.736661945
passed directly,3.736607143
sparse = lambda,3.736579276
takes minutes,3.735714286
`compile` requires,3.735623722
working correctly,3.735479798
states=cb,3.735449735
train_generator = train_datagen,3.735227273
nb_val_samples=val_samples,3.735042735
x_test <- vectorize_sequences,3.734717416
"depth

     [[node",3.734487734
label = features[,3.734154522
standard format,3.733808675
3 dimensional shape,3.733490566
submodel = sequential,3.733349963
"#

            submodel = sequential",3.733349963
net1 = tower_network,3.733333333
x_train_tmp  = encoder_func,3.733333333
separate problems,3.733333333
y_test = train_test_split,3.73312515
y_test=train_test_split,3.73312515
numeric labels,3.733108108
result false,3.732697273
create net,3.732222222
"reraise

    raise",3.732142857
updated version,3.732032316
241     return op,3.731740176
architecture=architecture,3.731343284
results = y_prediction[,3.731034483
sota results,3.731034483
poor results,3.731034483
unusable results,3.731034483
results remains,3.731034483
producible results,3.731034483
perfect results,3.731034483
bad results,3.731034483
params=model,3.730998585
gist playground,3.730434783
resnet part,3.73042362
filter length,3.730421687
evaluation/prediction,3.73022912
optional list,3.730202578
cpu-augmentation,3.72866242
tbcallback = tensorboard,3.728571429
input losses,3.728543225
blog works,3.728115942
writing set,3.728093727
no_inplace} [id,3.727619048
29         # pydot raises,3.727598566
x1_1 = layer1,3.727272727
x2_1 = layer1,3.727272727
gpu_device,3.727272727
cpu_feature_guard,3.727272727
input batch,3.726777689
"net = inputs

        #",3.726767677
source paper,3.726579521
`use_multiprocess = false`,3.726368159
inplace_oov=false,3.726368159
subsample_initial_block=false,3.726368159
revert=false,3.726368159
is_placeholder = false,3.726368159
previous sentences,3.726190476
maxlen=title_maxlen,3.725806452
maxlen=desp_maxlen,3.725806452
maxlen=max_review_length,3.725806452
maxlen=maxseqlength,3.725806452
extracted features,3.725757576
features extracted,3.725757576
10 features extracted,3.725757576
activations = get_activations,3.725694444
2 vector sequences,3.725108225
batch_normalization layers,3.724939588
full logs,3.724932249
top layer,3.724882629
"__call__

    return",3.724257871
"__call__



    return",3.724257871
larger model,3.72420453
class deconv3d,3.723602484
network = input_data,3.723443223
work fine,3.723219725
machines yields,3.723214286
"model_from_json

  file",3.722808436
/data/dog,3.722689076
656                             # => serialize calls,3.722222222
single timestep,3.722173787
original issue,3.722009569
"return main_model



```",3.721773399
py line 492 corresponds,3.721685638
char embedding,3.721491228
custom_variational_layer_1/reshape,3.721477725
correct til,3.721311475
train/test,3.721267202
larger inputs,3.721212121
calculated previously,3.721153846
stack size,3.720138557
hard time,3.72
pixel values,3.719919786
"]

    scale = 1

    return",3.718526646
input tensors,3.718512361
current issue,3.718421053
encode functions,3.718330849
layer works,3.718215962
originally created,3.718199609
feature-vector,3.717932752
internal error,3.717546225
state restored,3.717503218
tensor/layer,3.717335459
shuffle= true,3.717153497
shuffle=true,3.717153497
`shuffle=true`,3.717153497
>       5                     shuffle=true,3.717153497
shuffle = true,3.717153497
"8

cntk v2",3.716297787
"}

        base_config = super",3.715517241
y2 = layers,3.714838578
generator = gen,3.71475719
entire file,3.714436343
tiny probability,3.714285714
greatly increased,3.714285714
tensorboard callback,3.714285714
embedded_sequences = embedding_layer,3.714285714
pool request,3.714285714
probability distribution,3.714285714
val_losses increased,3.714285714
"```



side notes",3.714285714
undefined symbol,3.714285714
loader=loader,3.714285714
[tensorboard callback],3.714285714
reconstruction probability,3.714285714
preventing overfitting,3.714285714
android app,3.714285714
memory anymore,3.714285714
"probability
# distribution",3.714285714
modelling sentences,3.714285714
go_backwards=true,3.713656994
learnt weight,3.713395639
train function,3.713038433
blog post,3.712560386
[blog post],3.712560386
bias arrays,3.711956522
val_generator = datagen,3.711688312
begin batch,3.710734463
"begin batch

2017-11-19 08",3.710734463
lstm_1 =  gru,3.710627401
hidden = dense,3.710403619
expected input_1,3.710183428
decay parameter,3.709718876
word_trainlabelintpad = sequence,3.709023941
word_testlabelintpad = sequence,3.709023941
"inputs

        func =",3.708757909
network output,3.708693961
standard model,3.708518255
input tensor,3.708496055
"input

tensor",3.708496055
input-tensor,3.708496055
`tensor = input,3.708496055
calculation precision,3.708333333
testpredict = scaler,3.708333333
slightly modified,3.708333333
`prelu` layers,3.707894134
handles mse,3.707792208
matrix size,3.707660072
lambda functions,3.707435378
adding autoencoder,3.707070707
similar architecture,3.706941483
process nodes,3.706060606
1402   def _as_variant_tensor,3.706044905
def py_func,3.706044905
"= vects

    return",3.705900383
"= vects

       return",3.705900383
modify output,3.705488833
expected dense_2,3.705450501
theano optimizations,3.704962244
fortran flags,3.704545455
add attention,3.704422104
error occurs,3.703959268
"```



error occurs",3.703959268
define x_train,3.703745627
"][ja]



            x2=",3.703703704
word=vocabdic[,3.703296703
variable _i_,3.702857143
variable manipulations,3.702857143
variable conv_maxpool_2/,3.702857143
storing history,3.702380952
"0         

_________________________________________________________________

conv2d_1",3.702380952
"9248      

_________________________________________________________________

conv2d_3",3.702380952
"93670     

_________________________________________________________________

conv2d_3",3.702380952
history = losshistory,3.702380952
encodes sequences,3.702380952
validation_data=test_generator,3.702265372
/app/accuracy,3.701909477
` returns `false`,3.701777995
"]



# 4d input",3.701757511
impact performance,3.701612903
stateful lstm,3.701465201
lstm_network = lstm,3.701465201
enclstm= lstm,3.701465201
declstm = lstm,3.701465201
decoder_lstm = lstm,3.701465201
lstm equation,3.701465201
require_shape_fn=true,3.700669981
"main

    loss",3.700318234
valid_gen = data_gen,3.7
element-wisely,3.7
represents 1 song,3.7
deprecation warning,3.7
disable,3.7
"```



sample input",3.699827009
input sample,3.699827009
fft implementation,3.69980695
output sequences,3.699536452
weighted sum,3.699122807
receiving layers,3.698965562
steps=steps,3.698924731
manner similar,3.698412698
saved loses,3.698412698
dst_model = sequential,3.698262243
sub_model = sequential,3.698262243
encoder state,3.698198198
--> 107         return deserialize,3.697963875
--> 122         return deserialize,3.697963875
124         return deserialize,3.697963875
related label,3.697870631
cnn decoder,3.69715505
current situation,3.695906433
manually change,3.69535284
logits=output,3.69452392
output=distance,3.69452392
duplicate data,3.694117647
select data,3.694117647
batchnorm layer,3.694113398
calculate input,3.693821003
"```

tf version",3.693502184
tf version,3.693502184
target images,3.693054357
embedding = embedding,3.692982456
apply repeatvector,3.69296741
source code,3.692545487
[source code],3.692545487
source code],3.692545487
[source-code],3.692545487
nb_val_samples=nb_val_samples,3.692307692
"]]



noise shape",3.691823899
"<module>

    pd",3.69181641
return img / 255,3.691746101
zero-padding,3.691743119
lambda function,3.691707481
subgraph defined,3.691588785
defined boundaries,3.691588785
ill-defined,3.691588785
defined roadmap,3.691588785
backwards pass,3.691549296
takes arguments,3.691451991
n_step= np,3.690976514
modified_softmax_weights = np,3.690976514
yous np,3.690976514
y_pred_classes = np,3.690976514
dataindex = np,3.690976514
batch_mask  = np,3.690976514
351       nparray = np,3.690976514
354       nparray = np,3.690976514
"np



network_name =",3.690976514
pred_data = np,3.690976514
data_t1=np,3.690976514
data_x1=np,3.690976514
msk = np,3.690976514
weight_change = np,3.690976514
img_array_dcc = np,3.690976514
img_array_icc = np,3.690976514
img_array_dobl = np,3.690976514
monitor_op = np,3.690976514
outputs_info=[np,3.690976514
y_test_all=np,3.690976514
perm = np,3.690976514
batch_response = np,3.690976514
expected_initial_bias = np,3.690976514
365       nparray = np,3.690976514
368       nparray = np,3.690976514
"]

        this_x = np",3.690976514
yk = np,3.690976514
180                             raise error,3.690760511
`__getitem__` method,3.690598291
simple issue,3.689181287
weights parameter,3.689057956
parameter states,3.688978135
epoch 1 improves,3.688929001
worth adding,3.688888889
lr=lrate,3.688888889
previous mask,3.688871054
input vector,3.688770498
test code,3.688582199
index = input,3.688320453
691     def load_weights,3.687863087
timedistributed layers,3.6870608
created cats/,3.686453577
kernel matrix,3.685752183
augmented batch,3.685734463
# method similar,3.685714286
class init,3.685507246
samples = minmaxscaler,3.685240964
tune batch_size,3.685139573
pooling = maxpooling2d,3.684667908
on_batch_end method,3.684444444
**on_batch_end** method,3.684444444
method on_batch_end,3.684444444
530             score = scorer,3.684210526
--> 532             score = scorer,3.684210526
model_selection,3.684210526
under-fitting,3.684210526
`make notebook`,3.684090909
text part,3.683436533
"{

  results <- matrix",3.682841712
cnn model,3.682763088
test labels,3.682576193
files needed,3.682251082
bidirectional layer,3.682025486
kernel_initializer=truncatednormal,3.681957187
memory increase,3.681818182
resulting model,3.681780287
toy model,3.681780287
"function

--> 658                             generator_output =",3.681623932
saving weights,3.681561303
re-init,3.681481481
evaluation metric,3.681242808
backend file,3.681165315
label vector,3.681124219
match shapes,3.681034483
include writing,3.680672269
layers change,3.680032688
`old_keras` environment,3.68
# narrow convolution,3.68
advancedincsubtensor1{no_inplace,3.68
embedded = embedding,3.679824561
cnn inputs,3.67977068
saving model,3.679760085
model saving,3.679760085
@fchollet,3.679487179
fchollet@�,3.679487179
"rmsprop

model",3.678590495
config separately,3.678571429
gradient status,3.678571429
exact gradient,3.678571429
input_data = input,3.677947987
save data,3.677537336
l2 parameter,3.677030703
total width,3.67687747
gru cell,3.676861167
text make,3.676737968
406] failed call,3.676491994
_callable object,3.676056338
copyable object,3.676056338
stringio object,3.676056338
h5iterator object,3.676056338
unsized object,3.676056338
cdatatype object,3.676056338
compare output,3.675726928
pooling area,3.675213675
4th layer,3.674882629
conv4d layer,3.674882629
layer continues,3.674882629
run successfully,3.673101673
"multiclass targets

```",3.673076923
"1269 

   1270     def count_params",3.672711572
"```

def moving_average_update",3.672711572
tensor operation,3.67245283
class convlstm2d,3.672173913
output = layer,3.672038128
output layer,3.672038128
output=layer,3.672038128
# output layer,3.672038128
` output layer,3.672038128
input size,3.671896068
erase �merge�,3.671755725
2d inputs,3.671212121
`steps_per_epoch` argument,3.671010425
expected activation_14,3.670967742
expected lstm_1_input,3.670967742
expected conv_lst_m2d_1_input,3.670967742
expected conv3d_62_input,3.670967742
expected activation_11,3.670967742
expected activation_9,3.670967742
expected time_distributed_34_input,3.670967742
expected conv2d_29,3.670967742
expected lstm_12_input,3.670967742
expected dense_10,3.670967742
expected min_ndim=3,3.670967742
"expected 

time_distributed_1_input",3.670967742
expected conv2d_138,3.670967742
expected conv1_input,3.670967742
expected activation_4,3.670967742
expected lstm_input_3,3.670967742
expected firstclstmv2_input,3.670967742
expected dense_63,3.670967742
expected convolution2d_input_1,3.670967742
decode correctly,3.670833333
categorical numbers,3.670542636
start_time = time,3.67
batchnorm system,3.669230769
instance `base_network`,3.668478261
reset state,3.668052668
return [x_train,3.668043943
return x_train,3.668043943
exception occurs,3.66687079
2070     context_f = condcontext,3.666666667
res_f = context_f,3.666666667
faster interfere,3.666666667
marcelwhen evaluating,3.666666667
4/importlib/_bootstrap,3.666666667
specific crop,3.666666667
globally defining,3.666666667
chat bot,3.666666667
"nu98

```

# -*- coding",3.666666667
preprocess_input gave,3.666666667
161   tensor_value = attr_value_pb2,3.666666667
safely deploy,3.666666667
w_ij = w_ji,3.666666667
"_reduction_a_cell

    block_id=",3.666666667
aka splitting,3.666666667
embedding_vector = embeddings_index,3.666666667
shorter sequeunces,3.666666667
6/importlib/_bootstrap,3.666666667
`variancescaling` initialization,3.666666667
outer product,3.666666667
maximize m_t,3.666666667
#data_pre=scaler_labels,3.666666667
"code_**



> # -*- coding",3.666666667
worst 147% slower,3.666666667
#REF!,3.666666667
variancescaling lin 206,3.666666667
current workers,3.666666667
specific hyperparameters,3.666666667
fc = timedistributed,3.666666667
5x slower,3.666666667
model_history = head_model,3.666666667
successfully allocates,3.666666667
4x slower,3.666666667
"build_agent

    _costs_embd",3.666666667
_activation function_,3.666666667
jakob aungiers,3.666666667
jakob-aungiers,3.666666667
100   tensor_value = attr_value_pb2,3.666666667
cleaner wayhi,3.666666667
hydrangea flower,3.666666667
w_ij * d_kl_,3.666666667
5x faster,3.666666667
controll vars],3.666666667
appropriately constructed,3.666666667
differ considerable,3.666666667
#NAME?,3.666666667
image_generator = image_datagen,3.666666667
163   tensor_value = attr_value_pb2,3.666666667
xp card,3.666666667
"47us  cudagetlasterror

  0",3.666666667
test_id = load_test,3.666666667
shows approximately 95%,3.666666667
displayed unit,3.666666667
autograd,3.666666667
--> 621         ret = conversion_func,3.666666667
op_kernel,3.666666667
"0

cloning",3.666666667
complete gibberish,3.666666667
osama,3.666666667
"legacy_generator_methods_support



~",3.666666667
"ctc_update_log_p

    updated_log_p_prev =",3.666666667
--> 741           ret = conversion_func,3.666666667
--> 669           ret = conversion_func,3.666666667
sorted=sorted,3.666666667
`is_keras_tensor` function,3.666239316
prediction values,3.666057997
input shapes,3.666043225
partitions = input,3.666043225
final_input = input,3.666043225
input=final_input,3.666043225
268           // input shapes,3.666043225
validation loss,3.6659267
**validation loss**,3.6659267
time dimension,3.665762712
image_resized = tf,3.665173572
valid_images = tf,3.665173572
init_op = tf,3.665173572
estimator_model = tf,3.665173572
tags=[tf,3.665173572
sq2 = tf,3.665173572
pi*tf,3.665173572
sg1 = tf,3.665173572
sg2 = tf,3.665173572
y_train_batch = tf,3.665173572
b2 = tf,3.665173572
_learning_phase = tf,3.665173572
tf weights_no_top,3.665173572
sess_1 = tf,3.665173572
sess_2 = tf,3.665173572
dataset loaded,3.663690476
correctly passed,3.663690476
3 features predictions,3.663595414
feed data,3.663348416
"layers

# note",3.663251277
input {} -> output {},3.663198725
input-output,3.663198725
lstm network,3.663003663
2 modelcheckpoint instances,3.662962963
trainable flags,3.662545455
enlarging epsilon,3.6625
valid = read_data_file,3.662162162
write 2 bytes,3.661971831
define `optimizer`,3.661835985
input dimension,3.661805937
edit distance,3.661654135
writing predictions,3.66136725
nb_validation_samples // batch_size,3.661330049
nb_validation_samples/batch_size,3.661330049
"input_length



    return",3.661214393
session,3.661157025
session =,3.661157025
encoding space,3.660869565
#dataset = dataset,3.660714286
dataset = dataset,3.660714286
11     dataset = dataset,3.660714286
12     dataset = dataset,3.660714286
"predict

    verbose=verbose",3.660606529
device memory,3.660377358
device=gpu1,3.660377358
bit ugly,3.66025641
validation_generator = datagen,3.66010101
create group,3.66
saved properly,3.65995116
fitting times,3.659820282
dense_2/bias,3.659482759
passing callbacks,3.659214427
proper shape,3.658490566
layer definition,3.658215962
"`epoch 1/10

1s",3.657679001
losses� values,3.657419786
include raising,3.657142857
`model` function,3.657110513
return result,3.656673942
target values,3.656395196
shuffle layer,3.65565186
�nonnegative float�,3.655172414
set constraints,3.654564315
masked inputs,3.654545455
process images,3.65430622
final loss,3.654021938
loss gradient,3.654021938
loss separately,3.654021938
loss names,3.654021938
loss inside,3.654021938
good score,3.653990746
outputs=prediction2,3.653846154
outputs=sub_model2,3.653846154
outputs=sum_01,3.653846154
"]

outputs clients",3.653846154
outputs=scalar_output,3.653846154
outputs=[out_style,3.653846154
outputs=shared_layer,3.653846154
defaults = inspect,3.653846154
outputs=lst,3.653846154
outputs = [in_1],3.653846154
outputs=gradients_all,3.653846154
outputs=[p_output,3.653846154
outputs=[ct_1_1,3.653846154
conv5 = leakyrelu,3.653846154
conv6 = leakyrelu,3.653846154
outputs=[rdn],3.653846154
outputs=[dense_out],3.653846154
outputs clients,3.653846154
final number,3.653726708
symbolic number,3.653726708
neuron number,3.653726708
"```

def categorical_crossentropy",3.653413326
named arg,3.653409091
model identical,3.653371196
`nb_epoch` argument,3.653159502
typeerror occurs,3.65307971
passthrough=true,3.653050933
include_distance=true,3.653050933
big_is_error=true,3.653050933
"0]

# inverse transform",3.652173913
"```

class acccallback",3.652173913
"#



class normaldensity",3.652173913
`class conv3dtranspose`,3.652173913
class counts,3.652173913
"directory





failed",3.651960784
applied correctly,3.651785714
features=features,3.651515152
"```



`features = features",3.651515152
sec/samples`,3.651150055
`sec/samples`,3.651150055
network_1= sequential,3.650643196
stateful_model = sequential,3.650643196
final_model = sequential,3.650643196
default size = 10,3.650589685
"epoch 46/10000

    0s",3.650467463
"5004

    epoch 47/10000

    0s",3.650467463
"4060

    epoch 48/10000

    0s",3.650467463
"_train_model                  

    return",3.650344828
--> 230     return devicespec,3.650344828
"make_variable

    return",3.650344828
177         return _preprocess_symbolic_input,3.650344828
---> 62         return _wrapit,3.650344828
"recv_into

        return",3.650344828
--> 502         return _multimetric_score,3.650344828
712     return fbeta_score,3.650344828
return target_func,3.650344828
return longlong_as_double,3.650344828
"generate_negatives

    return",3.650344828
return ret[0],3.650344828
return to_translate,3.650344828
#x_valid_cv = paths_to_tensor,3.65
sentence separately,3.65
safe implementation,3.64980695
cell states,3.64973545
multi_gpu_model function,3.64957265
function multi_gpu_model,3.64957265
input received,3.649376559
convoluted nn,3.64893617
dataset/training_set,3.648538961
# apply model,3.64747497
cnn won,3.647447447
lstms stateful,3.647058824
`stateful` lstms,3.647058824
"nb_filter3 = filters

    conv_name_base =",3.646799806
cats_and_dogs_small/train,3.646799117
train-20news,3.646799117
train backpropagating,3.646799117
train ema,3.646799117
train curve,3.646799117
dense_1/add,3.646716011
@dense_1/add,3.646716011
folder structure,3.646153846
multigpu mode,3.645833333
sets entries,3.645833333
layers[num_layers,3.645394134
concatenate_1/concat,3.64527845
main problem,3.644999466
triplet case,3.644755245
default=get_json_type,3.644736842
--> 133         default=get_json_type,3.644736842
bidirectional wrapper,3.643107769
passes false,3.643034826
build functions,3.642714877
random selection,3.642694064
optimizer settings,3.64245614
thanksplease make,3.642424242
3 times slower,3.642276423
times slower,3.642276423
5 times slower,3.642276423
"0





# reshape image",3.64221317
300 real number,3.641821946
pickle-module,3.64153178
saving/loading,3.641127695
output_dim=layers[3],3.640764504
function `__call__`,3.64015236
evaluation results,3.640125392
2693             raise typeerror,3.639880952
raise typeerror,3.639880952
>     494                 raise typeerror,3.639880952
289       raise typeerror,3.639880952
701             raise typeerror,3.639880952
301       raise typeerror,3.639880952
edit layer,3.639168343
batch_index back,3.638983051
net = globalmaxpool2d,3.638888889
draws batches,3.638888889
build_fn=base_model,3.638554217
sgd = tf,3.638327935
"accuracy

    return",3.63796859
2074       raise valueerror,3.637778506
-> 1570     raise valueerror,3.637778506
raise valueerror,3.637778506
5655         raise valueerror,3.637778506
5588     raise valueerror,3.637778506
163                 raise valueerror,3.637778506
258         raise valueerror,3.637778506
526               raise valueerror,3.637778506
5286         raise valueerror,3.637778506
5219     raise valueerror,3.637778506
573             raise valueerror,3.637778506
576             raise valueerror,3.637778506
3155             raise valueerror,3.637778506
85     raise valueerror,3.637778506
241             raise valueerror,3.637778506
1023         raise valueerror,3.637778506
80         raise valueerror,3.637778506
218         raise valueerror,3.637778506
---> 37         raise valueerror,3.637778506
1342                 raise valueerror,3.637778506
231             raise valueerror,3.637778506
612     raise valueerror,3.637778506
2902             raise valueerror,3.637778506
---> 82         raise valueerror,3.637778506
method works,3.637777778
function [`to_categorical`],3.637667888
to_categorical function,3.637667888
tensor values,3.637372616
content type,3.637362637
unhashable type,3.637362637
@farizrahman4u,3.636363636
constant{0} [id,3.635854342
logic takes,3.635714286
quick question,3.635521886
set shuffle,3.635333546
`sample_weight` parameter,3.634847081
test samples,3.634709049
prototxt file,3.634436343
scale function,3.634421134
predicted values,3.63439347
# predicted values,3.63439347
summary utility,3.634177215
initial_state=initial_state_input,3.633333333
face_encoder = mobilenet,3.633333333
layer modified,3.633215962
virtual classes,3.633171913
output=wrapper,3.633120412
connection point,3.633012821
full filepath,3.632850242
net = dense,3.632625841
`trainable` option,3.632242424
vector<cntk,3.631882202
ascii files,3.631746032
vision_model = sequential,3.631595577
filter size 64,3.630852843
"api



likewise",3.630769231
target = wholesequence[1,3.629657228
binary list [1,3.629109682
output images,3.628734447
cudnngru cell,3.628571429
optimizer class,3.627963387
work correctly,3.627640845
pretty strange,3.627368421
`categorical_crossentropy `requires,3.627368421
activity_regularizer=regularizers,3.627350427
layers work,3.627201646
inputs=input_1,3.627094474
f1 score,3.627067669
build function,3.62698698
completely missing,3.626984127
official documentation,3.626666667
documentation shows,3.626666667
documentation formatting,3.626666667
understandable documentation,3.626666667
required information,3.626593807
model takes,3.626585482
lstm layer,3.626347831
layer lstm,3.626347831
`lstm` layer,3.626347831
properly read,3.625772038
results = cross_val_score,3.625771325
"on_batch_end

    callback",3.625714286
partial_captions = sequence,3.625690608
run `cifar10_cnn,3.625482625
get_input = lambda,3.625468165
weight_2 = lambda,3.625468165
"_gradientshelper

    lambda",3.625468165
imag_part = lambda,3.625468165
```ppi = lambda,3.625468165
"<lambda>

    grad_scope",3.625468165
"<lambda>

        grad_scope",3.625468165
lower_slices = lambda,3.625468165
upper_slices = lambda,3.625468165
# lower_slices = lambda,3.625468165
# upper_slices = lambda,3.625468165
outn = lambda,3.625468165
train_generator = gen,3.625108225
"```

q_approximator = create_model",3.625
q_approximator_fixed = create_model,3.625
multiprocessing makes,3.625
sw,3.625
cluster,3.625
_stop_event = multiprocessing,3.625
`intial_state=h0`,3.625
intial_state=h0,3.625
"[y4]

    [x3",3.625
"updates + training_updates

    962                 #",3.625
updates + training_updates +,3.625
unreleased resource,3.625
resource leak,3.625
1152] resource exhausted,3.625
numerical precision,3.625
"updates + training_updates

        #",3.625
measure weather,3.625
typical scenario,3.625
inside gates,3.625
model_broken = create_model,3.625
"updates + training_updates

            #",3.625
weights provided,3.624930478
gpu array,3.624309426
provided `model,3.623129261
target = target,3.62295082
opt,3.622807018
`opt,3.622807018
augment=true,3.622747903
activation areas,3.622393472
advanced activation,3.622393472
init = initializers,3.622222222
conv output,3.622155499
1415             use_multiprocessing=use_multiprocessing,3.621621622
2174                                                  use_multiprocessing=use_multiprocessing,3.621621622
1120                                         use_multiprocessing=use_multiprocessing,3.621621622
1154                                         use_multiprocessing=use_multiprocessing,3.621621622
wide range,3.621212121
prediction gap,3.621138211
re-load,3.621121121
layer_outs = func,3.620879121
batchnormalization layers,3.620394134
multiple workers,3.620166922
original goal,3.62012987
_search_1 = gru,3.61971831
gru_l = gru,3.61971831
score tensor,3.619520499
generator manner,3.619519095
embedding vector,3.619218501
as_ref=as_ref,3.619047619
@joelthchao mentioned,3.619047619
sequences shorter,3.619047619
include functionality,3.619047619
priority queue,3.619047619
validation_data=customsequence,3.618932039
input variable,3.618900368
embedding index,3.618768456
classes correctly,3.61829096
static axis,3.617741935
adam = adam,3.617391304
adam= adam,3.617391304
def predict_proba,3.617156016
generator = datagen,3.616921692
callbacks=[csv_logger,3.616600791
simply train,3.616496087
nxcxhxw format,3.616161616
nxcxwxh format,3.616161616
nchw format,3.616161616
readable  format,3.616161616
optimizer params,3.615916862
removing stopwords,3.615384615
/starnetiso {,3.615384615
network outputs,3.615384615
tf implementation,3.614980522
model0 = sequential,3.61492891
prediction works,3.614471545
call `datagen,3.614370782
code shows,3.614114114
gaussiannoise code,3.614114114
counting code,3.614114114
simplest code,3.614114114
code remains,3.614114114
poor code,3.614114114
492             // initialization code,3.614114114
standardization code,3.614114114
actual code,3.614114114
code typos,3.614114114
excluding code,3.614114114
"=0

    embedding_matrix = np",3.614053437
#NAME?,3.614053437
#NAME?,3.614053437
pretty narrow,3.614035088
`deserialize` function,3.613858364
encoded = dense,3.613736952
graph connections,3.613445378
/graph/pretrain_128px,3.613445378
graph disconnected,3.613445378
[bad-graph],3.613445378
graph=graph_1,3.613445378
graph=graph_2,3.613445378
gpuarray backend,3.613395639
error messages,3.613379558
decay=4e-5,3.613333333
decay=2e-5,3.613333333
decay ** num_updates,3.613333333
decay=decay_init,3.613333333
char information,3.612704918
logits = tf,3.612541993
198     void *workspace,3.612040134
ctc/log,3.611778846
multiprocessing = true,3.611384266
sparse miou,3.611111111
testy = create_dataset,3.611111111
"= 0

    n_symbols = rnn_x",3.611111111
py#l257,3.609225413
width = 48px,3.608695652
placeholder creation,3.608333333
temporal dataset,3.608134921
labels = y_train_cv,3.608108108
labels remains,3.608108108
labels= import_data,3.608108108
mutliple labels,3.608108108
informative labels,3.608108108
defined input,3.60763201
gpus uniquely,3.607142857
great tool,3.607142857
smaller gpus,3.607142857
generator method,3.606820682
"work

```



inside",3.606807512
modules work,3.606807512
"<module>

    exception_prefix=",3.606772422
high height,3.60619977
state dimension,3.606123072
ideal outcome,3.606060606
def conv_block,3.606044905
g2 = imagedatagenerator,3.605691057
g1 = imagedatagenerator,3.605691057
`metric improved,3.605485232
decoder side,3.605263158
testing phases,3.605263158
design suggestions,3.605263158
raise stopiteration,3.60515873
input_shape=data,3.605042017
properly initialized,3.604395604
call method,3.604269772
classified correctly,3.604166667
target tensor,3.60392824
input_dcc = layers,3.603727467
input_icc = layers,3.603727467
input_dobl = layers,3.603727467
input_iobl = layers,3.603727467
ratings = pd,3.603225806
similar functionality,3.603174603
`# arguments` section,3.603106126
re-direct,3.602693603
img = scipy,3.602625764
flattened tensors,3.602469136
5d tensors,3.602469136
embedding size,3.602344071
`response = add,3.602199882
45 pst valueerror,3.60206422
validation run,3.601673102
days ago,3.601503759
"1524         do_validation = false

   1525",3.601368159
td_concat/reshape,3.600265604
size_hidden_layer = size_hidden_layer,3.6
common practice,3.6
dies,3.6
limited amount,3.6
huge paragraph,3.6
casting elements,3.6
zoom transformation,3.6
strings,3.6
reduce_lr = reducelronplateau,3.6
possibly erroneous,3.6
"start

>     handler_func",3.6
y_train1[test_index],3.6
data_t=data_t1,3.6
data_x=data_x1,3.6
del,3.6
receptive field,3.6
secondary transformation,3.6
gaming laptop,3.6
insufficient elements,3.6
classify objects,3.6
simultaneously,3.6
intentionally limited,3.6
`on_train_begin` + `on_train_continue`,3.6
"start

    handler_func",3.6
model = load_model,3.599962105
model=load_model,3.599962105
`model = load_model,3.599962105
"```

model = load_model",3.599962105
----> 1 model=load_model,3.599962105
`model=load_model,3.599962105
``model = load_model,3.599962105
"load_model

    model",3.599962105
"load_model
    model",3.599962105
shape=<unknown>,3.599869876
unknown shape[0],3.599869876
"````

label =  np",3.599373461
label = 1 + np,3.599373461
train sequences,3.599180069
"0

_________________________________________________________________

train",3.599180069
re-implement,3.59912854
"}

val = sess",3.598883573
files = glob,3.598712999
`merge` layer,3.596638354
merge layer,3.596638354
mmap_mode parameter,3.596385542
error function,3.596285541
"tf

importerror",3.596208055
target sample,3.595259194
compare accuracies,3.595238095
references alexnet,3.595238095
roughness values,3.594919786
assert np,3.594202321
"np



assert",3.594202321
compute losses,3.59375
character lstm,3.593357093
create 3 iterators,3.593333333
create image_summaries,3.593333333
create prs,3.593333333
create/maintained,3.593333333
create placeholders,3.593333333
0 release notes,3.593073593
3 release notes],3.593073593
0 release notes],3.593073593
0-release-notes,3.593073593
weights = weight_com,3.592672414
transfering weights,3.592672414
weights correclty,3.592672414
storing weights,3.592672414
updates weights,3.592672414
weights = [char_weights],3.592672414
weights originated,3.592672414
weights=[embedding_weights],3.592672414
weights posterior,3.592672414
weights=embedding_weights,3.592672414
weights=lstm_weights,3.592672414
restores weights,3.592672414
weights=embedding_m,3.592672414
re-initialize,3.592592593
stateful states,3.592592593
forward states,3.592592593
tensor=probs_in,3.59245283
5d tensor,3.59245283
embedding dimension,3.59225394
json payloads,3.592105263
application/json,3.592105263
output values,3.592075285
"cnn

weightsfile =",3.591891892
cnn classifiers,3.591891892
"process_node

    layer",3.591549296
forward pass,3.591549296
decoder_embeddings layer,3.591549296
# pass instruction,3.591549296
"compute_output_shape

    output_shape[",3.591269841
batches = gen,3.591269841
reading images,3.591256367
large number,3.591226708
zy=rand,3.590909091
predict_classes schema,3.590909091
"epoch_counter += 1





 model",3.590871196
weight_com = model,3.590871196
model = deeplabv3,3.590871196
serialized model,3.590871196
encoder_decoder model,3.590871196
model=simple_cnn_network,3.590871196
expensive model,3.590871196
lrcn model,3.590871196
results_binary/model,3.590871196
resnet200v2 model,3.590871196
"0x118117dd8>

> 

> model",3.590871196
y_prediction = model,3.590871196
final_output = model,3.590871196
17     model = generate_model,3.590871196
model consists,3.590871196
model initialization,3.590871196
capable model,3.590871196
model = defmodel,3.590871196
application model,3.590871196
ordinary model,3.590871196
"```

model =  my_cnn_unet",3.590871196
replaces `model,3.590871196
test_acc = model,3.590871196
invoking model,3.590871196
sequence_autoencoder = model,3.590871196
decoder_model = model,3.590871196
model complexity,3.590871196
"get_weights_without_softargmax

    model",3.590871196
model retains,3.590871196
updates = model,3.590871196
persisted model,3.590871196
gradients_all = model,3.590871196
stateful* model,3.590871196
`gist2` model,3.590871196
nonstateful model,3.590871196
stateful model,3.590871196
test_scores = model,3.590871196
predicted_prob = model,3.590871196
#predicted_classes = model,3.590871196
critic model,3.590871196
"# layer3

        model",3.590871196
"# layer4

        model",3.590871196
model printout,3.590871196
seq_model = model,3.590871196
constructing model,3.590871196
rmodel = model,3.590871196
c3d model,3.590871196
resultant model,3.590871196
### model replication,3.590871196
"usual

model",3.590871196
"nn_model

    model",3.590871196
model comprises,3.590871196
model = kerasregressor,3.590871196
var_list=model,3.590871196
_another_ model,3.590871196
model constructors,3.590871196
model = read_model,3.590871196
`pred_y = model,3.590871196
"__init__

    **kwargs",3.589962536
code 3 times,3.58972387
evaluate api,3.589102564
5th epoch,3.588929001
u_regularizer = regularizers,3.588888889
"<module>

>     runfile",3.588590604
add `def,3.588244787
moving_variance_initializer=constant,3.588235294
4d tensors,3.588183422
inputs=base_model1,3.587878788
inputs=base_model2,3.587878788
inputs=input_sentence,3.587878788
inputs = get_source_inputs,3.587878788
inputs _x,3.587878788
inputs = [in_1,3.587878788
inputs=/input_3,3.587878788
"]

            inputs[perm] =",3.587878788
inputs = [actionplaceholder,3.587878788
inputs=[claims_input,3.587878788
transformed inputs,3.587878788
inputs=[query,3.587878788
inputs=[shared_input],3.587878788
heuristics based,3.587837838
big_model = sequential,3.587151132
output_dim=hidden,3.587037037
expected input,3.587010967
time actual_scales,3.586666667
properly happened,3.586538462
istraindataortest=true,3.586384266
show_shapes=true,3.586384266
support oss,3.586345382
dense cnn,3.585628844
output=predictions,3.584993337
tensor tensor,3.58490566
`images` variable,3.58443609
#discriminator attempts,3.583333333
net2 = tower_network,3.583333333
test2=test_generator,3.583333333
unwanted characters,3.583333333
"nasnetmobile

    default_size=224",3.583333333
`multi_gpu_model` makes,3.583333333
handled separately,3.583333333
train_transform = transforms,3.583333333
test doesn�,3.583088775
= 0 #batch index,3.583011691
batch index,3.583011691
"```

input0 = input",3.582709892
input3 = input,3.582709892
inputimg = input,3.582709892
"```



multi_filter_conv = input",3.582709892
input=multi_filter_conv,3.582709892
mainin=input,3.582709892
"#



input_array = input",3.582709892
inpt = input,3.582709892
qry = input,3.582709892
`conv_input = input,3.582709892
"`



`input_sequence = input",3.582709892
music_input = input,3.582709892
input=music_input,3.582709892
"```
    seq1=input",3.582709892
input=[seq1,3.582709892
class metrics,3.582476943
directory structure,3.581447964
239     op = _tfdevicecaptureop,3.581395349
`randomness op,3.581395349
`randomstreams` op,3.581395349
"input

<tf",3.581216797
"input

    <tf",3.581216797
#applied inplace,3.580952381
"```



test result",3.580797199
hdf5matrix dataset,3.580357143
exhausted iterator,3.578947368
adhoc things,3.578947368
mylayerhello guys,3.578947368
/temp/temp,3.578947368
outputs = [layer,3.578728783
source   keras_activate,3.578431373
end = [lambda,3.578298353
pass parameters,3.578215962
4d tensor,3.578167116
tensor 4d,3.578167116
lower case *,3.578088578
validation part,3.577694236
model parameters,3.577537863
running fine,3.577156015
encoding part,3.576659039
dense_1/relu,3.576261095
network code,3.575652576
straightaway created,3.575342466
axeli created,3.575342466
normal function,3.575330225
imgur image,3.575280899
related callback,3.57518797
31   int return_value = 0,3.575
individual chunks,3.575
function doesn,3.574860006
"[data]

attributeerror",3.574819401
default environment,3.574736842
test =  custom_loss,3.574468085
"6]

test_spec = test[",3.574468085
test consisted,3.574468085
timestep inside,3.574324324
main path,3.574074074
`seed` parameter,3.57386302
45 pst str,3.573598131
label = tf,3.573570519
hidden units,3.573188406
# 256 hidden units,3.573188406
10 hidden units,3.573188406
output 28 features,3.572913075
distance = lambda,3.572836586
checking model,3.572689378
images = np,3.572555462
f2_base = inceptionv3,3.572463768
similar results,3.572304324
input arguments,3.57178093
"input

    331         # arguments",3.57178093
5 dimension features,3.571520288
completely confident,3.571428571
completely baffled,3.571428571
shift,3.571428571
reproducibility,3.571428571
program crash,3.571428571
timing variance,3.571428571
"300000]



y_trainhot = to_categorical",3.571428571
y_testhot = to_categorical,3.571428571
real kld,3.571428571
datatype float16,3.571428571
"raise_with_op

    reraise",3.571428571
"variance

        var_true =",3.571428571
inline comments,3.571428571
windows ~1300s,3.571428571
word_train_label = nnu,3.571428571
windows 10_64x,3.571428571
invalid loss,3.570688605
api suggestion,3.57016317
starting point,3.570075758
use_bias=true,3.5697176
simple explain,3.569444444
shared weights,3.5694166
"```

m1 = load_model",3.569090909
submodel unchanged,3.568421053
output=prediction,3.568293711
�positive float�,3.568215892
model replica,3.567882691
"cbks

  file",3.567769677
pad sequences,3.567765568
expected behaviour,3.567519466
target size,3.567328253
w2=pickle,3.567226891
#NAME?,3.567136843
wrong gradient,3.567073171
======================== code end =======================,3.566944303
debugging data,3.56684492
decoder network,3.566801619
train time,3.566799117
platform,3.566666667
masked positions,3.566666667
production system,3.566666667
"bias_f

                x_c =",3.566666667
"b_f

                x_c =",3.566666667
batch size,3.566587306
16 batch size,3.566587306
batch size 1,3.566587306
batch size = 256,3.566587306
batch size = 1,3.566587306
batch size = 10,3.566587306
[batch size,3.566587306
batch size = 8,3.566587306
flow_from_csv function,3.566239316
`get_file` function,3.566239316
correct values,3.566231262
img_data = np,3.565976514
dot files,3.56577381
full range,3.565656566
"start

>     super",3.565517241
"start

    super",3.565517241
"replace 



tf",3.565173572
initializer=initializers,3.564298725
maxlen = predictions,3.563644289
target_names=list,3.563535912
"mailing list

3",3.563535912
optimizer = rmsprop,3.563508772
optimizer=rmsprop,3.563508772
state variable,3.563217503
simply create,3.563030303
"# arguments

        fn",3.562714449
generators internally,3.5625
identical problems,3.5625
returns arrays,3.562366358
layer type,3.562245266
label outputs,3.5622431
25% test accuracy,3.562091847
test accuracy,3.562091847
"10602876026708943

test accuracy",3.562091847
"33912858131

test accuracy",3.562091847
"916401538048

test accuracy",3.562091847
"16087053345

test accuracy",3.562091847
"20714796219

test accuracy",3.562091847
"081773182778

test accuracy",3.562091847
"0769035610346

test accuracy",3.562091847
5% test accuracy,3.562091847
previous 10 000 timesteps,3.561904762
properly indent,3.561538462
properly reconstruct,3.561538462
default image_generator=,3.561403509
encode layer,3.561246265
produce data,3.560784314
"build

    batch_sizes = [",3.560747664
stalled build,3.560747664
build/bdist,3.560747664
`maxpooling1d` layers,3.560716714
actual samples,3.560240964
samples // training_batch_size,3.560240964
samples // validation_batch_size,3.560240964
"samples

d_samples = 200  #",3.560240964
unmasked samples,3.560240964
"```

conv1 = leakyrelu",3.560096154
output_tensor = m1,3.56
"0x7feb3d2bd590>]

>>> m1",3.56
kl-div,3.56
skipvalidate=false,3.559701493
output losses,3.559655499
probability values,3.5592055
correct predictions,3.559149313
"data

print",3.559048734
input_layer = input,3.558900368
input = input_layer,3.558900368
slow compared,3.558823529
target output,3.558630909
timeseries lstm,3.558608059
layers **[ concat,3.558529727
variable length,3.55827883
proper max_queue_size,3.558064516
good results,3.55795756
batch output,3.557889963
dropout layers,3.557750456
word random,3.557529229
summaries similarly,3.555555556
accept fixed,3.555555556
xtest = day3,3.555555556
3 approaches yielded,3.555555556
output2 = make_encoder,3.555555556
image_size=default_image_size,3.555555556
missing somehting,3.555555556
missing spaces,3.555555556
cat sat,3.555555556
val loss,3.555537089
embedding dictionary,3.554824561
input=base_model,3.554597442
m2 = load_model,3.554545455
"return loss

```",3.554366765
return loss`,3.554366765
network weights,3.554210875
network + weights,3.554210875
compute metric,3.553401899
"0195



binary accuracy",3.553197533
--> 146                 return cls,3.55294223
-> 1268         return cls,3.55294223
142                 return cls,3.55294223
146                 return cls,3.55294223
return cls,3.55294223
137                 return cls,3.55294223
141                 return cls,3.55294223
pickle safe,3.552941176
--> 754                             dtype=dtypes,3.552918288
-> 1075                             dtype=dtypes,3.552918288
end-start,3.552830189
fall end,3.552830189
amazing wrapper,3.552631579
functions stddev,3.552555448
"request

---------

change",3.552495697
change request,3.552495697
standard approach,3.552429668
network model,3.552409658
"```

class radial",3.552173913
prediction results,3.552172694
auto encoder,3.552123552
matrix gestures,3.551807229
return x_test,3.551728911
train set,3.551363432
state = np,3.551336875
remaining axis,3.551075269
explicitly print,3.550645373
lambda layer,3.550350794
`lambda` layer,3.550350794
return model_input,3.550344828
"return input_mask

```",3.550344828
save checkpoints,3.550086356
train = pd,3.550024923
distributions graphs,3.55
initializing mobilenet,3.55
layer instance,3.549882629
#NAME?,3.549882629
elegant implementation,3.54980695
binary_crossentropy api,3.54968815
output tensors,3.549624635
hyperparameters configuration,3.549019608
updated values,3.54862349
"fold

history = []",3.548534799
images selected,3.548245614
10 hydrangea images,3.548245614
threshold=np,3.548119371
vector<int,3.547727273
lstm structure,3.547619048
w2=mdl,3.547619048
lib,3.547008547
lib &,3.547008547
0-gpu-py3,3.546760481
py runs,3.546725413
"convolution

588 // implementations",3.546666667
true samples,3.54662523
length = np,3.546398201
pred-true,3.546384266
read images,3.545812524
read {} images,3.545812524
create sequences,3.545714286
h5py/h5g,3.545454545
preds = smlayer,3.545454545
"0x7feaceb651d0>]

>>> m2",3.545454545
m2 = u_net,3.545454545
embedding_weights = loaded_model,3.545454545
lstm_weights = loaded_model,3.545454545
experiencing memoryerror,3.545454545
199     cudnnconvolutionfwdalgo_t chosen_algo,3.545454545
chosen_algo == cudnn_convolution_fwd_algo_fft,3.545454545
362          chosen_algo == cudnn_convolution_fwd_algo_fft_tiling,3.545454545
predicted size,3.545326527
def expand_dims,3.545260591
operation `tf,3.545173572
longer time,3.545
gru-layer,3.544600939
positive_vect = base_network,3.543478261
negative_vect = base_network,3.543478261
query_embedding = base_network,3.543478261
positive_embedding = base_network,3.543478261
negative_embedding = base_network,3.543478261
ind + 1 == steps_per_epoch,3.543103448
dropout rate,3.542911877
dropout rate=0,3.542911877
implement cnn,3.542872284
# skip header,3.542857143
leverage cudnn,3.542553191
action tensor,3.54245283
correct prediction,3.542449687
[api issue],3.54217274
yield np,3.542040344
optimizer function,3.54202879
"main

    validation_split=0",3.541910331
results = batch,3.541768946
discouraging people,3.541666667
trainpredict = scaler,3.541666667
`has_inf_or_nan` filter,3.541666667
has_inf_or_nan filter,3.541666667
random_state=random_seed,3.541666667
namehello people,3.541666667
function returns,3.541649152
train-docs,3.541535959
input_=input,3.541043225
input_ = input,3.541043225
main issue,3.541033138
"```



main issue",3.541033138
data order,3.540870894
data_format parameter,3.540829987
constant sequences,3.540616246
elemwise{maximum,3.540540541
elemwise{maximum}[,3.540540541
[[elemwise{maximum,3.540540541
inputs=[sequences,3.54025974
conv = tf,3.540173572
categorical variable,3.540066445
validation_split * data,3.539731682
sample size,3.539636627
sample size 10,3.539636627
sample size 12,3.539636627
output tensor,3.53960833
128 encoder = lstm,3.539303039
encoder = lstm,3.539303039
encoder lstm,3.539303039
research,3.538461538
sample_weight=train_weight,3.538461538
connection broken,3.538461538
requirement arose,3.538461538
//research,3.538461538
model = get_model,3.538239617
computing map,3.537634409
setting ```os,3.537588652
input1 = input,3.53673288
"```

input1 = input",3.53673288
"```

        input1 = input",3.53673288
predicted output,3.536629184
"]

    return x1",3.53630974
xs = paths_to_tensor,3.535714286
decoded = decoder_model,3.535714286
takes care,3.535714286
"validation_data

regr",3.535598706
probability prediction,3.535423926
proposed change,3.534638554
`init=customconstraint,3.533333333
init_func=init,3.533333333
thread thread-9,3.533333333
init=init_type_name,3.533333333
init=my_init,3.533333333
dataset variable,3.533214286
logger = csvlogger,3.532467532
input format,3.532204841
loss argument,3.531928915
d2 = tf,3.531840239
saved/loaded,3.531746032
insert activations,3.53125
�evaluate_generator� function,3.530525031
memory error,3.530046225
error relates,3.530046225
typical error,3.530046225
squaed error,3.530046225
reconstruction error,3.530046225
error disappears,3.530046225
arises error,3.530046225
error-prone,3.530046225
sqaured error,3.530046225
error accures,3.530046225
error persisted,3.530046225
error quoted,3.530046225
friendly error,3.530046225
error attributed,3.530046225
error blew,3.530046225
error occured,3.530046225
memory error`,3.530046225
#modify variance,3.529761905
left side,3.529411765
outputs=conv,3.528846154
conv2 = leakyrelu,3.528846154
cpu skylake,3.52866242
data file,3.52855399
compute output,3.528405499
train images,3.528378064
1000 train images,3.528378064
model compilation,3.528371196
graphviz version 2,3.528328612
deployed version,3.528328612
encode character,3.528255528
dtype=int,3.527918288
erroneous behavior,3.527777778
desired behavior,3.527777778
unspecified behavior,3.527777778
special reason,3.527777778
2d convolutions,3.527777778
train_generator = datagen,3.527272727
code snippet,3.527157592
"`



code snippet",3.527157592
state = tf,3.525533933
202             scale /= max,3.525324675
--> 204             scale /= max,3.525324675
nb_epoch=num_epochs,3.525252525
invalid shape,3.525157233
system breaks,3.525
layer lstm_layer,3.524882629
bilstm layer,3.524882629
temp directory,3.524767802
>     batch_x = np,3.524309848
interpolation=cv2,3.524234694
creating model,3.52420453
"``

``labels = input",3.524151333
"`

`labels = input",3.524151333
labels = input,3.524151333
mask parameter,3.523351834
# build network,3.522286125
1st epoch,3.522262335
simply loading,3.521935776
huge columns,3.52173913
explanatory comment,3.52173913
### compare weights,3.521243842
solution proposed,3.521226415
"cifar10



    img_rows",3.520879121
outputs=d2,3.520512821
freezing layers,3.520394134
time frame,3.52
start = time,3.52
output vector,3.519882772
output vector `,3.519882772
replace gru,3.51971831
tensorboard model,3.519442625
output metric,3.519307398
output = metric,3.519307398
"* batch_size

```



consequentially",3.518472906
num_val_samples/batch_size,3.518472906
train_labels_len // batch_size,3.518472906
valid_labels_len // batch_size,3.518472906
batch_size/ngpus,3.518472906
batch_size=nr_batch,3.518472906
capacity=2000 + 3 * batch_size,3.518472906
batch_size/max_word_length,3.518472906
batch_size=batch_size_init,3.518472906
get_config method,3.518357488
augment images,3.517942584
raise runtimeerror,3.517857143
8     raise runtimeerror,3.517857143
def relu,3.517789871
automatic script,3.517766497
"maxt]

            yield",3.517730496
yield batch_features,3.517730496
x_train = preprocess_input,3.517699115
conv1d layers,3.517585145
layer weights,3.517555043
weights = layer,3.517555043
gpu workers,3.517520715
conv3 = leakyrelu,3.517482517
features = np,3.51673409
"run_code

>     exec",3.516666667
"run_code

    exec",3.516666667
google group],3.516666667
overwrite=true,3.515796031
"layer

model",3.515753825
"layer # # #

    model",3.515753825
"layer    # # #

    model",3.515753825
layer = model,3.515753825
weights=[embedding_matrix],3.515749337
log message,3.515625
center loss,3.515133049
avoid logger,3.514285714
minimum probability,3.514285714
probability distributions,3.514285714
generates batches,3.513888889
10 fold faster,3.512820513
anchor-negative,3.512605042
"fit_generator

    callbacks",3.511847676
size <size,3.511705686
equivalent cell,3.511688312
embedding = tf,3.5116648
hyperparameters values,3.511586453
values=x_values,3.511586453
ran cifar10_cnn,3.511520737
"```

# alternative method",3.511111111
[list] section,3.510904333
default format,3.510898458
input_length=num_embed_cols,3.510869565
input_length=max_length,3.510869565
input_length=max_review_length,3.510869565
context window,3.510775862
maxpooling2d layers,3.510617598
output_dim=params[,3.510497759
values = tf,3.510093358
wholesequence = np,3.509158332
start small,3.509090909
temp_model = load_model,3.509090909
normal distribution,3.509090909
normal behavous,3.509090909
1892                 variance=var,3.508928571
input/weights,3.508715639
memory doesn,3.50862069
cnn = timedistributed,3.508558559
10 cnn = timedistributed,3.508558559
default graph,3.50818222
computation graph,3.50818222
provided optimizer,3.508047538
validation_steps=batch_size,3.507946591
works apparently,3.507619048
fixed matrix,3.507362784
api bug,3.507312441
"work

        return",3.507152339
bidirectional rnns,3.507142857
# model input,3.506914422
model input,3.506914422
stranger result,3.506329114
"worker

    result =",3.506329114
result = preprocessimage,3.506329114
"worker

>     result =",3.506329114
bad result,3.506329114
desired result,3.506329114
downsampled result,3.506329114
poor result,3.506329114
`test_data` argument,3.506285355
dtype=dtype,3.505836576
414                             dtype=dtype,3.505836576
397                             dtype=dtype,3.505836576
--> 212                                     dtype=dtype,3.505836576
199           dtype=dtype,3.505836576
imagenet contest,3.505494505
concatenate function,3.504595481
easily train,3.503941974
``inputs = input,3.503922013
inputs = input,3.503922013
`inputs = input,3.503922013
inputs=[input],3.503922013
inputs=input,3.503922013
#inputs = input,3.503922013
input=inputs,3.503922013
"225



inputs = input",3.503922013
"```
inputs = input",3.503922013
predicted probability,3.503759398
limited number,3.503726708
output size,3.503008342
code raises,3.503003003
line 31 specifically,3.502570115
"0]

target = np",3.502451924
validation_data = test_set,3.502265372
small weights,3.501763323
y1 = layers,3.501163365
loss parameter,3.50040748
"__exit__

    c_api",3.5
converting,3.5
constantly repeating,3.5
inception_feature_get = get_input,3.5
weight_gru2 = weight_2,3.5
=user_matrix[user_input,3.5
conv5 = conv2drelubatchnorm,3.5
major,3.5
easy implemention,3.5
q_values = q_approximator_fixed,3.5
h_decoded = decoder_h,3.5
nepoch %05d,3.5
1406         output_shapes=nest,3.5
sub_model1 = get_sub_model,3.5
filename_col specifies,3.5
fy=y_change,3.5
"query



patternzero =",3.5
y_testros = ros,3.5
--> 286     current_device = devicespec,3.5
fly,3.5
dima * dimb,3.5
x_transpose_a = transpose_conv,3.5
x_transpose_b = transpose_conv,3.5
increasing relevance,3.5
authors claim,3.5
pos_embed_1 = position_layer_1,3.5
pos_embed_2 = position_layer_2,3.5
optimal experience,3.5
worked flawlessly,3.5
relationship seams,3.5
xi = genx1,3.5
shared_conv_layer_a = shared_conv,3.5
shared_conv_layer_b = shared_conv,3.5
shared_conv_layer_c = shared_conv,3.5
enc_c = enclstm,3.5
pseudo_attention_input = dectd,3.5
tensor_shape,3.5
_ones = _generate_dropout_ones,3.5
verify_shape=verify_shape,3.5
compared fairly,3.5
"128





ds_gen = fa",3.5
supposedly addressed,3.5
unzip cdn-0*,3.5
"train_one_step

    loss_a =",3.5
autoencoder_a = kerasmodel,3.5
max_value = _to_tensor,3.5
fuse_output = ss,3.5
train_or_validation=which_val_data,3.5
input_dim= n_symbols,3.5
ps-adobe-3,3.5
procset graphviz 0 0,3.5
ps-interpreters,3.5
n0 0 1 beginpage,3.5
3 128         block1_conv1[0][0]                ______________________________________________________________________________________,3.5
xtrain = day1,3.5
pred_data_transpose = pred_data,3.5
yoshua bengio,3.5
channel_out = gaussiannoise,3.5
included glove,3.5
"dispatch_shell

>     handler",3.5
overfit thereon,3.5
input_noised = gaussiannoise,3.5
sat nov 25 00,3.5
> mod = gensim,3.5
ctx->mem_s,3.5
img_pred = kernel_2d,3.5
s1=sg1,3.5
desired amount,3.5
meta-monitoring,3.5
lstm_imbd,3.5
swap,3.5
train_x1 = train_x1,3.5
continuously push,3.5
"sipy-pc

2017-10-30 21",3.5
frequently,3.5
visually inspect,3.5
block5_conv1 = get_nontrainable_model,3.5
layer_conv2d_1_dcc = layer_conv2d_1_shared_cc,3.5
layer_conv2d_2_dcc = layer_conv2d_2_shared_cc,3.5
layer_conv2d_3_dcc = layer_conv2d_3_shared_cc,3.5
layer_conv2d_4_dcc = layer_conv2d_4_shared_cc,3.5
layer_conv2d_1_icc = layer_conv2d_1_shared_cc,3.5
layer_conv2d_2_icc = layer_conv2d_2_shared_cc,3.5
layer_conv2d_3_icc = layer_conv2d_3_shared_cc,3.5
layer_conv2d_4_icc = layer_conv2d_4_shared_cc,3.5
layer_conv2d_1_dobl = layer_conv2d_1_shared_obl,3.5
layer_conv2d_2_dobl = layer_conv2d_2_shared_obl,3.5
layer_conv2d_3_dobl = layer_conv2d_3_shared_obl,3.5
layer_conv2d_4_dobl = layer_conv2d_4_shared_obl,3.5
layer_conv2d_1_iobl = layer_conv2d_1_shared_obl,3.5
layer_conv2d_2_iobl = layer_conv2d_2_shared_obl,3.5
layer_conv2d_3_iobl = layer_conv2d_3_shared_obl,3.5
layer_conv2d_4_iobl = layer_conv2d_4_shared_obl,3.5
program saves,3.5
dirpath = imagepath +,3.5
extensive refactoring,3.5
imagenet_models/resnet50_weights_th_dim_ordering_th_kernels,3.5
**_question 3_**,3.5
numberofrows*numberofcolumns,3.5
"returna=[]

            returnb=[]",3.5
cylindrical problems,3.5
tho accomplish,3.5
"batch_set_value

    assign_op =",3.5
multiclasses versus,3.5
"output_length}

output_dict = {",3.5
b_skip_idxs = ctc_create_skip_idxs,3.5
"+ common_factor

    log_p_next =",3.5
"log_p_next



**_you",3.5
magnitude smaller,3.5
stack1_tensor = stack1_layer,3.5
stack2_tensor = stack2_layer,3.5
fly**,3.5
/articles/,3.5
algo_bwd_filter=deterministic,3.5
algo_bwd_data=deterministic,3.5
train_features = vgg_16,3.5
val_features = vgg_16,3.5
song spectrograms,3.5
fan_in + fan_out,3.5
carnd,3.5
w_ci * c_t-1,3.5
oldweights = modelorig,3.5
blindly trusted,3.5
final chunk,3.5
y_full = full_set,3.5
[untitled diagram],3.5
"logical



stats",3.5
vertical slices,3.5
crashing experiment,3.5
#embedding_vec=embeddinglayer,3.5
articles,3.5
prun224/1/img1021a,3.5
kindly assist,3.5
list_classes_test = load_data_from_file,3.5
# count_vect = countvectorizer,3.5
154                          cudandarray *om,3.5
247           cudnnconvolutionfwdalgoperf_t choosen_algo_perf,3.5
371       cudnndatatype_t data_type,3.5
class_imgs = defaultdict,3.5
partly ignoring,3.5
recommend `stateful`,3.5
training_epochs=training_epochs,3.5
blindly [resetting,3.5
"1430us  cudevicegetcount

  0",3.5
dt_i = shuffled_dates[,3.5
input_checkpoint=checkpoint_path,3.5
output_graph=output_frozen_graph_name,3.5
metric_result = masked_metric_fn,3.5
word_traintokenint = mapvalues,3.5
word_testtokenint = mapvalues,3.5
char_traintokenint = mapvaluescharlevel,3.5
char_testtokenint = mapvaluescharlevel,3.5
/datalogai/recurrentshop,3.5
"dispatch_shell

    handler",3.5
shows warning,3.5
cv iterators,3.5
careful orchestrating,3.5
encoding_1=embeddeding,3.5
encoding_2=embeddeding,3.5
blonde girl,3.5
extra array,3.499771167
"class

classes = [",3.49963154
load/save_model,3.498613999
mdl = tf,3.498506906
extract frames,3.497252747
set weights,3.497236729
output shapes,3.497155499
/output shapes,3.497155499
"`output`

          encodes",3.497155499
label masks,3.496632241
"high



epoch 1/20",3.496621309
metrics function,3.496542347
configuration code,3.496467055
validation-split,3.496279762
"2d-filters

361",3.495614035
model2 = load_model,3.495577396
dataset = tf,3.495530715
set `model,3.495435512
variable tensor,3.495309973
large loop,3.495192308
resulting loss,3.494931029
multi_gpu case,3.494755245
output=output,3.494310999
prediction2 = dense,3.493736952
decoder_h = dense,3.493736952
decoder_mean = dense,3.493736952
out_style = dense,3.493736952
smlayer = dense,3.493736952
shareddense = dense,3.493736952
p_output = dense,3.493736952
dense_out = dense,3.493736952
reshape=false,3.49330043
great wrapper,3.493107769
output dimension,3.492918211
`features = raw_dataset_train,3.492424242
on_epoch_end function,3.492165242
outputs=predictions,3.491683992
multilabel problem,3.491560313
"size_hidden_layer



        np",3.490976514
y_train1 = np,3.490976514
word_test_label = np,3.490976514
predicted = lstm,3.490938886
features = tf,3.490931148
csv [signal_class,3.490909091
training_set = train_generator,3.490909091
cnnmodel = sequential,3.48992891
kernel size,3.489797797
dict,3.489795918
dict `{0,3.489795918
images/labels,3.489687055
notebook [https,3.489490161
bounding boxes,3.489285714
unroll type,3.489214489
code generates,3.489114114
pr thread,3.488888889
glorot_normal **initializers**,3.488888889
red frame,3.488888889
gpudnnconv{algo=,3.488636364
[[gpudnnconv{algo=,3.488636364
layer list,3.488418541
steps=batches,3.488351254
processed_b = base_network,3.487922705
re-run,3.487916488
subset accuracy,3.487623762
weigted accuracy,3.487623762
accuracy plots,3.487623762
wronf accuracy,3.487623762
achieves 100% accuracy,3.487623762
main_input = input,3.487471797
anchor = input,3.487471797
input depends,3.487471797
"```

main_input = input",3.487471797
`main_input = input,3.487471797
input=main_input,3.487471797
re-open,3.487278583
model_1,3.487179487
>>> model_1,3.487179487
`model_1`,3.487179487
added subset,3.487179487
probability vector,3.487012987
continue train,3.486799117
show_layer_names=true,3.486384266
keep_dims=true,3.486384266
borrow=true,3.486384266
write_graph=true,3.486384266
194             return_times=true,3.486384266
fast_mode=true,3.486384266
add_image_summaries=true,3.486384266
quick fix,3.486166008
loss functions,3.485989151
kernel_constraint=constr,3.485714286
class collectavg,3.485507246
"autoencoder

parallel_autoencoder",3.484848485
o2 = layer2,3.484848485
simple check,3.484645449
### check box,3.484645449
anchor-positive,3.48447205
"funcs]

  file",3.484436343
kernel constraints,3.483944954
"kernel

240         // shapes",3.483944954
conv2d_1/kernel,3.483944954
--> 575     return _wrapfunc,3.483678161
return list_items,3.483678161
prediction + epsilon,3.483638211
11 emotion labels,3.483108108
main idea,3.482962963
``conv2dtranspose`` infers,3.482758621
transpose_conv = conv2dtranspose,3.482758621
ct_1_1 = conv2dtranspose,3.482758621
accident `conv2dtranspose`,3.482758621
gen[0] # error,3.482427177
compile=false,3.481991881
word**_,3.481908336
returned sequences,3.481792717
future data,3.481617647
classify images,3.481578947
build time,3.480747664
predicted = np,3.480450198
command np,3.480450198
gradients,3.480392157
gradients[,3.480392157
+ gradients[,3.480392157
] = gradients[,3.480392157
`inf` tensor,3.47995283
implementation error,3.479853175
ignore label,3.479825518
"exists starting

140",3.47979798
resultfinal = model,3.479760085
encoded = flatten,3.479649123
"network



x_train",3.479237577
"fc_load

typeerror",3.479166667
pain-point,3.479166667
installation point,3.479166667
mode=nanguardmode,3.479166667
line yields,3.478531653
test loss,3.478490023
"9755

test loss",3.478490023
"9772

test loss",3.478490023
"multi_gpu_test_simple_model

>     parallel_model",3.47826087
output results,3.478189982
seed=seed_val,3.477477477
kinda weird,3.477272727
correct size,3.477164318
train dataset,3.47715626
"_check_num_samples

valueerror",3.47706422
"array_concatenate

valueerror",3.47706422
freeze/checkpoint,3.476761619
/freeze/checkpoint,3.476761619
hidden2=shared,3.476744186
"predict

    return",3.476431784
input samples,3.476284189
"input



```

>>> m1",3.476043225
"7]]

x_test = test[",3.475852168
optimizer = optimiz,3.475789474
smorms3 optimizer,3.475789474
optimizer=fast_compile,3.475789474
specific optimizer,3.475789474
optimizer=sgd_ema,3.475789474
optimizer=adadelta_ema,3.475789474
optimizer=nonstateful_optimizer,3.475789474
optimizer=stateful_optimizer,3.475789474
optimizer=_optimizer,3.475789474
optimizer=multilradam,3.475789474
yourmsprop optimizer,3.475789474
times due,3.475609756
initializer=functools,3.475409836
returns inverse,3.475409836
character mapping,3.475225225
outputs=prediction,3.474984365
2nd epoch,3.474643287
metric history,3.474532851
test sentence,3.474468085
fed directly,3.474184783
train score,3.473866786
_address = reader,3.473684211
"```

tokenizer = tokenizer",3.473684211
requests,3.473684211
tokenizer = tokenizer,3.473684211
encoded = conv2d,3.473191489
batches = get_batches,3.472222222
] pr introducing,3.472222222
total loss,3.472203756
total number,3.471908526
target device,3.471852768
missing input,3.471598781
decoder architecture,3.4709348
loss function,3.470261254
loss function**,3.470261254
# loss function,3.470261254
simply embeds,3.46969697
inputs images,3.469457735
fed back,3.469417833
comment section,3.469107551
calculate np,3.468754292
tensor object,3.468509168
gpu lead,3.467395401
compiled correctly,3.466911765
y_train1[train_index],3.466666667
approximately divided,3.466666667
thread-safe,3.466666667
appears restricted,3.466666667
outputs=predicts,3.466346154
{model_dir}/{version}/{,3.465828612
max doesn,3.465763547
on_batch_end=lambda,3.465468165
return len,3.465413321
parameter `validation_data`,3.465317581
parameter validation_data,3.465317581
working perfecly,3.464646465
stack-distances,3.464285714
evaluate_generator executions,3.464285714
specific sentences,3.464285714
dictionary size,3.464186176
index= np,3.463253742
checkweight = modelcheckpoint,3.462962963
big number,3.462550237
generator = data_generator,3.462376238
npy files,3.462155388
neighbouring words,3.461538462
` surrounding words,3.461538462
1416             shuffle=shuffle,3.461538462
common words,3.461538462
shuffle=shuffle,3.461538462
aaron courville,3.461538462
network = max_pool_2d,3.461538462
network today,3.461538462
1155                                         shuffle=shuffle,3.461538462
10358 uniques words,3.461538462
network wouldn,3.461538462
662                               shuffle=shuffle,3.461538462
"input



```

>>> m2",3.461497771
probability output,3.461441214
return [input_shape,3.461269197
return input_shape[0],3.461269197
`data = pad_sequences,3.460784314
matrix doesn,3.460427919
significant variance,3.46031746
theano background,3.459864205
"constructed

tensor",3.459119497
test cases,3.45908347
[test cases],3.45908347
define 2 groups,3.458773784
bidirectional lstm,3.458608059
learn,3.458333333
complicated scenario,3.458333333
modify `locallyconnected2d`,3.458333333
weird results,3.45830721
"machine

gpu_list = []",3.457364341
introduce field,3.457142857
"]

]



longest_sequence = max",3.457142857
word_maximal_value_a = max,3.457142857
word_maximal_value_b = max,3.457142857
`grads = normalize,3.456730769
model architecture,3.456542838
simple relu,3.456189411
temp = mapfull[,3.456140351
implementation result,3.456136064
convert object,3.456056338
similar code,3.455383955
bitwise module,3.455257271
preprocessing_function=preprocess_image,3.454545455
failure makes,3.454545455
preprocessing_function = preprocess_input,3.454545455
"```



wrapping preprocessing_function",3.454545455
preprocessing_function=processing_function,3.454545455
direct vfd,3.454545455
unet pools,3.454545455
actual execution,3.454545455
input requirement,3.454504764
input1->output1,3.454022989
defined generator,3.453965023
outputs=output_layer,3.453846154
"<module>                                                                                                                       

    tf",3.453764176
question/improvement,3.453703704
categorical format,3.453370918
common_runtime,3.453125
input_data = np,3.452881276
action variable,3.452857143
return err,3.452670409
gen = timeseriesgenerator,3.452380952
"0         

_________________________________________________________________

flatten_2",3.452380952
"264192    

_________________________________________________________________

softmax_output",3.452380952
"36928     

_________________________________________________________________

max_pooling2d_2",3.452380952
"16220     

_________________________________________________________________

pool2",3.452380952
"5410      

_________________________________________________________________

conv5",3.452380952
"5420      

_________________________________________________________________

pool5",3.452380952
"0         

_________________________________________________________________

conv6",3.452380952
"16230     

_________________________________________________________________

pool6",3.452380952
"128       

_________________________________________________________________

secondlstm",3.452380952
"```

    tgen = gen",3.452380952
allowing compatibility,3.452380952
serialization information,3.451990632
good measure,3.451923077
e1 matrix,3.451807229
matrix wyh,3.451807229
monitoring performance,3.451612903
maxlen=maxlen,3.451612903
feature dimensions,3.451229576
previous epoch,3.450833763
call np,3.450801842
"ignore

                elif",3.45021645
--> 482     return array,3.450115995
class_weight = class_weight_for_training,3.45
net_positive = resnet_model,3.45
net_negative = resnet_model,3.45
class_weight=classweight,3.45
class_weight=class_weight_train,3.45
trouble implementing,3.45
easy implementation,3.44980695
implementation=2 trains,3.44980695
# resulting shape,3.449399657
resulting shape,3.449399657
input=init,3.449376559
optimizer= sgd,3.448943836
optimizer=sgd,3.448943836
sgd optimizer,3.448943836
optimizer = sgd,3.448943836
expected model_2,3.44874552
lstm output,3.448620701
train_or_validation][str,3.448598131
"standardize_input_data

    str",3.448598131
] = prefix_output_node_names_of_final_network+str,3.448598131
multithreaded context,3.448275862
calling `model,3.448014053
calling model,3.448014053
upper model,3.448014053
activations meant,3.447916667
float tensor,3.447625244
code straight,3.447447447
cen = sess,3.447368421
loss_val=sess,3.447368421
negative dimensions,3.447200567
"negative dimensions

2017-07-11 03",3.447200567
output=main_output,3.447155499
"train folder

#",3.446799117
conv-pool,3.446428571
outputs=tensor,3.446298984
compilation doesn,3.44612069
compiled separately,3.446078431
weights = pickle,3.44561359
dense matrix,3.445544181
convlstm2d layer,3.444882629
issue represents,3.444736842
return z_mean +,3.444462475
train_iter = train_gen,3.444444444
safety reasons,3.444444444
center-cropped,3.444444444
elegant method,3.444444444
`on_train_begin` method,3.444444444
ytrain = day2,3.444444444
common reasons,3.444444444
half-floats,3.444444444
form `loss_function,3.444444444
permute pattern [0,3.444444444
1x1 convolutions,3.444444444
"`

`gen_submission_test_batches = idg_sub",3.444444444
dilated convolutions],3.444444444
grouped convolutions,3.444444444
dtype=np,3.443894802
dtype = np,3.443894802
separate bug,3.443209877
encoder-decoder,3.443100996
error occurred,3.443089703
secde = sequential,3.441851987
30   int default_str = 1,3.441666667
feel weird,3.441558442
negative distances,3.441176471
layer indices,3.441011661
softmax_weights = np,3.440976514
y_arr = np,3.440976514
columna] + np,3.440976514
avg_fit = np,3.440976514
easily concatenated,3.44047619
[good-graph],3.440368455
toy problem,3.439612261
conv4 = leakyrelu,3.43956044
evaluation error,3.439137134
datagen_gcn = imagedatagenerator,3.43902439
"= 0

                yield inputs",3.438942618
yield inputs,3.438942618
final epoch,3.438929001
generator object,3.438432576
all_concats = concatenate,3.438356164
conc  = concatenate,3.438356164
expect support,3.438197233
predicts = lambda,3.437968165
change `version = 2`,3.437967166
writing code,3.437643526
code throws,3.437643526
weights values,3.4375922
kernel_initializer=initializers,3.437512742
"get_gradients

    grads =",3.4375
"get_gradients

        grads =",3.4375
/reference/k_rnn,3.4375
defined dimension,3.437351497
model structure,3.437025042
setidentifier = sequential,3.436357481
"<module>

    train",3.435389721
"<module>

>     train",3.435389721
clever approach,3.434782609
iteration v_t,3.434782609
traditional approach,3.434782609
23rd iteration,3.434782609
batch_size*input,3.434516132
load frames,3.434511435
load 40 frames,3.434511435
tiff file,3.434436343
file represents,3.434436343
yield [batch_x_left,3.434397163
write metric,3.43412373
test = flatten,3.434117208
4 constant values,3.43315508
constant values,3.43315508
test shape,3.432958651
"]

inputs values",3.432798574
high=maxval,3.432692308
block=true,3.432538112
code calculates,3.432295932
y_test = test_set,3.431675875
initial epoch,3.430308312
roc_auc = metrics,3.43030303
metrics=[metric_1,3.43030303
unlock metrics,3.43030303
accurate metrics,3.43030303
_metrics = [metrics,3.43030303
metrics=_metrics,3.43030303
latent dim,3.430260047
error coming,3.430046225
integer action,3.43
large patience,3.429924242
type tensor,3.429815468
encoder = model,3.428709034
predictions = model,3.428709034
encoder model,3.428709034
> predictions = model,3.428709034
model predictions,3.428709034
cpu system,3.42866242
cv=kfold,3.428571429
1647         output_types=nest,3.428571429
53                                     module_objects=globs,3.428571429
2 * covar_true_pred + c2,3.428571429
brown dog,3.428571429
h_tm12 shows,3.428571429
lazy dog,3.428571429
memory causing,3.428571429
tb = tensorboard,3.428571429
52                                     module_objects=globs,3.428571429
tboard = tensorboard,3.428571429
max_length=max_sent_length,3.428571429
theses errors,3.428571429
errors occured,3.428571429
offset=offset,3.428571429
conv_utils,3.428571429
sc = sc,3.428571429
"-------------------

                   hdf5 version",3.428328612
input called `,3.428238347
test = conv2d,3.427659574
dropout=params[,3.42748371
tf functionality,3.427078334
mask = load_image_gt,3.426966292
good practice,3.426923077
"``

``input_length = input",3.42691279
"` 

`input_length = input",3.42691279
input_length = input,3.42691279
master,3.42687747
` type command,3.426836322
defined constraint],3.426282663
working properly,3.426184926
"label

x_train",3.426096062
bigger object,3.426056338
weights loaded,3.426005747
loaded weights,3.426005747
accuracy taking,3.425123762
call tf,3.4249989
call `tf,3.4249989
"<module>

    vae",3.42495424
layer_losses = layer,3.424882629
layer res2a_branch1,3.424882629
dense_6  layer,3.424882629
locallyconnected1d layer,3.424882629
upsampled layer,3.424882629
envs,3.424479167
stateful option,3.424242424
model loaded,3.42420453
* var_auto_encoder = model,3.42420453
loaded model,3.42420453
"```

loaded model",3.42420453
execute model,3.42420453
complicated model,3.42420453
head_lstm = bidirectional,3.423809524
output object,3.423211837
fuzz factor,3.423076923
y_tm1 --> ht,3.423076923
prime factor,3.423076923
title shows,3.423076923
`# returns` section,3.422778257
"call

>     epsilon=",3.422325328
b_regularizer = regularizers,3.422222222
3 dimensions input,3.422067322
max 50 sentences,3.421428571
"2

inputs types",3.421212121
"1656

inputs types",3.421212121
inputs=x_in,3.421212121
"267

inputs types",3.421212121
"34

inputs types",3.421212121
"61

inputs types",3.421212121
inputs * dp_mask[0],3.421212121
inputs * dp_mask[1],3.421212121
inputs * dp_mask[2],3.421212121
inputs * dp_mask[3],3.421212121
"58

inputs types",3.421212121
"135

inputs types",3.421212121
"134

inputs types",3.421212121
generate actions,3.420731707
elif img,3.420189153
building,3.42
586         dispatch_timestamp = time,3.42
465         fit_time = time,3.42
directories = string,3.42
saves time,3.42
elapsed_time = time,3.42
user add,3.419623195
labels=target,3.419583518
/std normalization,3.419306184
raises error,3.418935114
issue occurs,3.418649886
layer = dense,3.418619581
dense layer,3.418619581
`dense` layer,3.418619581
# dense layer,3.418619581
expected output,3.418123241
dtype=tf,3.41809186
score = model,3.417938866
score=model,3.417938866
# score = model,3.417938866
`score = model,3.417938866
convert type,3.417362637
return reshape,3.417277099
fit-function,3.416940719
`fit` function,3.416940719
fit` function,3.416940719
fit function,3.416940719
fit function [,3.416940719
"+ 1

maxlen = np",3.416782966
expected dimension,3.416730454
true metrics,3.416687297
plug&play,3.416666667
dectd = timedistributed,3.416666667
197         # exceptions aren,3.416666667
timedistributed overrides,3.416666667
timedistributed warper,3.416666667
active_skip_idxs = skip_idxs[,3.416666667
failed finding,3.416666667
"`

 `conv_sequence = timedistributed",3.416666667
longest seq,3.416666667
decode_music=timedistributed,3.416666667
seq = return_sequences,3.416666667
raw,3.416666667
features = model,3.416628772
properly feeding,3.416083916
input2 = input,3.416043225
_input = input,3.416043225
"```

     input_image = input",3.416043225
`input_image=input,3.416043225
input_image = input,3.416043225
painter = input,3.416043225
"```

generator_inp = input",3.416043225
"31 

     32 generator_inp = input",3.416043225
generator_inp = input,3.416043225
"input



====================



m3",3.416043225
"input



```

>>> m3",3.416043225
net_a_input = input,3.416043225
in_2 = input,3.416043225
img_t0 = input,3.416043225
img_t1 = input,3.416043225
"```

inputs1= input",3.416043225
word_input = input,3.416043225
constant_input = input,3.416043225
sc = lstm,3.415750916
lstm recognize,3.415750916
epsilon=1e-08,3.41558642
epsilon=1e-3,3.41558642
epsilon=1e-7,3.41558642
epsilon=1e-8,3.41558642
epsilon=1e-06,3.41558642
add noise,3.415533215
functions restart,3.415300546
small dimensions,3.415115005
32-bits word,3.414835165
model throws,3.414400608
minimum code,3.414114114
words sequences,3.413919414
"output

        action_onehot_placeholder =",3.413822166
output=[hovedkategori_loss,3.413822166
`kernel_constraint` argument,3.413621262
obtained applying,3.413533835
layers figured,3.413251277
default batch_size,3.413209749
batch_size default,3.413209749
occurred due,3.413043478
tokenizer object,3.412898443
easily achieved,3.412698413
dimension `[bs,3.412429379
type=int,3.412362637
output = tf,3.412329072
"output

    <tf",3.412329072
contiguous filters,3.412280702
353     // 1x1 filters,3.412280702
originally written,3.412087912
model prediction,3.412009408
"prediction

model",3.412009408
"]



 

    prediction = model",3.412009408
prediction = model,3.412009408
trivial thing,3.411764706
slightly changing,3.411764706
stranger thing,3.411764706
strange results,3.411034483
size / float,3.411025257
fixed length,3.410977242
xp = dense,3.410403619
bit disappointed,3.41025641
lit bit,3.41025641
bit stumped,3.41025641
bit clunky,3.41025641
scipy problem,3.40992766
desired change,3.409638554
returned operation,3.409411765
iterator = dataset,3.409304511
---> 13     iterator = dataset,3.409304511
small amount,3.409090909
cnn_model = load_model,3.409090909
52 gb ram,3.409090909
giving warning,3.409090909
ram location,3.409090909
"save

    save_model",3.409060715
autoencoder = model,3.409053015
autoencoder model,3.409053015
dtype float,3.408090702
dtype=float,3.408090702
`conv2dtranspose` layer,3.40764125
big problem,3.407526699
code works,3.407447447
basically joins,3.407407407
classes_dest[idx],3.407407407
val_samples/batch_size,3.407361795
checkpoint file,3.406850136
callbacks = [monitor,3.406810581
conv1 = conv2drelubatchnorm,3.40625
exception occurred,3.406001225
create 2 generators,3.405833333
"]

colors = np",3.405262229
`build` method,3.405192108
theano implementations,3.404962244
221     set_y = set,3.404564315
documentation page,3.404444444
feed_dict=feed_dict,3.404255319
-> 1603                               feed_dict=feed_dict,3.404255319
bidirectional lstms,3.404201681
loss=huber_loss,3.404021938
loss=segmentation_loss,3.404021938
reconstruction loss,3.404021938
bad loss,3.404021938
loss = classification_type,3.404021938
loss=mycategoricalcrossentropy,3.404021938
loss=roc_auc_score_loss,3.404021938
loss=fake_loss,3.404021938
loss=triplet_loss,3.404021938
loss=ncce,3.404021938
loss=loss_type,3.404021938
loss penalizing,3.404021938
loss=contrastive_loss,3.404021938
0stest loss,3.404021938
loss=multiboxloss,3.404021938
loss turning,3.404021938
loss=loss_function,3.404021938
11 ephochs loss,3.404021938
loss shrinks,3.404021938
accept loss,3.404021938
loss contributions,3.404021938
outputs=out_dense,3.403846154
outputs=[binary_face_output,3.403846154
finite number,3.403726708
fewer number,3.403726708
expose number,3.403726708
exposing number,3.403726708
uneven number,3.403726708
abnormal number,3.403726708
activation = activations,3.403643472
implementation question,3.403510654
model predicts,3.403371196
states[batch+,3.403327056
"1]

    results_df = pd",3.403225806
joined = pd,3.403225806
result1 = pd,3.403225806
lstm = lstm,3.402930403
"tf



os",3.402762225
model target,3.402346606
"```

class embeddingdropout",3.402173913
word2vec embedding,3.402046784
expected results,3.402002225
outputs=output,3.401001653
outputs=[output],3.401001653
works great,3.40047619
"readinto

        return",3.400344828
`return dense3_1,3.400344828
"margin = 1

    return",3.400344828
reset states,3.4002849
outs = train_function,3.4
[imdb_cnn],3.4
squeezenet,3.4
header dealt,3.4
treating videos,3.4
823                            target_tensors=target_tensors,3.4
subwords coming,3.4
fpga hardware,3.4
decode bytes,3.4
saved_models,3.4
program crashes,3.4
classifies videos,3.4
target_tensors=target_tensors,3.4
"log_b_next

    [f_active",3.4
[imdb_cnn,3.4
disgusting crashes,3.4
arbitrary,3.4
input_mask = get_input_mask,3.4
biggest sentence,3.4
sentence 0 absence,3.4
"__call__

    node =",3.399309869
binary crossentropy,3.398907104
understand correctly,3.39874031
score holdout,3.398496241
sample code,3.397897898
code sample,3.397897898
results stay,3.397701149
predicted labels,3.397581792
ve landed,3.396694215
�ve exhausted,3.396694215
neatest solution,3.396226415
common solution,3.396226415
passing validation_steps,3.395723684
negative sampling,3.395721925
"output

```

train",3.393954616
official document,3.393939394
o1 = layer1,3.393939394
optional scope,3.393939394
verbose=false,3.393627946
draw samples,3.393574297
seed = input,3.393520703
timit task,3.393442623
"_handle_results

>     task =",3.393442623
frame works,3.393333333
trainy = create_dataset,3.393162393
"0x118194198>





note",3.392857143
side note,3.392857143
passed trhough,3.392857143
encoded rows,3.392727273
pixel = x_train,3.392699115
random initialization,3.392694064
* random shuffling,3.392694064
steps_per_epoch=steps,3.392565814
cntk implementations,3.392488263
predict function,3.392326273
"wrapper

    result =",3.392294026
stop character,3.391891892
code roughly,3.391891892
"tbcallback]



model",3.390871196
encoder_model = model,3.390871196
top model,3.390871196
validation_steps = x_test,3.390857767
"add_weight

    weight =",3.390478972
include `dilation_rate`,3.39047619
367       int pad[2],3.390384615
return tuple,3.390344828
batch iterator,3.389681832
possibly related,3.389473684
arguments received,3.389071038
"```

# gist1

epoch",3.388929001
docker,3.388888889
*batchsize+batchsize,3.388888889
required amount,3.388888889
fraction rate,3.388888889
shows effect,3.388888889
significant amount,3.388888889
completely wrong,3.388501742
inputs=probs_in,3.387878788
outputs kernel[0,3.387791108
initial_states type,3.387362637
reference  implementation,3.38730695
main addition,3.387205387
"test mode

                     ]",3.386968085
test mode,3.386968085
upper left,3.386554622
x1 = base_model1,3.385964912
lst = [x1,3.385964912
xtest = dataset[24*,3.385912698
"400 pixels

    frame =",3.385714286
predicting idc,3.385714286
"expected`



edit",3.385253456
flow method,3.384984985
great post,3.384920635
closed prs #4358 #4386,3.384615385
rr cases,3.384615385
"]]



**_i put",3.384615385
cudnntensordescriptor_t desc,3.384615385
cudnnfilterdescriptor_t desc,3.384615385
cudnnconvolutiondescriptor_t desc,3.384615385
"desc

step3",3.384615385
model works,3.38420453
total + x_batch,3.383971292
total += x_batch,3.383971292
concatenate feature,3.383561644
barely save,3.383419689
save-load_,3.383419689
save/restore_all,3.383419689
initial_states = [initial_state,3.383333333
separate item,3.383333333
2d array,3.3831045
total epochs,3.383098945
class` mylayer,3.382943144
"environment

variable",3.382857143
return channels,3.382228886
set seed,3.382041793
functions implemented,3.381967213
"np

np",3.381953028
borehole images,3.381578947
299x299 images,3.381578947
segment images,3.381578947
simply changing `,3.381461676
load label,3.38136992
"-1]

raw_dataset_train = sc",3.380952381
tensorconstant{1} [id,3.380952381
tensorconstant{0} [id,3.380952381
nonzero [id,3.380952381
} [id bp],3.380952381
constant tensor,3.380688124
"_standardize_user_data

>     exception_prefix=",3.380681818
"_standardize_user_data

    exception_prefix=",3.380681818
model predicted,3.380344881
predicted = model,3.380344881
inputs=tensor,3.380331618
"<module>

    model",3.3794618
"<module>

        model",3.3794618
"<module>

>     model",3.3794618
"<module>



    model",3.3794618
notes `tf,3.379459287
w2 = tf,3.379459287
lease give,3.379310345
create callback,3.379047619
5654       elif graph_element,3.378787879
5285       elif graph_element,3.378787879
697         elif function_type ==,3.378787879
`history` object,3.37843729
img = cv2,3.378135968
argument parse,3.377906977
anchor_vect = base_network,3.376811594
hidden1=shared,3.376744186
sample weights,3.376456198
concatenated tensor,3.375786164
square root,3.375471698
positive_d = lambda,3.375468165
model1 output,3.375062476
conv2 = conv2drelubatchnorm,3.375
dense1 = shareddense,3.375
`msk `patch,3.375
num_of_samples = img_data,3.375
`maxout + conv`,3.375
@flyyufelix,3.375
l2_norm/l2_normalize,3.375
rpn generates,3.375
sampler = classsampler,3.375
"__setitem__

    h5o",3.375
unambiguously refer,3.375
/lichengunc/refer,3.375
conv2d_1/bias,3.375
returned values,3.374331551
background pixels,3.37394958
regularizer function,3.373931624
# compute weights,3.373922414
"8]

y_test = test[",3.372810627
"7]

y_test = test[",3.372810627
y_test = test[,3.372810627
output = lambda,3.372623664
score = loaded_model,3.372522215
merged layer,3.37225105
9 target samples,3.371716374
updating theano,3.37162891
targets saved,3.371489621
word_train_label+word_test_label,3.371428571
similar error,3.371316066
/similar error,3.371316066
received type,3.370695971
x2 = base_model2,3.37037037
output_dim=output_dim_emb,3.37037037
output_dim = char_weights,3.37037037
output_dim=max_word_length,3.37037037
output_dim=row_hidden,3.37037037
internet simply,3.36969697
simply instantiate,3.36969697
return alpha *,3.369094828
output_shape=eucl_dist_output_shape,3.369047619
output_shape=kl_shape,3.369047619
output_shape=rel_shape,3.369047619
validation_data=nturgbd_test_datagen,3.368932039
validation_data=valid_gen,3.368932039
validation_data = valid_generator,3.368932039
"makes 



validation_data",3.368932039
validation_data = gen_valid,3.368932039
validation_data=valid_generator,3.368932039
validation_data = [validationstyledatagenerator,3.368932039
"run_ete_exp

    validation_data=",3.368932039
validation_data = val_batches,3.368932039
validation_data=validation_gen,3.368932039
validation_data=mytestgenerator,3.368932039
validation_data = [test1,3.368932039
validation_data=test_batches,3.368932039
validation_data=vgen,3.368932039
yield x_train,3.368762945
model_2 = model,3.368648974
model = clone_model,3.368648974
>>> model_2 = model,3.368648974
# explicitly add,3.367914167
total height,3.366689281
"start

    thread",3.366666667
decay=1e-6,3.366419753
decay=1e-4,3.366419753
decay=1e-5,3.366419753
kernel_regularizer=l2,3.366359447
kernel_regularizer = l2,3.366359447
create process,3.366060606
input vocabulary,3.366043225
trainable attribute,3.365894737
> trainable attribute,3.365894737
fcnn architecture,3.365671642
run save_model,3.365409365
binary array,3.365344938
targets = np,3.364053437
32 spatial,3.363636364
conv3 = conv2drelubatchnorm,3.363636364
`concatenate` layer,3.363238793
concatenate layer,3.363238793
"return y_pred

````",3.363196233
return y_pred,3.363196233
"index

model",3.363148424
"metric

model",3.363023095
`prelu` layer,3.362382629
windows 10 machine,3.362126246
cpu computations,3.361995754
optimizer wrapper,3.361754386
rgb images,3.361578947
extract features,3.361471861
# extract features,3.361471861
support strides,3.360855185
"support

355     // strides",3.360855185
"# checkpoint



filepath=",3.36081959
input_img = input,3.36048767
#input_img = input,3.36048767
d2 = dense,3.360403619
d2=dense,3.360403619
#d2=dense,3.360403619
"n_feature

        state",3.36036036
`y_true` argument,3.360230209
encoded = maxpooling2d,3.360223464
implement evaluation,3.360071301
45 pst file,3.359436343
input_tensor=resnet_input,3.359375
re-running,3.35889195
"0         

_________________________________________________________________

conv1",3.358630952
dense_3/sigmoid,3.358576642
"shape[0]

x_change = 1280",3.358490566
undesired shape,3.358490566
nnoise shape,3.358490566
merging shape 0,3.358490566
shape 10x100,3.358490566
shape incompatibility,3.358490566
flateen shape,3.358490566
datasate shape,3.358490566
"shape 

                    [bacthsize",3.358490566
"shape
b0",3.358490566
caffe mode,3.357954545
evaluate function,3.357905983
recurrent,3.357894737
`recurrent,3.357894737
batch_x1=np,3.357643181
batch_x2=np,3.357643181
movies = np,3.357643181
small_img = np,3.357643181
batch_features = np,3.357643181
horizontal_flip=config,3.357142857
correlated signal,3.357142857
calling `add_weights`,3.357142857
transfer,3.357142857
"sigrid

hey",3.357142857
calling othermodel,3.357142857
change get_model,3.357006975
actual work,3.356807512
unknown identifier,3.356763926
units=units_lstm,3.356521739
units=out_word_vocab_size,3.356521739
units=size_mem,3.356521739
units=nr_units,3.356521739
size filter_length,3.355852843
normal embedding,3.355582137
lr= n_step,3.355555556
lr=learn_r,3.355555556
minimum confidence,3.355555556
lr = 2e-4,3.355555556
```python,3.355223881
python,3.355223881
"04

python 3",3.355223881
python 3,3.355223881
> python 3,3.355223881
``` python,3.355223881
python 2,3.355223881
"`

```python",3.355223881
python-3,3.355223881
python=3,3.355223881
`python 3,3.355223881
"5

python",3.355223881
## python,3.355223881
"8

python 3",3.355223881
"```python

#",3.355223881
"8



```python",3.355223881
"```python

    [[[ -4",3.355223881
"6

%  python -",3.355223881
"```python

  #",3.355223881
"sample corresponds

#",3.355212355
masking=true,3.354805319
generator_train = datagen,3.354545455
datatype float32,3.354385965
scale pixels,3.353896104
outputs=main_output,3.353846154
throws error,3.353575637
layer config,3.353454058
255         config = layer,3.353454058
mul,3.352941176
dataframe = read_csv,3.352941176
add layers,3.352594016
decoder output,3.352418657
-> 2287             assert str,3.351823937
part takes,3.351503759
yield nxb,3.35106383
yield [xi[0],3.35106383
`yield [xi[0],3.35106383
yield batch_imgs,3.35106383
yield batch_input,3.35106383
"fit

    loss_name =",3.350701403
tbeen fit,3.350701403
call model,3.350696524
`model` call,3.350696524
call `model,3.350696524
batchnorm op,3.350626118
return y_,3.350344828
matching shapes,3.35
sees dense2,3.35
dense2 = shareddense,3.35
kinda odd,3.35
divide evenly,3.35
inputs=input_data,3.34978355
inputs=[input_data,3.34978355
lstm paper,3.34961335
validation_steps=test_size,3.349473684
problem persisted,3.34870317
mysterious problem,3.34870317
problem arises,3.34870317
problem wiil,3.34870317
scoping problem,3.34870317
2 functions produce,3.34863388
"_separable_conv_block

    kernel_initializer=",3.348623853
process created,3.348069738
"dataset

    x_train",3.348056258
process fails,3.347727273
initial_state=encoder_states,3.347619048
similar result,3.347598955
"columns

features",3.347496706
classes recurrant,3.347457627
twenty classes,3.347457627
refactored classes,3.347457627
output = last_layer,3.347155499
graph definition,3.346778711
model_output = embedding,3.346491228
e_x = embedding,3.346491228
in_embed = embedding,3.346491228
embeddings_enc = embedding,3.346491228
embeddings_dec = embedding,3.346491228
pinyin embedding,3.346491228
"```

qe = embedding",3.346491228
embed1=embedding,3.346491228
embedding_vec=embedding,3.346491228
head_embedding = embedding,3.346491228
docs_embedding = embedding,3.346491228
width information,3.34640057
parameter `resize_images,3.346385542
5 fold cv,3.346153846
avoid memoryerror,3.345454545
recently wrote,3.345238095
basically taking,3.344907407
negative number,3.344903179
# method explained,3.344444444
method trains,3.344444444
easy method,3.344444444
modelcheckpoint applied,3.343915344
nvidia,3.34375
nvidia 387,3.34375
weights=softmax_weights,3.342672414
validation_split parameter,3.341999577
timedistributed layer,3.341549296
`timedistributed` layer,3.341549296
partial code,3.341386841
outputs=grads,3.341346154
combined model,3.340871196
bigger model `,3.340871196
mid = model,3.340871196
"hdf5matrix

---> 32 model",3.340871196
"`

`conv_model = model",3.340871196
model_json = model,3.340871196
`y_pred` argument,3.340758382
partial graph,3.340718105
performance effect,3.340501792
perplexity calculation,3.34047619
randomly,3.340425532
"continue

            single_layer_mem *=",3.34
output weights,3.339827913
weights output,3.339827913
gonna run,3.33976834
#run forever,3.33976834
stacked_dists = lambda,3.339753879
file_to_read = open,3.339130435
3/scripts/train,3.339106809
/scripts/train,3.339106809
dataset doesn,3.338977833
callable function,3.338966589
saving events,3.338888889
"return

        

        filepath =",3.338750625
word_index[word] =,3.338748208
"info

------------------

hej",3.338461538
thread pool,3.338095238
output model,3.338026696
output=model,3.338026696
output = model,3.338026696
model output,3.338026696
"# output

        model",3.338026696
inputs shapes,3.337878788
"]

inputs shapes",3.337878788
inputs=[stateinput,3.337878788
prob_ = predictions[,3.337837838
train = np,3.337775631
gestures information,3.337704918
"82 seconds



loss",3.337355271
input_b = input,3.337095857
crash log,3.337053571
merge = tf,3.336929297
full_size_image = cv2,3.336734694
"dimension 30

model",3.336633908
"dimension 32

    model",3.336633908
optimizer state,3.336149834
general question,3.336056645
imagenet dataset,3.335851648
list index,3.335813139
add support,3.33521193
"output

        inputs = [",3.335034287
correct graph,3.334756854
786                          input_types=input_types,3.333333333
3390           input_types=input_types,3.333333333
bs=bs,3.333333333
input_dataset=input_dataset,3.333333333
database,3.333333333
simplified,3.333333333
hangs,3.333333333
amt=amt,3.333333333
x_bad  = x_bad,3.333333333
236         check_circular=check_circular,3.333333333
allow_nan=allow_nan,3.333333333
237         separators=separators,3.333333333
11 players + ball,3.333333333
10 players + ball,3.333333333
test_x1 = test_x1,3.333333333
test_x2 = test_x2,3.333333333
fapl=fapl,3.333333333
"reconst_data

reconst_data  =",3.333333333
"]

    crop = crop/255",3.333333333
babi_rnn,3.333333333
min_after_dequeue=min_after_dequeue,3.333333333
small_img = small_img[,3.333333333
im1 = im1,3.333333333
uk,3.333333333
art,3.333333333
val_ins=val_ins,3.333333333
val_rmse improved,3.333333333
optimized preferentially,3.333333333
x_decoded_mean = decoder_mean,3.333333333
classzero = fnmatch,3.333333333
classone = fnmatch,3.333333333
detect licenseplate,3.333333333
expecting atleast,3.333333333
"server

    516         writer",3.333333333
discussion presented,3.333333333
vram memory,3.333333333
input_dim=inp_word_vocab_size,3.333333333
input_dim=out_word_vocab_size,3.333333333
barely noticeable,3.333333333
_dropout_mask = _generate_dropout_mask,3.333333333
input_dim = char_weights,3.333333333
circular/toeplitz,3.333333333
avg_image_test=read_avg,3.333333333
mixing tensorshape,3.333333333
padded spot,3.333333333
"ascii_uppercase

    train_length=[]",3.333333333
enc = encoder_embeddings,3.333333333
"array_read







gpuarrayexception",3.333333333
tt   fe,3.333333333
"0           pos_dist[0][0]

                                                                     neg_dist[0][0]

    ==================================================================================================",3.333333333
"15



list_files = file_io",3.333333333
list_0_current_epoch = list_0[,3.333333333
occupy memory,3.333333333
independent terms,3.333333333
straight fwd,3.333333333
64 la = dense_to_conv1,3.333333333
---> 66 la = dense_to_conv2,3.333333333
36 la = dense_to_conv1,3.333333333
---> 38 la = dense_to_conv2,3.333333333
"19110686e-26]]



essentially",3.333333333
conceptually denotes,3.333333333
list_classes_train = load_data_from_file,3.333333333
potential problems,3.333333333
word_labelmap = buildintmap,3.333333333
warnings whatsoever,3.333333333
valuable contribution,3.333333333
tensor flow,3.332993371
process 32 samples,3.332968237
img_input = input,3.332709892
timedistributed input,3.332709892
solutions provided,3.332258065
add formulas,3.332199882
opts = tf,3.331840239
sq1 = tf,3.331840239
x_indices = tf,3.331840239
x_values = tf,3.331840239
print outs,3.331597754
predictions=dense,3.33157479
predictions = dense,3.33157479
encoder = dense,3.33157479
xx = base_model,3.330861909
validated dataset,3.330357143
xtrain = dataset[24*,3.330357143
"tf

tf",3.330347144
history = model1,3.330287929
easily load,3.33011583
top-1 error,3.330046225
supporting fact,3.33
similar accuracy,3.328893604
axis=bn_axis,3.328853047
serialization code,3.328399828
representation code,3.328399828
type np,3.328339152
vae defined,3.327952421
`oov_token` argument,3.327906977
instance variable,3.327857143
"changing input

```",3.327807931
"840       

_________________________________________________________________

pool1",3.327380952
"0         

_________________________________________________________________

conv2",3.327380952
create kernel,3.327278287
importerror                               traceback,3.327260898
"---------------------------------------------------------------------------

importerror                               traceback",3.327260898
"```

---------------------------------------------------------------------------

importerror                               traceback",3.327260898
decoder_dense = dense,3.327070285
output1 = dense,3.327070285
sigma = dense,3.327070285
continuous line,3.326745939
kernel weights,3.326617368
40 kernel weights,3.326617368
predict day4,3.326086957
predict multithreaded,3.326086957
predict}_function,3.326086957
"_train_model_default          

    features",3.325757576
"add_inbound_node

    node",3.325396825
fit_generator function,3.325122565
epsilon=epsilon,3.325
rgb values [103,3.324919786
maxpooling layer,3.324882629
layer receives,3.324882629
categorical accuracy,3.324833065
model definition,3.32420453
list call,3.323361239
modified code,3.322447447
early_stopper = earlystopping,3.322222222
model 1 results,3.321905679
model 2 results,3.321905679
compile function,3.321863038
`compile` function,3.321863038
takes paths,3.321428571
calling evaluate_generator,3.321428571
"tensorboard



```



**note",3.321428571
validation_data=gen,3.321312991
correct percentage,3.321311475
lstm/gru,3.321183511
conv block,3.321153846
prediction = rows_nr,3.321138211
"__call__

    output =",3.321068543
"__call__

>     output =",3.321068543
"__call__

             output =",3.321068543
cntk backends,3.320693391
outputs=model_origin,3.320512821
"```

outputs=[]

l_weights=[]",3.320512821
char_level=true,3.3197176
_one_shot=true,3.3197176
first_layer=true,3.3197176
error related,3.319519909
test case,3.31922333
outputs = tf,3.319019726
outputs=tf,3.319019726
progbar output,3.318584071
problem simply,3.31840014
work properly,3.318345973
unknown constants,3.318302387
x1_2 = layer2,3.318181818
x2_2 = layer2,3.318181818
steps_per_epoch=int,3.318103448
x_train[test_index],3.317699115
goinf wrong,3.317073171
_ = declstm,3.317073171
_ = decoder_lstm,3.317073171
totally wrong,3.317073171
somthing wrong,3.317073171
group = h5file,3.316666667
throws exception,3.316487158
reset_default_graph function,3.316239316
apply_gradients function,3.316239316
variable `decay`,3.316190476
variable * decay +,3.316190476
model_input = input,3.316043225
"input sentence

1",3.316043225
"```

model_input=input",3.316043225
model_input=input,3.316043225
ema_in = input,3.316043225
#NAME?,3.316043225
seq2=input,3.316043225
"0         

_________________________________________________________________

conv3",3.316017316
# nir part,3.315789474
lstm code,3.315579316
create pr,3.315555556
`alpha` parameter,3.315135542
num_layer = len,3.315068493
150       ly = len,3.315068493
categoryone=[0]*len,3.315068493
word_vocabsize=len,3.315068493
sent_len = len,3.315068493
epochs=numepoches,3.314917127
epochs=no_of_epochs,3.314917127
epochs = no_epoch,3.314917127
epochs = num_epochs,3.314917127
epochs=nr_epochs,3.314917127
epochs=n_epoches,3.314917127
num_epochs=epochs,3.314917127
prediction = dense,3.314875163
accuracy score,3.314691432
good accuracy,3.314546839
directory iterator,3.314241486
img = preprocess,3.314128547
nn read,3.313169747
small loss,3.313112847
source file,3.312867716
offline mode,3.3125
point making,3.3125
370       cudnnconvolutionmode_t mode,3.3125
layer2 = dense,3.31191877
fixed size,3.311408398
core,3.311403509
1 core,3.311403509
input_shape = tr_pair0,3.31092437
input_shape_ = input_shape,3.31092437
"keypoints



input_shape =",3.31092437
`    input_shape = _obtain_input_shape,3.31092437
y_true_batch = batch[1],3.310734463
list output,3.310691411
py _predict_loop,3.309225413
__please make,3.309090909
errorplease make,3.309090909
functionplease make,3.309090909
_please make,3.309090909
h5py/_objects,3.309090909
"normal

# distributions",3.309090909
make public,3.309090909
test file,3.308904428
big difference,3.308823529
prediction 8 accuracy,3.308761974
random input,3.308737289
infinite loop,3.307692308
outputs=outputs,3.307692308
greatly appreciated,3.307692308
outputs=[outputs],3.307692308
important concepts,3.307692308
py3keras,3.307692308
video clip,3.307692308
outputs = outputs,3.307692308
input_a = input,3.307347573
input=[input_a,3.307347573
"```

input_a = input",3.307347573
output=pred,3.307155499
i1 + abs,3.306451613
weird things,3.306220096
x_test set,3.305948398
"```bash

* accuracy",3.305805581
incompatible shapes,3.305555556
> incompatible shapes,3.305555556
base_model = vgg19,3.305220884
"code



```

np",3.305090628
continue working,3.304646465
set weight_decay = 10^9,3.304564315
validation_steps= len,3.304542177
validation_steps = len,3.304542177
validation_steps=len,3.304542177
permanent fix,3.304347826
fix planned,3.304347826
type=tensor_value,3.304029304
big issue,3.303560372
dtype bool,3.302918288
"dtype bool

>",3.302918288
`timedistributed` wrapper,3.302631579
timedistributed wrapper,3.302631579
results = pool,3.302463054
ga_int *err,3.302325581
248           err = cudnnfindconvolutionforwardalgorithm,3.302325581
372       err = cudnngetconvolutionnddescriptor,3.302325581
err == cudnn_status_not_supported,3.302325581
"421 

422       err = cudnngetconvolutionforwardworkspacesize",3.302325581
"439 

440     err = cudnnconvolutionforward",3.302325581
index error,3.302323453
x1 = input,3.302008138
lstm_layer = lstm,3.301465201
dimension fixed,3.301318267
run properly,3.301306801
`fit` implementation,3.300508353
timesteps depend,3.3
pil,3.3
`x_dev` flattened,3.3
worth tracking,3.3
vis_utils,3.3
list_train_0 = list_files_0[,3.3
list_train_1 = list_files_1[,3.3
doc_rep_plus = rep_layer,3.3
doc_rep_minus = rep_layer,3.3
setting `stop`,3.3
timesteps=max_word_length,3.3
1239         sample_weights = _standardize_sample_weights,3.3
"metric_result = {

                        metric_fn",3.3
dense1 layer,3.299882629
plain array,3.299771167
labels = np,3.299084622
"theano

            mask =",3.298595203
significant change,3.298527443
lose height,3.298507463
height = 48px,3.298507463
"0

y_test -=1    #reindex",3.298342541
y_test=y_test_all[0,3.298342541
"from_config

    process_node",3.297101449
ideally latest,3.296948357
maximum size,3.296393383
parameter oov_token,3.296385542
updated weights,3.296376117
error log,3.295671225
"color 

      num_classes",3.295634921
softmax_weights = loaded_model,3.295454545
"build

    constraint=",3.295441541
increase decay,3.295151515
time dependency,3.295
version produce,3.294995279
similar question,3.294973545
investigate properly,3.294871795
network = fully_connected,3.294871795
train_data=datagen,3.294545455
parameters stored,3.294358974
output_layer = dense,3.293736952
rep_layer = dense,3.293736952
model variable,3.293728339
parts depending,3.293706294
`samples_per_epoch` samples,3.293574297
strange graph,3.293445378
masking layer,3.293303682
```masking``` layer,3.293303682
"]

    history = model",3.293252149
"```

history = model",3.293252149
`history = model,3.293252149
history= model,3.293252149
history = model,3.293252149
history=model,3.293252149
"`

`history = model",3.293252149
"]

history=model",3.293252149
#history=model,3.293252149
"call

    dilation_rate=",3.293158661
put label,3.293012331
adding loss=,3.292910827
required number,3.292615597
float-type,3.292535051
type float,3.292535051
type=float,3.292535051
tensor hold,3.29245283
outputs=base_model,3.292400371
lstm model,3.292336398
model = lstm,3.292336398
[ lstm model],3.292336398
entry includes,3.292307692
double checked,3.291705069
temporary workaround,3.291666667
feature supported,3.291359326
convolution properties,3.291111111
saved weights,3.291085112
inp = input,3.291043225
input=inp,3.291043225
final line,3.291031653
data_t=np,3.290976514
data_x=np,3.290976514
"`target_tensors`

``` 

model",3.290871196
val_samples=x_test,3.290272972
`h0 = tf,3.290173572
feed_dict={inputs,3.290006447
temp location,3.289473684
saved model,3.289283895
conv10 = permute,3.288888889
output=seta,3.288822166
"integer

    width",3.288695652
module wouldn,3.288590604
"<module>

    get_p_net",3.288590604
df = pd,3.287841191
relevant accuracy,3.287623762
bn = batchnormalization,3.2875
write `lambda,3.287439996
#drop1 = dropout,3.287356322
dropout consists,3.287356322
expected format,3.287129358
"works

    dense",3.287070285
simply wrong,3.28677014
-> 2495                                       custom_objects=custom_objects,3.286624204
54                                     custom_objects=custom_objects,3.286624204
98                                     custom_objects=custom_objects,3.286624204
custom_objects=custom_objects,3.286624204
113                                     custom_objects=custom_objects,3.286624204
custom_objects = custom_objects,3.286624204
-> 2476                                       custom_objects=custom_objects,3.286624204
53                                     custom_objects=custom_objects,3.286624204
--> 174                         rv = reductor,3.286561265
x2 = input,3.286413596
prediction working,3.285784676
conv4 = conv2drelubatchnorm,3.285714286
remotemonitor constructor,3.285714286
"[y5]

    [x4",3.285714286
kernel_constraint = customconstraint,3.285714286
"_run_callback

>     callback",3.285714286
symbol table,3.285714286
upper limit,3.285714286
"_run_callback

    callback",3.285714286
"set_model

    callback",3.285714286
road pixels,3.285714286
performance benefit,3.284946237
dataset[train_size,3.284902597
layer made,3.284882629
"`

`embedding = concatenate",3.284847392
flatten layer,3.284531752
optimizer=adam,3.284485126
optimizer = adam,3.284485126
adam optimizer,3.284485126
`optimizer = adam,3.284485126
optimizer= adam,3.284485126
expected graph,3.28441312
reduced dimension,3.28422425
weights=[np,3.283648928
-> 3050             weights[0] = np,3.283648928
3052                 weights[1] = np,3.283648928
weights = [np,3.283648928
changing theano,3.283393616
shape=layer,3.283373195
net_anchor = resnet_model,3.283333333
"`

`hist=model",3.283178889
model includes,3.283178889
hist = model,3.283178889
hist=model,3.283178889
chosen implementation,3.283140283
final acc,3.282934132
defined model,3.282459981
l2 = lstm,3.282110363
/cc @rossumaiwhen,3.281879195
change theano,3.281267465
compute h1,3.28125
labels=targets,3.281185031
weight file,3.281165315
code break,3.280780781
tf `experiments`,3.280558188
nice features,3.28030303
error message,3.280046225
error showed,3.280046225
error varies,3.280046225
"```



error message",3.280046225
"```



###  error message",3.280046225
message error,3.280046225
epoch starting,3.279838092
1 epoch = 32 sec,3.279838092
expected width,3.279663394
"kernel_size[1] + 1

        

        return",3.279377086
copy=false,3.279298216
outputs=x3,3.278846154
graph=tf,3.27861895
graph = tf,3.27861895
conv2d layer,3.278074118
layer `conv2d`,3.278074118
causing steps,3.278033794
pull,3.277777778
"stop_train]



path =",3.277777778
origin=path,3.277777778
absolute path,3.277777778
potential reasons,3.277777778
reddit post],3.277777778
rnn2 picture,3.277777778
public properties,3.277777778
"compatible`

`valueerror",3.27706422
expected ndim=5,3.2762309
expected ndim=3,3.2762309
encoder =concatenate,3.276194002
input_tensor = input,3.275418225
initializer setting,3.275409836
fitting model,3.275081723
"<module>

    model2",3.275077091
empty batch,3.275020178
245           int requestedcount = 1,3.275
369       int upscale[2],3.275
batchnormalization layer,3.274882629
"]

    ytrain = dataset[24*",3.274801587
function set_weights,3.27457265
activation class,3.274567385
input shape,3.274533791
"input shape

2",3.274533791
size batch_size,3.274325749
size=batch_size,3.274325749
10 random images,3.274273011
labels * tf,3.27328168
referenced paper,3.273148148
set `submodel,3.272985368
load folder,3.272972973
return activation,3.2727383
augment=augment,3.272727273
debugging shows,3.272727273
adequately groups,3.272727273
datays = process,3.272727273
debugging utilities,3.272727273
input units,3.272564964
index problems,3.272277228
column index,3.272277228
index=result1,3.272277228
testing/evaluating],3.271929825
# encodes columns,3.27173913
trigger theano,3.27162891
taking maximal,3.270833333
[relevant loc],3.270588235
`on_epoch_end` method,3.27037037
changed greatly,3.27027027
tokenizer init,3.270175439
131 encoder_states = [state_h,3.26984127
encoder_states = [state_h,3.26984127
param,3.269230769
downsampling stage,3.269230769
output=scores,3.26889463
modified samples,3.268574297
found bellow,3.268518519
upconvolution found,3.268518519
batch_size=num_gpu*64,3.268472906
batch_size/max_word_len,3.268472906
error information,3.267751143
flatten_1/reshape,3.266932271
model object,3.266927534
"<module>

    parallel_model",3.266851474
"from_config

    process_layer",3.266798419
-> 2112                                       initial_state=initial_state,3.266666667
evaluating purposes,3.266666667
maxt = min,3.266666667
"generator_queue

    thread",3.266666667
mu2 = tf,3.265173572
print statement,3.264931087
"#print loss_val

```",3.264931087
print datagentrain,3.264931087
minimum working,3.264646465
significant codebase,3.263888889
error received,3.263379558
[guide,3.263157895
guide,3.263157895
unified answer,3.263157895
activation=params[,3.262520861
# combine generators,3.2625
"+ 1



word_train_label = np",3.262405086
"``

``my_generator = generator",3.262376238
"56 

     57 my_generator = generator",3.262376238
"`

`my_generator = generator",3.262376238
generator = [trainstyledatagenerator,3.262376238
x_a_shape = generator,3.262376238
z_p = generator,3.262376238
implementation mode,3.26230695
labels=outputs,3.261954262
model expected,3.261838938
assert shape ==,3.261716372
assert shape[1] ==,3.261716372
loss=vae_loss_func,3.261164795
"vae_loss_func

    loss =",3.261164795
convolution = conv1d,3.260524345
"save_model

  file",3.260077369
"save_model

>   file",3.260077369
run time,3.25976834
learnt weights,3.25933908
weights=[pretrained_weights],3.25933908
`supermodel=load_model,3.259090909
makes fit_generator,3.258883249
`fit_generator` forgets,3.258883249
`fit_generator + indexarraygenerator`,3.258883249
regularization doesn,3.25862069
backward_layer = layer,3.258215962
test_image = cv2,3.257787325
gan = model,3.257537863
model-arch,3.257537863
exported model,3.257537863
data_pre=model,3.257537863
gan model,3.257537863
head_model = model,3.257537863
pred_outcome = model,3.257537863
defining model,3.257537863
model gave,3.257537863
untrained model,3.257537863
error **indexerror,3.257318952
weird error,3.257318952
"``

``rnn_encoded=bidirectional",3.257142857
"``

``birnn_encoded=bidirectional",3.257142857
"`

`rnn_encoded=bidirectional",3.257142857
"`

`birnn_encoded=bidirectional",3.257142857
"`

`trirnn_encoded=bidirectional",3.257142857
l_lstm = bidirectional,3.257142857
docs_doc_lstm = bidirectional,3.257142857
argument kernel_size,3.256939235
xt --> ht,3.256410256
model = tf,3.256044769
tf model,3.256044769
input `run -,3.255811565
override `compile,3.255623722
state_initializer = initializers,3.255555556
recurrent_dropout=params[,3.255512004
parameters found,3.255185185
weird behavior,3.255050505
train labels,3.254907225
stay constant,3.254901961
inputs=[input0,3.254545455
inputs=input_sequence,3.254545455
inputs=input3,3.254545455
inputs=[input_layer1,3.254545455
inputs=[inputimg],3.254545455
inputs=mainin,3.254545455
inputs=[input_array],3.254545455
manage inputs,3.254545455
inputs=model_origin,3.254545455
inputs=inpt,3.254545455
inputs=[qry,3.254545455
inputs differ,3.254545455
inputs=conv_input,3.254545455
x_train = tokenizer,3.25454122
double check,3.254486719
utils,3.254237288
utils`,3.254237288
frameworks,3.254237288
monitor = earlystopping,3.253846154
#monitor = earlystopping,3.253846154
outputs matching,3.253846154
113       return obj,3.253793103
output result,3.253484613
output=result,3.253484613
3 dimensions output,3.253179596
prob < 1e-15,3.25308642
random state,3.253054424
"inputs

[<tf",3.25305236
"inputs

```



```

[<tf",3.25305236
inputs=tf,3.25305236
autoencoder approach,3.252964427
x3 = model1,3.252906977
yield x_test[,3.252447913
integer corresponds,3.251428571
yield/produced,3.25106383
pred = np,3.250976514
"__version__



theano",3.250939255
"<lambda>

    lambda",3.25093633
ctc loss,3.250175784
embeddings_constraint = max_norm,3.25
"```

image_test = mpimg",3.25
kaggle,3.25
internally upcast,3.25
huge difference,3.25
vertically,3.25
bigger concerns,3.25
identify painter,3.25
discard `encoder_outputs`,3.25
[step_input_shape] + constants_shape,3.25
caffenet_stack_1 = caffenet,3.25
caffenet_stack_2 = caffenet,3.25
"start_time

    466         # _score",3.25
card game,3.25
t4 2 roll,3.25
inputfilters = separableconv2d,3.25
conditional,3.25
vga 1080ti,3.25
s2=sg2,3.25
swig_import_helper,3.25
"```

discriminator = get_discriminator_model",3.25
fetch,3.25
parallel_autoencoder = multi_gpu_model,3.25
beeing executed,3.25
helper,3.25
margin=default_margin,3.25
comma,3.25
_p_prev[active_skip_idxs + 2],3.25
qry_emb = emb_layer,3.25
doc_emb_plus = emb_layer,3.25
doc_emb_minus = emb_layer,3.25
failing copying,3.25
# instantiating hdf5matrix,3.25
"------------------

               compilation mode",3.25
2x speedup,3.25
[path1]/generate_answer,3.25
"689us  cudasetdevice

  0",3.25
"65ms  cudathreadexit

  0",3.25
"02ms  cudadevicesynchronize

  0",3.25
word_trainlabelint = mapvalues,3.25
word_testlabelint = mapvalues,3.25
char_traintokenintpad = padwordlevel,3.25
image_model = vgg_16,3.25
input_encoded = input,3.249376559
item_input = input,3.249376559
"```

dummy_inp = input",3.249376559
input_positive = input,3.249376559
input_negative = input,3.249376559
visible2 = input,3.249376559
decoder_inputs = input,3.249376559
x_n = input,3.249376559
caffenet_inputs_2 = input,3.249376559
net_b_input_0 = input,3.249376559
net_b_input_1 = input,3.249376559
input_signal = input,3.249376559
inputtensor = input,3.249376559
autoencoder_input = input,3.249376559
in_info = input,3.249376559
input_frame = input,3.249376559
inp_bot = input,3.249376559
doc_plus = input,3.249376559
doc_minus = input,3.249376559
actioninput = input,3.249376559
docs_sentence_input = input,3.249376559
loss values,3.248941724
network = dropout,3.248894783
"_standardize_input_data

>     str",3.248598131
"_standardize_input_data

    str",3.248598131
flat = flatten,3.248538012
metrics=[rmse],3.248484848
"4216         break

-> 4217       op",3.248062016
bitwise op,3.248062016
w_regularizer=l2,3.247311828
alternating `conv1d`,3.247191011
output column,3.247155499
output = normaldensity,3.247155499
tee output,3.247155499
output = get_encoding,3.247155499
output neurons,3.247155499
168   *output = om,3.247155499
curr_layer = lstm,3.246919747
form 64 tensors,3.24691358
label info,3.246858485
installation order,3.246753247
increasing order,3.246753247
batch_x_right = np,3.24653207
emb = embedding,3.246491228
"```

input1 = lambda",3.24615782
inferred dimension,3.245762712
120x120 dimension,3.245762712
enabled `validation_split`,3.245614035
next_element = iterator,3.245614035
14     next_element = iterator,3.245614035
validation_split=validation_spli,3.245614035
gpudnnconv images,3.245215311
common case,3.244755245
misuse case,3.244755245
"```

_use case",3.244755245
331       case cudnn_convolution_fwd_algo_gemm,3.244755245
334       case cudnn_convolution_fwd_algo_direct,3.244755245
337       case cudnn_convolution_fwd_algo_fft,3.244755245
340       case cudnn_convolution_fwd_algo_fft_tiling,3.244755245
issue stems,3.244736842
trivial issue,3.244736842
seperate issue,3.244736842
issthis issue #5469,3.244736842
issue arises,3.244736842
issue aims,3.244736842
central issue,3.244736842
outputs = model,3.24471735
outputs=model,3.24471735
model outputs,3.24471735
# encode labels,3.244471744
d1 = tf,3.244120941
d1=tf,3.244120941
mid = dense,3.243736952
out_dense=dense,3.243736952
binary_face_output = dense,3.243736952
"load_model

  file",3.243527252
re-wrote,3.243386243
losses/metrics,3.24280303
float64 tensors,3.242469136
"depth

conv2dcustombackpropinput",3.242424242
#patience=early_stopping_patiente,3.242424242
"argument

[https",3.242397138
match input_shape,3.241958853
4 inputs + 2 outputs,3.241724942
parametricsoftplus removed,3.24137931
line represents,3.241031653
output = dense,3.240892451
#output=dense,3.240892451
output=dense,3.240892451
"`

`output = dense",3.240892451
paper states,3.240740741
easily save,3.240562546
p1 = maxpooling2d,3.240223464
nn model,3.239807367
averaging batches,3.238888889
good thing,3.238687783
system info,3.238461538
reproducible,3.238095238
predict_generator + lookback,3.238095238
"```

   

    small_img = imresize",3.238095238
"train



     model",3.237670313
"train

    model =",3.237670313
"train

    model",3.237670313
train [ model,3.237670313
train model,3.237670313
"train

>     model",3.237670313
train-model,3.237670313
random values,3.23761385
"12 @@

         datadir_base = os",3.237588652
flbase = os,3.237588652
sub_file = os,3.237588652
cache_path = os,3.237588652
decoded = lstm,3.237179487
predict_sequences = tokenizer,3.236842105
"cleanup



cv2",3.236734694
input_length=maxlen,3.236676017
assert{msg=,3.23655914
input dim,3.235192161
"size



    typeerror",3.235019509
globalaveragepooling2d operation,3.23483871
approach suggested,3.234782609
"_value

  file",3.234436343
file tensorflw_backend,3.234436343
"ndi

>   file",3.234436343
"ndi



  file",3.234436343
"_value

>   file",3.234436343
"run_globals

>   file",3.234436343
"% np_data







  file",3.234436343
"__str__







  file",3.234436343
"__array__







  file",3.234436343
"_pygpu_as_ndarray







  file",3.234436343
hdf file,3.234436343
actual file,3.234436343
truncated file,3.234436343
"model_from_cong

  file",3.234436343
"deseriize

  file",3.234436343
"derialize_keras_object

  file",3.234436343
"fromonfig

  file",3.234436343
"procs_layer

  file",3.234436343
"from_conf

  file",3.234436343
"dd

  file",3.234436343
file formats,3.234436343
"pygpu_concatenate

  file",3.234436343
jason file,3.234436343
"] = dset



     file",3.234436343
"run_globals

  file",3.234436343
"```sh

epoch 00001",3.234383547
wierd summary,3.234177215
pseudocode summary,3.234177215
causal kernel,3.233944954
conv2d_55/sigmoid,3.233576642
extracted verbs,3.233333333
"# deconvolution 

multi_modal",3.233333333
portable definition,3.233333333
understand kerasclassifier,3.233170135
code mentioned,3.233161733
test_data=datagen,3.232923833
exp function,3.232905983
layer loop,3.232574937
flow_from_directory variant,3.23255814
"roughly

    198         # equivalent",3.232323232
create batches,3.232222222
m1=merge,3.231755725
question post,3.231481481
general problem,3.231056111
plausible results,3.231034483
outstanding results,3.231034483
worse results,3.231034483
results agree,3.231034483
left=lstm,3.230876966
match array`,3.23080565
match array,3.23080565
scikit_learn,3.230769231
inputs=input_layer,3.230735931
inputs=[input_layer],3.230735931
re-add,3.23034803
require `metrics`,3.23030303
"```

wcounts = list",3.230202578
error reported,3.230046225
reported error,3.230046225
train_size = int,3.229545455
trainx = np,3.229438053
"#

#

    base_model = model",3.229425413
8 classes images,3.229036574
code code,3.228228228
network produce,3.228205128
conv = conv2d,3.228191489
"```

saved_model = ks",3.227272727
y_dec represent,3.227272727
preprocessing_function=preprocess,3.227272727
partial caption,3.227272727
# partial caption,3.227272727
# vae = model,3.227234833
"```

vae = model",3.227234833
vae = model,3.227234833
"<module>

    concatenate",3.226946768
joint = kl,3.226666667
inputs=base_model,3.226433005
inputs= base_model,3.226433005
local,3.226238286
"_run

    feed_dict_string",3.226190476
"```

modified script",3.226099831
22                               validation_data = val_generator,3.226074896
validation_data=val_generator,3.226074896
maxlen=longest_sequence,3.225806452
optimizer=rms,3.225789474
wrapped `optimizer`,3.225789474
"failed

make",3.225757576
"]

                slice_i = lambda",3.225468165
input_fn = lambda,3.225468165
start = [lambda,3.225468165
kernel_size parameter,3.2254178
`# properties` section,3.225146199
anaconda3,3.225
epoch takes,3.224643287
127 encoder_inputs = input,3.223735533
encoder_inputs = input,3.223735533
trainy labels,3.223492723
dot function,3.222489316
ga_half *addr,3.222222222
serialize `lstmweights`,3.222222222
behave similarly,3.222222222
created train/,3.222141583
"from_config

    model",3.221305979
save predictions,3.221257527
layer1 = dense,3.221009679
context vector,3.221003135
expected bool,3.220967742
"``

``label_length = input",3.220391051
"`

`label_length = input",3.220391051
label_length = input,3.220391051
mask tensor,3.219419122
"`



testing code",3.219377272
documentation states,3.219259259
shape = state,3.218850926
version tested,3.218804802
activation= parameter,3.218779015
model1 = model,3.218778173
alpha=multiboxloss_alpha,3.21875
accuracy results,3.218658245
assert len,3.2182943
>     776                     assert len,3.2182943
specific axis,3.217741935
vertical axis,3.217741935
z-axis,3.217741935
maxandargmax{axis=,3.217741935
axis=img_channel_axis,3.217741935
axis=img_channel_index,3.217741935
resized = cv2,3.217687075
bias weights,3.217672414
changed get_model,3.217638691
"list

        outputs",3.217382065
coming wrong,3.217073171
"index shifted

```",3.216721672
212       bool reuse_previous_algo,3.216666667
w1=pickle,3.21657754
loss=losses,3.216521938
softmax version,3.216402006
"<lambda>

    model",3.216339361
number losses,3.216226708
labels=labels,3.216216216
labels = labels,3.216216216
inputs2 = input,3.216043225
inputs2= input,3.216043225
metrics callback,3.216017316
model instance,3.215871196
foo = model,3.215871196
training_updates = model,3.215871196
steps_per_epoch= train_generator,3.215830721
future version,3.215828612
input array,3.215814392
general terms,3.215686275
loss target,3.215497348
"continue

                    vect",3.215
images processed,3.214912281
batch number,3.214461171
# setup works,3.214385965
direct call,3.214370782
w__1-w2[,3.214285714
diffw=[w2[,3.214285714
gpus=gpus,3.214285714
loaded resized,3.214285714
outputs=[pred,3.213846154
outputs = kl,3.213846154
`categorical_crossentropy` function,3.213607737
function `categorical_crossentropy`,3.213607737
function  `categorical_crossentropy`,3.213607737
import,3.213240955
batchsize = batch_size,3.212917351
batch_size = batchsize,3.212917351
batch_size=batchsize,3.212917351
roughly 20 iteration,3.212560386
`dropout` layer,3.212238951
layer=dropout,3.212238951
dropout layer,3.212238951
# dropout layer,3.212238951
classification,3.212121212
81 elif _backend ==,3.212121212
"on_epoch_end

    callback",3.211640212
left increase 1,3.211229947
provide word,3.211226917
gru model,3.210589506
normal lstm,3.210556111
10397 mb memory,3.210526316
barely 100 mb,3.210526316
9734 mb memory,3.210526316
~415 mb / epochi,3.210526316
update messages,3.21031746
bit hard,3.21025641
"times]

    file",3.210046099
legit bug,3.209876543
steps_done < steps_per_epoch,3.209770115
steps_done >= steps_per_epoch,3.209770115
"np



batch_size = 1",3.209449421
incompatible outputs,3.209401709
small mistake,3.209090909
correct accuracy,3.208935238
x_train = np,3.208675629
"=-1

x_train = np",3.208675629
"-1]



    #x_train = np",3.208675629
x_train=np,3.208675629
inputs=[input1,3.208568443
inputs = [input1,3.208568443
inputs=input1,3.208568443
x_conv_a = conv,3.208333333
x_conv_b = conv,3.208333333
decoder_outputs = decoder_dense,3.208333333
linear interpolation,3.208333333
_per_input_losses` dictionary,3.208333333
dictionary wrongly,3.208333333
json format,3.208266879
>>> metrics = model_2,3.208080808
dense representation,3.208022666
calling `fit`,3.20784426
5 achieves mse 0,3.207792208
achieves mse 0,3.207792208
strange behavior,3.207777778
line importing,3.20769832
"code



#create",3.207447447
default mode,3.207236842
word_maximal_value = max,3.207142857
longest_word = max,3.207142857
train samples,3.207040081
conv2d_2,3.206896552
neg = tf,3.206840239
#         neg = tf,3.206840239
vocabulary size,3.205852843
model code,3.20498531
play nice,3.204545455
nice speedup,3.204545455
graph = model,3.204316574
"```
model = graph",3.204316574
"output_dim]

                x_f =",3.203703704
"output_dim]

                x_o =",3.203703704
parameter zoom_range,3.203528399
removing 2 inputs,3.203263403
**history = multi_tasking_model,3.202380952
model encountered,3.201982307
"fitting

x_train",3.201909641
input_length=np,3.201846079
"**



    sequence_input = input",3.201757511
sequence_input = input,3.201757511
constant graph,3.201680672
validation_labels = encoder,3.201474201
b_lstm1 = lstm,3.201465201
b_lstm2 = lstm,3.201465201
lstm3=lstm,3.201465201
decode_seq = lstm,3.201465201
rnn_ = lstm,3.201465201
y_test_b = lstm,3.201465201
y_test_c = lstm,3.201465201
y_test_d = lstm,3.201465201
encoded_music = lstm,3.201465201
encoded_columns = lstm,3.201465201
process finished,3.201298701
expected error,3.201013967
implement conv4d,3.200980392
sc = model2,3.200772201
fit methods,3.200701403
"```

num_filters=32

kernel=",3.200611621
run state,3.2001287
istraindataortest = istraindataortest,3.2
indent=indent,3.2
mind submitting,3.2
"metric_1]

      # out2",3.2
keywords associate,3.2
mu2=mu2,3.2
nb_features = nb_features,3.2
target_tensors=[yp],3.2
--> 206                                      closure=closure,3.2
clear specification,3.2
theoretical knowledge,3.2
my_gen = data_gen,3.2
loss_weights=l_weights,3.2
"walk

    nondirs",3.2
current_class_imgs = defaultdict,3.2
word_tokenmap = buildintmap,3.2
* searching onlineplease,3.2
opening prs,3.2
working directory,3.199940582
build batches,3.199636552
completely understand,3.199335548
float32 values,3.199305751
outputs=preds,3.199300699
outputs = m2,3.199300699
outputs=[densemodule],3.199300699
outputs=m2,3.199300699
`steps_per_epoch` arguments,3.198841153
expected behavior,3.19874552
init = tf,3.198506906
result = np,3.197305628
"input

attributeerror",3.19674498
massive error,3.196712892
error consistently,3.196712892
6/multiprocessing/pool,3.196428571
float16 precision,3.196428571
"3]

pool = multiprocessing",3.196428571
7/multiprocessing/pool,3.196428571
bug=true,3.196260809
solution suggested,3.196226415
suggested solution,3.196226415
decoder = model,3.196134354
log metrics,3.19592803
metrics log,3.19592803
outputs= top_model,3.195512821
outputs=top_model,3.195512821
`fit` method,3.195145847
fit method,3.195145847
fit method],3.195145847
implementation issue,3.194543792
inexplicable reason,3.194444444
specific reason,3.194444444
unintuitive behavior,3.194444444
suspected reason,3.194444444
1 million items,3.194029851
elif len,3.193856372
return hasattr,3.193823088
main_output = dense,3.193736952
creation works,3.193333333
create histograms,3.193333333
exception-safe,3.192957746
float64 dtype,3.192918288
random resizing,3.192694064
predictions = globalaveragepooling2d,3.192676548
"<module>

    loss",3.192612542
"shape[0]

    batch_x =",3.191823899
# reshape layer,3.1918149
reshape layer,3.1918149
roughly equal,3.191570881
n_bias= np,3.190976514
n_batch= np,3.190976514
k2=np,3.190976514
jb = np,3.190976514
batch_image = np,3.190976514
img_arr=np,3.190976514
img_dims=np,3.190976514
x_val = np,3.190976514
user_id = np,3.190976514
input_y = np,3.190976514
50 input_y = np,3.190976514
stdv = np,3.190976514
stop] = np,3.190976514
x_arr_icc = np,3.190976514
x_arr_dobl = np,3.190976514
new_h = np,3.190976514
"+2

new_c = np",3.190976514
lane_drawn = np,3.190976514
xv = np,3.190976514
yv = np,3.190976514
"5

    np_d_stepy = np",3.190976514
expected_prediction = np,3.190976514
expected_loss = np,3.190976514
expected_weights = np,3.190976514
expected_bias = np,3.190976514
expected_scales = np,3.190976514
this_y = np,3.190976514
"]]
            ppl -= np",3.190976514
model compiles,3.190871196
xpred = model,3.190871196
`   last_layer = model,3.190871196
tested domains,3.19047619
briefly tested,3.19047619
config functionality,3.19047619
dimension mismatch,3.190207156
accuracy = history,3.190004715
similar problem,3.189973011
"0

        print layer",3.189813716
outputs=decoded,3.18956044
images stored,3.189271255
code fails,3.189114114
unet6_test_{epoch,3.188929001
specific epoch,3.188929001
global_step=epoch,3.188929001
epoch comprised,3.188929001
suggest adding,3.188888889
initial_state=[state_h],3.188888889
reducing lr,3.188888889
_ = theano,3.188702081
132 cudnntensordescriptor_t apply_specific,3.188679245
133 cudnnfilterdescriptor_t apply_specific,3.188679245
146 cudnnconvolutionfwdalgo_t apply_specific,3.188679245
147 cudnnconvolutionbwdfilteralgo_t apply_specific,3.188679245
148 cudnnconvolutionbwddataalgo_t apply_specific,3.188679245
activation function,3.188632789
"random_state = 51

    train",3.188465784
filepath=output_dir+,3.188405797
ae_input = concatenate,3.188356164
aux inputs,3.187878788
generator_valid = datagen,3.187878788
accuracy reported,3.187623762
parser = argparse,3.1875
bad idea,3.186666667
desired idea],3.186666667
rough idea,3.186666667
label picture,3.186174724
input_shape=img_data[0],3.18592437
output = concatenate,3.185511664
weights=[weights],3.185344828
weights=weights,3.185344828
compute loss,3.185271938
x_train[train_index],3.184365782
shape = features,3.184248142
pass weights,3.18422171
make sense,3.184090909
700] sum total,3.183971292
py` test,3.183693499
batch_size = tf,3.183646479
computed weights,3.183581505
weights = model,3.18354361
******** model & weights,3.18354361
model-weights,3.18354361
predict_on_batch methods,3.183333333
indices=x_indices,3.182795699
pretty confused,3.182662539
intended behaviour,3.18226601
missing documentation,3.182222222
potential problem,3.182036503
steps_per_epoch=batches,3.181992337
csv_logger = csvlogger,3.181818182
"``

``model=model",3.181742393
"``

``model = model",3.181742393
model = model,3.181742393
"`

`model=model",3.181742393
"`

`model = model",3.181742393
"model

    model",3.181742393
"model



model",3.181742393
model `model,3.181742393
"model

model",3.181742393
model=model,3.181742393
#model = model,3.181742393
"]`

`model = model",3.181742393
>model = model,3.181742393
`model = model,3.181742393
"```

model = model",3.181742393
"model

        model",3.181742393
"model

---> 35 model",3.181742393
"model 
model",3.181742393
learning_rate=1e-4,3.181657848
indices = tf,3.181302604
lambda vects,3.18102372
weird question,3.180976431
"input

  print",3.180974313
"resized

train_dir =",3.180952381
history = parallel_model,3.180641822
convert sentence,3.18
"assignment



environment",3.18
prediction shape,3.179628777
153     copier = _deepcopy_dispatch,3.179190751
inputs=model,3.178749984
model inputs,3.178749984
"allocated

    config",3.178571429
tr_y = create_pairs,3.178571429
allowed values,3.178253119
sentence pairs,3.177777778
expected result,3.177296856
sample = random,3.176477848
methods `predict`,3.176086957
mapping weights,3.176005747
inputs=inputs,3.175757576
inputs=[inputs,3.175757576
inputs=[inputs],3.175757576
"inputs = inputs[0]

```",3.175757576
inputs = inputs,3.175757576
`epoch` parameters,3.175595668
model_dir = os,3.175088652
graphconv layer,3.174882629
cropping layer,3.174882629
similar gain,3.174603175
validation_data=validation_generator,3.174487594
150         validation_data=validation_generator,3.174487594
#validation_data=validation_generator,3.174487594
code samples,3.174355078
model = multi_gpu_model,3.17420453
calculates lr,3.173737374
weight update,3.173713099
run trainer,3.173101673
dimensions aren,3.172690763
"deserialize_keras_object

    list",3.172231564
decoded = repeatvector,3.172077922
conv1d layer,3.17207364
result = tf,3.171502686
place losses,3.171474359
windows laptop,3.171428571
layer2 = conv2d,3.171373308
train_labels = encoder,3.171171171
categorical cross_entropy,3.170542636
categorical crossentropy,3.170542636
predict method,3.170531401
`predict` method,3.170531401
time **t1**,3.17
dense object,3.16979329
code im,3.16966967
increase accuracy,3.169441944
setting feed,3.169230769
prediction classes,3.168595839
2224         seed = np,3.168453992
"seed = 11

    np",3.168453992
"pd

print",3.168156894
attrs=attr_protos,3.166666667
97                                     module_objects=globals,3.166666667
trials centered,3.166666667
vgg_conv_model = vgg19,3.166666667
c_p] * y_pred_max_mat[,3.166666667
maximize icc,3.166666667
112                                     module_objects=globals,3.166666667
40                 flag_train = random_pattern,3.166666667
dec = decoder_embeddings,3.166666667
action_prob_placeholder * action_onehot_placeholder,3.166666667
dictmovies = {movies[,3.166666667
ap = argparse,3.166666667
profiler = cprofile,3.166666667
elemwise{exp,3.166666667
shortcut_tensor = shortcut_layer,3.166666667
i1 * i2,3.166666667
* i2 * i3,3.166666667
s_t_+_1 =,3.166666667
s_t_+_1,3.166666667
"exe

                         cflags",3.166666667
bias_constraint=nonneg,3.166666667
mask_generator = mask_datagen,3.166666667
dl=0,3.166666667
dl,3.166666667
batch_x_left = batch_x_left,3.166666667
model created,3.166213662
"errors

os",3.166160081
"input



img_shape =",3.166043225
input_points = input,3.166043225
"```

input_video = input",3.166043225
input_accel = input,3.166043225
input texts,3.166043225
input_anchor = input,3.166043225
genre   = input,3.166043225
user_in = input,3.166043225
movie_in = input,3.166043225
"```

    minput = input",3.166043225
a_tensor = input,3.166043225
info_seq_input = input,3.166043225
model fails,3.165871196
flops = tf,3.165173572
image_string = tf,3.165173572
image_decoded = tf,3.165173572
image_decoded / tf,3.165173572
valid_labels = tf,3.165173572
"``` 

individual_channels = tf",3.165173572
builder = tf,3.165173572
"signature_def_map={

      tf",3.165173572
test_predict_tf = tf,3.165173572
lmi = tf,3.165173572
img_pred = tf,3.165173572
"0]]

yp = tf",3.165173572
updating tf,3.165173572
tf hasn,3.165173572
x_shape = tf,3.165173572
embedding_vec = tf,3.165173572
concatstateaction = tf,3.165173572
centers_batch = tf,3.165173572
"1]]

        my_range = tf",3.165173572
"[1]]

        my_range_repeated = tf",3.165173572
"2]

        full_indices = tf",3.165173572
full_indices = tf,3.165173572
"set_model

    tf",3.165173572
progbar create,3.164761905
`x_train = train[,3.164498232
x_train = train[,3.164498232
kwargs argument,3.164106072
"``

``output = timedistributed",3.163822166
"`

`output = timedistributed",3.163822166
` conv1 = bidirectional,3.163392857
conv1d input,3.163234237
tensorboard file,3.163007772
change 1e-6,3.162724974
model printed,3.162299768
keras_model = model,3.162299768
keras_model=model,3.162299768
/model/keras_model,3.162299768
main_model = model,3.162299768
"__call__

    inputs",3.161791831
stddev = np,3.16156475
206             stddev = np,3.16156475
run prediction,3.160906551
x_newfc = dense,3.160403619
hovedkategori_loss=dense,3.160403619
--> 259     device = _get_current_tf_device,3.160377358
android device,3.160377358
ps device,3.160377358
"ps device

*",3.160377358
graphics device,3.160377358
logits=y_pred,3.160219827
x_valid = preprocess_input,3.16
"1]]



        # change shapes",3.159638554
size <number,3.159579551
inputs=main_input,3.159307359
inputs = [anchor,3.159307359
inputs=[main_input],3.159307359
"<module>

    validation_data=",3.157522643
top max_features,3.157142857
docs_word_lstm = bidirectional,3.157142857
include array,3.156914024
awesome work,3.156807512
normal lstms,3.156149733
correct approach,3.156094084
condition tensor,3.156089194
size > maxsize,3.155852843
weird errors,3.155844156
make ```embedding```,3.155582137
length=timesteps,3.155421687
initial_lr=float,3.155172414
error happened,3.155046225
set resize_target,3.154564315
inspecting prediction,3.154471545
gave accuracy,3.154290429
accuracy <  stop_accuracy,3.154290429
accuracy < stop_accuracy,3.154290429
d2 = dropout,3.154022989
make values,3.154010695
outputs = currmodel,3.153846154
"```





shortened outputs",3.153846154
train = result[,3.153128231
weight_decay=1e-4,3.15308642
gpuallocempty{dtype=,3.152918288
# num_classes applies,3.152777778
multiply tensor,3.15245283
transform = count_vect,3.152173913
tensor=input_tensor,3.15182783
build model,3.15161886
# build model,3.15161886
parallel,3.151515152
108     elif callable,3.151515152
`pred = model,3.150871196
yield array,3.150834997
expected point,3.150134409
<img width=,3.150096926
"```



<img width=",3.150096926
"```

<img width=",3.150096926
sequential_1,3.15
`sequential_1`,3.15
trigger graphs,3.15
maximum width,3.149236193
error mentioned,3.149093844
add function,3.148439198
fixed weights,3.148227969
usage,3.148148148
100% usage,3.148148148
input channels,3.147927283
inputs = m1,3.147878788
inputs=m1,3.147878788
inference process,3.147727273
outputs=dense,3.147583106
outputs = dense,3.147583106
outputs=[dense,3.147583106
`outputs = dense,3.147583106
minimal code,3.147447447
distance measures,3.147368421
select output,3.147155499
output = radial,3.147155499
default binary_crossentropy,3.146989094
# make predictions,3.146928747
make predictions,3.146928747
input shouldn,3.146812456
nb_filter=nf,3.146666667
word2vec model,3.146426752
loading weights,3.14491122
left pad,3.14479638
beta_1 parameters,3.144561404
train_gen = data_gen,3.144444444
script documentation,3.144433164
error code,3.144160339
code & error,3.144160339
"batch

            y_pred_batch =",3.144067797
h5py file,3.143527252
loading model,3.143110002
possibly caused,3.142857143
vertical_flip,3.142857143
3773         variance=variance,3.142857143
maxp1 = averagepooling2d,3.142857143
maxp2 = averagepooling2d,3.142857143
maxp3 = averagepooling2d,3.142857143
maxp4 = averagepooling2d,3.142857143
avpl5 = averagepooling2d,3.142857143
log_dir = logdir,3.142857143
n_samples=n_samples,3.142857143
accuracy = float,3.142796176
good part,3.142712551
train_op=optimizer,3.14245614
train_op = optimizer,3.14245614
activated character,3.141891892
epoch end,3.14175919
evaluate methods,3.141666667
tf optimizer,3.140963046
optimizer = tf,3.140963046
shared_conv = convolution2d,3.14084507
initializer=tf,3.140583408
# initializer=tf,3.140583408
found theano,3.140147429
output passed,3.140012642
weird thing,3.139037433
significant drop,3.138888889
reader = tf,3.138857783
net_positive = base_model,3.138554217
net_negative = base_model,3.138554217
relevant info,3.138461538
x_test = tokenizer,3.138226188
compile configuration,3.137976663
inception,3.137931034
expected dense_1_input,3.137634409
categorical array,3.136980469
desp = tokenizer,3.136842105
1 seq2 = tokenizer,3.136842105
input_shape=features,3.136681946
"theano

print",3.136559998
decoder_1 = repeatvector,3.136363636
decode_seq = repeatvector,3.136363636
scale=scale,3.136363636
preds = model,3.136325742
batch_x_middle = np,3.135420959
"h5



    parameters",3.135053763
lab = df[,3.134615385
put constraints,3.134615385
file-system,3.134436343
train accuracy ~0,3.134422879
train accuracy,3.134422879
`1` means increase,3.134199134
"`

`embedding = dropout",3.13384755
--> 416     shape = [int,3.133490566
"```

o_t= output_layer",3.133333333
answers received,3.133333333
expects,3.133333333
"top 1

p1d =[]",3.133333333
"top 5

p5d =[]",3.133333333
qry_rep = rep_layer,3.133333333
initial_state=old_inner_state,3.133333333
avoid duplicates,3.133333333
minor edits,3.133333333
require essentially,3.133333333
"set_weights

    layer",3.133215962
run` works,3.133101673
timeout configuration,3.132352941
dropout values,3.132276108
updated `config`,3.132275132
working alternative,3.131313131
validation_data=<generator,3.131308276
` shape vector,3.131217839
sample_weight=weights,3.131133952
float64 == np,3.130976514
train_data = np,3.130976514
#summarize history,3.130952381
# summarize history,3.130952381
time running,3.130743802
make prediction,3.13022912
error immediately,3.130046225
lstm receiving,3.13003663
learned parameters,3.12952381
applying dropout,3.129461585
reduced = model,3.129332735
kernel_size=filter_length1,3.129032258
architecture shown,3.128829537
"binary_accuracy

                    elif",3.128787879
"<module>

    run",3.128358944
normal queue,3.128138528
wheight update,3.126984127
"robert



update",3.126984127
x_batch = batch[0],3.126523937
calling validate,3.126373626
case images,3.126334192
loss_weights = weights,3.126005747
maxlen=max_caption_len,3.125806452
stddev = float,3.125760649
e_x = lambda,3.125468165
"`

    latent_sampled = lambda",3.125468165
dummy_inp_zero = lambda,3.125468165
x2_pos_matrix_1 = lambda,3.125468165
x2_pos_matrix_2 = lambda,3.125468165
positive_dist = lambda,3.125468165
negative_dist = lambda,3.125468165
concat_layer = lambda,3.125468165
sqrts = lambda,3.125468165
encoded3 = lambda,3.125468165
"1

    att_vec1 = lambda",3.125468165
input2 = lambda,3.125468165
expanded_embeddings = lambda,3.125468165
plus_score = lambda,3.125468165
minus_score = lambda,3.125468165
correct loss,3.125333413
_manager = multiprocessing,3.125
video_newtork = foo,3.125
acc_newtork = foo,3.125
inspect `adversarial_model,3.125
textbooks explain,3.125
minimal model,3.12420453
model implementations,3.12420453
easily reshape,3.124075128
results note,3.123891626
rows yield =,3.123791103
"```

    global_feature = maxpooling1d",3.123655914
piece_pool = maxpooling1d,3.123655914
#encoded_y = encoder,3.123552124
encoded_y = encoder,3.123552124
"~~~~

---------------------------------------------------------------------------

---------------------------------------------------------------------------

indexerror                                traceback",3.123499142
testing script,3.123029655
combine train_generator,3.122727273
conv = conv1d,3.122191011
warnings module,3.121923937
columns=listcolumnsoutputs,3.12173913
colors[idx],3.121693122
shape=generator,3.120866804
initialize object,3.120500782
"wrapper

  file",3.120401256
model returned,3.120282961
key docs,3.119736842
flags = tf,3.119719027
encoder_1 = gru,3.11971831
encoder_2 = gru,3.11971831
decoder_2 = gru,3.11971831
decoder_4 = gru,3.11971831
la_lstm = gru,3.11971831
recurrent_sentence = gru,3.11971831
gru_1b = gru,3.11971831
gru_2 = gru,3.11971831
gru_2b = gru,3.11971831
emb_docs = gru,3.11971831
k1=np,3.119547943
210             limit = np,3.119547943
merged = merge,3.119124146
workarounds mentioned,3.119047619
small bug,3.118967452
validation_data = subtract_mean_gen,3.118932039
direct read,3.118779031
x3 = dense,3.118736952
loss increased,3.118307652
"autoencoder





timesteps =",3.118181818
lstm passes,3.118131868
wholesequence array,3.117952985
inputs error,3.117925013
# combine inpt,3.116666667
"~~~~

    output_shape = output",3.116203118
implement tf,3.116153964
"}



looked = input",3.116043225
missing 31 samples,3.115796519
hard part,3.115789474
"parameters

    ----------

    

    kernel_size",3.115698925
class_mode=model_type,3.115384615
"_data_generator_task

    generator_output =",3.115384615
"data_generator_task

    generator_output =",3.115384615
pr passed,3.115079365
context=gpu_list,3.114942529
3 epochs worth,3.114917127
"n_samples

        steps_per_epoch =",3.11453202
"@yaroslavvb



https",3.114490161
prs https,3.114490161
concatenate object,3.114412502
size=shape,3.114343409
returns batches,3.114298725
code ends,3.114114114
code reviews,3.114114114
"code



```

incoming_layer =",3.114114114
code worked,3.114114114
code location,3.114114114
"<code>
a0",3.114114114
code aswell,3.114114114
factor=np,3.114053437
update parameters,3.113650794
5651         graph = graph_element,3.113445378
5282         graph = graph_element,3.113445378
graph1 = graph,3.113445378
graph2 = graph,3.113445378
"`

`embedding = reshape",3.113423499
fit generator,3.11307764
`conv2d` call,3.113016817
softmax layer,3.112956024
accuracy measure,3.112623762
scores = model,3.112610327
sess = tf,3.112541993
"0



sess = tf",3.112541993
run `preprocess`,3.112495612
loss dictionary,3.112355271
test_image = np,3.112029146
test_image= np,3.112029146
test_image=np,3.112029146
include_optimizer=true,3.111384266
target array,3.111246577
"+24]

    

    xtest = xtest",3.111111111
batch_x_right = batch_x_right,3.111111111
momentum=momentum_init,3.111111111
change lstm,3.111103756
ve spent,3.110979929
call fit,3.11052673
`fit` call,3.11052673
merge = concatenate,3.11011189
py#l112,3.109225413
py#l1058,3.109225413
py#l144,3.109225413
py#l286,3.109225413
py#l650,3.109225413
py#l78,3.109225413
py#l254,3.109225413
py#l149,3.109225413
py#l776,3.109225413
py#l858,3.109225413
py#l2326,3.109225413
py#l1746,3.109225413
py#l763,3.109225413
py#l853,3.109225413
py#l1460,3.109225413
py#l509,3.109225413
py#l486,3.109225413
py#l32,3.109225413
py#l138,3.109225413
py#l36,3.109225413
> absl-py,3.109225413
py#l208,3.109225413
py#l275,3.109225413
py#l343,3.109225413
py#l2425,3.109225413
"```

absl-py==0",3.109225413
py#l82,3.109225413
py#l1447,3.109225413
py#l1150,3.109225413
py#l444,3.109225413
py#l396,3.109225413
py#l829,3.109225413
py#l384,3.109225413
py#l400,3.109225413
py#l957,3.109225413
py#l161,3.109225413
py#l183,3.109225413
py#l284,3.109225413
py#l72,3.109225413
py#l178,3.109225413
py#l83,3.109225413
py#l877,3.109225413
py#l904,3.109225413
py#l832,3.109225413
py#l707,3.109225413
py#l1797,3.109225413
py#l1806,3.109225413
"py#l1474



`",3.109225413
py#l87,3.109225413
py#l2895,3.109225413
py#l198,3.109225413
py#l17,3.109225413
py#l206,3.109225413
py#l188,3.109225413
py#l1127,3.109225413
py#l632,3.109225413
py#l768,3.109225413
py#l3183,3.109225413
py#l120,3.109225413
py#l2940i,3.109225413
py#l361,3.109225413
py#l1864,3.109225413
py#l2867,3.109225413
"py



supposedly",3.109225413
py#l87i,3.109225413
py#l722,3.109225413
py#l1163],3.109225413
py#l60,3.109225413
py#l495,3.109225413
py#l817,3.109225413
py#l1311,3.109225413
py#l1099,3.109225413
py#l1805,3.109225413
py#l307,3.109225413
py#l305,3.109225413
py#l805,3.109225413
py#l785,3.109225413
py#l873,3.109225413
py#l1824,3.109225413
py#l1338],3.109225413
py#l1338,3.109225413
py#l1605],3.109225413
py#l1605,3.109225413
py#l15,3.109225413
py#l8,3.109225413
py#l1678,3.109225413
py#l494,3.109225413
"``` py
tersorflow",3.109225413
lr=1e-3,3.108641975
lr=1e-4,3.108641975
lr=1e-5,3.108641975
lr=1e-2,3.108641975
strange errors,3.108571429
k_val = int,3.108333333
document representation,3.108225108
labels = y_valid_cv,3.108108108
dtype=float32,3.107304253
"dtype=float32>]

```",3.107304253
"dtype=float32>

`",3.107304253
dtype=float32>,3.107304253
dtype=float32>]},3.107304253
dtype float32,3.107304253
"dtype=float32>

```",3.107304253
"dtype=float32>]}

{",3.107304253
"dtype=float32>]}

```",3.107304253
include deleting,3.107142857
easily adapt,3.107142857
calling `discriminator,3.107142857
encoder stage,3.107068607
work continues,3.106807512
output = flatten,3.106804622
variable number,3.106583851
units=d_latent,3.106521739
frame dimensions,3.106024096
output shape,3.105646065
integers length 30,3.105421687
predicted 4 days,3.105263158
pos = tf,3.105173572
#         pos = tf,3.105173572
ve modified,3.105027548
"<module>

    epochs",3.103507731
`fit_generator` method,3.103327693
conv_1 = conv2d,3.103191489
binary_face_output = conv2d,3.103191489
"0

inp = saved_model",3.102272727
weird isn,3.102272727
labels = dense,3.10184506
dense labels,3.10184506
max_sequence_length=maxlen,3.100806452
maxlen=max_sequence_length,3.100806452
ve updated,3.100397919
piece_pool = reshape,3.100265604
# clipnorm enabled,3.1
"```

seqlg = x_training",3.1
[capture jpg1],3.1
immediately overfit,3.1
gtest = sns,3.1
"maxout

    nb_features",3.1
active_next] + updated_log_p_prev,3.1
1387         sample_weights = [_standardize_weights,3.1
"odd

bottom_crop = 0",3.1
pascal,3.1
indexing elements,3.1
model doesn,3.099491886
decoder = dense,3.09900011
predict process,3.098814229
bigger problem,3.09870317
make command,3.098564593
imagenet weights,3.098166919
result = model,3.09720031
inputs doesn,3.096499478
embs = embedding,3.096491228
correct inference,3.096311475
rgb format,3.096161616
241     memo[id,3.09606866
216     memo[id,3.09606866
output problem,3.095858669
generator=gen_train,3.095709571
end goal,3.095687332
total_loss list,3.095450805
predict probabilities,3.095317726
calling `predict_generator`,3.095238095
causing troubles,3.095238095
ac-gan,3.095238095
gave errors,3.095238095
file `state%,3.094796704
output classes,3.094613126
noofinstances/batchsize,3.094444444
mu1 = tf,3.093745001
config = tf,3.093745001
config=tf,3.093745001
b1 = tf,3.093745001
dense3 = dense,3.093736952
last_layer = dense,3.093736952
f1_x = dense,3.093736952
f2_x = dense,3.093736952
mask=input_masks,3.093632959
mask=input_masks[0],3.093632959
` call [resets],3.093158661
timedistributed object,3.092723005
reusing weights,3.092672414
weights[c_t,3.092672414
weights=w_array,3.092672414
weights=[emb_weights],3.092672414
weights=[head_embedding_file],3.092672414
weights=[doc_embedding_file],3.092672414
#x_test = np,3.092360597
x_test = np,3.092360597
x_test=np,3.092360597
x_test= np,3.092360597
strange thing,3.091764706
cylindrical padding,3.091743119
periodic padding,3.091743119
inf number,3.091226708
coords = np,3.090976514
"400]

x_train_tmp = np",3.090976514
"_call_tf_sessionrun

    run_metadata",3.090909091
loss1 = model,3.090871196
model_0 = model,3.090871196
history_fold = model,3.090871196
model initializes,3.090871196
"model

        in_x =",3.090871196
auto_encoder = model,3.090871196
add_model = model,3.090871196
* auto_encoder =  model,3.090871196
multi_tasking_model = model,3.090871196
currmodel = model,3.090871196
model_predict_valid = model,3.090871196
"`

`loss1 = model",3.090871196
probs1 = model,3.090871196
m3 = model,3.090871196
`m3 = model,3.090871196
18     model = compile_model,3.090871196
model trains,3.090871196
model explained,3.090871196
test_predict = model,3.090871196
y_pre = model,3.090871196
coreml model,3.090871196
nontrainable_model = model,3.090871196
encoded_model = model,3.090871196
new_weights = model,3.090871196
quantized model,3.090871196
x_validf = model,3.090871196
model configurations,3.090871196
"seq2seq_plain

    model",3.090871196
> model ready,3.090871196
docs_sent_encoder = model,3.090871196
"```

y_test_pred = model",3.090871196
y_test_pred_prob = model,3.090871196
model_working = model,3.090871196
actual_prediction = model,3.090871196
actual_loss = model,3.090871196
othermodel = model,3.090871196
out_tmp = model,3.090871196
lr_temp=model,3.090871196
delete model,3.090871196
proba = model,3.090871196
bid2 = bidirectional,3.09047619
`sample_weight_mode=temporal`,3.090277778
epochs=int,3.089917127
"batch_size

        n_samples =",3.089901478
wrong index,3.089350398
webcam open,3.089130435
**predict generator**,3.088463194
predict generator,3.088463194
[info] approx,3.088461538
ve defined,3.088283
inputs=inception_feature_compute,3.087878788
inputs=inception_feature_weight,3.087878788
inputs=_input,3.087878788
inputs=input2,3.087878788
inputs=currmodel,3.087878788
inputs=[visible1,3.087878788
inputs=[input_image],3.087878788
inputs=[inputs1,3.087878788
inputs=[word_input],3.087878788
inputs=[f1_base,3.087878788
stated accuracy,3.087623762
dtype=int8,3.086251621
1704                               steps_per_epoch=steps_per_epoch,3.086206897
steps_per_epoch=steps_per_epoch,3.086206897
>     959                               steps_per_epoch=steps_per_epoch,3.086206897
>    1656                               steps_per_epoch=steps_per_epoch,3.086206897
similar issue,3.086006683
6 instances x1,3.085964912
type=str,3.085960768
"predict call

```",3.085912284
reference paper,3.085648148
model = dense,3.084608148
arguments affect,3.084309133
integer number,3.083726708
tanh function,3.083480696
commit,3.083333333
`_costs_embd = timedistributed,3.083333333
timedistributed reshapes,3.083333333
40       default_str *= cudandarray_host_dims,3.083333333
random_state=random_state,3.083333333
subsequently loaded,3.083333333
thoughts @souptc,3.083333333
"perform

        conv_out =",3.083333333
p_prev[active_skip_idxs],3.083333333
b_constraint = constraints,3.083333333
fits mdl,3.083333333
--> 353             img = img,3.082802548
img = img,3.082802548
#img = img,3.082802548
x_a = input,3.082709892
multipy-add,3.082199882
sum_01 = add,3.082199882
[[elemwise{add}[,3.082199882
p_re_lu_11/add,3.082199882
edge_1446_loss/add,3.082199882
elemwise{add,3.082199882
[[elemwise{add,3.082199882
"problem definition

------------------",3.082036503
rho = tf,3.081840239
dot layer,3.081132629
ytest = dataset[24*,3.080357143
correct place,3.080285834
fact makes,3.08
correct shape,3.079802041
"evaluate_generator

    generator_output =",3.07967033
list indices,3.079664944
weights = model2,3.0791589
dimension image_dim,3.079096045
"# arguments

        

        factor",3.078814628
working code,3.078760579
samples % batch_size,3.07871387
accuracy = model,3.078494959
model accuracy,3.078494959
"accuracy



model",3.078494959
output_shape modified,3.077380952
type float64,3.077362637
model2 = model,3.077357683
loss targets,3.077098861
f1_micro score,3.077067669
flow_from_directory method,3.077002584
x1 = np,3.076941426
bit slower,3.076923077
2229                                                sample_weight=sample_weight,3.076923077
bit lost,3.076923077
--> 714                        sample_weight=sample_weight,3.076923077
--> 828                                                  sample_weight=sample_weight,3.076923077
1634             sample_weight=sample_weight,3.076923077
870                               sample_weight=sample_weight,3.076923077
862                               sample_weight=sample_weight,3.076923077
844                               sample_weight=sample_weight,3.076923077
--> 664                               sample_weight=sample_weight,3.076923077
"words            

trainy = [[[0",3.076923077
run tokenizer,3.076610445
decoder_outputs = lstm,3.076465201
predict day 2,3.076086957
"<module>

    dropout=0",3.075946926
coordinates giving,3.075757576
label assigned,3.075063613
multiprocessing context,3.073275862
6/multiprocessing/context,3.073275862
predict output,3.073242456
---> 23                               validation_steps = ceil,3.072807018
d1 = dense,3.07268432
d1=dense,3.07268432
#d1=dense,3.07268432
"# arguments

            schedule",3.072404372
"continue

            y_true =",3.072323232
suggest index 0,3.072277228
nan regularly,3.072202166
nan  logloss,3.072202166
#ifdef nan,3.072202166
#undef nan,3.072202166
nan irrespective,3.072202166
set verbose,3.071824102
# merge net1,3.071755725
timestep output,3.071479824
nxl = to_categorical,3.071428571
y_trainroshot = to_categorical,3.071428571
y_testroshot = to_categorical,3.071428571
y_train2 =  to_categorical,3.071428571
train_labels_one_hot = to_categorical,3.071428571
validation_labels_one_hot = to_categorical,3.071428571
lane_image = imresize,3.071428571
"14393

              uname information",3.071038251
subcallback = os,3.070921986
predict_fpath = os,3.070921986
"9000

```



run results",3.070802823
stddev=epsilon_std,3.070588235
outputs=seq,3.070512821
"create

valueerror",3.070397554
tensor properties,3.070230608
tokenizer stores,3.070175439
running cntk,3.069898731
test_data = np,3.069354893
loss = tf,3.06919551
loss=tf,3.06919551
validation_data=data_generator,3.068932039
signature `fn,3.066976744
valid set,3.066726478
learning,3.066666667
300                       loss_weights=loss_weights,3.066666667
273                       loss_weights=loss_weights,3.066666667
pred_outcome produced,3.066666667
idxs < f_active,3.066666667
"2

                    host system",3.066666667
"optimizer

model",3.06666067
# dim output,3.066304436
output dim,3.066304436
inp = np,3.065976514
middle part,3.065789474
train_spec = tf,3.065173572
epochs=training_epochs,3.064917127
start working,3.064646465
working prototype,3.064646465
results vary,3.064367816
classify sentences,3.064285714
lstm1 = gru,3.064162754
<code>class_weight = {0,3.064114114
load model,3.063844169
# load model,3.063844169
ve pasted,3.063360882
ve laid,3.063360882
"---------------------------------------------------------------------------

eoferror                                  traceback",3.062893082
"iteration

> model1",3.062689585
"_standardize_user_data

    _check_array_lengths",3.0625
n_features=d_samples,3.0625
"set attribute

```",3.062459052
key = cv2,3.061734694
"```

parallel_model = multi_gpu_model",3.061594203
parallel_model = multi_gpu_model,3.061594203
steps_per_epoch=batch_size,3.061576355
steps_per_epoch=batch_size * 1000,3.061576355
"]

x2=np",3.061346885
y_val = np,3.061346885
x2 = np,3.061346885
steps_per_epoch=x_train,3.060802563
clever ideas,3.060606061
sounds weird,3.060606061
low=minval,3.060483871
x_c = dense,3.060403619
code block,3.06026796
validated samples,3.060240964
num samples,3.060240964
scores = reduced,3.060200669
outputs=conv1,3.060096154
"error



> error",3.06009245
"buildloop

    pred",3.06
"]

    join_func = kl",3.06
pp = pred[,3.06
validation_data = 10*np,3.059908553
validation_data = np,3.059908553
validation_data=[np,3.059908553
"wcounts]

# note",3.05952381
"random_state = 51

    x_train",3.059365782
greatly helpful,3.058823529
lstm units,3.057986941
10 lstm units,3.057986941
lr history,3.057936508
graph mismatch,3.057889823
#load mapping,3.056306306
size <timesteps>,3.055852843
compile setting,3.055623722
input2->output2,3.055555556
pattern due,3.055555556
working model,3.055517661
"* epsilon



# note",3.055357143
"* epsilon

    

    # note",3.055357143
validation_labels = np,3.054612878
found 4d,3.054232804
**evaluate generator**,3.054042904
evaluate generator,3.054042904
unique characters,3.053921569
pred = dense,3.053736952
pred   = dense,3.053736952
"plt

#list",3.05373199
dataparalleloptimizer instance,3.053571429
"<module>

    print",3.053521691
join [id,3.053399394
code lines,3.053138504
lines code,3.053138504
mem copy,3.052930057
mse values,3.052711994
metric logs,3.052639704
"]=x1

            batch_x2[",3.052631579
"<listcomp>

    batch_sizes = [",3.052631579
cudandarray *kerns,3.052631579
x1 = tf,3.051138485
x1=tf,3.051138485
"train                         

    loss =",3.050821055
train loss,3.050821055
predict_generator predicts 640,3.050595238
nb_epoch=nb_epoch,3.050505051
nb_epoch = nb_epoch,3.050505051
`load_model` line,3.050122562
shape defined,3.050079351
sizes,3.05
suggest introducing,3.05
array shapes,3.049771167
output2 = dense,3.049292508
includes work,3.049115204
submodels defined,3.048731642
arguments passed,3.048594848
y_test = le,3.048342541
result = top_model,3.047995781
concatenated sentences,3.047619048
easily tested,3.047619048
queue fast,3.047619048
histogram_freq > 0` clause,3.047619048
activation layer,3.047276101
output = dense_layer,3.047155499
output array,3.046926666
"7]



train_spec = train[",3.046799117
"`state`

        args",3.046695764
embed = embedding,3.046491228
multiprocessing setup,3.046052632
call `_make_predict_function`,3.045539613
ht = activation,3.045470395
continuum analytics,3.045454545
"```

model = unet",3.045416651
"```



model = unet",3.045416651
compile command,3.045097406
normalized values,3.044919786
means model,3.043252149
steps_per_epoch=xtrain,3.043103448
compare https,3.04306159
linked code,3.042685543
graph` errors,3.042016807
model implement,3.041851588
lease enumerate,3.041666667
faster inference,3.041666667
skip_idxs < active,3.041666667
people stand,3.041666667
validation_data=train_generator,3.041659312
kernel regularizer,3.041637262
models,3.041338583
models**,3.041338583
models//123,3.041338583
dotted line,3.041031653
darkblue line,3.041031653
"line 116

    % delta_t_median",3.041031653
bottom-line,3.041031653
line `image_datagen,3.041031653
show warning,3.040540541
sanity check,3.040201005
check grammar,3.040201005
guess ill,3.04
gpudnnconvdesc{border_mode=,3.039215686
densemodule = dense,3.039191497
preds = dense,3.039191497
min_delta = 1e-3,3.038800705
min_delta=1e-3,3.038800705
min_delta=1e-4,3.038800705
error doesn,3.038666915
activity_regularizer=reg,3.038461538
reduced compared,3.038461538
# slice_i = concatenate,3.038356164
dense3 = concatenate,3.038356164
merged model,3.038239617
initialize weights,3.037116858
"[y3]

    [x2",3.037037037
"# block 2

    model",3.037025042
"# block 3

    model",3.037025042
"# block 4

    model",3.037025042
"# block 5

    model",3.037025042
"# block 6

    model",3.037025042
batch_size=batch_size,3.036945813
batch_size = batch_size,3.036945813
1522             batch_size=batch_size,3.036945813
-> 1358             batch_size=batch_size,3.036945813
stackoverflow describes,3.03654485
stackoverflow gods [1],3.03654485
behavior doesn,3.036398467
"_clone_functional_model  

    **kwargs",3.036199095
kernel_constraint=maxnorm,3.035714286
extract/slice,3.035714286
validation_data=multiple_inputs_generator,3.035598706
seta = dense,3.035403619
"8]



x_train = x_train",3.03539823
x_train = x_train,3.03539823
x_train = x_train[,3.03539823
x_train = x_train[0,3.03539823
x_train = x_train/255,3.03539823
"1]

x_train = x_train",3.03539823
"28



x_train = x_train",3.03539823
input_tensors = [model,3.035315641
epoch `__getitem__`,3.035082847
l3 = lstm,3.034798535
encode_seq = lstm,3.034798535
ema_lstm1 = lstm,3.034798535
ema_lstm2 = lstm,3.034798535
y_test_a = lstm,3.034798535
fixed point,3.034722222
unique = list,3.034124147
`nb_epoch` doesn,3.033873215
epoch 51 values,3.033848787
sample correspond,3.033783784
"[sample]



expression 2",3.033783784
initial_state=[init_state,3.033333333
nmovies = ratings,3.033333333
google cloud,3.033333333
fixed seed,3.033033033
output paths,3.032869785
--> 297             state = deepcopy,3.032512259
inputs=input_tensors,3.032323232
running prediction,3.031882013
"_run

    feed_dict_tensor",3.031746032
conv1=lambda,3.031718165
handle cases,3.031674208
ll handle,3.031674208
targets shape,3.031567489
ll train,3.031414502
figure shows,3.03125
[loss documentation],3.030688605
error telling,3.030046225
"------error--------



valueerrortraceback",3.030046225
eexist error,3.030046225
error thrown,3.030046225
error displayed,3.030046225
"error-

```

outofrangeerror",3.030046225
# convert texts,3.03
# convert integers,3.03
set `image_data_format=,3.029564315
loss = lambda,3.029490103
expected shape,3.029458308
expected shape=,3.029458308
decoded = dense,3.029451238
perplexity metric,3.029294756
epochs increased,3.029202841
w1 = tf,3.028809936
strange problem,3.02870317
change queue,3.028686173
cpu cores,3.02866242
56 cpu cores,3.02866242
batch axis,3.028476399
compiling model,3.028371196
empty list,3.027821626
integer classes,3.027457627
## pr freeze,3.026570048
pr freeze,3.026570048
x_newfc = flatten,3.026315789
"txt`

output",3.026225267
predictions/softmax,3.025911232
nb_epoch=n_epochs,3.025252525
shape=img_dim,3.025157233
shape` gave,3.025157233
shape=state_shape,3.025157233
# shape = [n_input,3.025157233
shape=[n_input,3.025157233
"dropout

os",3.024944974
`val_loss` imply,3.0248307
04d}-{val_loss,3.0248307
input_tensor=tf,3.024548572
"14]



#x_test1 = np",3.024309848
"np



conf =",3.024309848
"```

input_values = np",3.024309848
preds_test = np,3.024309848
x_e = np,3.024309848
x_d = np,3.024309848
y_d = np,3.024309848
target_data = np,3.024309848
img_lst_train = np,3.024309848
label_lst_train = np,3.024309848
img_lst_test = np,3.024309848
label_lst_test = np,3.024309848
39                 rand_x = np,3.024309848
train_labels = np,3.024309848
input_x1 = np,3.024309848
input_x2 = np,3.024309848
denom = 2*np,3.024309848
dummy_y = np,3.024309848
num1 = np,3.024309848
num2 = np,3.024309848
top_img = np,3.024309848
bot_img = np,3.024309848
max_val = np,3.024309848
blanks = np,3.024309848
rnn_y = np,3.024309848
sample_input = np,3.024309848
train_target = np,3.024309848
outputs=x2,3.024216524
temp file,3.023910027
change code,3.023752668
3 object classes,3.023513965
object classes,3.023513965
amazing work,3.023474178
"<module>

>   file",3.023026947
"<module>

  file",3.023026947
"<module>
  file",3.023026947
"<module>
>   file",3.023026947
meaning vector,3.022727273
tokenizer constructor,3.022556391
create errors,3.021904762
dont create,3.021904762
temp += y_true[,3.021796917
temp -= y_true[,3.021796917
good reason,3.021367521
metrics computed,3.021212121
h_tm12 = states[0],3.021164021
prediction referring,3.021138211
bilinear interpolation,3.020833333
345     config = json,3.020676692
mse losses,3.020292208
ideal output,3.019882772
model receiving,3.019442625
config = model,3.019442625
exact model,3.019442625
random_state=seed,3.019144144
y_train = hdf5matrix,3.019090909
y_train = le,3.019090909
`fit_generator` call,3.018708576
_ = lstm,3.018538372
batch_size= n_batch,3.018472906
==> script loads,3.017766497
x_train_1 = x_train[,3.017699115
"]

    x_train_2 = x_train[",3.017699115
x_trainshape = x_train,3.017699115
"error= 3

        accuracy= 0",3.017669987
l1 = lstm,3.017254675
ve mentioned,3.015741834
call `compile,3.015449049
production problem,3.015369837
path = os,3.01536643
ins variable,3.015357143
kernel_initializer = randomnormal,3.01529052
"]

            mask = masks[",3.015201586
mask=masks[,3.015201586
open object,3.015186773
"start_time

    print",3.014931087
code crashes,3.014114114
reshape output,3.01408777
shape[0] / float,3.01366298
good idea,3.013589744
job failed,3.01344086
directory path+,3.013071895
02d}-{val_acc,3.012690355
result=result,3.012658228
width & number,3.01242236
tuple index,3.012277228
"run_internal_graph

  file",3.012214121
"0

                    elif file_name",3.012121212
"output

    print",3.012086587
odd thing,3.011764706
conv2d_287/relu,3.011744966
beating relu,3.011744966
x1 = lambda,3.011433077
-> 2929             maximum_iterations=input_length,3.010869565
input_length=sentence_length,3.010869565
input_length=word_traintokenintpad,3.010869565
add tensorboard,3.01077131
# build vocabulary,3.010747664
# create ae,3.01
longer exist,3.009615385
accuracy scores,3.009362893
"error



`typeerror",3.009212892
error `typeerror,3.009212892
"error



    typeerror",3.009212892
2f rmse,3.008658009
ve encountered,3.007805326
ae=model,3.007537863
gru1 = bidirectional,3.007142857
"error

`valueerror",3.007110445
"error



valueerror",3.007110445
error  valueerror,3.007110445
"error



> valueerror",3.007110445
"```



error 

```

valueerror",3.007110445
error valueerror,3.007110445
"add

    layer",3.007082511
add layer,3.007082511
outputs = conv2d,3.007037643
code passed,3.006971257
train shape,3.005289683
"inputs = img_input



#",3.004545455
inputs=img_input,3.004545455
hinge loss,3.004021938
loss percentage,3.004021938
org/3,3.003861004
org,3.003861004
outputs=dense2,3.003846154
filters= model,3.003151898
variable timesteps,3.002857143
weights change,3.002310968
change `model,3.000509751
progbarlogger = lambda,3.000468165
conv2=lambda,3.000468165
size_input_image = size_input_image,3
[slow_tensorflow_backend,3
_50 column,3
issues,3
`pretrained_word_embeddings,3
js,3
json_str = json_str,3
cuhk03,3
bring,3
s1=s1,3
_deepcopy_method,3
output_shapes=output_shapes,3
cnns,3
images_to_read = x_train_cv_path,3
--> 284     explicitly_on_cpu = _is_current_explicit_device,3
ticket tracking,3
[trainexperiment,3
128 logical cores,3
issues],3
prediction_generator = timeseriesgenerator,3
issues #3358,3
output_row * output_col,3
"**



run_tf_backend",3
series,3
lecun,3
immediately tells,3
3dcnn,3
dice,3
>>> torch,3
noop,3
benchmark,3
coreml_model = coremltools,3
loaded_model_json = json_file,3
"execute_instructions

        cmd",3
[winerror 2] filenotfounderror,3
"mbe1_4

```",3
fi,3
kernel_dims = kernel_dims,3
"_run_fn

    status",3
sort_keys=sort_keys,3
319                                 n_jobs=n_jobs,3
--> 321                                 pre_dispatch=pre_dispatch,3
avoid keeping,3
/set_font {,3
"]

              

    xtrain = xtrain",3
centralized location,3
gmax = globalmaxpool1d,3
pretrained_word_embeddings,3
customregularization,3
proof,3
ioloop,3
rstudio,3
[seis01,3
[xy_time01,3
"=-1

    kk=kk+1",3
test_labels = data_x[0,3
annmodel,3
handwriting,3
gmm,3
imagenet_utils,3
sampled,3
relus,3
tflearn,3
train_x2 = train_x2,3
operators,3
adjust,3
[theanorc],3
launched,3
concatenate_2,3
`imagenet_utils,3
hwnd = win32gui,3
extracting,3
15s,3
`embedding_2`,3
#NAME?,3
"*output_len

input_dict = {",3
language,3
2 benchmarks,3
didnt,3
x_full = x_full,3
"num_epoch = 1000

regularizerl2 =",3
title_size*wordvec_size,3
[pretrained_word_embeddings],3
builder = saved_model_builder,3
"1

matplotlib",3
inner_input = inner_input[,3
[wrapper_output] + inner_state,3
company_vec = company_vec_dict[,3
"]]

            title_vec = title_vec_dict[",3
"]]

            skill_vec = skill_vec_dict[",3
u_constraint = constraints,3
batch_output = postprocess,3
@albertomontesg,3
benchmarks,3
reads,3
nvcc fatal,3
[issues],3
"99989152e-01]]



y_test_pred_prob=

[[  1",3
buy_hold_sell,3
#NAME?,3
output_power_sample_weights,3
class_imgs[class_],3
sharedvar,3
output_masks[tensor_index],3
3 issues,3
finalized proposal,3
coco,3
83     slices = [slice,3
1483                               val_f=val_f,3
1484                               callback_metrics=callback_metrics,3
prob = pp[,3
1141                               val_f=val_f,3
1142                               callback_metrics=callback_metrics,3
well-,3
output_len = output_len,3
array element,2.999771167
valid_spec = tf,2.998506906
train_labels = tf,2.998506906
patches_true = tf,2.998506906
patches_pred = tf,2.998506906
norm2 = tf,2.998506906
favor `tf,2.998506906
centers = tf,2.998506906
## tf integration,2.998506906
github gist,2.998339292
method fit_on_texts,2.998290598
train/fit,2.99750052
train / fit,2.99750052
error appears,2.996712892
loss weights,2.996694352
"deserialize

    printable_module_name=",2.99589491
x2 = lambda,2.995838535
57     dot = pydot,2.994959677
loss = model,2.994893134
"model

loss",2.994893134
model loss,2.994893134
"loss

    model",2.994893134
output_shape=lambda,2.994515784
"call

  file",2.994261671
train 4 classes,2.994256744
relevant items,2.994029851
metrics list,2.993838942
dens1 = dense,2.993736952
dens2 = dense,2.993736952
e_64 = dense,2.993736952
mdn = dense,2.993736952
y_c = dense,2.993736952
out_genre = dense,2.993736952
out_painter = dense,2.993736952
344 dense neurons,2.993736952
hidden2 = dense,2.993736952
l_dense = dense,2.993736952
encoded2 = dense,2.993736952
decoded1 = dense,2.993736952
h_o = dense,2.993736952
dense_out1 = dense,2.993736952
dense_out2 = dense,2.993736952
dense1_out = dense,2.993736952
out_lambda = dense,2.993736952
out_mu = dense,2.993736952
out_sigma = dense,2.993736952
out_rho = dense,2.993736952
v_dense1 = dense,2.993736952
v_dense2 = dense,2.993736952
model_output = dense,2.993736952
underkategori_loss=dense,2.993736952
general tips,2.993464052
random transformation,2.992694064
reshaped tensor,2.99245283
dtype=int32,2.991724258
dtype=int32>,2.991724258
scale factor,2.991258741
build metrics,2.991050694
inputs2 = np,2.990976514
readcsv = csv,2.990909091
csv_file1=csv,2.990909091
model = vgg16_model,2.990871196
model receives,2.990871196
>array = np,2.990747681
np array,2.990747681
file size,2.990289186
fig = plt,2.990196078
y_test = np,2.989319056
y_test=np,2.989319056
logs dictionary,2.988821138
`logs` dictionary,2.988821138
inputs=model_input,2.987878788
inputs=[ema_in],2.987878788
duplicate inputs,2.987878788
inputs=[model_input],2.987878788
feed_dict = {xs,2.987841945
printing information,2.987704918
accuracy improve,2.987623762
9% top1 accuracy,2.987623762
094% top1 accuracy,2.987623762
decent accuracy,2.987623762
img_list=os,2.987588652
predict_path = os,2.987588652
dense = dense,2.987473904
`dense=dense,2.987473904
outputs=[ema_output],2.987179487
proba = model2,2.986486486
"default=4

    padding",2.986479961
"correct += 1



print",2.986242563
"0

_________________________________________________________________

acc",2.985315084
index `y_pred`,2.985128633
module compiled,2.984669035
x3=flatten,2.984649123
"_fit_loop

  file",2.984436343
"_test_loop

  file",2.984436343
py generates,2.984225413
supported type,2.983516484
transpose operation,2.983448276
variable logs[,2.983344948
ct_2_1 = conv2dtranspose,2.982758621
"x_batch]

       break  #",2.98245614
rank 4 output,2.982449617
_ = tf,2.982246743
top `num_words`,2.981818182
pos * neg,2.981666667
output file,2.981591843
epochs=num_epoch,2.981583794
sigmoid output,2.980732142
slack,2.980237154
train nets,2.98013245
date,2.979890311
% date,2.979890311
label `argmax,2.979825518
"starty + 15

            cv2",2.979591837
kindly point,2.979166667
point puts,2.979166667
"repeat



things",2.978947368
test_data= data_t[0,2.978378378
x3=conv2d,2.978191489
output y1,2.97792473
"accuracy

plt",2.977819841
mode == tf,2.977673572
mode=tf,2.977673572
`tf` mode,2.977673572
input_shape=img_dim,2.977591036
input_shape=inpshape,2.977591036
weird difference,2.977272727
save weights,2.976092103
#save weights,2.976092103
kinda ran,2.975806452
gvs = optimizer,2.975789474
optimizer=optimizer_function,2.975789474
make gan,2.975757576
loss obtained,2.975450509
1556                 split_at = int,2.975
valid generators,2.974662162
epoch callback,2.974643287
stopiteration error,2.974490669
important concern,2.974358974
save model,2.974290885
# save model,2.974290885
# resource problem,2.97370317
"3

input_style = reader",2.973684211
serialized_example = reader,2.973684211
metric formula,2.972151899
net_anchor = base_model,2.97188755
alpha=1e-4,2.97183642
"```

  my_layer = keras_model",2.971428571
**_deferredtensor** type,2.970695971
build/change,2.970386218
decay work,2.970140845
target_tensors = [y_train],2.969090909
"lr

             decay =",2.968888889
lstm = reshape,2.968397472
err = tf,2.967499154
activation values,2.967313258
"history

print",2.96731204
shape=[width,2.967186218
passing build,2.966997664
discussed earlier,2.966666667
compatible license,2.966666667
crop = array[,2.966437834
great place,2.966117216
json_string = model,2.965871196
"```

        inp = model",2.965871196
input_length=flags,2.96541502
array = tf,2.964944739
stop working,2.964646465
demonstrates working,2.964646465
reader = csv,2.964593301
samples * number,2.963967672
great work,2.963950369
"141 */

142 int apply_specific",2.963679245
143 int apply_specific,2.963679245
144 int apply_specific,2.963679245
constant isn,2.963235294
inputs=inp,2.962878788
provide input,2.962434978
curr_layer = timedistributed,2.962121212
file represent,2.961709071
oov words,2.961538462
"outputs = []

    # loop",2.961538462
changed np,2.961246784
model1 ouput,2.96124031
epoch index,2.961206229
"[4]]]

y_train = np",2.960067423
y_train=np,2.960067423
y_train = np,2.960067423
nb_filter = nb_filter,2.96
nb_filter=nb_filter,2.96
"output_shape



    model",2.959918815
"output_shape



    #model",2.959918815
118 #concat = merge,2.959891318
encountered problem,2.959814281
loss achieved,2.959577493
train mode,2.959299117
fixed number,2.959282264
negative_d = lambda,2.958801498
causing error,2.958617654
exact error,2.958617654
odd shape,2.958490566
massive workaround,2.958333333
guys give,2.958257713
fix outputs,2.95819398
"blog 

http",2.957903996
softmax probabilities,2.957304164
print hist,2.95723878
"cpu

btw",2.957233849
gru2 = bidirectional,2.957142857
switch `bidirectional`,2.957142857
127] check failed,2.956867672
717] check failed,2.956867672
671] check failed,2.956867672
`logs` object,2.956544143
wanted layer,2.956132629
found `inf`,2.956018519
print np,2.955907602
"]
        #print np",2.955907602
"<module>

    verbose=2",2.955850391
"<module>

    verbose=1",2.955850391
experiments run,2.955152955
seed=seed,2.954954955
"seed = seed

```",2.954954955
execution due,2.954545455
"get_updates

    grads =",2.954166667
"get_updates

        grads =",2.954166667
run code,2.953882454
code run,2.953882454
silly question,2.953703704
applications,2.952380952
applications`,2.952380952
"[y3]

    [x4",2.952380952
2/applications/,2.952380952
"verify

stateful_model",2.952380952
optimizer=optimizer,2.951578947
optimizer = optimizer,2.951578947
implement branching,2.950980392
columns=listcolumnsinputs,2.950310559
cntk haven,2.95006402
284     spec = devicespec,2.95
shortcut = batchnormalization,2.95
w_constraint = constraints,2.95
input_shape=base_model,2.949478587
input_dim=trainy,2.948717949
conv3d autoencoder,2.948616601
model work,2.947678708
"```

# code adapted",2.947447447
code corrected,2.947447447
nxl = sess,2.947368421
inputs=input_tensor,2.947253788
input_tensor=inputs,2.947253788
output dims,2.947155499
batch_size=config,2.947044335
"_do_run

    target_list",2.946428571
`conv2d` [states],2.945784082
increase happening,2.944976077
"raise_from

stopiteration",2.944444444
"raise_from

> stopiteration",2.944444444
"1

y2 = cropping2d",2.944444444
#prediction = activation,2.943531684
prediction = activation,2.943531684
model=save_weights,2.942222548
"]



y_train = targets[",2.942167832
ve attached,2.94214876
y_val= to_categorical,2.941798942
discriminator defined,2.941588785
l1 = lambda,2.941257638
_impl,2.941176471
feats = np,2.940976514
expectation_1 = np,2.940976514
x_bad_id = np,2.940976514
x_good_id = np,2.940976514
> vec_y = np,2.940976514
data1 = np,2.940976514
y_classes = np,2.940976514
masking_value=np,2.940976514
next_words = np,2.940976514
great contribution,2.94047619
lambda epochs,2.940385292
input_length=max_sent_length,2.939440994
latex=s_t_&,2.939393939
"open

oserror",2.939130435
in_merged = concatenate,2.938356164
encoder_full_state = concatenate,2.938356164
merged_caffenet_stack = concatenate,2.938356164
net_b = concatenate,2.938356164
m3 = concatenate,2.938356164
recurrent_sentence_and_info = concatenate,2.938356164
order defined,2.938342032
"classes
    model",2.938328823
classes = model,2.938328823
device properties,2.938155136
setting `floatx,2.937931034
# divide inputs,2.937878788
batch update,2.93771859
datadir = os,2.937588652
optimizer=nadam,2.937327935
btw doesn,2.937192118
"output_dim]

                x_c =",2.937037037
spyder-py3,2.936507937
input_file = args,2.936335404
hey guys,2.936090226
dtype=int64,2.936016879
loss=total_loss,2.935936831
add_loss` method,2.935353535
softmax output,2.935228894
# softmax output,2.935228894
iteration trains,2.934782609
iteration due,2.934782609
place fails,2.933974359
frame = imutils,2.933333333
speed purposes,2.933333333
wrong format,2.933234787
saved file,2.932849042
file saved,2.932849042
cpu loss,2.932684358
validation_data = list,2.93246795
"on_epoch_end

    result =",2.93225504
unique words,2.932126697
"break

        

    print",2.931597754
"] = embedding_vector

            print",2.931597754
print o1,2.931597754
print o2,2.931597754
run model,2.930639536
run `model,2.930639536
"run

    model",2.930639536
model run,2.930639536
model & run,2.930639536
missing dependency,2.930555556
saves metrics,2.93030303
"tf





print",2.93010466
"2-tf

print",2.93010466
line adding,2.929920542
shape printed,2.929919137
happening consistently,2.929824561
1356] found device 0,2.928895877
1344] found device 0,2.928895877
1030] found device 0,2.928895877
955] found device 0,2.928895877
885] found device 0,2.928895877
102] found device 0,2.928895877
k1==k2,2.928571429
options=opts,2.928571429
optimal config,2.928571429
config = currmodel,2.928571429
word_train_token+word_test_token,2.928571429
float16` work,2.928236083
url list,2.927172275
connected,2.926829268
couple outputs,2.926573427
call get_layer,2.926491994
x_c = flatten,2.926315789
"```



error

```

traceback",2.92627264
"error

###################################

traceback",2.92627264
"object

```



searched",2.926056338
directoryiterator object,2.926056338
random init,2.926027397
"fit_generator

    enqueuer",2.925549915
timedistributed doesn,2.925287356
"1924 

   1925         do_validation = bool",2.925
"2078 

   2079         do_validation = bool",2.925
history = big_model,2.924603175
make experiments,2.924475524
testpredict = model,2.92420453
model lack,2.92420453
predictions_valid = model,2.92420453
bottleneck_features_train = model,2.92420453
bottleneck_features_validation = model,2.92420453
probs2 = model,2.92420453
model_all = model,2.92420453
model_b = model,2.92420453
autoencoder_model = model,2.92420453
sample_output = model,2.92420453
evals = model,2.92420453
"noise_input
model",2.92420453
bug report,2.924162257
os = args,2.923924056
good job,2.92369727
y_true = np,2.923299747
nan`steps,2.921664532
constant volume,2.921568627
x_i = inputs[,2.921212121
decoder part,2.921052632
outputs=reshape,2.920778425
find information,2.920397226
ndim=len,2.920331651
kernel_initializer=randomuniform,2.920052425
embeddings,2.92
x_c = conv2d,2.919858156
equal dimensions,2.9198172
x_test = x_train,2.919083198
"run

    run_metadata_ptr",2.918715708
accuracy= metrics,2.917926793
metrics=[accuracy,2.917926793
metrics=[accuracy],2.917926793
368       int stride[2],2.917857143
freeze/graph,2.917793204
testing mode,2.917763158
supported depends,2.917582418
predict = model,2.916958153
set_learning_phase affects,2.916666667
putting set_learning_phase,2.916666667
inception_feature2 = timedistributed,2.916666667
decoded_sequence = timedistributed,2.916666667
x_c = batchnormalization,2.916666667
fc_dt=timedistributed,2.916666667
time_dist_layer = timedistributed,2.916666667
img_feature_t0 = timedistributed,2.916666667
img_feature_t1 = timedistributed,2.916666667
idxs < b_active,2.916666667
docs_doc_encoder = timedistributed,2.916666667
te_y = create_pairs,2.916666667
calculating fscore,2.916666667
emb_words = timedistributed,2.916666667
emb_sents = timedistributed,2.916666667
encoded_frame_sequence = timedistributed,2.916666667
x_masked = timedistributed,2.916666667
encoded_rows = timedistributed,2.916666667
bidirectional_1,2.916666667
upsampling,2.916666667
[upsampling,2.916666667
line generates,2.916031653
"]

y_train = train[",2.915890026
"7]]

y_train = train[",2.915890026
y_train = train[,2.915890026
"-1]

    y_train = train[",2.915890026
suggest removing,2.915384615
timestep model,2.915195521
"= 3

        difference = tf",2.915173572
norm12 = tf,2.915173572
sq12 = 2 * tf,2.915173572
abval = tf,2.915173572
filename_queue = tf,2.915173572
shape=image_size,2.914046122
loss doesn,2.912642627
filters spatially,2.912280702
guys meet,2.912280702
keras_version  # pylint,2.911764706
annoying thing,2.911764706
vocabulary words,2.911538462
run windows 10,2.911196911
"0000e+00

epoch 2/2

1/1 [==============================]",2.911151223
"0000e+00

epoch 2/10

1/1 [==============================]",2.911151223
"0000e+00

epoch 5/10

1/1 [==============================]",2.911151223
"0000e+00

epoch 6/10

1/1 [==============================]",2.911151223
"0000e+00

epoch 7/10

1/1 [==============================]",2.911151223
classes = list,2.910993539
input_length=max_caption_len,2.910869565
file object,2.910492681
bit unsure,2.91025641
tf issue,2.909910414
expected int32,2.909773712
] + alpha * np,2.909726514
breaking change,2.909638554
give error,2.90935657
_traceback = _extract_stack,2.909090909
0/lib64,2.909090909
"flags
flags",2.909090909
targets = cast,2.908371041
"get_config

>   file",2.908349387
idea correct,2.907978142
labels array,2.907879275
946932 stored elements,2.907692308
72                 idx = slice,2.907407407
min_lr=1e-7,2.906932574
min_lr * 1e-4,2.906932574
"nb_filters = 32

# size",2.905852843
"epochs

model",2.905788323
"# arguments

            texts",2.905737705
ubuntu 16,2.905660377
"**

ubuntu 16",2.905660377
ubuntu,2.905660377
ubuntu 14,2.905660377
"errors



valueerror",2.905635649
densemodule = flatten,2.905103668
dimensionality error,2.905046225
windows terminal,2.904761905
y_val_new = to_categorical,2.904761905
suitable problem,2.904258726
loss displayed,2.904021938
"shape[0]

memoryerror",2.903945111
shape[2]*curr_layer,2.903945111
shape[3]*curr_layer,2.903945111
y_pred = np,2.90382792
per_process_gpu_memory_fraction call,2.90268247
#print type,2.902293725
print type,2.902293725
input_shape=model,2.901795566
`random normal`,2.901784973
lstm2=lstm,2.901465201
lstm timestamp,2.901465201
"]

    x_test_1 = x_test[",2.901384083
"]

    x_test_2 = x_test[",2.901384083
x_testflat = x_test,2.901384083
seta = flatten,2.901315789
-> 2230                                                class_weight=class_weight,2.9
images_to_read = x_valid_cv,2.9
1635             class_weight=class_weight,2.9
problems understanding,2.9
"[loss_3]

      # out4",2.9
arduino hardware,2.9
class_weight=class_weight,2.9
869                               class_weight=class_weight,2.9
_1&space,2.9
861                               class_weight=class_weight,2.9
1356             class_weight=class_weight,2.9
843                               class_weight=class_weight,2.9
663                               class_weight=class_weight,2.9
279         preprocessed array,2.899771167
input_length=max_len,2.899758454
c_p] * y_true[,2.898989899
"6000 samples

info",2.898702502
model stored,2.898563504
"2558 trials

22 channels",2.898550725
"h5

model_loaded",2.898387097
serialize object,2.89827856
>     y_true = tf,2.897496805
y_true = tf,2.897496805
y_true * tf,2.897496805
y_true*tf,2.897496805
dense_list = list,2.896869245
documentsarray=list,2.896869245
templist=list,2.896869245
label_instance_shape = list,2.896869245
`-1` means decrease,2.896825397
"n_cases]



# train",2.896799117
scores = scoring,2.89673913
read y_true,2.896556809
l1 & l2,2.896434635
densemodule = batchnormalization,2.895454545
curr_layer = batchnormalization,2.895454545
sess=sess,2.894736842
segmentation,2.894736842
"loss

plt",2.894218016
recent_fit = lanes,2.893939394
x_fc = dense,2.893736952
range index,2.893489349
seq2seq,2.892857143
#weights array,2.892443581
setting padding=,2.891743119
non-,2.891566265
"4



trial_batch_1 = np",2.890976514
> vec_x = np,2.890976514
x0 = np,2.890976514
data_in = np,2.890976514
dense_layer = model,2.890871196
357         dtype = floatx,2.890849322
float beta,2.890466531
decoded = conv2d,2.888905775
902       data_format=data_format,2.888888889
data_format=data_format,2.888888889
input_tensors=input_tensors,2.888888889
approaches couldn,2.888888889
ytrain = ytrain,2.888888889
accepts,2.888888889
batch_x_middle = batch_x_middle,2.888888889
expected axis -1,2.888709677
shape error,2.888536791
"# arguments

            y_true",2.888060937
device scope,2.887650086
"error

```

runtimeerror",2.887189082
values = line,2.885951439
input_shape fails,2.88592437
input_length=max_sequence_length,2.885869565
"3-channels]

outputs",2.885730212
merged = concatenate,2.885724585
closed due,2.884615385
= df[target_column],2.884615385
"error



invalidargumenterror",2.884212892
error `invalidargumenterror,2.884212892
written code,2.883344883
29   int *strides =,2.882843137
bias_initializer=bias,2.882142857
kernel_initializer=init,2.881957187
file handle,2.881495167
split train,2.881174117
random accuracy,2.880317826
train_data = train_data,2.88
# train_data = train_data,2.88
x1 = dense,2.879701864
"code

`print",2.879045201
model `concat,2.87900679
filters=num_filters,2.878947368
filters=num_filters*2,2.878947368
filters=num_filters*3,2.878947368
pretrained,2.878787879
y_pred = tf,2.878024978
code shown,2.877272009
"complains

valueerror",2.87706422
shape[0] // batch_size,2.876963472
shape[0]//batch_size,2.876963472
documentation mentions,2.876666667
steps_per_epoch=train_flow,2.876436782
shape=x_train,2.876189681
> x_train shape,2.876189681
shape[1]*x_train,2.876189681
shape[2]*x_train,2.876189681
x_train shape,2.876189681
outputs = fc1,2.876068376
pc_attention_vector = lambda,2.875468165
typeerror                                 traceback,2.875393082
"```

---------------------------------------------------------------------------

typeerror                                 traceback",2.875393082
"---------------------------------------------------------------------------

typeerror                                 traceback",2.875393082
tf bug,2.875050115
model_dir = model_dir,2.875
past,2.875
model_dir=model_dir,2.875
optimize h0,2.875
forget gates,2.875
"fit_generator

    generator_output =",2.874267864
"fit_generator

>     generator_output =",2.874267864
class_weight option,2.874242424
`class_weight` option,2.874242424
155                          float alpha,2.873922414
"found ndim=6

`",2.873781676
"found ndim=5

```",2.873781676
found ndim=4`,2.873781676
found ndim=2`,2.873781676
found ndim=2,2.873781676
"found ndim=4

```",2.873781676
found ndim=4,2.873781676
valueerror                                traceback,2.873290635
"> ---------------------------------------------------------------------------

> valueerror                                traceback",2.873290635
"---------------------------------------------------------------------------

valueerror                                traceback",2.873290635
"===================================================



-------------------------------------------------------------------------------------------------------------------------------------------valueerror                   traceback",2.873290635
"```

---------------------------------------------------------------------------

valueerror                                traceback",2.873290635
> valueerror                                traceback,2.873290635
samples = ins[0],2.872740964
3d,2.871794872
beta-vae,2.871657754
py generator,2.871601651
logs/model,2.871359001
"process_layer

  file",2.87079998
"output_dim]

            z1 =",2.87037037
"output_dim]

            z2 =",2.87037037
"output_dim]

            z3 =",2.87037037
output_dim=dh,2.87037037
random seed,2.870171541
y_test = to_categorical,2.869771113
issue referenced,2.869736842
alt,2.869565217
alt=,2.869565217
"// batch_size



# fit",2.869174309
validation_data=test_iterator,2.868932039
validation_data=val_gen,2.868932039
validation_data=generate_data_from_file,2.868932039
dense1 = dense,2.868736952
combinedx=dense,2.868736952
finally finding,2.868421053
outputs=y_pred,2.866697559
sentence appears,2.866666667
input_shape=image_size,2.866479925
[ipython,2.865853659
ipython = 6,2.865853659
ipython,2.865853659
ipython 6,2.865853659
x3=maxpooling2d,2.865223464
s1s2 = tf,2.865173572
"frame

            print",2.864931087
"from_config

  file",2.864871126
line throws,2.864561065
x2 = dense,2.864107322
error msg,2.863379558
happening immediately,2.863157895
kernel_size= kernel,2.862977212
model_path = os,2.862588652
"0

__________________________________________________________________________________________________",2.861842105
"0

__________________________________________________________________________________________________

```",2.861842105
pool = maxpooling1d,2.861751152
selected items,2.860696517
299                       metrics=metrics,2.860606061
metrics=metrics,2.860606061
272                       metrics=metrics,2.860606061
flat1 = flatten,2.859649123
flat2 = flatten,2.859649123
encoded1 = flatten,2.859649123
flat_output = flatten,2.859649123
flatten_layer_dec = flatten,2.859649123
p_flat1 = flatten,2.859649123
v_flat1 = flatten,2.859649123
file resource,2.859436343
model found,2.859389715
input_tensor=mainmodel,2.859375
py located,2.859225413
"### issue

* code",2.858850956
shape=in_sh,2.858490566
shape=[sentence_length,2.858490566
shape=x_a_shape,2.858490566
shape=[output_len],2.858490566
shape=trainingdata[0],2.858490566
"shape[1]
    ppl = 0",2.858490566
steps_per_epoch = len,2.858171941
steps_per_epoch=len,2.858171941
steps_per_epoch= len,2.858171941
val_loss improved,2.858164033
inputlayer object,2.85787452
lambda y_true,2.857791397
problem doesn,2.85732386
densenet-121,2.857142857
densenet-201,2.857142857
algorithm,2.857142857
---> 56         output_types=output_types,2.857142857
densenet,2.857142857
tr_y=tr_y,2.857142857
interface,2.857142857
config=config,2.857142857
causing errors,2.857142857
geforce 1060,2.857142857
mu1=mu1,2.857142857
averages,2.857142857
work initially,2.856807512
"units]

            z1 =",2.856521739
"units]

            z2 =",2.856521739
"units]

            z3 =",2.856521739
save/load,2.856392662
"train_size]

x_test =",2.855929538
"model

print",2.855802284
print model,2.855802284
`lr/decay_mult`,2.855555556
lr=lr_init,2.855555556
216         reuse_previous_algo = apply_specific,2.855345912
activity_regularizer=l1,2.854251012
2110                                       mask=mask,2.853932584
607                                              mask=mask,2.853932584
outputs=[out1,2.853846154
repeat question,2.853703704
dense = flatten,2.853386075
conva = conv2d,2.853191489
convb = conv2d,2.853191489
conv11 = conv2d,2.853191489
conv12 = conv2d,2.853191489
conv21 = conv2d,2.853191489
conv22 = conv2d,2.853191489
decoded_data = conv2d,2.853191489
conv1_out = conv2d,2.853191489
conv2_out = conv2d,2.853191489
conv3_out = conv2d,2.853191489
conv4_out = conv2d,2.853191489
conv_2 = conv2d,2.853191489
conv_3 = conv2d,2.853191489
conv_5 = conv2d,2.853191489
bbox_output = conv2d,2.853191489
passthrough args,2.85300207
args = vars,2.85300207
"load_weights_from_hdf5_group

valueerror",2.85206422
"```

image_dim = 784

x_train",2.851032448
x_valid = np,2.850976514
"#fit

nb_files=18900",2.850701403
passing data_format,2.850694444
file format,2.850597959
key=lambda,2.850468165
b_norm = batchnormalization,2.85
fcn,2.85
ema_in_bn = batchnormalization,2.85
ema_lstm1_bn = batchnormalization,2.85
ema_lstm2_bn = batchnormalization,2.85
ema_dense1_bn = batchnormalization,2.85
ema_dense2_bn = batchnormalization,2.85
ema_dense3_bn = batchnormalization,2.85
flatten_layer_dec = batchnormalization,2.85
batch1 = batchnormalization,2.85
batch2 = batchnormalization,2.85
p_batch1 = batchnormalization,2.85
v_batch1 = batchnormalization,2.85
[fcn,2.85
filter_length=fl,2.85
"=-1



y_valid= np",2.848871251
perplexity computed,2.848051948
"error 

_",2.847119396
typically train,2.846799117
z_log_var = dense,2.846678128
model %>% compile,2.846494918
"#compile



model",2.846494918
doc,2.846153846
res,2.846153846
[res],2.846153846
factor = factor,2.846153846
val_acc improved,2.846023689
bias_initializer= constant,2.845378151
gist https,2.844924944
gist [https,2.844924944
min case,2.844755245
input_length=sequence_len,2.844202899
dense2 = dense,2.843736952
dense2 =dense,2.843736952
index + sequence_length],2.843705799
"deserialize_keras_object

  file",2.843131995
movieid = ratings,2.842857143
library],2.842592593
library,2.842592593
#NAME?,2.842592593
test_image = test_image,2.842105263
outputs=softmax,2.841919548
`img `array,2.841172441
pretrained_cnn1 = model,2.840871196
pretrained_cnn2 = model,2.840871196
preds_test_fold = model,2.840871196
"detail

----------------

model",2.840871196
meaning model,2.840871196
auto_encoder_embedding = model,2.840871196
metrics_tensors += model,2.840871196
ema_model = model,2.840871196
x_trainf = model,2.840871196
y_train = to_categorical,2.840519481
y_train= to_categorical,2.840519481
labels=y_true,2.84043134
dont thing,2.840336134
epochs=nb_epoch,2.840169652
nb_epoch=epochs,2.840169652
#NAME?,2.84
code ran,2.839920566
height = img,2.839908737
"654                 summary_str = result[0]

    655",2.839662447
"```

json_file = open",2.839130435
output padding,2.838898619
sample_weight=sample_weights,2.838461538
"]

            sample_weight = sample_weights[",2.838461538
md5=info[,2.838461538
ascii format,2.838383838
create issue,2.838070175
conv1d model,2.838062208
"inputs = []

            # retrieve",2.837878788
exist means,2.836996337
pr https,2.836712383
train epoch,2.835728118
"+batch_size]

            _",2.835546077
precision * recall,2.835526316
precision + recall,2.835526316
"texts_to_sequences_generator
  file",2.834436343
fix error,2.834394051
loss = metrics,2.834324968
"metrics

loss =",2.834324968
loss metrics,2.834324968
classes = model2,2.833944114
fit_generator` fails,2.833883249
action_prob = np,2.833833657
xtrue = np,2.833833657
x_batch=x_train,2.833488589
"batch_size=1

          epochs=1",2.833390033
dockerfile,2.833333333
rho=rho,2.833333333
schedule = schedule,2.833333333
builds,2.833333333
imdb_lstm,2.833333333
nested,2.833333333
"timedistributed

seq",2.833333333
ls,2.833333333
[dockerfile],2.833333333
e5,2.833333333
`sequential_2`,2.833333333
reproduced faster,2.833333333
"layer_from_config



```",2.833333333
_c_op = _create_c_op,2.833333333
"{

rankdir=tb",2.833333333
"_run_fn

    options",2.833333333
imagepatches[lowerindex,2.833333333
lets suppose,2.833333333
sorted_voc = [wc[0],2.833333333
"combinations

**den_total_sample**",2.833333333
"_do_run

    options",2.833333333
ssim /= denom,2.833333333
author optimizes,2.833333333
input_dim=embedding_dims+1,2.833333333
softargmax = spatial_softargmax,2.833333333
dramatically reduce,2.833333333
layer_output = get_1st_layer_output,2.833333333
ax = fig,2.833333333
input_dim=in_out_neurons,2.833333333
dense_shape=x_shape,2.833333333
input_dim=input_dimi,2.833333333
dimstate+dimaction,2.833333333
trainset = imagefolder,2.833333333
trainloader = dataloader,2.833333333
update_delta = _zero_debias,2.833333333
[openai gym],2.833333333
`lr_mult`/`decay_mult`,2.833333333
pred_idx = test_y[,2.833333333
optimizer=adadelta,2.832932331
"`

`         optimizer=adadelta",2.832932331
densemodule = dropout,2.832810867
loss turns,2.832593366
exact number,2.832298137
batches--8 workers,2.831871345
norm1 = tf,2.831840239
preds = final_model,2.831168831
understanding metrics,2.83030303
mistake / error,2.830046225
"]

y2=df[",2.829059829
seta = dropout,2.829022989
input_shape=x_train,2.828623485
imagine train,2.828617299
"fit



```

valueerror",2.827765623
random iteration,2.827476673
weights file,2.827108757
policy_out = dense,2.827070285
value_out = dense,2.827070285
latent_vec = dense,2.827070285
net_a = dense,2.827070285
ema_dense1 = dense,2.827070285
ema_dense2 = dense,2.827070285
ema_dense3 = dense,2.827070285
ema_output = dense,2.827070285
documentation looked,2.826666667
json file,2.826541606
width-axis,2.826437588
ran oom,2.825806452
softmax type,2.825436032
model file,2.82530754
nb_epoch=nb_epochs,2.825252525
signature = tf,2.825173572
shape=[num_filters],2.825157233
"```



model summary",2.825048412
model summary,2.825048412
details refer,2.825
running code,2.824857916
filters=filters,2.824561404
"14

reading https",2.82416758
reading https,2.82416758
kernel_initializer=initializer,2.824033689
"load_weights_from_hdf5_group

    str",2.823598131
47 variables,2.823529412
variables,2.823529412
variables`,2.823529412
3 variables,2.823529412
dot product,2.822916667
main_output = activation,2.822393472
`activation` instances,2.822393472
input_length = input_shape[1],2.821793935
hot,2.820512821
1-hot,2.820512821
outputs=prediction1,2.820512821
suitable answer,2.81871345
image_ocr,2.818181818
padding = maxlen,2.817549571
input_shape=dimensions,2.816948466
part due,2.815789474
syntax error,2.815760511
problem appears,2.815369837
kernel_initializer=glorot_uniform,2.81529052
kernel_initializer = glorot_uniform,2.81529052
filesize = len,2.815068493
285     gpus_available = len,2.815068493
"]



        train_steps = len",2.815068493
num_files_0 = len,2.815068493
num_files_1 = len,2.815068493
test_num = len,2.815068493
epochs=max_epoch,2.814917127
wrappers,2.814814815
train_size+test_size,2.814545455
sklearn,2.81443299
sklearn 0,2.81443299
#sklearn,2.81443299
"0

sklearn",2.81443299
`momentum` variable,2.813968254
behavior intended,2.813492063
# serialize model,2.813093419
model3 = model,2.813093419
y_pred[start,2.812851406
predict = model2,2.812573443
set_random_seed,2.8125
obtain,2.8125
kernels],2.8125
progress,2.8125
kernels,2.8125
discussion point,2.8125
"kernels

221         //",2.8125
curr_layer = reshape,2.812386816
input_shape=xtrain,2.81092437
--> 609                                              input_length=timesteps,2.810869565
input_length=timesteps,2.810869565
error `attributeerror,2.810747979
"error



attributeerror",2.810747979
"] = img





y_train[0",2.810492183
fix dimensions,2.810371922
logic bug,2.809876543
2177                 output_generator = enqueuer,2.80952381
find documentation,2.809358974
optimizer=tfoptimizer,2.809122807
happy make,2.809090909
make [launching],2.809090909
html#details,2.808974359
embeddings_initializer=initializer,2.808743169
`cols` == `width`,2.808695652
array doesn,2.808391857
"__call__

  file",2.808349387
loss=loss,2.808043876
loss=[loss,2.808043876
loss=[loss],2.808043876
x_c = maxpooling2d,2.80689013
numpy,2.806034483
"6

numpy",2.806034483
#NAME?,2.806034483
`numpy,2.806034483
> numpy,2.806034483
"11

numpy==1",2.806034483
"0

numpy",2.806034483
numpy>=1,2.806034483
split holdout,2.805803571
channels_first format,2.805350805
short gist,2.805147426
"integer

    bbox",2.805
easiest fix,2.804347826
obvious fix,2.804347826
fix problems,2.804347826
target_size=[width,2.803817603
y_pred = model,2.803722602
tuple/list,2.803535912
shape mismatch,2.80293501
copy-paste,2.802930057
"300000]

x_test = x_test[0",2.802768166
x_test = x_test,2.802768166
x_test = x_test/255,2.802768166
passes [x1,2.802631579
1 + decay * epoch,2.802262335
n_hidden= np,2.802087625
batch_y=np,2.802087625
running  `model,2.801614998
running model,2.801614998
@dref360,2.8
model_gen,2.8
device_type == device_type,2.8
functional,2.8
suggest extending,2.8
expectation_2 = expectation_2*2         #,2.8
typo mistake,2.8
713                        pos_label=pos_label,2.8
facing difficulty,2.8
array_dim = array_dim,2.8
array_dim=array_dim,2.8
coords = coords,2.8
`state_spec`,2.8
`embedding_network_title`,2.8
predict_text = predict_text[,2.8
timesteps=max_sentence_length,2.8
tutorials,2.8
descriptor,2.8
//medium,2.8
675       preferred_dtype=preferred_dtype,2.8
max_q_size=max_q_size,2.8
saver = saver,2.8
hidden_len = hidden_len,2.8
code expect,2.799299299
"{}

     batch_size = logs",2.798960711
height-desired_height,2.798507463
shape=train_data,2.798490566
activation object,2.79844981
behavior changed,2.798048048
eval = model,2.797767748
val_loss metric,2.796982599
loss passed,2.796879081
"outputs follow**



**",2.796703297
add serialization,2.796485596
"hdf5

traceback",2.796226415
# rgb part,2.795789474
"compile

    sample_weight",2.79408526
classify items,2.794029851
great idea,2.793809524
dense_layer = dense,2.793736952
"break



    # update",2.793650794
progbar creates,2.793650794
predict_generator won,2.793650794
error shown,2.79320412
exact condition,2.792207792
expected range,2.792179863
8xlarge instance,2.791666667
model_a = model,2.790871196
l_pool1 = maxpooling1d,2.790322581
l_pool2 = maxpooling1d,2.790322581
activation=_activation,2.789060139
train_loss/float,2.788505747
merge_images = concat,2.788135593
document=document,2.787878788
z_mean = dense,2.787854599
drop2 = dropout,2.787356322
endoder_1_dropout=dropout,2.787356322
decoder_2_dropout=dropout,2.787356322
embedded_sequences1 = dropout,2.787356322
gmax = dropout,2.787356322
pool2 = dropout,2.787356322
pool5 = dropout,2.787356322
pool6 = dropout,2.787356322
encoded_music=dropout,2.787356322
interesting question,2.787037037
compiled model,2.786949628
model compiled,2.786949628
show issue,2.785277383
comment shown,2.784897025
run form,2.784212784
lr=learning_rate,2.784126984
* add lstm,2.783665083
problem approach,2.783485779
"batch_size = 128       



    print",2.783403994
"batch_size = 32



print",2.783403994
decoded = conv1d,2.782905297
nhwc format,2.782828283
"```

print x_train",2.782630202
supports,2.782608696
running variance,2.782172373
"deserialize

  file",2.782055391
suffix = str,2.781931464
[total_loss] + metrics_tensors,2.781914894
seta = maxpooling2d,2.78189013
imagine percentage,2.781818182
context manager,2.781609195
posted code,2.780780781
code introduced,2.780780781
contribute code,2.780780781
tf_graph = sess,2.780701754
"error



internalerror",2.780046225
en error,2.780046225
assign round,2.779956427
"model

epoch 1",2.779800198
"epoch

                model",2.779800198
loss isn,2.779021938
101] allocation,2.777777778
matmul,2.777777778
model_to_dot,2.777777778
training_generator,2.777777778
picture segmented,2.777777778
"fit_generator

    batch_size =",2.777356155
kernel_initializer=config,2.777195282
"fit_generator



**script 02",2.776649746
y_pred = list,2.776387317
outputs = activation,2.776239626
img_input = input_tensor,2.776041667
tf py 2,2.774398986
data2 = np,2.774309848
expect inputs,2.773063973
asarray loads,2.772727273
x1=x1,2.771929825
"dense



# path",2.77151473
_**question 1,2.770776874
validation_data = [x_test,2.770316122
changed due,2.77027027
codebases written,2.769230769
found warning,2.768518519
nchannels = x_train,2.767699115
resolve memoryerror,2.767676768
input_t = reshape,2.766932271
feature_t = reshape,2.766932271
encoded_music=reshape,2.766932271
fixed bug,2.765432099
print classification_report,2.764931087
"y_test_pred



print",2.764931087
"#

print mydata",2.764931087
print repr,2.764931087
"#error

  file",2.764482568
"error---

file",2.764482568
"```



**error**  

```

  file",2.764482568
empty array,2.764056881
metrics=[crossentropy,2.763636364
metrics = [sig_eq],2.763636364
201             chunks = list,2.763535912
char_list = list,2.763535912
logical answer,2.763157895
cnn1 = convolution1d,2.763157895
paper https,2.762638309
"np

nb_classes = 10",2.762405086
# resized = resized,2.761904762
config=conf,2.761904762
shape[1]*x_test,2.759874649
shape[2]*x_test,2.759874649
x_test shape,2.759874649
x_fc = flatten,2.759649123
conv1 = conv2d,2.759441489
"`

`conv1 = conv2d",2.759441489
renamed `epochs`,2.759361572
estimator,2.759259259
understanding shape,2.758490566
gtx 1080,2.757575758
gtx 1070,2.757575758
"categorical_accuracy]

model",2.757537863
std returns,2.757461118
test_data = test_data,2.756756757
# test_data = test_data,2.756756757
ve made,2.756694215
title description,2.756410256
x1-x2,2.756335283
"assert_input_compatibility

    str",2.756290439
"```

run_metadata = tf",2.756082663
gpu_options = tf,2.756082663
py train -,2.75602453
`evaluate` / `evaluate_generator`,2.755952381
words present,2.755656109
lr=5e-3,2.755555556
x2=df[,2.754985755
> update model1,2.754891104
classes[idx],2.754865035
"train_size]

y_test =",2.752887996
std=stddev,2.752639517
train_data = ins,2.7525
bias update,2.751984127
input_shape=train_data,2.75092437
target_size=image_size,2.750677507
"```

invalidargumenterror                      traceback",2.750393082
keras,2.750193648
keras 1,2.750193648
keras 2,2.750193648
`keras,2.750193648
//keras,2.750193648
"```

keras",2.750193648
"5

keras 2",2.750193648
"0

keras",2.750193648
<keras,2.750193648
* keras,2.750193648
5-keras-2,2.750193648
keras ==2,2.750193648
#NAME?,2.750193648
"7

keras 2",2.750193648
[keras],2.750193648
4/keras 2,2.750193648
**keras,2.750193648
[keras 2,2.750193648
> keras,2.750193648
"0

keras 2",2.750193648
"9999999

keras==2",2.750193648
keras-2,2.750193648
"3

keras",2.750193648
[<keras,2.750193648
>keras 2,2.750193648
>keras 1,2.750193648
keras==2,2.750193648
/keras,2.750193648
%keras,2.750193648
"```





keras",2.750193648
keras`2,2.750193648
>>> keras,2.750193648
"### 



-keras 2",2.750193648
**keras 2,2.750193648
"1

keras==2",2.750193648
"6

keras==2",2.750193648
4 + keras 2,2.750193648
keras = 2,2.750193648
**keras**,2.750193648
keras=2,2.750193648
#NAME?,2.750193648
* keras 2,2.750193648
`keras`,2.750193648
keras],2.750193648
#NAME?,2.750193648
"2

keras",2.750193648
keras #5358,2.750193648
## keras 2,2.750193648
keras`,2.750193648
[keras,2.750193648
"```
keras",2.750193648
inception_feature1 = timedistributed,2.75
/tmp,2.75
"3

    x_trainrosreshaped = x_trainros",2.75
"3

    x_testrosreshaped = x_testros",2.75
dropout_w=param_dropout_w,2.75
stays,2.75
principle difference,2.75
style,2.75
number_of_record=0,2.75
number_of_record,2.75
decisiontreeclassifier,2.75
"noised

    constensor =",2.75
#NAME?,2.75
comparison,2.75
[loss_1,2.75
"metric_2]

      # out3",2.75
img_pred-img_true,2.75
sharing,2.75
poorly documented,2.75
origin_predict = block5_conv1,2.75
"114*14

style_predict = block5_conv1",2.75
num_files_train_1 * 2,2.75
seq_encoded = timedistributed,2.75
this-,2.75
analyse/visualise,2.75
mention,2.75
eventually cut,2.75
json_model = json_file,2.75
char_embedding_size,2.75
tmp,2.75
sampler=sampler,2.75
"9810us  cuinit

  0",2.75
num chars,2.75
"needed



valueerror",2.749791493
err = sess,2.749694002
"10000 samples

epoch 1/12",2.749169965
"10000 samples

epoch 1/8",2.749169965
kernel_initializer=glorot_normal,2.748623853
shape=[max_len],2.747379455
validation_data=test_data,2.747310417
l_cov1= conv1d,2.747191011
l_cov2 = conv1d,2.747191011
l_cov3 = conv1d,2.747191011
"_deepcopy_list

>     append",2.746838302
x1=flatten,2.745614035
328       case cudnn_convolution_fwd_algo_implicit_precomp_gemm,2.744755245
issue today,2.744736842
"batch_index=0`

`gen_submission_test_batches",2.744444444
`mean_squared_error` loss,2.744021938
loss=mean_squared_error,2.744021938
mean_squared_error loss,2.744021938
la_dense1 = dense,2.743736952
clas = dense,2.743736952
# df shape,2.743105951
file doesn,2.743057033
zipped = zip,2.742424242
np_y_pred = zip,2.742424242
documentation https,2.741156828
csv_file=csv,2.740909091
shortcut = convolution2d,2.74084507
gather,2.740740741
output_dim = output_dim,2.740740741
gather`,2.740740741
gather`],2.740740741
x2=x2,2.740740741
words = [txt,2.740608229
pool2 = maxpooling2d,2.740223464
pool11 = maxpooling2d,2.740223464
pool12 = maxpooling2d,2.740223464
pool21 = maxpooling2d,2.740223464
pool22 = maxpooling2d,2.740223464
encoded_data = maxpooling2d,2.740223464
h5 model,2.739258293
x1=conv2d,2.739156402
145 bool apply_specific,2.738679245
"#categorical_crossentropy

model",2.738239617
validation_data = validation_data,2.737864078
accuracy drop 10%,2.737623762
accuracy drop 30%,2.737623762
kld loss,2.737355271
reduce number,2.737060041
ve run,2.736462555
encoder_sampled = model,2.733728339
wikipedia pages,2.733333333
input_dim=emb,2.733333333
1858                                         initializer=bias_initializer,2.732552693
10 [units]*4 [gates],2.731521739
ve googled,2.730027548
ve switched,2.730027548
ve instantiated,2.730027548
x2=flatten,2.730019493
"---------------------------------------------------------------------------

unboundlocalerror                         traceback",2.729559748
"```

```

resourceexhaustederror                    traceback",2.729559748
github repo,2.729442971
wrong thing,2.728837877
"code

https",2.728604275
code https,2.728604275
code- https,2.728604275
running script,2.728510299
conv2 = conv2d,2.728191489
find ways,2.728146853
channel,2.727272727
"channel

---> 29",2.727272727
1 channel,2.727272727
concat = concatenate,2.726491758
year passed,2.726190476
channels = dense,2.72562101
csv file,2.725345434
key hold,2.725
key == ord,2.725
eval script,2.724663049
"dump

    forkingpickler",2.724637681
train_loss += model,2.72420453
x2=conv2d,2.72356186
"conv2d

    output_dim",2.72356186
create link,2.723541667
txt form,2.723514212
google groups,2.722727273
peculiar situation,2.722222222
wrong number,2.720799879
"texts]
unique = []",2.720588235
test_size=test_size,2.72
copy/pasted,2.719596723
important thing,2.719457014
flatten = flatten,2.719298246
flatten=flatten,2.719298246
"error

```

epoch 00001",2.718975226
bug doesn,2.718497233
flatten shape,2.718139689
ide closed,2.717948718
put input_dim,2.717948718
"axis=-1

    square_sum =",2.717741935
shape=shape,2.716981132
conv3 = conv2d,2.716827853
fc1 = dense,2.715959174
noofinstances = len,2.715068493
start https,2.714490161
dropout mask,2.714322614
regression,2.714285714
enable,2.714285714
imdb,2.714285714
mnist_siamese,2.714285714
#NAME?,2.714285714
cells,2.714285714
"0496

    batch_normalization_1

    0",2.714285714
**dask,2.714285714
rotate,2.714285714
dask,2.714285714
nb_epoch=epoch,2.714181526
"activation



model",2.713264669
units = units,2.713043478
found mismatch,2.712962963
y_pred-other_tensor,2.712851406
y_pred = _check_targets,2.712851406
filters=mc,2.712280702
rgb channels,2.711884058
3 rgb channels,2.711884058
nb_epoch=args,2.711587929
issue appears,2.711403509
lr=lr,2.711111111
running pydoc,2.710743802
"batch_set_value

    get_session",2.710526316
summary returns,2.709587051
subtensor{int64,2.709414381
subtensor{int64},2.709414381
print rnn_x,2.709375532
order words,2.708291708
finally run,2.708189392
"621         }

622         void cleanup",2.707692308
"fit_generator

    str",2.70748138
`const`,2.705882353
labels don,2.705123033
"train_data /= 255

print",2.704931087
batch_size=args,2.70480831
tensorflow,2.704545455
<tensorflow,2.704545455
"6

tensorflow 1",2.704545455
"5

tensorflow==1",2.704545455
tensorflow 1,2.704545455
"0

tensorflow 1",2.704545455
"6

* tensorflow",2.704545455
"0196

* tensorflow",2.704545455
"9939

* tensorflow",2.704545455
tensorflow�,2.704545455
"2

tensorflow 1",2.704545455
[tensorflow],2.704545455
tensorflow =,2.704545455
"5

tensorflow",2.704545455
[tensorflow,2.704545455
** tensorflow,2.704545455
5 & tensorflow 1,2.704545455
tensorflow],2.704545455
> tensorflow,2.704545455
tensorflow-1,2.704545455
"0

tensorflow==1",2.704545455
tensorflow `1,2.704545455
"8

tensorflow",2.704545455
[`tensorflow,2.704545455
**tensorflow,2.704545455
tensorflow 0,2.704545455
0 tensorflow 1,2.704545455
tensorflow==1,2.704545455
5 + tensorflow,2.704545455
"tensorflow**

2",2.704545455
* tensorflow 1,2.704545455
"640

tensorflow",2.704545455
"1625



tensorflow",2.704545455
"```

tensorflow",2.704545455
`tensorflow`,2.704545455
3/tensorflow,2.704545455
#NAME?,2.704545455
key point,2.704166667
output_dim= embed_size,2.703703704
"**background**

https",2.702725455
output_shape_ = output_shape,2.702380952
model move,2.701982307
py model,2.70009661
class_weight = class_weights,2.7
cikis = af,2.7
* intersection + smooth,2.7
output_fld = input_fld +,2.7
class_weight=class_weights,2.7
mask callable,2.699693565
pass `strides`,2.699392433
failure case,2.699300699
"] = img



   

   

y_valid[0",2.699296011
"code

#train_x",2.697447447
242         model_config = json,2.697368421
232         model_config = json,2.697368421
"axis]

typeerror",2.696908602
ve implemented,2.696694215
"]

inputs strides",2.695721925
repeated_decoded_mean = rv,2.695652174
classes=classes,2.694915254
dense2_out = dense,2.693736952
flat_input = flatten,2.692982456
face,2.692307692
#NAME?,2.692307692
shape # => tensorshape,2.691823899
shape=input_dim,2.691823899
inference part,2.690789474
samples fed,2.690675746
work operate,2.690140845
"_make_train_function

    loss=",2.689736224
"_make_train_function

        loss=",2.689736224
x_c = activation,2.689060139
epoch ends,2.688929001
short code,2.688826758
filepath=checkpoint_file,2.688405797
inputs=[encoder_input,2.687878788
float32 assuming,2.687719298
networks,2.6875
level,2.6875
inference mode,2.6875
dummy,2.6875
pool3 = dropout,2.687356322
idea whats,2.686666667
conv_4 = conv2d,2.686524823
conv_out = conv2d,2.686524823
"test_image /= 255

print",2.685983719
"set_weights

valueerror",2.685397554
batch_size=numbatches,2.685139573
"+batch_size]

            y_batch=",2.685139573
recommended approach,2.684782609
"loss

attributeerror",2.684723692
`y_true` means,2.684704185
"{}

        loss = logs",2.684509743
"spec



  file",2.684436343
"fit 

val_score",2.684034736
conv_out = batchnormalization,2.683333333
batch3 = batchnormalization,2.683333333
training,2.68286445
# training,2.68286445
training=,2.68286445
training 120,2.68286445
"training

*",2.68286445
`training,2.68286445
> training,2.68286445
65% training,2.68286445
[training,2.68286445
surely find,2.682692308
seta = convolution2d,2.682511737
tensorshape problem,2.682036503
problem description,2.682036503
problem persist,2.682036503
jpg format,2.68195109
"```

assertionerror                            traceback",2.681940701
"> epoch 1/5

> exception",2.681886748
model_from_config,2.681818182
"load_weights

    load_weights_from_hdf5_group_by_name",2.681818182
softmax = dense,2.681810346
output_shape=input_shape,2.679971989
"tests/

```",2.678571429
tests,2.678571429
3 tests,2.678571429
valid indices,2.678291194
"valid indices

```",2.678291194
input_length=seq_length,2.677536232
checked min,2.677419355
line vae,2.677395289
"```

attributeerror                            traceback",2.676928169
"```

---------------------------------------------------------------------------

attributeerror                            traceback",2.676928169
"---------------------------------------------------------------------------

attributeerror                            traceback",2.676928169
attributeerror                            traceback,2.676928169
"```
   ---------------------------------------------------------------------------
attributeerror                            traceback",2.676928169
wrong place,2.67604753
wrong shape,2.675563737
output_dim=embedding_dim,2.674718196
short paragraph,2.674712644
"}



max_features = len",2.67221135
"#### warnings

```

info",2.671794872
"paper 



http",2.671269535
"input_tensor

    input_shape",2.67029937
channels = concatenate,2.670240222
people understand,2.669573643
ve needed,2.669421488
shape=input_shape,2.669414936
shape=input_shape[1,2.669414936
shape=input_shape[0],2.669414936
shape=input_shape[1],2.669414936
conv1=convolution1d,2.669407895
dropout applied,2.668308703
issue title,2.667813765
change max_queue_size,2.66770307
conv10 = reshape,2.666932271
dropout_u=param_dropout_u,2.666666667
_keras_shape = output_shapes[,2.666666667
target_shape=conv_to_rnn_dims,2.666666667
predict_data = pad_sequences,2.666666667
total_samples = hdf5data[,2.666666667
fixed_generator,2.666666667
strict,2.666666667
xception,2.666666667
prints,2.666666667
@bzamecnik,2.666666667
2s,2.666666667
input_dim = input_dim,2.666666667
"==================================================================================================

input_9",2.666666667
noise_shape=noise_shape,2.666666667
dense_4,2.666666667
src_model,2.666666667
[src_model,2.666666667
frequency,2.666666667
densenet121,2.666666667
return_train_score=return_train_score,2.666666667
deepface,2.666666667
environments,2.666666667
till,2.666666667
y_true_f * y_pred_f,2.666666667
noise_shape = noise_shape,2.666666667
gen_handle = gen_handle,2.666666667
`graph_editor`,2.666666667
challenge,2.666666667
incorporate,2.666666667
ocr,2.666666667
operations,2.666666667
advanced_activations,2.666666667
@edersantana,2.666666667
# prints,2.666666667
executes,2.666666667
objectives,2.666666667
"convs1=[]
    convs2=[]",2.666666667
line `adversarial_model,2.666031653
ve written,2.665924984
ve found,2.665212733
print my_layer,2.664931087
"glorot_normal



print",2.664931087
solution found [,2.664744934
empty street,2.664285714
zeros elements,2.663829787
config file,2.663007772
combinedx=dropout,2.662356322
pool1 = dropout,2.662356322
dense1 = dropout,2.662356322
"_do_run

    run_metadata",2.662337662
max_queue_size  + number,2.661791224
prediction1 = dense,2.660403619
mu = dense,2.660403619
shape[0]/timesteps,2.658490566
# fit loop,2.65839371
array shape,2.658261733
maxsize=max_queue_size,2.658064516
removing line 257,2.656416268
binary_crossentropy loss,2.65627419
boxes show,2.654826255
line graph,2.654477031
loss=_loss,2.654021938
key errors,2.653571429
"active_next]

    # copy",2.652930057
"28x28

num_classes = 10 #",2.652777778
dim * sizeof,2.65248227
"make_tensor_proto

    _assertcompatible",2.65
`grucell` combine,2.65
"</details>



## observation",2.65
valid accuracy,2.649785925
equal rank,2.649087221
input_dim= len,2.648401826
input_dim = len,2.648401826
nb_cl = len,2.648401826
input_dim=len,2.648401826
"#%%

train_file_fp = h5",2.648387097
fit_generator effect,2.647772138
exception raised,2.6468039
ve searched,2.646694215
ve managed,2.646694215
"---------------------------------------------------------------------------

nameerror                                 traceback",2.646226415
adapt solution 3,2.646226415
supported/implemented,2.646153846
"text_to_word_sequence
typeerror",2.645833333
### copy weights,2.645602471
copy weights,2.645602471
# copy weights,2.645602471
bit confused,2.645550528
"input_dim = input_shape

            #",2.644257703
input_shape=input_dim,2.644257703
"__version__

print",2.644241432
timestep dim,2.64347326
batch_size=numsamples,2.643472906
"test_data /= 255

print",2.643309466
disk,2.642857143
1d,2.642857143
search,2.642857143
l_pool3 = globalmaxpooling1d,2.642857143
interested folks,2.642857143
fit/evaluate,2.642368069
thought people,2.641666667
pool3 = maxpooling2d,2.640223464
"num_layers = 15

print",2.639931087
step,2.639506173
step=1,2.639506173
# step 1,2.639506173
# step 2,2.639506173
# step 3,2.639506173
# step 4,2.639506173
step 50,2.639506173
step 51,2.639506173
step=0,2.639506173
"step 1

4",2.639506173
step 4,2.639506173
step 1],2.639506173
step 2,2.639506173
step 45,2.639506173
random order,2.639447311
"shape[0]

attributeerror",2.63919232
people don,2.638681592
"+1

look_back = 3

trainx",2.638461538
"[0]]

x0 = concatenate",2.638356164
fusion = concatenate,2.638356164
conv2=convolution1d,2.638157895
ve removed,2.638073525
dense2 = dropout,2.637356322
range indices,2.637341153
row presents,2.636363636
-> 2083             output_tensors,2.636363636
hdf5 file,2.634436343
issue exists,2.633625731
op_def,2.633333333
1732           op_def,2.633333333
chosen timesteps,2.633333333
"**attempted solutions**



1",2.633333333
file_name = list_data[,2.633333333
`128x128` array,2.6331045
wrong part,2.632862644
script https,2.632256658
"expand_dims

model",2.630086883
epochs=epochs,2.629834254
149         epochs=epochs,2.629834254
epochs = epochs,2.629834254
work needed,2.629534784
y_pred = timedistributed,2.629518072
found shape=,2.627009085
x1=maxpooling2d,2.626188376
size_input_image=input_size,2.625
downloads,2.625
--> 301                       sample_weight_mode=sample_weight_mode,2.625
property,2.625
**objective,2.625
--> 178                                           mode=mode,2.625
pandas,2.625
--> 274                       sample_weight_mode=sample_weight_mode,2.625
architectures,2.625
**pandas,2.625
`pandas,2.625
"2

pandas",2.625
acc = model,2.623805328
target_size=config,2.62369338
maxpool1 = maxpooling1d,2.623655914
l1 regularizer,2.623481781
important part,2.623481781
input_shape=ins,2.62342437
"shape

print",2.623421653
"shape[0]

            print",2.623421653
att_vec = activation,2.622393472
maxout activation,2.622393472
p_act1 = activation,2.622393472
v_act1 = activation,2.622393472
v_act2 = activation,2.622393472
v_output = activation,2.622393472
convout1 = activation,2.622393472
attention,2.622222222
**attention,2.622222222
y_pred = zip,2.621942315
input_shape=input_shape,2.621848739
input_shape = input_shape,2.621848739
input_shape[0][-1]+input_shape[1][-1],2.621848739
shuffled_dates = range,2.621212121
dropout1 = dropout,2.620689655
local_connect1 = dropout,2.620689655
output_dim=hidden_dim,2.62037037
freeze part,2.6201373
#NAME?,2.62
dimensionality issue,2.619736842
"save

>   file",2.617856032
save file,2.617856032
predict & evaluate,2.617753623
finished epoch,2.61750043
epoch hack,2.61750043
wrap `fit`,2.617368069
github problem,2.616607679
scalar loss,2.61614315
line fails,2.616031653
valid question,2.615865866
fit print,2.61563249
backward,2.615384615
pool1 = maxpooling2d,2.615223464
epochs=nb_epochs,2.614917127
> update model2,2.613470613
fit options,2.612606165
mse loss,2.611814146
i0 * i1,2.611111111
"#path

image_path =",2.611111111
my_file = path,2.611111111
x2=maxpooling2d,2.610593834
bit confusing,2.61025641
key parts,2.609615385
py#l779,2.609225413
py` resolves,2.609225413
shape=[n_output],2.608490566
extend evaluate_generator,2.607142857
ideal world,2.606060606
validation_split=test_size,2.605614035
base_model_output = globalaveragepooling2d,2.60483871
sparse_categorical_crossentropy loss,2.604021938
loss=sparse_categorical_crossentropy,2.604021938
determine loss,2.604021938
val_acc = model,2.603561552
"_**



assertionerror",2.602787456
check/build/,2.600948669
fit meaning,2.600701403
/average,2.6
average,2.6
average=,2.6
conv2d_transpose`,2.6
conv2d_transpose,2.6
concept,2.6
yt,2.6
avg_sum =,2.6
avg_sum,2.6
vggface,2.6
division,2.6
scan,2.6
cmpt,2.6
"50]`

`shape2 = [",2.6
optimizing,2.6
945us         2  21,2.6
73s,2.6
holds,2.6
"classes     

gtactual = []",2.597457627
easy job,2.596774194
ve included,2.596694215
ve looked,2.596694215
"300000] 

y_test = y_test[0",2.596685083
y_test = y_test,2.596685083
pattern = line,2.596587209
clear solution,2.596226415
supported wheel,2.596153846
"supported

419       // todo",2.596153846
obj = plt,2.593644354
"shape]

  file",2.592926909
epoch number,2.592655709
run cifar10_cnn_capsule,2.58976834
crop_height = args,2.586335404
crop_width = args,2.586335404
"fit

  file",2.585137746
ll send,2.584615385
open issue,2.583867277
weighted,2.583333333
input_dim=n_words,2.583333333
reshape part,2.582721745
b_lstm = add,2.582199882
add recurrentshop,2.582199882
"validation_data

        y_pred =",2.581783444
matrix_layer = conv1d,2.580524345
units=1*ngaussians,2.578743961
units=2*ngaussians,2.578743961
axis] += shape[,2.576232502
c1 = conv2d,2.575413712
dropout=dropout,2.574712644
open file,2.573566778
file = open,2.573566778
info file,2.572897882
summary info,2.572638754
#NAME?,2.571428571
`keras_learning_phase`,2.571428571
diff=0,2.571428571
diff,2.571428571
320                                 fit_params=fit_params,2.571428571
keras_learning_phase,2.571428571
diff =,2.571428571
`rows` == `height`,2.571234735
# error line,2.571077878
attribute `filters,2.570175439
file = <_io,2.567769677
5         squeeze = conv2d,2.567477204
reshape array,2.566703438
sep tells,2.566666667
range form,2.565656566
implement https,2.565470553
preprocessing,2.565217391
tutorial,2.565217391
"##preprocessing

#",2.565217391
tutorial],2.565217391
[ tutorial,2.565217391
filters=num_classes,2.56505848
dense_1,2.564516129
----> 6         squeeze = batchnormalization,2.564285714
106         identifier = str,2.563982746
121         identifier = str,2.563982746
_p_prev = zeros[,2.563829787
wrong order,2.563826417
named,2.5625
"0         

    embedding_1",2.5625
embedding_1,2.5625
v3,2.5625
logs = logs,2.56097561
75         logs = logs,2.56097561
>      71         logs = logs,2.56097561
73         logs = logs,2.56097561
shape=w_shape,2.558490566
trained,2.55704698
"trained



---",2.55704698
"load_weights

    load_weights_from_hdf5_group",2.556818182
"load_weights

load_weights_from_hdf5_group",2.556818182
dont understand,2.556478405
differences,2.555555556
`cifar10_resnet,2.555555556
cifar10_resnet,2.555555556
/cifar10_resnet,2.555555556
ranging,2.555555556
generation,2.555555556
topic,2.555555556
topic=,2.555555556
__init__,2.553763441
"__init__

``

``",2.553763441
"__init__

>",2.553763441
`__init__`,2.553763441
__init__`,2.553763441
width_shift_range=config,2.553571429
height_shift_range=config,2.553571429
leave conv2d,2.553191489
287     copy_spec = copy,2.552930057
important issue,2.55242915
"dropout



print",2.552287409
"_

  file",2.551509514
loss=categorical_crossentropy,2.551390359
categorical_crossentropy loss,2.551390359
`categorical_crossentropy` loss,2.551390359
loss `categorical_crossentropy`,2.551390359
loss *categorical_crossentropy,2.551390359
input_shape = tuple,2.55092437
lines throw,2.550135501
versions,2.55
0+ versions,2.55
split*len,2.549443493
ncl = y_pred,2.546184739
global,2.545454545
processing,2.545454545
"h5

traceback",2.544613512
running couldn,2.544077135
users,2.543956044
/users,2.543956044
sum mask,2.542755766
mask sum,2.542755766
picture shown,2.540935673
"error



userwarning",2.540462892
kindly check,2.540201005
num_words=max_features,2.538961039
"300000] 

y_train = y_train[0",2.538181818
"]

    y_train = y_train[0",2.538181818
y_train = y_train,2.538181818
endoder_2_dropout=dropout,2.537356322
pool4 = dropout,2.537356322
zoom_range=config,2.535714286
prediction_1= network_1,2.535714286
"changed

print",2.535201358
ran `make`,2.534897361
reshape = reshape,2.533864542
classes = args,2.533793031
misunderstanding sparse_categorical_crossentropy,2.533333333
`save_weights/load_weights`,2.533169533
save_weights/load_weights,2.533169533
y_true array,2.532094399
long,2.531914894
**loss update,2.531006065
problem occur,2.530521352
target_size=input_dim,2.528455285
attach picture,2.527777778
validation_data` attribute,2.526826776
random fraction,2.526027397
compile stage,2.524854491
period needed,2.522727273
speed/epoch,2.522262335
acc > accuracy,2.520557894
response,2.52
channels = dropout,2.51924038
padding mask,2.518709411
max_queue_size=max_queue_size,2.516129032
"max_queue_size = max_queue_size

    702",2.516129032
padding option,2.515985544
num_words=max_nb_words,2.515151515
loss=vae_loss,2.515133049
bug fix,2.514224369
txt file,2.513506111
shown interest,2.513157895
github issue,2.512641351
"y_pred



array",2.512622573
uint8 shape,2.51233672
file/path,2.512214121
options meaningful,2.511904762
units=embedding_size,2.510367893
"randint

valueerror",2.509322285
fit_generator meaning,2.508883249
_make_train_function creates,2.507936508
"333 

    334     def",2.506044905
} def,2.506044905
0 def,2.506044905
concat axis,2.505877529
basically don,2.504422333
epochs=epoch,2.503846128
wrong idea,2.503739837
"py

```



note",2.502082556
epochs=args,2.501252531
verbose description,2.50059312
classes=num_classes,2.500235405
ve noticed,2.500142491
__create_model,2.5
conversion,2.5
operating,2.5
norm,2.5
recognized,2.5
preloaded,2.5
mkdocs,2.5
accumulate,2.5
trainscore,2.5
transferring,2.5
demo,2.5
collect_trainable_weights,2.5
mses,2.5
keras_weird_beh,2.5
"==================================================================================================

input_10",2.5
max_num_of_sentences_for_an_entity_pair/maxlen_of_sentences,2.5
[input_embed,2.5
`lstm_benchmark,2.5
unsupported,2.5
multiplier,2.5
train_scores = [],2.5
statistic,2.5
advanced,2.5
4i,2.5
simple_rnn_model,2.5
# initialising,2.5
~400 ms,2.5
norm =,2.5
/norm,2.5
norm],2.5
principles,2.5
private,2.5
5/socket,2.5
reduced_loss =,2.5
2 blocks,2.5
cs,2.5
/biasadd,2.5
822                            weighted_metrics=weighted_metrics,2.5
contained,2.5
conflict,2.5
placement,2.5
3 percent,2.5
/layercolorseq,2.5
{invis},2.5
handles,2.5
"_init_from_args

    initial_value",2.5
pid,2.5
fasttext,2.5
r1 =,2.5
r1,2.5
calls `,2.5
action_one_hot,2.5
input_dim=input_dims,2.5
classifying,2.5
iso-8859-1,2.5
improvements,2.5
128 ssd,2.5
mathematically,2.5
gettop1acc,2.5
[iou_test,2.5
content_loss =,2.5
#NAME?,2.5
list_validation_0,2.5
`remove_slice`,2.5
bn_conv1,2.5
numpartitions,2.5
ended,2.5
"==================================================================================================

input_actor_column_first_item",2.5
`sequential_3`,2.5
#NAME?,2.5
automatically,2.5
blockidx,2.5
+= griddim,2.5
threadidx,2.5
+= blockdim,2.5
memorycallback],2.5
plotting,2.5
density,2.5
[wine-,2.5
_the,2.5
predict_point_by_point,2.5
design,2.5
translation,2.5
increases,2.5
mygenerator,2.5
concatv2,2.5
latin-1,2.5
new_state =,2.5
starts,2.5
"]*num_output

pred_node_names = [",2.5
exceeded,2.5
links,2.5
backports,2.5
exotic,2.5
conveniently,2.5
[smoke_epoch_39,2.5
differently,2.5
calls,2.5
[conversion,2.5
overview,2.5
run_keras_simple,2.5
bank,2.5
crf,2.5
he_normal initializer,2.49980008
activation isn,2.497393472
activation=act,2.497393472
latex=s_t,2.494949495
latex=a_t,2.494949495
greater loss,2.494931029
order=order,2.493506494
signature = predict_signature_def,2.493333333
validation_split=validation_split,2.49122807
"label_length = args

    #",2.49068323
stackoverflow [question],2.490248554
stackoverflow question,2.490248554
model_from_json,2.488372093
#NAME?,2.488372093
add loss,2.48622182
sigmoid + binary_crossentropy,2.485828895
patience = patience,2.484848485
input_dim=vocab_size,2.484848485
patience=patience,2.484848485
py isn,2.484225413
shape=top_dim,2.483490566
shape=bot_dim,2.483490566
out4 = add,2.482199882
"conv1d

  file",2.481627354
np_utils,2.481481481
"np_utils

```",2.481481481
#NAME?,2.481481481
[np_utils,2.481481481
requires,2.48
square loss,2.479493636
channels] order,2.478637305
additional `,2.47826087
original,2.477272727
padding parts -2^15,2.476358504
nan loss,2.476224104
returning,2.476190476
log_dir=path_model+,2.476190476
` returning,2.476190476
make get_layer,2.475757576
"ckpt

epoch 2/10

74/74 [==============================]",2.474643287
"ckpt

epoch 3/10

73/74 [============================>",2.474643287
current,2.473684211
[current],2.473684211
[rows*cols,2.472727273
ideally resolve,2.472222222
"print eval

```",2.471827639
inp2 = flatten,2.470760234
png form,2.470760234
generating,2.470588235
num_samples = num_samples,2.470588235
y_train = train_set,2.469090909
stream_executor,2.46875
1s,2.46875
0/1s,2.46875
num_classes = len,2.467846271
num_classes=len,2.467846271
ll add,2.466815266
14s,2.466666667
vocab_size = len,2.466583645
batch_input_shape=img_input,2.464285714
"jpg

> traceback",2.462015889
test_model,2.461538462
0s,2.461538462
specifically,2.461538462
0s[7,2.461538462
inp1 = flatten,2.459649123
10 epochs attempt,2.45777427
act1 = activation,2.455726806
inception_v3,2.454545455
custom_variational_layer_1,2.454545455
run https,2.454258501
= [word_index[txt],2.452982811
`resnet50,2.451612903
resnet50,2.451612903
oov_token reserved,2.45
batchcount >= batchsz,2.45
sum = __float2half_rn,2.449122807
backend,2.446728972
"6

backend",2.446728972
backend={0},2.446728972
"9

backend",2.446728972
backend],2.446728972
0 backend,2.446728972
3 backend,2.446728972
backend *,2.446728972
y_true * y_pred,2.445174638
#NAME?,2.445174638
y_true -y_pred,2.445174638
simple,2.444444444
full,2.444444444
pooling=,2.444444444
pooling,2.444444444
produces,2.444444444
labelencoder,2.444444444
#NAME?,2.444444444
4s,2.444444444
pooling**,2.444444444
pooling ==,2.444444444
"~~~~



produces",2.444444444
"```



produces",2.444444444
test_multiprocessing,2.444444444
[test_multiprocessing,2.444444444
"[0]

        cls = line",2.443629056
py  _make_test_function,2.442558747
"shape[0]



            # add",2.440690448
yields,2.4375
runs,2.4375
loss=0 acc=1,2.43695607
axis=axis,2.435483871
train_test_split,2.434782609
sparse_categorical_cross_entropy don,2.430348259
kernel_size=mc,2.429032258
providing,2.428571429
download,2.428571429
mlp,2.428571429
cifar10,2.428571429
#NAME?,2.428571429
asked,2.428571429
//download,2.428571429
"items]

  file",2.428466194
ll close,2.428093645
multiple,2.427184466
[multiple],2.427184466
y_pred =y_pred,2.425702811
y_pred = y_pred[,2.425702811
`y_pred = 1 + y_pred,2.425702811
line `df,2.425647038
hope responses,2.424242424
github raised,2.421750663
`nan` problem,2.420905336
nan problem,2.420905336
deep,2.419753086
optimizers,2.419354839
img_path = x_names[,2.416666667
"load_weights

  file",2.416254525
csvfile = open,2.416053512
gru1_merged = add,2.415533215
resnet,2.414634146
resnet 50,2.414634146
resnet-50,2.414634146
[resnet],2.414634146
files,2.40952381
2 files,2.40952381
10000 files,2.40952381
files**,2.40952381
cnmem attribute,2.407894737
thought appreciated,2.407692308
strides array,2.407614304
rest 4 run,2.406435006
give val_loss,2.404141045
keras_contrib,2.4
vectors,2.4
top5,2.4
policy,2.4
`keras_contrib`,2.4
requested,2.4
[fw_cell],2.4
on_epoch_begin,2.4
proxy,2.4
static,2.4
labeling,2.4
branches,2.4
svg,2.4
prototxt,2.4
#NAME?,2.4
elapsed,2.4
`embedding_network_actor`,2.4
classic,2.4
significantly,2.4
requested 128,2.4
[gru_1,2.4
bi,2.4
"]

                    acc_fn =",2.4
acc_fn,2.4
representations,2.4
input_len = input_len,2.4
>     514             # check shape,2.398691571
github link,2.398112843
single,2.397849462
split valid,2.396537162
vgg16`,2.395061728
vgg16,2.395061728
"padding

sample_weights =",2.391743119
flow_from_directory attribute,2.390452876
target_size=target_size,2.390243902
problem line,2.389734823
vgg,2.388888889
[vgg-16],2.388888889
vgg-16,2.388888889
vgg-,2.388888889
t2 copy,2.38626339
workers=workers,2.385964912
1119                                         workers=workers,2.385964912
h5 file,2.38282344
h5` file,2.38282344
axes don,2.382729211
find explanation,2.382692308
add array,2.381971049
2f}-{epoch,2.379405192
kernel_size = kw,2.379032258
src=,2.378378378
/src,2.378378378
src=0,2.378378378
src,2.378378378
minor issue,2.378070175
filepath=filepath,2.376811594
filepath = filepath,2.376811594
sequence,2.375690608
sequence ->,2.375690608
sequence [,2.375690608
sequence�,2.375690608
sequence``,2.375690608
image,2.375280899
[image],2.375280899
image[0],2.375280899
#NAME?,2.375280899
#image,2.375280899
#NAME?,2.375280899
224*224 image,2.375280899
32*32 image,2.375280899
] = image,2.375280899
# image,2.375280899
/image/,2.375280899
image /= 255,2.375280899
image -= 0,2.375280899
"5

    image *= 2",2.375280899
[image,2.375280899
image**,2.375280899
"image

#",2.375280899
128-dimensional,2.375
#NAME?,2.375
keras_backend,2.375
4 dimensional,2.375
translate,2.375
svm,2.375
#NAME?,2.375
notebook],2.375
devices,2.375
feedforward,2.375
dimensional,2.375
notebook,2.375
traces,2.375
individual,2.375
previously,2.375
issue link,2.374945175
line 1058 stands,2.374364986
line x_predict,2.374364986
args = parser,2.373835404
activation=act_func,2.372393472
act2 = activation,2.372393472
classifier,2.369230769
port=args,2.368153586
text,2.367647059
text`,2.367647059
text],2.367647059
fine,2.366412214
short workaround,2.36637931
alpha * categorical_crossentropy,2.366118421
#NAME?,2.36492891
sequential`,2.36492891
`sequential,2.36492891
`sequential`,2.36492891
sequential,2.36492891
running fit_on_texts,2.364589955
vocab,2.363636364
issue https,2.359227003
issue [https,2.359227003
batch_shape=tuple,2.357647059
concatenate_1,2.357142857
sigmoid activation,2.355970115
check `len,2.355269498
channels = activation,2.35427753
logging,2.352941176
"```

logging",2.352941176
lstm_2,2.352941176
codes,2.35
datasets,2.346938776
6 datasets,2.346938776
datasets],2.346938776
#NAME?,2.346938776
"_dispatch

    job =",2.346774194
directly],2.34375
directly,2.34375
py file,2.343661757
array = line,2.34080282
pygpu/gpuarray,2.34057971
back,2.338983051
short answer,2.337870538
based,2.337837838
"```



based",2.337837838
user,2.337423313
* user,2.337423313
7         squeeze = activation,2.336679187
"``

``y_pred = activation",2.335244878
"`

`y_pred = activation",2.335244878
y_pred = activation,2.335244878
verbose=verbose,2.334519573
"texts_to_sequences
  file",2.334436343
new_node_index,2.333333333
bidirectional_3,2.333333333
lower,2.333333333
exploration,2.333333333
ndimage,2.333333333
n_entries <,2.333333333
v77,2.333333333
[v77,2.333333333
aka,2.333333333
special,2.333333333
pictures,2.333333333
"0         

    ***bottleneck",2.333333333
bottleneck,2.333333333
noise,2.333333333
studio,2.333333333
val_indices <- 1,2.333333333
"==================================================================================================

input_6",2.333333333
quickly,2.333333333
french,2.333333333
spacy,2.333333333
grad,2.333333333
td_concat,2.333333333
storage_map,2.333333333
successfully,2.333333333
corpus,2.333333333
entity,2.333333333
encodingvector 0,2.333333333
[grad],2.333333333
deepid,2.333333333
hit,2.333333333
converging,2.333333333
adamh,2.333333333
test_loss2,2.333333333
prepare,2.333333333
old_lr >,2.333333333
get_custom_objects,2.333333333
rval,2.333333333
x_arr_iobl],2.333333333
"```



restoring",2.333333333
encoder_func,2.333333333
slowly,2.333333333
restoring,2.333333333
skeleton,2.333333333
reconst_layer_1,2.333333333
"62750**     

dropout_6",2.333333333
old_lr <,2.333333333
stop_epoch,2.333333333
build_model,2.333333333
normalised_data = [],2.333333333
"```

# prepare",2.333333333
23 000 pictures,2.333333333
dw_model,2.333333333
plugins,2.333333333
tower,2.333333333
@athundt,2.333333333
data_tensor,2.333333333
internal_convert_to_tensor,2.333333333
lambdabug,2.333333333
grad=,2.333333333
truncated_normal,2.333333333
earlystop,2.333333333
dimention,2.333333333
lm,2.333333333
review,2.333333333
redundant,2.333333333
dso_loader,2.333333333
inspired,2.333333333
add leaky_relu,2.332199882
ins advance,2.332107843
flow_from_directory don,2.329573065
channels don,2.328898983
short texts,2.324712644
gpu,2.324538259
/gpu,2.324538259
0/gpu,2.324538259
1 gpu,2.324538259
gpu ->,2.324538259
gpu 0,2.324538259
"gpu



```

2018-02-01 12",2.324538259
"13

gpu",2.324538259
5 gpu,2.324538259
"8

gpu",2.324538259
"_make_predict_function

    **kwargs",2.321913381
project,2.321428571
project],2.321428571
counter = 0,2.32
counter += 1,2.32
counter,2.32
counter=0,2.32
counter  6144,2.32
counter  4540180,2.32
counter  7067412,2.32
counter  9074728,2.32
x_valid = x_valid,2.32
epoch update,2.315913128
"]

        x_sum = [ sum",2.315789474
add sigmoid,2.315776524
share,2.3125
sets,2.3125
activation = softmax,2.310466867
`softmax` activation,2.310466867
softmax activation,2.310466867
softmax = activation,2.310466867
softmax  activation,2.310466867
high=,2.307692308
high=10,2.307692308
high,2.307692308
high = 5,2.307692308
high=100,2.307692308
high=1,2.307692308
math,2.307692308
] * math,2.307692308
reshaping occur,2.306818182
18                             target_size = img_size,2.306233062
"line

print",2.30596274
num_classes = num_classes,2.305555556
workspace,2.304347826
447       workspace,2.304347826
generated,2.303030303
py  resnet_50,2.300401884
root,2.3
suggests,2.3
mobilenet,2.3
plot_model,2.3
glove,2.3
`plot_model,2.3
proper,2.3
exit,2.3
clone,2.3
[mobilenet],2.3
func_load,2.3
h5f,2.3
#plot_model,2.3
phase,2.3
# score_array,2.3
score_array /=,2.3
score_array,2.3
#3477 suggests,2.3
`func_load,2.3
` api,2.297435897
api,2.297435897
applicable] provide,2.296391753
main,2.296296296
----> 1 main,2.296296296
data,2.294117647
optimization,2.294117647
data[,2.294117647
data={,2.294117647
/data/,2.294117647
# data,2.294117647
#NAME?,2.294117647
data =,2.294117647
data/,2.294117647
data/0,2.294117647
"data

136",2.294117647
#NAME?,2.294117647
data = [[0,2.294117647
green line,2.291031653
export,2.285714286
# predicting,2.285714286
predicting,2.285714286
dependencies,2.285714286
`cifar10_cnn,2.285714286
217] allocator,2.285714286
273] allocator,2.285714286
facenet,2.285714286
simple_model,2.285714286
explicitly,2.285714286
/export/1/,2.285714286
cifar10_cnn,2.285714286
continuous,2.285714286
manually,2.285714286
#NAME?,2.283333333
[mnist],2.283333333
mnist,2.283333333
`mnist`,2.283333333
kernel_size=num_classes,2.281810036
[stackoverflow issue],2.281281693
activations,2.28125
`activations`,2.28125
"```

----- activations -----",2.28125
[row*col,2.279220779
installed,2.277777778
runtime,2.277777778
4 installed,2.277777778
vocab_size = load_data,2.271515152
correctly,2.270833333
layers,2.270394134
layers],2.270394134
layers[,2.270394134
layers[-5,2.270394134
layers[0],2.270394134
"```



layers",2.270394134
533 layers,2.270394134
527 layers,2.270394134
2 layers,2.270394134
layers[],2.270394134
layers[7,2.270394134
layers[1],2.270394134
layers[0,2.270394134
layers[14,2.270394134
layers[17,2.270394134
"layers

#",2.270394134
layers[-2],2.270394134
3 layers,2.270394134
25 layers,2.270394134
249 layers,2.270394134
layers[249,2.270394134
13 layers,2.270394134
18 layers,2.270394134
layers[2],2.270394134
layers[3],2.270394134
4-layers,2.270394134
8-layers,2.270394134
#NAME?,2.270394134
172 layers,2.270394134
8 layers,2.270394134
7 layers,2.270394134
1 layers,2.270394134
71 layers,2.270394134
` layers,2.270394134
#NAME?,2.270394134
layers[-4],2.270394134
layers[141],2.270394134
12 layers,2.270394134
layers[-1],2.270394134
complex,2.266666667
`get_layer` don,2.263681592
validation,2.261904762
validation 25%,2.261904762
previous,2.261904762
validation/,2.261904762
"0

cuda",2.261538462
"04

cuda 9",2.261538462
cuda 9,2.261538462
cuda,2.261538462
"7

cuda",2.261538462
"0

cuda 9",2.261538462
cuda 8,2.261538462
cuda 7,2.261538462
"nan

epoch 3/4

8/8 [==============================]",2.261131167
"nan

epoch 4/4

8/8 [==============================]",2.261131167
encoding=,2.260869565
kernel_size = kernel_size,2.258064516
follow https,2.257347304
rate=0,2.255555556
rate = 0,2.255555556
rate 0,2.255555556
rate,2.255555556
rate`,2.255555556
"1/rate

2",2.255555556
kernel_size=embed_dim,2.254032258
support,2.253012048
support `,2.253012048
callbacks,2.252964427
[callbacks,2.252964427
-> 1255             callbacks,2.252964427
callbacks=,2.252964427
> -> 1233             callbacks,2.252964427
`callbacks,2.252964427
## callbacks,2.252964427
* callbacks,2.252964427
-> 1160             callbacks,2.252964427
842                 callbacks,2.252964427
subsample=strides,2.25070028
bidirectional_2,2.25
gradient,2.25
loss_functions[,2.25
"617             loss_functions = []

    618",2.25
interpolate,2.25
inside,2.25
tqdm,2.25
separately,2.25
multi_gpu,2.25
person,2.25
stuff,2.25
vanilla,2.25
processes,2.25
experiment,2.25
names=[,2.25
supporting `,2.25
ugly,2.25
input_5,2.25
modules,2.25
siamese,2.25
tmp_x,2.25
decode_predictions,2.25
community,2.25
resolution,2.25
final,2.25
lstm_3,2.25
nasnetmobile,2.25
"376]=0 

    names = [",2.25
load_dynamic,2.25
picks,2.25
"`



inside",2.25
224 # resolution,2.25
names,2.25
tuned,2.25
"250000    

dropout_5",2.25
atomicexch,2.25
parallelised *,2.25
sparse_softmax_cross_entropy_with_logits`],2.25
{}-siamese,2.25
nature,2.25
recently,2.25
` inside,2.25
fc,2.25
folders,2.25
----> 2 data2 = pad_sequences,2.25
imports,2.25
sparse_softmax_cross_entropy_with_logits,2.25
"----------

                        fortran",2.25
"====================================================================================================

input_5",2.25
slicing,2.25
gemm,2.25
`moving_averages,2.25
output_loss,2.25
modelling,2.25
supporting,2.25
pure,2.25
samplewise_center,2.25
samplewise_std_normalization,2.25
unknown,2.24137931
initial,2.24137931
-> unknown,2.24137931
line `weight_values =,2.241031653
inceptionv3,2.239130435
[inceptionv3,2.239130435
real,2.238095238
"80832



real",2.238095238
"50072



real",2.238095238
flag,2.238095238
separate,2.233333333
_apply_op_helper,2.230769231
sentiment,2.230769231
video,2.230769231
---------------------------auc----------------------------------------,2.230769231
auc,2.230769231
class_mode=class_mode,2.230769231
log_loss,2.230769231
300 video,2.230769231
FALSE,2.226368159
false},2.226368159
`false`,2.226368159
"[*false*]

[   0",2.226368159
FALSE,2.226368159
"py

https",2.223715574
act3 = activation,2.222393472
fetches=fetches,2.222222222
pytest -,2.222222222
combination,2.222222222
checks,2.222222222
base,2.222222222
distributed,2.222222222
scaling,2.222222222
> pytest,2.222222222
compute_output_shape,2.222222222
term,2.222222222
"==================================================================================================

input_2",2.222222222
`pytest,2.222222222
`@pytest,2.222222222
input_2,2.222222222
= *base,2.222222222
hidden,2.216666667
strides=strides,2.215686275
matrices,2.214285714
app,2.214285714
wasn,2.210526316
row = round,2.21043771
placeholder,2.208333333
"placeholder

>",2.208333333
#NAME?,2.208333333
trainable,2.208
trainable`,2.208
deprecation,2.2
mxnet,2.2
unchanged,2.2
augmentation,2.2
yy,2.2
extra,2.2
implementing,2.2
grus,2.2
reasonable,2.2
dogs,2.2
free,2.2
restore,2.2
mxnet�,2.2
unused,2.2
blank,2.2
[gist1],2.2
`gist1`,2.2
describing,2.2
tiff,2.2
external,2.2
constr,2.2
"62   }

63     

64   free",2.2
&free,2.2
288                                                     free,2.2
storage_v3,2.2
storage_v5,2.2
storage_v7,2.2
storage_v9,2.2
storage_v11,2.2
storage_v13,2.2
storage_v1,2.2
reasonable [,2.2
"unchanged

```",2.2
aspect,2.2
boxes checked,2.191705069
access,2.1875
internal,2.1875
large,2.1875
"nb_classes = 8 

img_width",2.18618267
define,2.186046512
# define,2.186046512
"```



# define",2.186046512
pool_size=pool_size,2.186046512
line `lstm_out,2.183888796
padding=padding,2.183486239
__name__ attribute,2.182894737
quick,2.181818182
img_array_iobl,2.181818182
dataframe,2.176470588
occurs,2.173913043
** occurs,2.173913043
checkpoint],2.172413793
checkpoint,2.172413793
generate,2.170731707
# generate,2.170731707
**generate,2.170731707
"includes_bool

      isinstance",2.168478261
moving,2.166666667
pytorch,2.166666667
capability,2.166666667
misc,2.166666667
unit,2.166666667
encoded_vid,2.166666667
[pytorch],2.166666667
//pytorch,2.166666667
warn_float64=,2.166666667
test_dir =,2.166666667
test_dir,2.166666667
turn,2.166666667
complete,2.166666667
conversion_func,2.166666667
settings,2.166666667
importing,2.166666667
dnn,2.166666667
fps,2.166666667
checkpoints,2.166666667
warn_float64 =,2.166666667
standardize,2.166666667
conv2d_4,2.166666667
optional,2.166666667
nanguardmode,2.166666667
tune,2.166666667
invalid,2.166666667
```vec```,2.166666667
"```

regr",2.166666667
on_batch_begin,2.166666667
suggestions/ideas,2.165869219
word,2.164835165
1 word,2.164835165
word**,2.164835165
[word,2.164835165
/add = add[,2.164399763
rnn,2.161290323
1 rnn,2.161290323
[rnn,2.161290323
rnn`,2.161290323
raise,2.160714286
692                 raise,2.160714286
--> 693             raise,2.160714286
#NAME?,2.160714286
>     raise,2.160714286
"check

https",2.154691166
including,2.153846154
defaults,2.153846154
leakyrelu,2.153846154
connection,2.153846154
class,2.152173913
<class,2.152173913
class [99,2.152173913
class 0,2.152173913
1 class,2.152173913
class 1,2.152173913
"class 
[5",2.152173913
`val`,2.151515152
val,2.151515152
val +,2.151515152
65% val,2.151515152
stackoverflow [https,2.151035012
return,2.150344828
202         return,2.150344828
167                 return,2.150344828
1896             return,2.150344828
905   return,2.150344828
1315       return,2.150344828
1318       return,2.150344828
244     return,2.150344828
219     return,2.150344828
855                 return,2.150344828
1010             return,2.150344828
>   return,2.150344828
# return,2.150344828
return `2,2.150344828
"> 0

    286     return",2.150344828
260     return,2.150344828
57         return,2.150344828
#NAME?,2.150344828
"7

    return 0",2.150344828
--> 860         return,2.150344828
117         return,2.150344828
return [,2.150344828
2081             return,2.150344828
return `[299,2.150344828
107             return,2.150344828
829     return,2.150344828
"6

  return",2.150344828
"return

```",2.150344828
>    1316       return,2.150344828
>    1319       return,2.150344828
"+1

    return",2.150344828
"+= 1

    return",2.150344828
"return 0



    #",2.150344828
"]

        return",2.150344828
---> 55         return,2.150344828
return 1,2.150344828
406             return [,2.150344828
--> 408             return [,2.150344828
211             return,2.150344828
615   return,2.150344828
74     return -1,2.150344828
87     return -1,2.150344828
"88   }

89   return 0",2.150344828
161     return 1,2.150344828
172     return 1,2.150344828
174     return 1,2.150344828
184       return 1,2.150344828
"185     }

186     return 0",2.150344828
190     return 1,2.150344828
192     return 1,2.150344828
194     return 1,2.150344828
260             return 1,2.150344828
278             return 1,2.150344828
295             return 1,2.150344828
379         return 1,2.150344828
434       return 1,2.150344828
438       return 1,2.150344828
454     return 1,2.150344828
"455   }

456   return 0",2.150344828
554         return 15,2.150344828
620             return 0,2.150344828
return 0,2.150344828
--> 214             return,2.150344828
"`

 return",2.150344828
1014       return,2.150344828
1017       return,2.150344828
`return,2.150344828
py line 100,2.150257066
py  line,2.150257066
re-,2.148148148
_do_call,2.142857143
levels,2.142857143
web,2.142857143
color,2.142857143
semantic,2.142857143
request,2.142857143
consisting,2.142857143
readme,2.142857143
[readme],2.142857143
originally,2.142857143
indexes,2.142857143
pipeline,2.142857143
params[,2.140127389
params,2.140127389
959                         params=,2.140127389
989                         params=,2.140127389
params=,2.140127389
net *,2.138888889
net],2.138888889
net,2.138888889
normalization,2.137254902
# normalization,2.137254902
`normalization,2.137254902
relu activation,2.134138439
larger,2.133333333
test_set,2.133333333
argument,2.127906977
lock,2.125
numeric,2.125
dense_3,2.125
#create_model,2.125
45 pst,2.125
"0

________________________________________________________________________________

```",2.125
trace,2.125
documents,2.125
minmaxscaler,2.125
ga_size,2.125
proposed,2.125
algo,2.125
algo %,2.125
n_days_other=20,2.125
n_days_other,2.125
func,2.120879121
func =,2.120879121
`func`,2.120879121
encoded,2.12
standard,2.117647059
adds,2.117647059
__len__,2.111111111
106             sparse,2.111111111
1646             sparse,2.111111111
-> 1648             sparse,2.111111111
center,2.111111111
latent,2.111111111
mechanism,2.111111111
sparse,2.111111111
cats,2.111111111
`imagedatagenerator`,2.105691057
imagedatagenerator,2.105691057
**imagedatagenerator**,2.105691057
`imagedatagenerator,2.105691057
kerasclassifier,2.105263158
`kerasclassifier`,2.105263158
earlystopping,2.1
dropout_2,2.1
> validate_indices,2.1
limited,2.1
`earlystopping`,2.1
parameter,2.096385542
3 parameter,2.096385542
/ 255` parameter,2.096385542
cnn,2.091891892
**cnn**,2.091891892
3 cnn-,2.091891892
reductor,2.090909091
toy,2.090909091
lstm_1,2.090909091
lstm_1/,2.090909091
utf-8,2.090909091
utf-8 -*-,2.090909091
"utf-8 -*-

>",2.090909091
starting,2.090909091
resulting,2.090909091
`lstm_1`,2.090909091
1 sec,2.090909091
saving,2.088888889
regularizers,2.088888889
initializers,2.088888889
1851                         initializers,2.088888889
rmsprop,2.087719298
2 arrays,2.086956522
arrays,2.086956522
"arrays]

    407",2.086956522
"arrays]

    409",2.086956522
messages,2.083333333
calculation,2.083333333
mask_zero,2.083333333
2d,2.083333333
line = line,2.082063306
functions,2.081967213
` functions,2.081967213
source,2.078431373
[source],2.078431373
count,2.076923077
tasks,2.076923077
# count,2.076923077
cost,2.076923077
"544



count",2.076923077
254                                                      &count,2.076923077
test,2.074468085
test[,2.074468085
/test/,2.074468085
# test,2.074468085
test -,2.074468085
/001/test/*,2.074468085
/003/test/*,2.074468085
/004/test/*,2.074468085
/005/test/*,2.074468085
<test>,2.074468085
200 test,2.074468085
#test =,2.074468085
completely,2.071428571
stream,2.071428571
total,2.068181818
total = 0,2.068181818
&total,2.068181818
total += 1,2.068181818
2228                     outs =,2.066666667
outs,2.066666667
#NAME?,2.066666667
masked,2.066666667
group,2.066666667
--> 843                 outs =,2.066666667
`-function,2.066239316
function`,2.066239316
function,2.066239316
` function,2.066239316
`` function,2.066239316
binary,2.06557377
window,2.0625
identical,2.0625
window[0],2.0625
scipy,2.06122449
> scipy,2.06122449
"12

scipy==1",2.06122449
scipy>=0,2.06122449
slow,2.058823529
big,2.058823529
"slow

2",2.058823529
cell,2.057142857
cell `,2.057142857
`cell`,2.057142857
apply,2.056603774
apply [,2.056603774
431                 instructions,2.055555556
instructions,2.055555556
1 instructions,2.055555556
2 instructions,2.055555556
create_op,2.052631579
grid,2.05
grid-,2.05
grid[0],2.05
id,2.047619048
} [id,2.047619048
> [id,2.047619048
0 [id,2.047619048
-1} [id,2.047619048
id=180169,2.047619048
/id,2.047619048
latest,2.046948357
weight,2.046728972
--> 413         weight =,2.046728972
--> 396         weight =,2.046728972
--> 391         weight =,2.046728972
caffe,2.045454545
sh,2.045454545
"```sh

60000/60000 [==============================]",2.045454545
```sh,2.045454545
//caffe,2.045454545
_deepcopy_dict,2.043956044
"_deepcopy_dict

>",2.043956044
base_network,2.043478261
cudnn 9,2.042553191
0 cudnn 6,2.042553191
"0

cudnn 7",2.042553191
"0

> cudnn 7",2.042553191
"5

cudnn",2.042553191
cudnn,2.042553191
cudnn 6,2.042553191
cudnn 7,2.042553191
cudnn 5,2.042553191
cudnn 6021,2.042553191
cudnn 5005,2.042553191
cudnn 4007,2.042553191
"==================================================================================================

input_1",2.039215686
input_1,2.039215686
takes,2.035714286
256 takes,2.035714286
takes <,2.035714286
dense_2,2.034482759
"9800      

    dense_2",2.034482759
provided,2.032258065
provided [,2.032258065
version 2,2.028328612
version,2.028328612
`version = 2`,2.028328612
7004 version,2.028328612
0 version,2.028328612
**version 1,2.028328612
"`

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

**version 2",2.028328612
version=2,2.028328612
08 version,2.028328612
version 5,2.028328612
version 0,2.028328612
version 1,2.028328612
save_model,2.025641026
`save_model`,2.025641026
recent,2.015463918
convolution,2.013333333
convolution 9,2.013333333
load_model,2.009090909
`load_model`,2.009090909
`load_model,2.009090909
``load_model``,2.009090909
branch=0,2
enter,2
is_training,2
correspding,2
biased,2
lp = 0,2
_make_callable_from_options,2
_callable,2
makes,2
[output_tensor],2
last_index =,2
last_index >,2
epoch_counter,2
hyperparameter,2
employed,2
meta,2
increasing,2
padded,2
fuse,2
specific,2
multiclass,2
visible,2
memory,2
stateful,2
palette,2
titan,2
region,2
forward,2
e_128,2
chain,2
return_sequences=0,2
application,2
old_keras,2
_set_inputs,2
showing,2
pythonhashseed,2
program,2
metadata,2
1 worker,2
identity,2
batchsizescheduler,2
shows,2
preprocess_input,2
run_local,2
linearndinterpolator,2
#NAME?,2
#NAME?,2
tp,2
original_graph_element,2
improving,2
augmented_generator,2
stratifiedkfold,2
train_images,2
stochastic,2
timing,2
errno,2
#NAME?,2
effective,2
maps,2
specifies,2
seperate,2
image_gray_test,2
reducelronplateau,2
x_testshape,2
x_trainflat,2
y_trainros,2
dfros[,2
labros,2
documentations,2
side,2
_clone_functional_model,2
relu6,2
inherits,2
[attnrnn,2
placeholders,2
slightly,2
heavy,2
layer_loss_name,2
complex_tensor,2
microsoft,2
active_class_ids[0],2
current_device,2
objects,2
common-,2
leading,2
trainpredict_extended[,2
trainpredict_extended,2
reach,2
transferred,2
conv_11,2
conv_12,2
layer_number,2
initialization,2
independent,2
fixes,2
s2s,2
display,2
# bad,2
encoded_frame,2
totally,2
convtranspose2d,2
% datasize,2
datasize,2
u_net,2
----> 2 u_net,2
event,2
#NAME?,2
unclear,2
persistence-,2
remains,2
fairly,2
initing,2
numepoches = 1,2
numepoches = 5,2
make_node,2
shapes_mem_count = 0,2
equation,2
**t0**,2
considered,2
bad,2
enabled,2
tensorcores,2
points,2
verifying,2
partial_x_train,2
managing,2
bottom,2
contents,2
get_bdclstm,2
zoom,2
boolean,2
display=40*2000,2
4% improvement,2
experience,2
displays,2
installation,2
te[0,2
output_tensor,2
useless,2
performing,2
4000 objects,2
//pan,2
961                 updates =,2
updates,2
529             prefix =,2
991                 updates =,2
outputting,2
trivial,2
neg_dist,2
`proxy_of_class =,2
proxy_of_class =,2
_constant_tensor_conversion_function,2
opcode,2
ahead,2
common,2
recorded,2
lt,2
#REF!,2
inverse,2
tensor_map,2
ret_l2,2
pretraining,2
dropping,2
shuffling,2
formats,2
binary_op_wrapper,2
**classes_dest**,2
classes_dest,2
wh =,2
wh,2
#NAME?,2
tuples,2
/desired,2
#shows,2
slows,2
training_data,2
82     sys,2
one_hot,2
sys,2
argv[1],2
argv[2],2
presented,2
front,2
protocolerror,2
chunkedencodingerror,2
condaruntimeerror,2
pair,2
allocating,2
experiencing,2
epsilon_annealing_steps,2
= training_data[,2
famil,2
batch_list_y,2
num_images,2
`ind`,2
`inceptionresnetv2`,2
inceptionresnetv2,2
dropped,2
var_true,2
init_op,2
rescaled,2
lookback,2
out_channels,2
`preprocess_input`,2
detailed,2
caffenet_inputs_1,2
[caffenet_inputs_1,2
cross_validate,2
delay,2
"memory

--> 332",2
contrast,2
utilities,2
npages,2
/languagelevel,2
cvn,2
introduces,2
lambdacallback`,2
official,2
insufficient,2
702] stats,2
emnist,2
famous,2
googlenet,2
actual,2
wideresnet,2
embeddings_index = {},2
loss_tr,2
nchw,2
application`,2
x_data[,2
deepvo,2
msk,2
`msk `,2
multiplication,2
02d},2
representing,2
stateless,2
huge,2
iterators,2
att_vec0,2
att_vec2,2
att_vec9],2
adversarial,2
ld=,2
ld,2
[layer1_wt,2
layer2_wt],2
itertools,2
embedding_vecor_length,2
savekerasmodelasprotobuf,2
tag_constants,2
truncated,2
convergence,2
320 visible,2
minibatch,2
consists,2
__build_train_fn,2
log_action_prob =,2
run_cell,2
spike,2
sir,2
l_c,2
l_s,2
lengths,2
cosine,2
baxter001,2
infinite,2
variant,2
suspected,2
`preprocess_input,2
converted,2
arranged,2
>titan,2
te,2
flips,2
accept,2
workflow,2
cards,2
briefly,2
traing,2
prefix,2
branch,2
animation,2
"#

# animate",2
animate,2
merging,2
#NAME?,2
improvement,2
loaded_simple_model,2
statement,2
hdf,2
unicodeencodeerror,2
article,2
article][1],2
incorrect,2
weight_change,2
lnk=,2
compile_cmodule,2
possession,2
applies,2
maxoutconv2d,2
"�

contributions",2
curve,2
p1all[,2
mem,2
misleading,2
dilation=,2
treatment,2
collected,2
register,2
ind,2
file_dcc,2
fila,2
img_array_dcc,2
img_array_icc,2
img_array_dobl,2
list_validation_1,2
mac,2
"```

testfile =",2
de,2
8s,2
simplernncell,2
`simplernncell`,2
max_length,2
multidimensional,2
reward,2
content,2
_as_graph_element_locked,2
scaled,2
deserialization,2
siamese_network`,2
reduce_lr_m,2
early_stopping_m],2
8 gtx1080,2
150x150,2
in_channels,2
_get_conv_pool,2
`sys,2
18s,2
ga_half,2
#NAME?,2
#NAME?,2
ga_int *,2
#NAME?,2
< numindices,2
< numcolsx,2
* stridesindices],2
x_row < 0,2
set_instead_of_inc,2
stateful**,2
ckvalue,2
word2intclassvalue,2
categoryone,2
n_images=10,2
n_images,2
v_conv1,2
compute_loss,2
num_batches,2
return_sequences,2
monitor_op,2
embedding_layer,2
contrastive_loss,2
smaller,2
svc,2
distribution,2
implements,2
server,2
crop_image_ratio,2
batch_len + 1,2
pan =,2
[gist2],2
`gist2`,2
ctc_batch_cost,2
elemwise{,2
desired,2
brown,2
jumped,2
twod_model,2
plot_results,2
terrible,2
accepted,2
multi_gpu_test_simple_model,2
loss2,2
n-,2
f_start,2
tracing,2
distribution ==,2
bytes-,2
batch_labels,2
inp_top,2
[inp_top,2
gaussiannoise,2
spark,2
seedvector,2
gru_l,2
mapstar,2
_recursive_list,2
tpl[0],2
parsing,2
nn_model,2
train_seq2seq,2
file_io,2
filename_list,2
critic,2
`white_list_formats = {,2
"38     lengths = []

     39",2
developed,2
x_dset[,2
y_dset[,2
road_lines,2
vid_output,2
[errno -2],2
hidp,2
inner_initial_input =,2
b2,2
impose,2
m_b =,2
m_b,2
formatted,2
x_data,2
x_sample,2
nonneg,2
rnnlm,2
connections,2
novice,2
`forward`,2
phases,2
2000 lengths,2
centos,2
980m,2
officially,2
reuses,2
gate,2
`13 million`,2
batch_response[,2
br,2
worker,2
waste,2
[accurate,2
depend,2
expected_shape,2
query,2
triplet_loss,2
list_of_all_indices = [],2
list_of_all_indices,2
206       // timing,2
395             input_w > 1024,2
np_stepy,2
write_images = 0,2
write_grads = 1,2
output_power,2
output_slack,2
classsampler,2
prevent,2
prone,2
`stateful`,2
cast_to_floatx,2
top_k_categorical_accuracy,2
activate,2
kerasregressor,2
repository,2
`0` biased,2
zero_debias,2
`reducelronplateau`,2
public,2
flexible,2
n_channels,2
bellow,2
invocation,2
updates =,2
loss_tensor,2
tf_saver,2
freeze_graph,2
deeper,2
[segmentation_keras],2
sparse_categorical_accuracy,2
masked_fn,2
`_masked_objective`,2
[_masked_objective],2
positives,2
min_max_scaler,2
adopt,2
standardscaler,2
lstm_dim,2
by_name,2
v1,2
activity_l2,2
`output_length`,2
datagentrain,2
cnn_input,2
get_lstm_resnet_batchnorm,2
preparing,2
prs,2
serve,2
concatenation,2
gen_model,2
create_node,2
get_input_mask =,2
x_test_id,2
mlogloss,2
create_submission,2
"```

excuting",2
cutting,2
y_binary,2
lstmweights,2
storing,2
eval_map,2
my_init,2
my_init},2
"my_init
```",2
hanging,2
typing,2
infinity,2
"0
    total_words = 0",2
sent_len,2
total_words,2
vgg16_weights,2
stretched,2
water,2
expose,2
occurring,2
validation_steps,1.989473684
validation_steps=50,1.989473684
validation_steps=800,1.989473684
validation_steps=1000,1.989473684
validation_steps=,1.989473684
validation_steps = 8,1.989473684
validation_steps=20,1.989473684
validation_steps = 60,1.989473684
validation_steps=1200,1.989473684
validation_steps=2216,1.989473684
validation_steps = 2000,1.989473684
#validation_steps=800,1.989473684
localhost,1.988235294
parameters[,1.986666667
parameters,1.986666667
000 parameters,1.986666667
TRUE,1.986384266
true},1.986384266
true`,1.986384266
`true`,1.986384266
"[ true]

[   0",1.986384266
"[ true]]



[   0",1.986384266
"[ true]

```",1.986384266
TRUE,1.986384266
checking,1.981818182
* checking,1.981818182
replica,1.977011494
shared,1.976744186
shared=,1.976744186
#NAME?,1.976744186
times,1.975609756
# 1606 times,1.975609756
10 times,1.975609756
30 times,1.975609756
3 times,1.975609756
1/20 times,1.975609756
2 times,1.975609756
6 times,1.975609756
sgd,1.973154362
simply,1.96969697
super,1.965517241
298         super,1.965517241
# stack,1.964285714
stack,1.964285714
initial_epoch,1.963855422
initial_epoch=0,1.963855422
initial_epoch==0,1.963855422
`initial_epoch`,1.963855422
modelcheckpoint,1.962962963
modelcheckpoint`,1.962962963
{modelcheckpoint,1.962962963
`modelcheckpoint,1.962962963
network,1.961538462
"network

    

```

1/4 [======>",1.961538462
40 frames,1.961538462
50*40 frames,1.961538462
frames,1.961538462
"network

#",1.961538462
properly,1.961538462
87 frames,1.961538462
network 2,1.961538462
2 frames,1.961538462
network],1.961538462
modify,1.958333333
include_top,1.957746479
include_top=,1.957746479
max,1.957142857
max 30%,1.957142857
max],1.957142857
`max`,1.957142857
reuse,1.954545455
"219       {

220         // reuse",1.954545455
"312       {

313           // reuse",1.954545455
end,1.952830189
end>,1.952830189
end[0]],1.952830189
end=150,1.952830189
`end`,1.952830189
sequences,1.952380952
sequences[[,1.952380952
"256

_________________________________________________________________

```",1.952380952
"0

_________________________________________________________________

```",1.952380952
_________________________________________________________________,1.952380952
gen,1.952380952
"0

_________________________________________________________________",1.952380952
150 sequences,1.952380952
sequences=[,1.952380952
"64

_________________________________________________________________",1.952380952
`sequences`,1.952380952
"1

_________________________________________________________________

```",1.952380952
matrix,1.951807229
2] matrix,1.951807229
performance,1.951612903
performance`,1.951612903
resnet_model,1.95
`resnet_model`,1.95
`resnet_model,1.95
implementation,1.94980695
implementation=2,1.94980695
implementation == 2,1.94980695
implementation == 0,1.94980695
implementation == 1,1.94980695
"implementation

211       //",1.94980695
section,1.947368421
logits,1.947368421
#NAME?,1.947368421
get_model,1.947368421
distance,1.947368421
# logits,1.947368421
#NAME?,1.947368421
> pretty,1.947368421
pretty,1.947368421
section 4,1.947368421
feature,1.945205479
negative,1.941176471
negative],1.941176471
var,1.9375
taking,1.9375
bn,1.9375
compilation,1.9375
low,1.935483871
low=0,1.935483871
low = -5,1.935483871
low=-1,1.935483871
//blog,1.934782609
blog,1.934782609
creating,1.933333333
nodes,1.933333333
16 seconds,1.933333333
2511         # nodes,1.933333333
#50 nodes,1.933333333
2 seconds,1.933333333
seconds,1.933333333
30 seconds,1.933333333
truth,1.933333333
truth[,1.933333333
2492         # nodes,1.933333333
[30 seconds,1.933333333
match,1.931034483
> importerror,1.931034483
importerror,1.931034483
"33 



importerror",1.931034483
"344 



importerror",1.931034483
[match,1.931034483
horizontal_flip,1.928571429
compare,1.928571429
tensorboard,1.928571429
kfold,1.928571429
alexnet,1.928571429
globs,1.928571429
3 compare,1.928571429
tensorboard],1.928571429
`tensorboard,1.928571429
[alexnet],1.928571429
`tensorboard`,1.928571429
layer,1.924882629
[layer,1.924882629
layer--,1.924882629
--> 166                     layer,1.924882629
#NAME?,1.924882629
layer %,1.924882629
"```

layer",1.924882629
` layer,1.924882629
layer 1,1.924882629
layer 2,1.924882629
layer 3,1.924882629
#layer 1,1.924882629
#layer 2,1.924882629
`layer,1.924882629
layer #,1.924882629
-> 2477                     layer,1.924882629
2479                     layer,1.924882629
#NAME?,1.924882629
layer=190,1.924882629
layer {},1.924882629
```layer,1.924882629
">>>

layer",1.924882629
# layer 0,1.924882629
layer=8,1.924882629
"layer

#",1.924882629
-> 2445                         layer,1.924882629
2447                         layer,1.924882629
# position,1.923076923
allocate 865,1.923076923
allocate 533,1.923076923
allocate 3,1.923076923
allocate 2,1.923076923
allocate 8,1.923076923
embedding_matrix[,1.923076923
position 92-93,1.923076923
allocate 75%,1.923076923
position 18,1.923076923
position 0,1.923076923
ht,1.923076923
ht =,1.923076923
incsubtensor{,1.923076923
position,1.923076923
time,1.92
time = 2,1.92
time `,1.92
"243         {

244           // time",1.92
time],1.92
exec,1.916666667
failed,1.916666667
81] failed,1.916666667
xp,1.916666667
input,1.916043225
#NAME?,1.916043225
"input

      2",1.916043225
input 0,1.916043225
[input] + [,1.916043225
input 30,1.916043225
"input 

```",1.916043225
11�11 input,1.916043225
input=[,1.916043225
[0] = input,1.916043225
[1] = input,1.916043225
�`input 0,1.916043225
input},1.916043225
"= []



#input",1.916043225
input[0],1.916043225
input[1],1.916043225
"```

input",1.916043225
input],1.916043225
input =,1.916043225
# input,1.916043225
input = [1,1.916043225
input[2],1.916043225
input[2] = <3>,1.916043225
input=,1.916043225
snippet,1.913043478
positive,1.913043478
occurred,1.913043478
errors_impl,1.909090909
small,1.909090909
_get_batches_of_transformed_samples,1.909090909
ram,1.909090909
depending,1.909090909
depth,1.909090909
giving,1.909090909
> h5py,1.909090909
evaluation,1.909090909
#NAME?,1.909090909
h5py,1.909090909
components,1.909090909
depth=40,1.909090909
depth = 32,1.909090909
inputspec,1.909090909
` depending,1.909090909
depth=16,1.909090909
`h5py,1.909090909
# evaluation,1.909090909
607 components,1.909090909
label,1.908396947
4697463056 [label=,1.908396947
4697597392 [label=,1.908396947
4697462800 [label=,1.908396947
4697463568 [label=,1.908396947
4697598608 [label=,1.908396947
4697705616 [label=,1.908396947
4644568976 [label=,1.908396947
4644565456 [label=,1.908396947
label 1,1.908396947
# 1 label,1.908396947
label =,1.908396947
label +,1.908396947
#NAME?,1.908396947
label=,1.908396947
6] --> label,1.908396947
3] --> label,1.908396947
"6] --> label



2",1.908396947
label],1.908396947
fn,1.906976744
`fn`,1.906976744
set,1.904564315
# set,1.904564315
set-,1.904564315
"462 

    463         # set",1.904564315
% set,1.904564315
<= set,1.904564315
&set,1.904564315
>set,1.904564315
pd,1.903225806
[pd,1.903225806
assert,1.903225806
] = pd,1.903225806
"12

       conda",1.901869159
conda,1.901869159
replace,1.9
extracted,1.9
system,1.9
begin,1.9
rotation_range=0,1.9
coming,1.9
#rotation_range=20,1.9
rotation_range=40,1.9
num_partitions,1.9
] * num_partitions,1.9
rotation_range = 5,1.9
rotation_range=5,1.9
deconvolution,1.9
"-----------------------

system",1.9
# replace,1.9
rotation_range=15,1.9
rotation_range=20,1.9
rotation_range=60,1.9
rotation_range=8,1.9
rotation_range= 0,1.9
rotation_range=90,1.9
"]]]

```

system",1.9
behaviour,1.896551724
default,1.894736842
computation,1.894736842
default=,1.894736842
//docs,1.894736842
docs,1.894736842
cross_val_score,1.894736842
74%      default,1.894736842
67%      default,1.894736842
default=`0,1.894736842
----> 1 cross_val_score,1.894736842
"```

cross_val_score",1.894736842
`docs,1.894736842
default=0,1.894736842
default],1.894736842
default 10,1.894736842
default=5557,1.894736842
default=5556,1.894736842
default=64,1.894736842
default=20,1.894736842
default=10000,1.894736842
5000 docs &,1.894736842
[docs],1.894736842
docs/,1.894736842
character,1.891891892
`character,1.891891892
"# character 1

        [1",1.891891892
"# character 2

        [1",1.891891892
"# character 3

        [1",1.891891892
"# character 4

    ]",1.891891892
"# character 1

        [0",1.891891892
"# character 2

        [0",1.891891892
"# character 3

    ]",1.891891892
character 4,1.891891892
required,1.888888889
libraries,1.888888889
flat,1.888888889
resultfinal == 0,1.888888889
adding,1.888888889
raises,1.888888889
* adding,1.888888889
red,1.888888889
[red,1.888888889
red],1.888888889
roc_auc_score],1.888888889
similarly,1.888888889
6 raises,1.888888889
# adding,1.888888889
significant,1.888888889
//drive,1.888888889
similarly #2801,1.888888889
` raises,1.888888889
roc_auc_score,1.888888889
drive,1.888888889
permute,1.888888889
"libraries



2",1.888888889
compiler,1.888888889
#NAME?,1.888888889
0 locally,1.888888889
1 locally,1.888888889
5 locally,1.888888889
val_samples=10000,1.888888889
val_samples,1.888888889
"wrapper

2018-06-02 11",1.885964912
wrapper,1.885964912
92         wrapper,1.885964912
88         wrapper,1.885964912
configuration,1.882352941
general,1.882352941
avg,1.882352941
avg=,1.882352941
pyobject,1.882352941
`avg`,1.882352941
pyobject *,1.882352941
images,1.881578947
2 images,1.881578947
#       images,1.881578947
"256

#  images",1.881578947
"256

# images",1.881578947
"images

    #",1.881578947
405 images,1.881578947
images = [],1.881578947
50000 images,1.881578947
100 images,1.881578947
16 images,1.881578947
10 images,1.881578947
32 images,1.881578947
5 images,1.881578947
~1000 images,1.881578947
* 64 = 960 images,1.881578947
"]

images = [",1.881578947
"]
images = []",1.881578947
[images,1.881578947
operation,1.88
#NAME?,1.88
"```

elif",1.878787879
elif,1.878787879
release,1.878787879
release 7,1.878787879
"]

            elif",1.878787879
"212 

    213         elif",1.878787879
"215 

    216         elif",1.878787879
ratio,1.875
img_data],1.875
emotion,1.875
filter,1.875
grayscale,1.875
conv,1.875
construct,1.875
ratio=,1.875
augmented,1.875
conv =,1.875
higher,1.875
5�5 filter,1.875
sense,1.875
"2]



        # filter",1.875
img_data,1.875
#NAME?,1.875
char *,1.875
pixel,1.875
ratio*10,1.875
# construct,1.875
#NAME?,1.875
generates,1.875
"{

323       char *",1.875
char,1.875
char],1.875
`conv*,1.875
theano,1.87162891
theano 0,1.87162891
"0

* theano",1.87162891
* theano,1.87162891
theano 1,1.87162891
"```

theano",1.87162891
"1

theano 1",1.87162891
"0

theano==1",1.87162891
theano-1,1.87162891
"2

theano 0",1.87162891
%theano,1.87162891
[theano,1.87162891
"0

theano==0",1.87162891
"0



theano",1.87162891
8 theano 0,1.87162891
"-

theano",1.87162891
0+theano,1.87162891
<theano,1.87162891
map,1.870967742
#map,1.870967742
# map,1.870967742
map[,1.870967742
d2,1.866666667
checkpointer,1.866666667
architecture,1.865671642
state,1.86036036
[state,1.86036036
`state%,1.86036036
state%,1.86036036
state[,1.86036036
state `,1.86036036
# state,1.86036036
state =,1.86036036
4 state,1.86036036
state],1.86036036
cntk,1.85915493
//cntk,1.85915493
`cntk-2,1.85915493
/cntk-2,1.85915493
"1

cntk 2",1.85915493
fusedbatchnorm,1.857142857
built,1.857142857
floating`,1.857142857
leads,1.857142857
introduce,1.857142857
calling,1.857142857
upper,1.857142857
timeseries,1.857142857
vae_loss_func,1.857142857
"vae_loss_func

```",1.857142857
include,1.857142857
restored,1.857142857
cuda_dnn,1.857142857
v2,1.857142857
signal,1.857142857
scorer,1.857142857
built-,1.857142857
loader,1.857142857
calling `,1.857142857
easily,1.857142857
#calling,1.857142857
gt = [],1.857142857
gt,1.857142857
manner,1.857142857
h_tm1,1.857142857
5 threshold,1.857142857
val_generator,1.857142857
4 #include,1.857142857
">

8 #include",1.857142857
9 #include,1.857142857
0/include,1.857142857
d_input,1.857142857
* built-,1.857142857
1586 length,1.855421687
length,1.855421687
length-1,1.855421687
`length`,1.855421687
length=10,1.855421687
length 15,1.855421687
length 0,1.855421687
length =,1.855421687
length 6,1.855421687
`datagen,1.854545455
datagen,1.854545455
#datagen,1.854545455
` datagen,1.854545455
pickle,1.852941176
#NAME?,1.852941176
608                                              unroll=,1.851851852
unroll,1.851851852
yield,1.85106383
6719 yield,1.85106383
9297 yield,1.85106383
9551 yield,1.85106383
6816 yield,1.85106383
6633 yield,1.85106383
` yield,1.85106383
"]

            yield",1.85106383
methods,1.85
steps,1.849462366
steps=10,1.849462366
25 steps,1.849462366
"```



steps",1.849462366
486 steps,1.849462366
`steps=,1.849462366
`steps`,1.849462366
steps=1,1.849462366
steps=2,1.849462366
steps=0,1.849462366
steps=,1.849462366
## steps,1.849462366
embedding,1.846491228
#NAME?,1.846491228
"[

                embedding",1.846491228
#NAME?,1.846491228
"[

          embedding",1.846491228
`embedding,1.846491228
"` 

`embedding",1.846491228
"`

`embedding",1.846491228
"`

`embedding=[]`

`",1.846491228
"`

`         embedding",1.846491228
ctc,1.846153846
structure,1.846153846
fold,1.846153846
fold {},1.846153846
__getitem__,1.846153846
nb_val_samples,1.846153846
nb_val_samples=1000,1.846153846
`__getitem__`,1.846153846
nb_val_samples=20001,1.846153846
nb_val_samples=,1.846153846
values,1.844919786
values],1.844919786
values[0],1.844919786
values[,1.844919786
values[1,1.844919786
4 values**,1.844919786
4 values,1.844919786
9 values,1.844919786
10 values,1.844919786
128 values,1.844919786
256 values,1.844919786
~200 values,1.844919786
values `,1.844919786
[4] values,1.844919786
` method,1.844444444
method,1.844444444
method `,1.844444444
applying,1.842105263
similar,1.841269841
continue,1.84
on_batch_end,1.84
"continue

```",1.84
`on_batch_end`,1.84
pydot,1.838709677
---> 27         pydot,1.838709677
`pydot`,1.838709677
encoder,1.837837838
predictions,1.837837838
* encoder,1.837837838
"```



encoder",1.837837838
[predictions[10][,1.837837838
#encoder,1.837837838
] == predictions[,1.837837838
-1 predictions,1.837837838
predictions =,1.837837838
categorical,1.837209302
cv2,1.836734694
#cv2,1.836734694
#REF!,1.836734694
draw,1.833333333
doubt,1.833333333
batch_x[,1.833333333
batch_x,1.833333333
trainer,1.833333333
view,1.833333333
making,1.833333333
decoder_dense,1.833333333
loaded,1.833333333
computations,1.833333333
straight,1.833333333
reducing,1.833333333
testy,1.833333333
var_auto_encoder,1.833333333
#var_auto_encoder,1.833333333
types,1.833333333
complicated,1.833333333
global_feature,1.833333333
computes,1.833333333
piece_pool,1.833333333
horizontal,1.833333333
potential,1.833333333
overflow,1.833333333
optimizations,1.833333333
numbers,1.833333333
x_in,1.833333333
execute,1.833333333
explains,1.833333333
model_checkpoint],1.833333333
embedded,1.833333333
adapting,1.833333333
track,1.833333333
dropout_1,1.833333333
# draw,1.833333333
bid2_last_step,1.833333333
keepdims,1.833333333
improved,1.833333333
`dp_mask`,1.833333333
[output1,1.833333333
softmax_cross_entropy_with_logits,1.833333333
get_batches,1.833333333
sorted,1.833333333
x_f +,1.833333333
x_o +,1.833333333
sigma],1.833333333
sigma,1.833333333
output1,1.833333333
gains,1.833333333
softmax_cross_entropy_with_logits],1.833333333
mdl,1.833333333
"dataset



>",1.830357143
dataset,1.830357143
** dataset,1.830357143
= dataset[,1.830357143
dataset[,1.830357143
#NAME?,1.830357143
7 score,1.827067669
score[1],1.827067669
score[0],1.827067669
score,1.827067669
score[1]*100,1.827067669
score =,1.827067669
score = 0,1.827067669
"==1]

    score = 0",1.827067669
score/=,1.827067669
"==1]

        score = 0",1.827067669
good,1.826923077
"good

=",1.826923077
features,1.825757576
6 features,1.825757576
`features,1.825757576
3 features,1.825757576
1 features,1.825757576
features],1.825757576
100 features,1.825757576
features = [,1.825757576
2 features,1.825757576
features = 33,1.825757576
30 features,1.825757576
1024 features,1.825757576
[features],1.825757576
000 features,1.825757576
features={,1.825757576
4 features,1.825757576
[[node,1.825396825
node,1.825396825
"128]

 [[node",1.825396825
"]]

 [[node",1.825396825
"]]

         [[node",1.825396825
1 node,1.825396825
"10]

         [[node",1.825396825
"[12]

         [[node",1.825396825
`[[node,1.825396825
"]]

        [[node",1.825396825
writing,1.823529412
# throws,1.823529412
throws,1.823529412
prediction,1.821138211
prediction /=,1.821138211
prediction =,1.821138211
[prediction],1.821138211
#prediction,1.821138211
autoencoder,1.818181818
rmse,1.818181818
```bash,1.818181818
bash]`,1.818181818
from_logits,1.818181818
[processed_a,1.818181818
training_set,1.818181818
"autoencoder

```",1.818181818
`rmse`,1.818181818
csvlogger,1.818181818
calculates,1.818181818
layer2,1.818181818
`layer2,1.818181818
"```bash

#",1.818181818
processed_a =,1.818181818
layer2],1.818181818
"0051



rmse",1.818181818
-> 1238                                     exception_prefix=,1.818181818
exception_prefix,1.818181818
wholesequence,1.818181818
losses,1.8125
predicts,1.8125
] == losses,1.8125
generators,1.8125
"predicts

#",1.8125
"```

losses = {}",1.8125
losses[,1.8125
predicts 1,1.8125
target,1.81147541
target=,1.81147541
target = [0,1.81147541
use_multiprocessing,1.810810811
batch,1.810734463
batch #,1.810734463
batch > 1,1.810734463
batch = 16,1.810734463
batch %,1.810734463
== batch,1.810734463
## batch,1.810734463
# batch,1.810734463
batch <= 1,1.810734463
batch>*<,1.810734463
#NAME?,1.810734463
batch 1/12682,1.810734463
batch 2/12682,1.810734463
batch 3/12682,1.810734463
batch 4/12682,1.810734463
batch 5/12682,1.810734463
batch 6/12682,1.810734463
batch 7477/12682,1.810734463
batch 7478/12682,1.810734463
batch 7479/12682,1.810734463
batch 7480/12682,1.810734463
batch 7481/12682,1.810734463
batch 7482/12682,1.810734463
batch 7483/12682,1.810734463
as_ref,1.80952381
adam,1.808695652
`adam,1.808695652
"adam

---> 45",1.808695652
reset,1.807692308
abs,1.806451613
validation_generator,1.805555556
tensors,1.802469136
tensors],1.802469136
**tensors,1.802469136
651                     tensors =,1.802469136
train_dir,1.8
size_hidden_layer,1.8
dtypes,1.8
top,1.8
hard,1.8
require,1.8
setting,1.8
flattened,1.8
performed,1.8
registered,1.8
"+ 1



#setting",1.8
top 1,1.8
5d,1.8
travis],1.8
folder,1.8
avoid,1.8
worth,1.8
"compatible

>     602             #",1.8
tbcallback],1.8
suggested,1.8
awesome,1.8
top=3,1.8
early_stopping],1.8
expectation,1.8
_standardize_input_data,1.8
batch_list_x,1.8
resizing,1.8
minimum,1.8
divided,1.8
`_standardize_weights`,1.8
confusion,1.8
y_train1,1.8
folder =,1.8
test_index,1.8
check_batch_axis,1.8
encoder_model,1.8
compatible,1.8
top=1,1.8
top=5,1.8
list_files_0 = [,1.8
"]

list_files_1 = [",1.8
list_files_0,1.8
list_files_1,1.8
max_pooling2d_1,1.8
probs_in,1.8
relevant,1.8
f1,1.8
upgrading,1.8
earlier,1.8
atomicadd,1.8
raising,1.8
[top,1.8
rep_layer,1.8
output_layer,1.8
_standardize_weights,1.8
shuffle_batch,1.8
shuffle_batch/,1.8
gap,1.8
distributions,1.8
top 1000,1.8
validate_shape,1.8
runfile,1.8
voc,1.8
return_value = -1,1.8
61     return_value = -1,1.8
_popen =,1.8
_popen,1.8
top-,1.8
metric_fn,1.8
``setting,1.8
word_test_label,1.8
y_holdout,1.8
works,1.793333333
8 works,1.793333333
"```

#works",1.793333333
` works,1.793333333
`tensor,1.79245283
tensor,1.79245283
tensor[0],1.79245283
tensor`,1.79245283
`tensor`,1.79245283
2288             tensor,1.79245283
"tensor



```",1.79245283
#NAME?,1.79245283
tensor>,1.79245283
tensor=,1.79245283
tensor =,1.79245283
[tensor ],1.79245283
tensor %,1.79245283
machine,1.790697674
/machine,1.790697674
* machine,1.790697674
command,1.789473684
related,1.789473684
predicted,1.789473684
[related,1.789473684
temp = [],1.789473684
temp,1.789473684
temp[0],1.789473684
temp = 0,1.789473684
"```



related",1.789473684
predicted[0,1.789473684
"**

**related",1.789473684
<module>,1.788590604
"<module>

2018-06-02 11",1.788590604
"<module>

>",1.788590604
module,1.788590604
"<module>
>",1.788590604
callback,1.785714286
---> 77             callback,1.785714286
kernel_regularizer=,1.785714286
kernel_regularizer,1.785714286
callback`,1.785714286
disabled,1.785714286
pixels,1.785714286
callback=,1.785714286
113             callback,1.785714286
`4d`,1.785714286
> ---> 73             callback,1.785714286
4d,1.785714286
``kernel_regularizer``,1.785714286
---> 75             callback,1.785714286
sample,1.783783784
1 sample,1.783783784
compute,1.78125
# compute,1.78125
convert,1.78
1569     # convert,1.78
# convert,1.78
post,1.777777778
retrain,1.777777778
temporal,1.777777778
clone_model,1.777777778
run_internal_graph,1.777777778
[post ],1.777777778
address,1.777777778
calculate,1.777777778
half,1.777777778
**category**,1.777777778
page],1.777777778
page 329,1.777777778
>>> model_2,1.777777778
category,1.777777778
%%page,1.777777778
create_dataset,1.777777778
roughly,1.777777778
"clone_model

>",1.777777778
page,1.777777778
[retrain,1.777777778
roughly `[-1,1.777777778
pairs,1.777777778
"3



    pairs += [[",1.777777778
model_2,1.777777778
post/,1.777777778
# half,1.777777778
int,1.775
%int,1.775
#NAME?,1.775
int *,1.775
process,1.772727273
preprocess,1.772727273
vector,1.772727273
vector `,1.772727273
# 3 process,1.772727273
1 process,1.772727273
process-1,1.772727273
index,1.772277228
index 0,1.772277228
index 1,1.772277228
index],1.772277228
index+1,1.772277228
index=,1.772277228
[index[,1.772277228
index[0],1.772277228
index[1],1.772277228
][index],1.772277228
metric,1.772151899
`metric,1.772151899
"`

`metric",1.772151899
#NAME?,1.772151899
metric ==,1.772151899
batchnorm,1.769230769
normalize,1.769230769
probabilities,1.769230769
# normalize,1.769230769
thread,1.766666667
[thread],1.766666667
log,1.765625
/log/2018-06-02 10,1.765625
log={},1.765625
[log],1.765625
generator,1.762376238
<generator,1.762376238
#generator,1.762376238
generator`,1.762376238
[generator,1.762376238
generator=,1.762376238
functionality,1.761904762
input_data,1.761904762
input_data=,1.761904762
[input_data],1.761904762
call,1.759825328
` call,1.759825328
`call`,1.759825328
call`,1.759825328
call `,1.759825328
[call,1.759825328
call  `,1.759825328
bidirectional,1.757142857
bidirectional/,1.757142857
`bidirectional,1.757142857
#NAME?,1.757142857
`bidirectional`,1.757142857
"**

                        bidirectional",1.757142857
size=,1.755852843
size 1,1.755852843
size,1.755852843
size [,1.755852843
408         size,1.755852843
size 3,1.755852843
size 1*12,1.755852843
size=128,1.755852843
"size 256

```",1.755852843
size =,1.755852843
size 10,1.755852843
size 3000000,1.755852843
"2048>

    size",1.755852843
"size`

2",1.755852843
size 48,1.755852843
"size

        415",1.755852843
size=[30000,1.755852843
-> 1344                     size,1.755852843
size %,1.755852843
size [120,1.755852843
1.00E-03,1.75308642
1e,1.75308642
1.00E-06,1.75308642
1.00E-04,1.75308642
1.00E-07,1.75308642
1.00E-08,1.75308642
1.00E-08,1.75308642
1.00E-100,1.75308642
1.00E+08,1.75308642
> 1e-3,1.75308642
1.00E-07,1.75308642
dtype=,1.752918288
dtype,1.752918288
412             dtype =,1.752918288
dtype =,1.752918288
395             dtype =,1.752918288
--> 101             dtype=,1.752918288
390             dtype =,1.752918288
dtype %,1.752918288
fused_batch_norm,1.75
shapes,1.75
executed,1.75
early_stop,1.75
message,1.75
#NAME?,1.75
action=,1.75
input_file,1.75
softmax_weights,1.75
_fit_loop,1.75
initial_states,1.75
while_loop,1.75
beginner,1.75
located,1.75
get_gradients,1.75
ae_input,1.75
#NAME?,1.75
converges,1.75
maxnorm,1.75
`conv2d_1`,1.75
tm,1.75
tc,1.75
`tm,1.75
`tc,1.75
conv_seq,1.75
validaccuracy,1.75
showed,1.75
requirements,1.75
lab,1.75
graphs,1.75
lets,1.75
bigger,1.75
dima,1.75
dimb,1.75
play,1.75
regularization,1.75
separableconv2d,1.75
combined,1.75
nb_channel,1.75
action,1.75
model_json,1.75
continues,1.75
coded,1.75
partitions,1.75
dynamicpartition,1.75
partitions],1.75
decide,1.75
w_categorical_crossentropy,1.75
perform,1.75
constraints,1.75
base_config,1.75
md,1.75
kinda,1.75
allocated,1.75
varies,1.75
paste,1.75
speedup,1.75
"fused_batch_norm

>",1.75
decreased,1.75
word_dropout,1.75
word_dropout < 1,1.75
identify,1.75
technique,1.75
wrapped,1.75
90 kb/,1.75
23 kb/,1.75
exceptions,1.75
subtract_mean_gen,1.75
numerator,1.75
numerator =,1.75
rnns,1.75
get_json_type,1.75
caffenet,1.75
start_time,1.75
hdf5matrix`,1.75
digit,1.75
day 1,1.75
train_top_model,1.75
message =,1.75
regularization],1.75
constraints=[],1.75
dsc,1.75
digits,1.75
introducing,1.75
reduction=0,1.75
reduction,1.75
1080ti,1.75
webcam,1.75
conv_1,1.75
hdf5matrix,1.75
#NAME?,1.75
conv2d_1,1.75
[train_x1,1.75
model_name =,1.75
model_name,1.75
columna,1.75
columna] > 0,1.75
y_arr,1.75
conv2d_3,1.75
roughness,1.75
#NAME?,1.75
indices_arr =,1.75
indices_arr,1.75
returna,1.75
"]]]=1

                returnb",1.75
returnb,1.75
conv4d,1.75
middle,1.75
mid,1.75
approx,1.75
positive_d,1.75
[positive_d,1.75
internally,1.75
"conv2d_1

    -0",1.75
[active_skip_idxs,1.75
f_end,1.75
final_input,1.75
lstm_x,1.75
_test_loop,1.75
verify_shape,1.75
emb_layer,1.75
num_gpu,1.75
impact,1.75
04 lts,1.75
out_dense,1.75
data_train,1.75
avg_fit,1.75
stateinput,1.75
[stateinput,1.75
max_word_len,1.75
binary_face_output,1.75
create_pairs,1.75
rms,1.75
threads,1.75
day,1.75
tmp_model,1.75
shapes[,1.75
discard,1.75
le,1.75
210       //   shapes,1.75
fft,1.75
1/4th,1.75
3/4th,1.75
procedure,1.75
conv_model,1.75
d_latent,1.75
training_epochs,1.75
d_latent=2,1.75
replacing [,1.75
card,1.75
+model_name+,1.75
//warmspringwinds,1.75
early_stop],1.75
----> 4 model_loaded,1.75
--> 965                              feed_dict_string,1.75
featurewise,1.75
news,1.75
replacing,1.75
# encodes,1.75
shapes %,1.75
output,1.747155499
--> 460             output =,1.747155499
--> 454             output =,1.747155499
"```

output",1.747155499
`output =,1.747155499
--> 619             output =,1.747155499
[output],1.747155499
# output,1.747155499
output],1.747155499
"```



output",1.747155499
output=[,1.747155499
--> 617             output =,1.747155499
output /,1.747155499
output},1.747155499
"```



> output",1.747155499
# output [1,1.747155499
# output [2,1.747155499
**output**,1.747155499
output-%,1.747155499
------> output,1.747155499
output =,1.747155499
[output,1.747155499
"`





output",1.747155499
output=,1.747155499
* output,1.747155499
`output,1.747155499
output[,1.747155499
`output`,1.747155499
*output,1.747155499
--> 585             output =,1.747155499
output[1],1.747155499
output[50],1.747155499
output[-1],1.747155499
dimension,1.745762712
dimension = 10000,1.745762712
dimension 0,1.745762712
1 dimension,1.745762712
[dimension,1.745762712
dimension 7,1.745762712
dimension 2,1.745762712
dimension 1,1.745762712
_deepcopy_list,1.740740741
information,1.737704918
information**,1.737704918
os,1.737588652
```os,1.737588652
"0

os",1.737588652
`os,1.737588652
"###################

    os",1.737588652
] += os,1.737588652
#NAME?,1.736842105
tokenizer,1.736842105
"]

tokenizer",1.736842105
`tokenizer`,1.736842105
# tokenizer,1.736842105
directory,1.735294118
directory =,1.735294118
constraint,1.734693878
constraint=,1.734693878
-> 1860                                         constraint=,1.734693878
--> 134                                       constraint=,1.734693878
-> 1028                                       constraint=,1.734693878
100             constraint=,1.734693878
kernel,1.733944954
kernel 4,1.733944954
kernel =,1.733944954
kernel[1,1.733944954
kernel[,1.733944954
`kernel`,1.733944954
kernel=,1.733944954
4 <= kernel,1.733944954
received,1.733333333
definition,1.733333333
samples_per_epoch=1000,1.733333333
samples_per_epoch=14812565,1.733333333
samples_per_epoch=113526,1.733333333
samples_per_epoch=5000,1.733333333
samples_per_epoch=,1.733333333
samples_per_epoch=10000,1.733333333
* samples_per_epoch,1.733333333
1134       results =,1.731034483
results,1.731034483
5 results,1.731034483
results[,1.731034483
"```



results",1.731034483
results},1.731034483
>    1119       results =,1.731034483
"```

**results",1.731034483
**results,1.731034483
12 results,1.731034483
964       results =,1.731034483
shuffle,1.730769231
`shuffle=,1.730769231
#NAME?,1.730769231
"]



shuffle",1.730769231
shuffle=,1.730769231
gist,1.730434783
//gist,1.730434783
gist],1.730434783
[gist],1.730434783
weird,1.727272727
saved_model,1.727272727
represent,1.727272727
> indexerror,1.727272727
go_backwards,1.727272727
"]

indexerror",1.727272727
partial,1.727272727
layer1,1.727272727
`layer1,1.727272727
indexerror,1.727272727
[layer1,1.727272727
"[0] * 255



    

    lanes",1.727272727
lanes,1.727272727
"]



    

    lanes",1.727272727
maxlen,1.725806452
maxlen=75,1.725806452
maxlen=50,1.725806452
maxlen=100,1.725806452
pr,1.722222222
"0000e+00

```",1.722222222
pr #9031,1.722222222
[pr #8021],1.722222222
"0000e+00

1/1 [==============================]",1.722222222
"0000e+00

 3/20 [===>",1.722222222
[pr,1.722222222
0.00E+00,1.722222222
[pr#5537],1.722222222
pr #7267,1.722222222
correct,1.721311475
"<---------- correct

2018-01-31 15",1.721311475
"correct 

```",1.721311475
correct = 0,1.721311475
correct += 1,1.721311475
string,1.72
<string>,1.72
representation,1.714285714
spyder,1.714285714
offset,1.714285714
3391           original_op=,1.714285714
original_op,1.714285714
convnet,1.714285714
increased,1.714285714
feel,1.714285714
"```



edit",1.714285714
colors,1.714285714
recognize,1.714285714
edit,1.714285714
auto,1.714285714
apparently,1.714285714
overfitting,1.714285714
control,1.714285714
embedded_sequences,1.714285714
report `,1.714285714
"## notes

*",1.714285714
3 colors,1.714285714
plot,1.714285714
stacked_dists,1.714285714
probability,1.714285714
sc],1.714285714
`encoder_states`,1.714285714
spent,1.714285714
`logger,1.714285714
notes,1.714285714
10 notes**,1.714285714
notes `,1.714285714
anymore,1.714285714
sc,1.714285714
logger,1.714285714
ga_uint *,1.714285714
ga_uint,1.714285714
undefined,1.714285714
as_graph_element,1.714285714
require_shape_fn,1.714285714
w2,1.714285714
serialization,1.714285714
report,1.714285714
reading,1.709677419
reading [,1.709677419
modified,1.708333333
dictionary,1.708333333
dictionary&&,1.708333333
assign,1.705882353
dear,1.705882353
assign [0,1.705882353
updated,1.703703704
variable,1.702857143
2 variable,1.702857143
variable *=,1.702857143
variable`,1.702857143
/variable/,1.702857143
variable>>&,1.702857143
[/variable],1.702857143
`variable`,1.702857143
variable -=,1.702857143
[variable,1.702857143
#NAME?,1.702857143
history,1.702380952
"```

history =",1.702380952
"history 

```",1.702380952
history[,1.702380952
history],1.702380952
"5

  ```## history",1.702380952
history`,1.702380952
[history,1.702380952
`history`,1.702380952
feed_dict,1.70212766
feed_dict={,1.70212766
feed_dict = {,1.70212766
lstm,1.701465201
[lstm],1.701465201
`lstm`,1.701465201
#NAME?,1.701465201
/lstm,1.701465201
lstm ------------,1.701465201
->lstm--------,1.701465201
2 lstm</,1.701465201
#NAME?,1.701465201
] = lstm,1.701465201
"```

lstm",1.701465201
] # lstm,1.701465201
element,1.7
instances,1.7
reported,1.7
target_tensors,1.7
data_gen,1.7
data_generator,1.7
directories,1.7
main_output,1.7
safe,1.7
reported [,1.7
ratings,1.7
detections,1.7
# `detections`,1.7
detections[0,1.7
minutes,1.7
"10 minutes



```

2017-11-19 08",1.7
`data_gen,1.7
5 minutes,1.7
minutes  =,1.7
saved,1.698412698
5 saved,1.698412698
saved *********,1.698412698
batchsize,1.694444444
25 batchsize,1.694444444
*batchsize,1.694444444
batchsize*2,1.694444444
[batchsize,1.694444444
batchsize=16,1.694444444
hist,1.692307692
scripts,1.692307692
xx,1.692307692
"includes

#",1.692307692
` includes,1.692307692
includes,1.692307692
"includes

        #",1.692307692
[hist],1.692307692
hist =,1.692307692
defined,1.691588785
defined [,1.691588785
` defined,1.691588785
360     // defined,1.691588785
"defined

```



---",1.691588785
np,1.690976514
#NAME?,1.690976514
`np,1.690976514
[np,1.690976514
#NAME?,1.690976514
#NAME?,1.690976514
"```

np",1.690976514
"np

----> 3",1.690976514
"np

----> 9",1.690976514
] = np,1.690976514
=[np,1.690976514
"np

>",1.690976514
8*np,1.690976514
#NAME?,1.690976514
7] * np,1.690976514
"np

     48 

---> 49",1.690976514
#np,1.690976514
#NAME?,1.690976514
/ np,1.690976514
"=3

np",1.690976514
"]

    np",1.690976514
**np,1.690976514
6 / np,1.690976514
-= np,1.690976514
inf,1.6875
interpolation,1.6875
grads],1.6875
#NAME?,1.6875
interpolation=,1.6875
grads`,1.6875
grads,1.6875
1231                            interpolation=,1.6875
fitting,1.684210526
increase,1.681818182
strange,1.68
integer,1.68
environment,1.68
"```

strange",1.68
"```

strange/",1.68
no_inplace},1.68
object,1.676056338
object 1,1.676056338
get_config,1.673913043
`get_config`,1.673913043
targets,1.673076923
# targets,1.673076923
**targets**,1.673076923
targets[0],1.673076923
{1} targets,1.673076923
targets =,1.673076923
targets`,1.673076923
targets[,1.673076923
train_generator,1.672727273
train_generator =,1.672727273
`merge`,1.671755725
merge,1.671755725
merge`,1.671755725
#NAME?,1.671755725
# merge,1.671755725
`merge,1.671755725
#NAME?,1.671755725
expected,1.670967742
expected 2,1.670967742
expected %,1.670967742
"expected

2",1.670967742
"expected

3",1.670967742
"]]

```

expected",1.670967742
broadcasting,1.666666667
2071     context_f,1.666666667
input_types,1.666666667
gan,1.666666667
comparing,1.666666667
evaluating,1.666666667
vgg19,1.666666667
raw_dataset_train,1.666666667
opened,1.666666667
val_ins,1.666666667
nasnetlarge,1.666666667
batch_x1[,1.666666667
batch_x2],1.666666667
verify,1.666666667
manage,1.666666667
randomnormal,1.666666667
frozen,1.666666667
gan-,1.666666667
troubles,1.666666667
references,1.666666667
accuracies,1.666666667
crop,1.666666667
original_dim,1.666666667
grad_fn,1.666666667
bs =,1.666666667
bs,1.666666667
] =  bs,1.666666667
]=bs,1.666666667
shorter,1.666666667
next_element,1.666666667
input_dataset,1.666666667
folds,1.666666667
experimenting,1.666666667
resources,1.666666667
autogen,1.666666667
normalize_batch_in_training,1.666666667
"```

# -*- coding",1.666666667
testpredict_extended[,1.666666667
testpredict_extended,1.666666667
backprop,1.666666667
decoder_input,1.666666667
[input0,1.666666667
massive,1.666666667
proposes,1.666666667
interval,1.666666667
-> 2176                 enqueuer,1.666666667
eoferror,1.666666667
defining,1.666666667
recommendation,1.666666667
faster,1.666666667
book,1.666666667
#NAME?,1.666666667
original_backend,1.666666667
input3,1.666666667
img_dim,1.666666667
y3,1.666666667
filled,1.666666667
steps_done,1.666666667
input_name,1.666666667
modifying,1.666666667
selected,1.666666667
sigmoid_x,1.666666667
defines,1.666666667
computing,1.666666667
wcounts,1.666666667
alternative,1.666666667
decoder_input],1.666666667
break,1.666666667
c_p,1.666666667
product,1.666666667
lost,1.666666667
162   tensor_value,1.666666667
slower,1.666666667
slowdown,1.666666667
**~30% slower**,1.666666667
~30% slower,1.666666667
input_layer1,1.666666667
i2,1.666666667
efficient,1.666666667
-> 3153                                                        original_backend,1.666666667
assigning,1.666666667
assigning 0,1.666666667
fault,1.666666667
scenarios,1.666666667
retraining,1.666666667
reaches,1.666666667
approximately,1.666666667
trials,1.666666667
stop_accuracy = 0,1.666666667
100x100,1.666666667
amt,1.666666667
x_bad,1.666666667
x_bad],1.666666667
-> 2520                         process_node,1.666666667
process_node,1.666666667
ids,1.666666667
osx,1.666666667
floats,1.666666667
summaries,1.666666667
osx 10,1.666666667
rounded,1.666666667
"-

gan",1.666666667
_bootstrap,1.666666667
break 1,1.666666667
break 2,1.666666667
var_pred =,1.666666667
var_pred,1.666666667
% block_id,1.666666667
check_circular,1.666666667
allow_nan,1.666666667
separators,1.666666667
flag_train,1.666666667
75 >> rounded,1.666666667
amazing,1.666666667
_check_pydot,1.666666667
paired,1.666666667
autogen`,1.666666667
notimplementedtype,1.666666667
"untrained

#",1.666666667
test_input,1.666666667
inputimg,1.666666667
constructed,1.666666667
embedding_vector,1.666666667
multi_filter_conv,1.666666667
gave,1.666666667
has_inf_or_nan`,1.666666667
gpualloc<,1.666666667
`variancescaling`,1.666666667
accessed,1.666666667
valid_chars,1.666666667
= [[valid_chars[,1.666666667
shallow,1.666666667
decoder_embeddings,1.666666667
discount_reward_placeholder =,1.666666667
action_onehot_placeholder,1.666666667
discount_reward_placeholder],1.666666667
train_index,1.666666667
phenomenon,1.666666667
maximizing,1.666666667
# -*- coding,1.666666667
data_pre,1.666666667
"37%

evaluating",1.666666667
weightclip,1.666666667
dst,1.666666667
mainin,1.666666667
"+1

    

    #coding",1.666666667
augmenting,1.666666667
4% faster,1.666666667
movies,1.666666667
pretrained_weights,1.666666667
input_array,1.666666667
interval=1,1.666666667
deploy,1.666666667
# grab,1.666666667
"2]

    # grab",1.666666667
encoded_input,1.666666667
sq1,1.666666667
aren,1.666666667
plug,1.666666667
bid1,1.666666667
tables,1.666666667
11 players +,1.666666667
ball,1.666666667
o1,1.666666667
o2,1.666666667
test_x1,1.666666667
test_x2,1.666666667
stay,1.666666667
mapfull,1.666666667
garbage,1.666666667
_pywrap_tensorflow_internal,1.666666667
model_origin,1.666666667
/dcc,1.666666667
/dcc/,1.666666667
multiple_inputs_generator,1.666666667
init_stuff,1.666666667
nprobs,1.666666667
pasted,1.666666667
maximize,1.666666667
globals,1.666666667
fapl,1.666666667
x_newfc,1.666666667
wxh,1.666666667
whh,1.666666667
state_shape,1.666666667
break`,1.666666667
cleaner,1.666666667
draft,1.666666667
head_model,1.666666667
pred_outcome,1.666666667
reconst_data,1.666666667
parallel_autoencoder,1.666666667
passthrough,1.666666667
_costs_embd,1.666666667
* stridesx1,1.666666667
* stridesy1,1.666666667
inpt,1.666666667
maxt],1.666666667
`[bs,1.666666667
**vars,1.666666667
include_distance,1.666666667
laid,1.666666667
mixture,1.666666667
reused,1.666666667
frame_len,1.666666667
big_is_error=,1.666666667
f_active_next,1.666666667
log_f_next,1.666666667
idxs =,1.666666667
skip_idxs,1.666666667
[train_op,1.666666667
shortcut_layer],1.666666667
threed_model,1.666666667
differ,1.666666667
jakob,1.666666667
systems,1.666666667
production,1.666666667
opts,1.666666667
101   tensor_value,1.666666667
bot,1.666666667
qry,1.666666667
/ i2,1.666666667
3x3,1.666666667
hyperparameters,1.666666667
coding,1.666666667
saltandpepper,1.666666667
n_input,1.666666667
x_indices,1.666666667
x_values,1.666666667
gpu_list,1.666666667
arch,1.666666667
l_weights,1.666666667
concern,1.666666667
num_epoch,1.666666667
"```

_activation =",1.666666667
title_size,1.666666667
50 hydrangea,1.666666667
min_after_dequeue=2000,1.666666667
nf =,1.666666667
inpshape =,1.666666667
w_ij,1.666666667
exported,1.666666667
small_img,1.666666667
service,1.666666667
_run_inner,1.666666667
wrapper_output,1.666666667
s_t_&,1.666666667
[head_lstm,1.666666667
w_regularizer=,1.666666667
w_regularizer,1.666666667
"]                              

y_sample =",1.666666667
y_sample,1.666666667
joint,1.666666667
theano_vs_tf,1.666666667
all_text =,1.666666667
all_text,1.666666667
im1,1.666666667
reshapes,1.666666667
fscore,1.666666667
"[0]

            batch_features[",1.666666667
karpathy,1.666666667
//karpathy,1.666666667
list_classes,1.666666667
] = default_str,1.666666667
reuse_previous_algo,1.666666667
"{

274             cudagetlasterror",1.666666667
99997377e-01   2,1.666666667
stepy,1.666666667
narrow,1.666666667
**data_gen_args,1.666666667
mask_datagen,1.666666667
image_generator,1.666666667
declared,1.666666667
untrained,1.666666667
actual_scales,1.666666667
xor,1.666666667
bitwise,1.666666667
conv_input,1.666666667
input_sequence,1.666666667
120                 input_masks,1.666666667
164   tensor_value,1.666666667
40% slower,1.666666667
dense_sum,1.666666667
-> 2900                                                        original_backend,1.666666667
outlined,1.666666667
decorators,1.666666667
cache_data,1.666666667
maintain,1.666666667
music_input,1.666666667
unintuitive,1.666666667
consistently,1.666666667
10 folds,1.666666667
"break

#",1.666666667
seq1,1.666666667
[hovedkategori_loss,1.666666667
learnt,1.666666667
integrate,1.666666667
`tf,1.665173572
tf,1.665173572
#NAME?,1.665173572
3006         # tf,1.665173572
tf 1,1.665173572
[tf,1.665173572
"`

<tf",1.665173572
[<tf,1.665173572
<tf,1.665173572
"```

[<tf",1.665173572
~tf,1.665173572
"tf

      6",1.665173572
"3

tf 1",1.665173572
#NAME?,1.665173572
8-tf`,1.665173572
"tf

      2",1.665173572
tf},1.665173572
<=> tf,1.665173572
*tf,1.665173572
* tf,1.665173572
] = tf,1.665173572
"4



tf 1",1.665173572
"]]

  tf",1.665173572
tf-,1.665173572
read,1.664233577
# read,1.664233577
read-,1.664233577
* read,1.664233577
--> 165                     epsilon=,1.6625
epsilon,1.6625
#NAME?,1.6625
--> 181             epsilon=,1.6625
epsilon=0,1.6625
epsilon=,1.6625
write,1.661971831
"write 



>",1.661971831
device,1.660377358
0/device,1.660377358
device`,1.660377358
/device,1.660377358
arguments={,1.655737705
arguments,1.655737705
3 arguments,1.655737705
#     arguments,1.655737705
**arguments,1.655737705
662             arguments[,1.655737705
# arguments,1.655737705
4 arguments,1.655737705
`float`,1.655172414
float,1.655172414
]=float,1.655172414
float 64,1.655172414
/ float,1.655172414
outputs[,1.653846154
outputs,1.653846154
-> 1883         outputs =,1.653846154
**outputs**,1.653846154
outputs=[,1.653846154
outputs[0],1.653846154
outputs=,1.653846154
2 outputs,1.653846154
>outputs =,1.653846154
outputs={,1.653846154
outputs=[],1.653846154
outputs =,1.653846154
"outputs

```",1.653846154
`outputs`,1.653846154
outputs = [],1.653846154
"]

outputs",1.653846154
outputs + [,1.653846154
transform,1.652173913
nn,1.64893617
<nn,1.64893617
nn-0-36-20180209,1.64893617
**nn,1.64893617
paper,1.648148148
paper],1.648148148
[paper ],1.648148148
[paper],1.648148148
paper][1],1.648148148
handle,1.647058824
lstms,1.647058824
256 lstms,1.647058824
train,1.646799117
# train,1.646799117
train[,1.646799117
/train/,1.646799117
"```

train",1.646799117
---> 19     train,1.646799117
#NAME?,1.646799117
"#

# train

#",1.646799117
"0403

train",1.646799117
/001/train/*,1.646799117
/002/train/*,1.646799117
/003/train/*,1.646799117
/004/train/*,1.646799117
/005/train/*,1.646799117
<train>,1.646799117
`train,1.646799117
{train,1.646799117
[train,1.646799117
train [,1.646799117
#train =,1.646799117
"```
train",1.646799117
custom_objects,1.643312102
custom_objects={,1.643312102
custom_objects=,1.643312102
custom_objects = {,1.643312102
`custom_objects`,1.643312102
initialized,1.642857143
input_layer,1.642857143
averagepooling2d,1.642857143
#NAME?,1.642857143
batches,1.638888889
5000 batches,1.638888889
100 batches,1.638888889
10 batches,1.638888889
#NAME?,1.638554217
base_model,1.638554217
#base_model,1.638554217
*base_model,1.638554217
type,1.637362637
type %,1.637362637
type`,1.637362637
"]



type",1.637362637
"type

    #",1.637362637
type `,1.637362637
`<type,1.637362637
"]

type",1.637362637
<type,1.637362637
encode,1.636363636
augment,1.636363636
vae,1.636363636
repeatvector,1.636363636
-> 2509             process_layer,1.636363636
process_layer,1.636363636
"1

    vae",1.636363636
`repeatvector,1.636363636
# encode,1.636363636
h5g,1.636363636
-> 2490             process_layer,1.636363636
-> 2450             process_layer,1.636363636
initial_state,1.633333333
`initial_state`,1.633333333
initial_state =,1.633333333
from_config,1.630434783
model1,1.627906977
> model1,1.627906977
model1],1.627906977
[model1,1.627906977
documentation,1.626666667
[documentation],1.626666667
documentation],1.626666667
lambda,1.625468165
#NAME?,1.625468165
<lambda>,1.625468165
"lambda

---> 42",1.625468165
multiprocessing,1.625
longer,1.625
bias,1.625
resource,1.625
#NAME?,1.625
_reconstruct,1.625
instance],1.625
instance,1.625
input_,1.625
[input_],1.625
referenced,1.625
scenario,1.625
`h0`,1.625
**instance,1.625
bias =,1.625
x3,1.625
x3],1.625
958                     training_updates =,1.625
988                     training_updates =,1.625
breaks,1.625
measure,1.625
foo,1.625
precision,1.625
computer,1.625
1 bias,1.625
computer 1,1.625
computer 2,1.625
h0,1.625
h0=0,1.625
happened,1.625
adversarial_model,1.625
precision=,1.625
happened],1.625
"]



            training_updates =",1.625
<foo>,1.625
input1,1.620689655
input1],1.620689655
[input1,1.620689655
gru,1.61971831
`gru`,1.61971831
` gru,1.61971831
"gru

     41",1.61971831
queue,1.619047619
mentioned,1.619047619
pdf,1.619047619
queue =,1.619047619
pdf / 2,1.619047619
pdf],1.619047619
"pdf



**",1.619047619
format,1.616161616
` format,1.616161616
format=,1.616161616
--format=,1.616161616
generator_output =,1.615384615
experiments,1.615384615
--> 155                 generator_output =,1.615384615
generator_output,1.615384615
trainy,1.615384615
"]]

```



removing",1.615384615
pad,1.615384615
removing,1.615384615
code,1.614114114
#NAME?,1.614114114
"#4674



code",1.614114114
"31053334]



code",1.614114114
"8





code",1.614114114
"code

```",1.614114114
**code,1.614114114
4}</code>,1.614114114
code],1.614114114
[code],1.614114114
"`

code",1.614114114
#NAME?,1.614114114
"code





```",1.614114114
"```

code",1.614114114
"code 



```#",1.614114114
"```



## code



```",1.614114114
"]
</code>",1.614114114
graph,1.613445378
#graph =,1.613445378
graph         #,1.613445378
/graph,1.613445378
graph =,1.613445378
"graph

```",1.613445378
decay= 0,1.613333333
decay=0,1.613333333
decay,1.613333333
decay = 0,1.613333333
`decay`,1.613333333
decay],1.613333333
encountered,1.611111111
#NAME?,1.608695652
width,1.608695652
deserialize_keras_object,1.608695652
"deserialize_keras_object

>",1.608695652
width=400,1.608695652
width*2,1.608695652
width/2,1.608695652
50 width,1.608695652
labels,1.608108108
5 labels,1.608108108
1000 labels,1.608108108
labels /=,1.608108108
labels /,1.608108108
# labels,1.608108108
labels=,1.608108108
labels[0,1.608108108
labels = [,1.608108108
great,1.607142857
gpus=4,1.607142857
gpus,1.607142857
2 gpus,1.607142857
gpus=[0,1.607142857
gpus=2,1.607142857
4-gpus,1.607142857
4 gpus,1.607142857
8 gpus,1.607142857
3 gpus,1.607142857
gpus=8,1.607142857
gpus=3,1.607142857
1-4 gpus,1.607142857
decoder,1.605263158
testing,1.605263158
``ndim,1.605263158
``ndim``,1.605263158
--> 204                 decoder,1.605263158
206                     decoder,1.605263158
ndim,1.605263158
ndim=3,1.605263158
* decoder,1.605263158
ndim == 1,1.605263158
"```



testing",1.605263158
ndim <= 5,1.605263158
start,1.6
slice_i,1.6
istraindataortest,1.6
ensemble,1.6
orthogonal,1.6
denominator,1.6
prototype,1.6
laptop,1.6
min,1.6
fall,1.6
extension,1.6
immediately,1.6
transformation,1.6
possibly,1.6
input_fn,1.6
output_classes,1.6
elegant,1.6
rescaling,1.6
# start,1.6
25-50 min,1.6
20-40 min,1.6
20-25 min,1.6
oserror,1.6
reconstruct,1.6
sns,1.6
classify,1.6
oom,1.6
2 elements,1.6
odd,1.6
/v0/,1.6
stated,1.6
dense3,1.6
paragraph,1.6
head,1.6
trial_batch_2,1.6
reduce_lr,1.6
x_training,1.6
"```





x_training",1.6
"64 elements



[1",1.6
show_shapes,1.6
denominator =,1.6
aux,1.6
entry,1.6
preprocessed,1.6
purposes,1.6
indent,1.6
apply_async,1.6
field,1.6
percentage %,1.6
`orthogonal`,1.6
run_code,1.6
#data_x=,1.6
data_t[,1.6
data_x[,1.6
`epsilon_std`,1.6
is_keras_tensor,1.6
xpred[,1.6
frame,1.6
#NAME?,1.6
frame[0][0][0],1.6
mu2,1.6
codecs,1.6
----> 1 codecs,1.6
#NAME?,1.6
nb_features=4,1.6
nb_features,1.6
matching,1.6
closure,1.6
indent=4,1.6
start=1,1.6
shortcut,1.6
shortcut],1.6
`oom,1.6
* natively,1.6
elements,1.6
natively,1.6
lstm_layer,1.6
start=0,1.6
logic,1.6
`min`,1.6
averaging,1.6
"]

    active_next =",1.6
active_next],1.6
tokens,1.6
[start[0],1.6
gestures,1.6
histograms,1.6
last_layer,1.6
listcolumnsoutputs,1.6
teo,1.6
texts_to_sequences_generator,1.6
150 elements,1.6
[start],1.6
[start,1.6
start +,1.6
start <,1.6
compiles,1.6
bilstm,1.6
percentage,1.6
practice,1.6
hinge,1.6
f1_x,1.6
f2_x,1.6
[f1_x,1.6
f2_x],1.6
v0,1.6
`on_train_begin`,1.6
on_train_begin],1.6
filter_length=5,1.6
create,1.593333333
# create,1.593333333
"create

                `",1.593333333
"7

     

    # create",1.593333333
2 create,1.593333333
weights,1.592672414
weights=,1.592672414
#weights =,1.592672414
weights[0],1.592672414
weights[1],1.592672414
`weights,1.592672414
weights =,1.592672414
weights[1,1.592672414
= weights[0],1.592672414
2 weights,1.592672414
#NAME?,1.592672414
weights],1.592672414
[weights,1.592672414
/weights,1.592672414
weights = [,1.592672414
weights =[,1.592672414
weights[,1.592672414
states,1.592592593
4 states,1.592592593
states[0],1.592592593
states [0],1.592592593
states[1],1.592592593
states = [,1.592592593
states[1,1.592592593
states],1.592592593
states =,1.592592593
json,1.592105263
] = json,1.592105263
pass,1.591549296
# pass,1.591549296
computed,1.590909091
model`],1.590871196
model,1.590871196
`model,1.590871196
"``

``model",1.590871196
---> 58 model,1.590871196
[model,1.590871196
"`

`model",1.590871196
----> 2 model,1.590871196
3 model,1.590871196
"model

#",1.590871196
"96%

model",1.590871196
*model,1.590871196
"```

 model",1.590871196
---> 50 model,1.590871196
`  model,1.590871196
/model,1.590871196
model`,1.590871196
`model`,1.590871196
#model,1.590871196
"```

model",1.590871196
----> 1 model,1.590871196
"```

# model",1.590871196
-> model,1.590871196
` model,1.590871196
#NAME?,1.590871196
> ----> 3     model,1.590871196
# model,1.590871196
"152 

    153 model",1.590871196
``model,1.590871196
"------                                             ---------------

model            ----------------",1.590871196
`# model,1.590871196
>>> model,1.590871196
"]]



model",1.590871196
---> 41             model,1.590871196
"*

model",1.590871196
>model,1.590871196
* model,1.590871196
> model,1.590871196
"> 

> model",1.590871196
"**



  model",1.590871196
"51 

---> 52 model",1.590871196
"#

    # model",1.590871196
"#

# model",1.590871196
#NAME?,1.590871196
] + model,1.590871196
"150528

model",1.590871196
model **,1.590871196
"+10

model",1.590871196
**model,1.590871196
"```

//model",1.590871196
"0



model",1.590871196
"1}

model",1.590871196
>>> model =,1.590871196
"model

5",1.590871196
"```

# model 1",1.590871196
model 2,1.590871196
33 model,1.590871196
"```



model",1.590871196
"14 

     15 model",1.590871196
---> 16 model,1.590871196
"model

```",1.590871196
"constant



```",1.588235294
constant,1.588235294
masks,1.588235294
constant{1},1.588235294
constant =,1.588235294
background,1.588235294
constant**,1.588235294
constant`,1.588235294
constant{1,1.588235294
constant{0,1.588235294
inputs,1.587878788
inputs =,1.587878788
[inputs],1.587878788
`inputs`,1.587878788
#NAME?,1.587878788
**inputs**,1.587878788
180             inputs,1.587878788
2 inputs,1.587878788
inputs[0],1.587878788
*inputs,1.587878788
"```

inputs",1.587878788
>     inputs =,1.587878788
"inputs

```",1.587878788
inputs=,1.587878788
inputs[1],1.587878788
#inputs,1.587878788
inputs={,1.587878788
inputs=[,1.587878788
inputs],1.587878788
inputs = [,1.587878788
inputs = [],1.587878788
inputs = [1],1.587878788
inputs[,1.587878788
#NAME?,1.587878788
inputs`,1.587878788
"0]

inputs",1.587878788
30 inputs,1.587878788
inputs += [,1.587878788
multi_gpu_model,1.583333333
visualize,1.583333333
//cloud,1.583333333
mapping,1.583333333
use_bias,1.583333333
`multi_gpu_model`,1.583333333
transforms,1.583333333
debug,1.583333333
concatenated,1.583333333
****`multi_gpu_model`,1.583333333
characters,1.583333333
multi_gpu_model`,1.583333333
"-1]

                batch_x_left",1.583333333
batch_x_left,1.583333333
"-1]

                    batch_x_left",1.583333333
1 mapping,1.583333333
[transforms,1.583333333
op,1.581395349
785         op =,1.581395349
"op

    789",1.581395349
#NAME?,1.581395349
l2,1.580645161
l2=0,1.580645161
--> 900                          run_metadata_ptr,1.578947368
run_metadata_ptr,1.578947368
things,1.578947368
iterator,1.578947368
[d1,1.578947368
d1,1.578947368
guys,1.578947368
"iterator

```",1.578947368
> --> 889                          run_metadata_ptr,1.578947368
"iterator

*",1.578947368
--> 767                          run_metadata_ptr,1.578947368
--> 766                          run_metadata_ptr,1.578947368
created,1.575342466
> created,1.575342466
fails,1.575
7 fails,1.575
6 fails,1.575
# <<fails,1.575
"```



fails",1.575
__call__,1.573913043
"__call__

    **",1.573913043
"__call__

2018-04-09 02",1.573913043
__call__`,1.573913043
``__call__,1.573913043
variance,1.571428571
al,1.571428571
windows 7/ 10,1.571428571
windows,1.571428571
_do_run,1.571428571
_run_fn,1.571428571
ignore,1.571428571
9599999785423279`float16,1.571428571
pool,1.571428571
to_categorical,1.571428571
observed,1.571428571
kl_loss =,1.571428571
keras_model,1.571428571
64284 corresponds,1.571428571
corresponds,1.571428571
reraise,1.571428571
+        # ignore,1.571428571
variance =,1.571428571
windows 10,1.571428571
windows 7,1.571428571
progbar,1.571428571
uses_correlation = {,1.571428571
= uses_correlation[,1.571428571
uses_correlation,1.571428571
comments,1.571428571
printed,1.571428571
float16,1.571428571
replicate,1.571428571
main_input,1.571428571
cifar-10,1.571428571
obtained,1.571428571
cifar,1.571428571
deconv3d,1.571428571
n_samples,1.571428571
randomuniform,1.571428571
map_fn,1.571428571
`deconv3d,1.571428571
crash,1.571428571
depends,1.571428571
anchor,1.571428571
cudnngru,1.571428571
`cudnngru`,1.571428571
n_samples=1000,1.571428571
imresize,1.571428571
windows-10,1.571428571
"windows

2017-08-30 11",1.571428571
[n_samples,1.571428571
"====================================================================================================

main_input",1.571428571
word_train_label,1.571428571
# ignore,1.571428571
14     # ignore,1.571428571
main_model,1.571428571
holdout,1.571428571
# corresponds,1.571428571
scale,1.568181818
scale=127,1.568181818
* scale,1.568181818
# scale,1.568181818
scale=1,1.568181818
scale=0,1.568181818
x_c,1.566666667
x_c +,1.566666667
[[list,1.563535912
list,1.563535912
144                                                            list,1.563535912
list `[0,1.563535912
#NAME?,1.563535912
`list`,1.563535912
# list,1.563535912
"+

--> 144                                                            list",1.563535912
#NAME?,1.563535912
"+

--> 139                                                            list",1.563535912
#NAME?,1.563535912
_standardize_user_data,1.5625
build,1.560747664
# build,1.560747664
samples,1.560240964
60000 samples,1.560240964
200000 samples,1.560240964
[samples,1.560240964
~ 4000 samples,1.560240964
15000 samples,1.560240964
1107 samples,1.560240964
277 samples,1.560240964
25000 samples,1.560240964
32 samples,1.560240964
779 samples,1.560240964
30 samples,1.560240964
0 samples,1.560240964
8 samples,1.560240964
50000 samples,1.560240964
3000 samples,1.560240964
1604 samples,1.560240964
7 samples,1.560240964
46460 samples,1.560240964
6000 samples,1.560240964
10 samples`,1.560240964
"samples

4",1.560240964
582 samples,1.560240964
100 samples,1.560240964
54000 samples,1.560240964
2804 samples,1.560240964
3 samples,1.560240964
000 samples,1.560240964
pred,1.56
m1,1.56
--> m1 -->,1.56
"```

>>> m1",1.56
>>> m1,1.56
pred[1],1.56
[m1,1.56
pred = [,1.56
pred[,1.56
#NAME?,1.56
kl,1.56
kl =,1.56
achieved,1.555555556
fixed,1.555555556
feed_dict_tensor,1.555555556
-> 1135                              feed_dict_tensor,1.555555556
im,1.555555556
missing,1.555555556
incompatible,1.555555556
xtest,1.555555556
word2vec,1.555555556
suitable,1.555555556
approaches,1.555555556
image_size,1.555555556
#NAME?,1.555555556
vects,1.555555556
output2,1.555555556
state_h,1.555555556
keras2,1.555555556
1 #keras2,1.555555556
pattern,1.555555556
won,1.555555556
> -> 1120                              feed_dict_tensor,1.555555556
cat,1.555555556
#NAME?,1.555555556
confidence,1.555555556
`confidence`,1.555555556
confidence > 0,1.555555556
confidence * 100,1.555555556
2 approaches,1.555555556
output2],1.555555556
image_size[0],1.555555556
image_size[1],1.555555556
batch_x_right,1.555555556
batch_x_right],1.555555556
"```



im",1.555555556
"```



fixed",1.555555556
#NAME?,1.555555556
loading,1.552238806
"```



loading",1.552238806
#  loading,1.552238806
#loading,1.552238806
loading  15,1.552238806
282         bool,1.55
bool,1.55
deserialize,1.547619048
attached,1.545454545
ways,1.545454545
m2,1.545454545
preds+1,1.545454545
memoryerror,1.545454545
preds,1.545454545
"```

>>> m2",1.545454545
>>> m2,1.545454545
densemodule,1.545454545
m2],1.545454545
loaded_model,1.545454545
preds[,1.545454545
curr_layer,1.545454545
> memoryerror,1.545454545
"15674345853

```

attached",1.545454545
"```

memoryerror",1.545454545
289                                                     &chosen_algo,1.545454545
#NAME?,1.545454545
chosen_algo,1.545454545
415                                                   chosen_algo,1.545454545
427                                                     chosen_algo,1.545454545
446       chosen_algo,1.545454545
preds[0,1.545454545
steps_per_epoch,1.543103448
`steps_per_epoch`,1.543103448
steps_per_epoch=200,1.543103448
steps_per_epoch=100,1.543103448
steps_per_epoch=2000,1.543103448
steps_per_epoch=1000,1.543103448
steps_per_epoch=120,1.543103448
steps_per_epoch=,1.543103448
steps_per_epoch =,1.543103448
steps_per_epoch = 42,1.543103448
steps_per_epoch=2,1.543103448
steps_per_epoch = 486,1.543103448
steps_per_epoch = 1,1.543103448
steps_per_epoch=2801,1.543103448
steps_per_epoch = 20,1.543103448
steps_per_epoch = 25,1.543103448
steps_per_epoch=8856,1.543103448
steps_per_epoch = 0,1.543103448
steps_per_epoch=128,1.543103448
steps_per_epoch=10,1.543103448
steps_per_epoch=4,1.543103448
steps_per_epoch=1,1.543103448
steps_per_epoch = 8000,1.543103448
steps_per_epoch=50000,1.543103448
steps_per_epoch=500,1.543103448
caused,1.542857143
"]]



caused",1.542857143
"]]

caused",1.542857143
"]]

> 

> caused",1.542857143
random_state=43,1.541666667
people,1.541666667
random_state=1,1.541666667
neg,1.541666667
neg =,1.541666667
random_state=2,1.541666667
top_model,1.541666667
random_state=42,1.541666667
//people,1.541666667
seta,1.541666667
random_state=,1.541666667
img,1.541401274
[img,1.541401274
-> 1233                 img =,1.541401274
`img `,1.541401274
"```

img #",1.541401274
] = img,1.541401274
[img],1.541401274
{img,1.541401274
show,1.540540541
flow,1.540540541
maximum,1.540540541
maximum`,1.540540541
# show,1.540540541
sample_weight,1.538461538
activity_regularizer,1.538461538
requirement,1.538461538
trainx,1.538461538
sample_weight>,1.538461538
activity_regularizer=,1.538461538
sample_weight=,1.538461538
reduced,1.538461538
vocabdic,1.538461538
"+1

    vocabdic[",1.538461538
"reduced

5",1.538461538
> requirement,1.538461538
decoded,1.535714286
# extract,1.535714286
extract,1.535714286
"385 

386       // extract",1.535714286
gamma,1.533333333
loss_weights,1.533333333
loss_weights=[1,1.533333333
dilation_rate,1.533333333
init,1.533333333
minimal,1.533333333
implementations,1.533333333
init=,1.533333333
`init`,1.533333333
dilation_rate=8,1.533333333
`dilation_rate ==,1.533333333
dilation_rate=,1.533333333
#           loss_weights=[1,1.533333333
> loss_weights,1.533333333
gamma =,1.533333333
"gamma

```",1.533333333
total_loss,1.531914894
total_loss] +,1.531914894
total_loss`,1.531914894
total_loss =,1.531914894
total_loss = 0,1.531914894
#total_loss = 0,1.531914894
error,1.530046225
error= 1,1.530046225
[error],1.530046225
"error

```",1.530046225
"```



error",1.530046225
> error,1.530046225
"`



error",1.530046225
^^^^ error,1.530046225
"0



error",1.530046225
#error,1.530046225
"�

`error",1.530046225
` error,1.530046225
"]

> 



**error",1.530046225
"`

```

error",1.530046225
"`

error",1.530046225
"` 



error",1.530046225
[#error,1.530046225
"`

















error",1.530046225
"14

error",1.530046225
# error,1.530046225
"```



**error",1.530046225
overwrite,1.529411765
left,1.529411765
[left,1.529411765
returned,1.529411765
`left`,1.529411765
cpu,1.52866242
/cpu,1.52866242
0/cpu,1.52866242
[cpu],1.52866242
>cpu</,1.52866242
#NAME?,1.52866242
behavior,1.527777778
subtensor{,1.526315789
nb_epoch=200,1.525252525
nb_epoch=10,1.525252525
nb_epoch=10002,1.525252525
nb_epoch=1,1.525252525
nb_epoch=20,1.525252525
nb_epoch=100,1.525252525
nb_epoch=11,1.525252525
nb_epoch=500,1.525252525
nb_epoch=1000,1.525252525
`nb_epoch`,1.525252525
5     nb_epoch=500,1.525252525
nb_epoch=10000,1.525252525
nb_epoch=2,1.525252525
nb_epoch=6,1.525252525
nb_epoch = 25,1.525252525
nb_epoch,1.525252525
nb_epoch=50,1.525252525
nb_epoch=32,1.525252525
nb_epoch=250,1.525252525
nb_epoch=5,1.525252525
nb_epoch=40,1.525252525
nb_epoch=3,1.525252525
handling,1.523809524
50 columns,1.52173913
2 columns,1.52173913
comment,1.52173913
columns,1.52173913
# comment,1.52173913
scores,1.52173913
columns=[,1.52173913
4 columns,1.52173913
scores[0],1.52173913
scores[1],1.52173913
comment],1.52173913
128 columns,1.52173913
scores[,1.52173913
linear,1.520833333
#NAME?,1.520833333
convlstm2d,1.52
batch_size,1.518472906
batch_size},1.518472906
+= batch_size,1.518472906
* batch_size,1.518472906
batch_size=64,1.518472906
batch_size]+[160,1.518472906
batch_size=500,1.518472906
batch_size = 128,1.518472906
batch_size=128,1.518472906
batch_size = 200,1.518472906
batch_size=5,1.518472906
batch_size=1,1.518472906
`batch_size = 16,1.518472906
`16 batch_size`,1.518472906
batch_size=20,1.518472906
batch_size=100,1.518472906
batch_size=32,1.518472906
batch_size = 64,1.518472906
batch_size = 100,1.518472906
// batch_size,1.518472906
batch_size=16,1.518472906
>= batch_size,1.518472906
batch_size = 8,1.518472906
0*batch_size*,1.518472906
batch_size==1,1.518472906
batch_size = 512,1.518472906
batch_size=4,1.518472906
batch_size=,1.518472906
batch_size=2,1.518472906
---> 20                             batch_size = 1024,1.518472906
//batch_size,1.518472906
batch_size = 2,1.518472906
/batch_size,1.518472906
*batch_size,1.518472906
batch_size=8,1.518472906
batch_size=10,1.518472906
batch_size=512,1.518472906
batch_size=256,1.518472906
batch_size = 32,1.518472906
batch_size=50,1.518472906
batch_size=2000,1.518472906
[batch_size,1.518472906
batch_size=1024,1.518472906
batch_size=30,1.518472906
4     batch_size=512,1.518472906
batch_size=1000,1.518472906
1 batch_size,1.518472906
batch_size=60000,1.518472906
/ batch_size,1.518472906
* batch_size`,1.518472906
batch_size=40,1.518472906
*batch_size],1.518472906
#NAME?,1.518472906
`batch_size`,1.518472906
`batch_size=100`,1.518472906
batch_size *,1.518472906
[batch_size],1.518472906
batch_size = 16,1.518472906
batch_size = 256,1.518472906
batch_size=6,1.518472906
batch_size=200,1.518472906
< batch_size,1.518472906
batch_size=777,1.518472906
3200/batch_size,1.518472906
batch_size=150,1.518472906
batch_size = 1,1.518472906
`batch_size` = 64,1.518472906
`batch_size` = 32,1.518472906
0 * 109527 / batch_size,1.518472906
0 * 13692 / batch_size,1.518472906
batch_size = 10,1.518472906
`batch_size=1`,1.518472906
batch_size=6000,1.518472906
`batch_size = 1`,1.518472906
"```

batch_size",1.518472906
batch_size = 3,1.518472906
script,1.517766497
script],1.517766497
script 02,1.517766497
**script 01,1.517766497
script 01,1.517766497
x_train,1.517699115
"0



x_train",1.517699115
x_train[1,1.517699115
x_train[,1.517699115
x_train =,1.517699115
#NAME?,1.517699115
**x_train =,1.517699115
"> 

> x_train",1.517699115
"```

# x_train",1.517699115
2     x_train,1.517699115
#NAME?,1.517699115
"```

    x_train = [

        [0",1.517699115
`x_train,1.517699115
447           indices=,1.516129032
indices,1.516129032
`429`-indices,1.516129032
indices[0,1.516129032
indices[2,1.516129032
>     indices =,1.516129032
indices[1,1.516129032
called,1.512195122
` called,1.512195122
called `,1.512195122
input_length,1.510869565
input_length=55,1.510869565
input_length = 1,1.510869565
input_length = 27,1.510869565
input_length=1,1.510869565
input_length =,1.510869565
input_length=50,1.510869565
input_length=1415684,1.510869565
input_length=,1.510869565
input_length=25,1.510869565
input_length=3,1.510869565
normal,1.509090909
normal `,1.509090909
doesn,1.50862069
` doesn,1.50862069
# doesn,1.50862069
[doesn,1.50862069
doesn�,1.50862069
result,1.506329114
899       result =,1.506329114
"```



result",1.506329114
result[0][0],1.506329114
result[0][0] == 1,1.506329114
> --> 778                     result =,1.506329114
>     888       result =,1.506329114
result =,1.506329114
result[0],1.506329114
result[1],1.506329114
9 * result,1.506329114
--> 653                 result =,1.506329114
766       result =,1.506329114
765       result =,1.506329114
# dimensions,1.506024096
dimensions,1.506024096
3 dimensions,1.506024096
5 dimensions,1.506024096
dimensions =,1.506024096
2 dimensions,1.506024096
4 dimensions,1.506024096
6 dimensions,1.506024096
[1]->dimensions[0] = 32,1.506024096
[0]->dimensions[0] = 320,1.506024096
"dimensions

137",1.506024096
imagenet,1.505494505
size_input_image,1.5
in_sh =,1.5
size_input_image[0],1.5
size_input_image[1],1.5
post_summaries,1.5
pre_summaries,1.5
_c_op =,1.5
compared,1.5
putting,1.5
typo,1.5
problems,1.5
proposal,1.5
performs,1.5
shortened,1.5
_call,1.5
thrown,1.5
ring,1.5
ignoring,1.5
instantiating,1.5
slice,1.5
get_slice,1.5
"slice

            #",1.5
val_rmse,1.5
"keyboardinterrupt

2018-06-02 11",1.5
n_bias,1.5
ps,1.5
aws,1.5
easy,1.5
ready,1.5
kindly,1.5
rnn_encoded,1.5
birnn_encoded,1.5
my_generator,1.5
feeds,1.5
inception_feature_compute,1.5
inception_feature_get,1.5
pool2,1.5
inception_feature_weight =,1.5
input2,1.5
inception_feature2,1.5
[weight_gru1,1.5
weight_gru2],1.5
input2],1.5
[x_train_1,1.5
x_train_2],1.5
[x_test_1,1.5
x_test_2],1.5
_50,1.5
column,1.5
user_input,1.5
slices,1.5
quantized,1.5
json_str =,1.5
json_str,1.5
write_graph,1.5
maxp1,1.5
maxp2,1.5
maxp3,1.5
maxp4,1.5
conv5,1.5
avpl5,1.5
flat1,1.5
dens1,1.5
drop2,1.5
dens2,1.5
val_f,1.5
callback_metrics,1.5
tensor_index],1.5
trirnn_encoded,1.5
"`

`gc",1.5
maximum_iterations,1.5
embeds,1.5
model_output,1.5
k2>=,1.5
k2,1.5
][jb],1.5
raise_from,1.5
`conv3dtranspose`,1.5
inferred,1.5
e_64,1.5
annoying,1.5
updating,1.5
warning,1.5
"rn



#",1.5
rn,1.5
loss1,1.5
apply_softmax,1.5
model_0,1.5
versus,1.5
q_approximator,1.5
q_approximator_fixed,1.5
"```

q_approximator",1.5
stand,1.5
h_decoded,1.5
repeated_decoded_mean,1.5
decoded_sequence,1.5
output_masks,1.5
reviews,1.5
_input,1.5
input_image,1.5
6 column,1.5
flops,1.5
cmd=,1.5
_train_model,1.5
_train_model_default,1.5
image_string,1.5
image_decoded =,1.5
image_decoded,1.5
nxb,1.5
nxl,1.5
outofrangeerror,1.5
#NAME?,1.5
tb,1.5
_data_generator_task,1.5
output_shapes,1.5
graph_element,1.5
% graph_element,1.5
list_of_tensors,1.5
images_to_read,1.5
filesize,1.5
#saves,1.5
y_valid_cv,1.5
x_train_cv_path,1.5
history_fold,1.5
potentially,1.5
due,1.5
encoder_1,1.5
endoder_1_dropout,1.5
encoder_2,1.5
decoder_1,1.5
decoder_2,1.5
decoder_2_dropout,1.5
decoder_4,1.5
mdn,1.5
y_c,1.5
locallyconnected1d,1.5
get_file,1.5
datadir_base,1.5
eexist,1.5
sub_model1,1.5
flow_from_csv,1.5
filename_col=,1.5
e_x,1.5
y_change = 720,1.5
gridsearchcv,1.5
patternzero,1.5
lowerindex,1.5
full_size_image,1.5
#NAME?,1.5
x_trainshape,1.5
x_testflat,1.5
y_testros,1.5
classification_report,1.5
runkerascnnaugment,1.5
x_trainrosreshaped,1.5
y_trainroshot,1.5
x_testrosreshaped,1.5
y_testroshot,1.5
spikes,1.5
trains,1.5
borehole,1.5
initializes,1.5
xtrain,1.5
module_objects,1.5
]*e1[,1.5
bengio,1.5
happy,1.5
analyse,1.5
layer_losses,1.5
designed,1.5
regard,1.5
x_val,1.5
delete,1.5
devicespec,1.5
"2 

      3 compile_model",1.5
explicitly_on_cpu,1.5
gpus_available,1.5
_is_current_explicit_device,1.5
_get_current_tf_device,1.5
_device_function,1.5
288     copy_spec,1.5
wishes,1.5
[in_x,1.5
_build_residual_block,1.5
in_x,1.5
testscore,1.5
workarounds,1.5
improve,1.5
pop,1.5
x_dev,1.5
latent_sampled,1.5
auto_encoder,1.5
amount,1.5
#NAME?,1.5
output_len,1.5
fcnn,1.5
param_dropout_w,1.5
param_dropout_u,1.5
cores,1.5
`timeseriesgenerator,1.5
assignment,1.5
breaking,1.5
block1_conv1,1.5
"201       

    flatten_2",1.5
embedded_sequences1,1.5
ends,1.5
timeseriesgenerator,1.5
prediction_generator,1.5
reports,1.5
reports `,1.5
x_transpose_a,1.5
x_transpose_b,1.5
neurons,1.5
distorted,1.5
batch_image[,1.5
keyboardinterrupt,1.5
_manager,1.5
ctx=,1.5
loads,1.5
configurations,1.5
w__1,1.5
triggers,1.5
make_variable,1.5
single_layer_mem = 1,1.5
get_model_memory_usage,1.5
other_tensor,1.5
layer_outs,1.5
fig,1.5
# lookup,1.5
tracking,1.5
location,1.5
gc,1.5
img_arr,1.5
img_dims,1.5
nb_files-1,1.5
ensure,1.5
dummy_inp_zero,1.5
reusing,1.5
x2_pos_matrix_1,1.5
x2_pos_matrix_2,1.5
pos_embed_1,1.5
pos_embed_2],1.5
forget,1.5
locallyconnected2d,1.5
individual_channels,1.5
output_row,1.5
output_col,1.5
json_file,1.5
worked,1.5
overwritten,1.5
initially,1.5
sentence_length,1.5
fwd,1.5
[conva,1.5
convb],1.5
input_t},1.5
feature_t},1.5
trainingdata,1.5
scrolling,1.5
outstanding,1.5
apply_n_times,1.5
`use_multiprocess`,1.5
train_steps,1.5
vgg_model,1.5
>     490                           output_shapes=[,1.5
x_shape,1.5
10 cores,1.5
[in_embed,1.5
in_merged,1.5
la_lstm,1.5
acccallback,1.5
rows_nr,1.5
relationship,1.5
bugs,1.5
w_array,1.5
xi[0],1.5
"xi[1]

```",1.5
xi[1]]`,1.5
yp,1.5
present_expected,1.5
video_newtork,1.5
acc_newtork,1.5
"```

warning",1.5
puts,1.5
collections,1.5
folks,1.5
vgg_conv_model,1.5
wc,1.5
__next__,1.5
_preprocess_symbolic_input,1.5
l2norm,1.5
net_positive],1.5
net_negative],1.5
[positive_dist,1.5
negative_dist],1.5
mean_pos_dist,1.5
mean_neg_dist],1.5
painter,1.5
[shared_conv_layer_a,1.5
shared_conv_layer_b,1.5
shared_conv_layer_c],1.5
merged_layer,1.5
painter],1.5
out_genre,1.5
out_painter],1.5
multi_tasking_model,1.5
trainstyledatagenerator,1.5
embeddings_enc,1.5
enc_c],1.5
encoder_full_state],1.5
concat_layer,1.5
embeddings_dec,1.5
pseudo_attention_input,1.5
fitted,1.5
x_enc[0],1.5
y_dec[0],1.5
validated,1.5
pack,1.5
softmax_output,1.5
y_pred_max_mat =,1.5
c_t,1.5
c_t],1.5
explained,1.5
--> 129 encoder_outputs,1.5
ret,1.5
repr,1.5
coreml_model,1.5
af,1.5
299x299,1.5
[submodel1,1.5
submodel2,1.5
8 compared,1.5
i1,1.5
#REF!,1.5
square_sum,1.5
generator_inp,1.5
"2285         output_shapes = []

   2286",1.5
loaded_model_json,1.5
weightsfile,1.5
currmodel,1.5
_wrapit,1.5
_ones,1.5
encoders,1.5
train_test_separation,1.5
block5_conv1,1.5
displayed,1.5
inplace_oov,1.5
oov,1.5
worse,1.5
borrow,1.5
generator_train,1.5
model_predict_valid[1],1.5
model_new_predict_valid[1],1.5
wouldn,1.5
contrary,1.5
improve`,1.5
&algorithms,1.5
today,1.5
#NAME?,1.5
seqlg,1.5
explore,1.5
pinyin,1.5
28x28,1.5
120x120,1.5
recv_into,1.5
__exit__,1.5
execute_instructions,1.5
md5,1.5
pp,1.5
x_good,1.5
visible1,1.5
conv11,1.5
pool11,1.5
conv12,1.5
pool12,1.5
conv21,1.5
pool21,1.5
conv22,1.5
pool22,1.5
[flat1,1.5
flat2],1.5
hidden2,1.5
[x_good,1.5
# slice,1.5
28     # slice,1.5
2 months,1.5
drove,1.5
probs1,1.5
stop,1.5
custom_loss,1.5
monitoring,1.5
create_network,1.5
#filenotfounderror,1.5
[winerror 2],1.5
graphviz,1.5
show_layer_names,1.5
plausible,1.5
claim,1.5
results_df,1.5
joined,1.5
encoder_outputs,1.5
care,1.5
readcsv,1.5
avg_image,1.5
correlated,1.5
segment,1.5
segmented,1.5
x_a_shape =,1.5
x_a_shape,1.5
[z_p,1.5
init_gan,1.5
train_one_step,1.5
autoencoder_a,1.5
ssim,1.5
baffled,1.5
>>> m3,1.5
m3,1.5
"```

>>> m3",1.5
kernel_dims,1.5
kernel_dims +,1.5
involve,1.5
create_group,1.5
sort_keys,1.5
[caffenet_stack_1,1.5
caffenet_stack_2],1.5
merged_caffenet_stack,1.5
fuse_output,1.5
cv=2,1.5
cv,1.5
n_jobs,1.5
pre_dispatch,1.5
dispatch_timestamp,1.5
_fit_and_score,1.5
return_times,1.5
"fit_time

    469",1.5
_score,1.5
_multimetric_score,1.5
fbeta_score,1.5
_check_targets,1.5
cuhk-03,1.5
random_pattern,1.5
flag_val,1.5
which_val_data,1.5
multitask,1.5
game,1.5
/beginpage {,1.5
finding,1.5
overwriting,1.5
_body,1.5
concerns,1.5
pred_data_transpose,1.5
inputfilters,1.5
[net_a_input],1.5
[net_b],1.5
qe,1.5
l_cov1,1.5
l_pool1,1.5
l_cov2,1.5
l_pool2,1.5
l_cov3,1.5
l_pool3,1.5
l_dense,1.5
x_val =,1.5
optimal,1.5
user_id,1.5
mmap_mode=,1.5
android,1.5
caption,1.5
test_spec,1.5
magnitude,1.5
resume,1.5
subwords,1.5
y_train_arousal,1.5
` due,1.5
sqrts,1.5
"```

```

ks",1.5
recommend,1.5
emb_weights,1.5
globalmaxpool1d,1.5
b_norm,1.5
cnn1,1.5
[b_lstm1,1.5
b_lstm2],1.5
b_lstm,1.5
gmax,1.5
encoded1,1.5
encoded2,1.5
encoded3,1.5
channel_out,1.5
decoded1,1.5
repeating,1.5
precise,1.5
n_feature[0],1.5
n_batch,1.5
[att_vec1,1.5
att_vec,1.5
"[1]

        reg =",1.5
reg,1.5
[x1_2,1.5
x2_2,1.5
noised,1.5
trainlabel,1.5
leverage,1.5
builder,1.5
presents,1.5
my_r,1.5
buildloop,1.5
`add_weights`,1.5
dec,1.5
telling,1.5
__build_network,1.5
action_prob_placeholder =,1.5
desired_height = 48,1.5
start_x,1.5
_run_callback,1.5
dispatch_shell,1.5
fatal,1.5
/keras_activate,1.5
checkweight],1.5
mainmodel,1.5
optimizes,1.5
generate_arrays,1.5
input_noised,1.5
h_o,1.5
kk=-1,1.5
[kk,1.5
csv_file1,1.5
intersection =,1.5
l_lstm,1.5
# stop,1.5
test_predict,1.5
test_predict_tf,1.5
dependent,1.5
remember,1.5
> [mod,1.5
input_y,1.5
"]

-> 1323         _check_array_lengths",1.5
_check_array_lengths,1.5
set_y,1.5
classifiers,1.5
nov  8 2017,1.5
dictmovies,1.5
nb_labels=2,1.5
nb_labels,1.5
train_docs,1.5
test_docs,1.5
song**,1.5
song,1.5
fc_dt,1.5
lstm3,1.5
coordinate,1.5
fast_mode,1.5
add_image_summaries,1.5
principle,1.5
time_dist_layer,1.5
decode_seq,1.5
loss_3,1.5
metric_2,1.5
vga 980,1.5
gibberish,1.5
y_pre[,1.5
subsample_initial_block,1.5
# ensure,1.5
concatenate_922,1.5
inspect,1.5
load_weights_from_hdf5_group_by_name,1.5
batch_set_value,1.5
overfit,1.5
normaldensity,1.5
power,1.5
/stdv,1.5
[dense_out1,1.5
dense_out2],1.5
embedding_dims,1.5
num_of_samples,1.5
encoded_data,1.5
decoded_data,1.5
l1_distance,1.5
s1,1.5
img_pred,1.5
lmi,1.5
conv1_out,1.5
conv2_out,1.5
conv3_out,1.5
conv4_out,1.5
flat_output,1.5
dense1_out,1.5
[out_lambda,1.5
out_mu,1.5
out_sigma,1.5
out_rho],1.5
in_2],1.5
"problems



```",1.5
peculiar,1.5
conv_2,1.5
conv_3,1.5
softargmax,1.5
conv_5,1.5
generalized,1.5
gtest,1.5
embed1,1.5
causal,1.5
distances,1.5
comb_model,1.5
**comb_model**,1.5
keep_dims,1.5
"3]

foo1",1.5
"3]

foo2",1.5
ann,1.5
friend,1.5
positions,1.5
target_func,1.5
] = loss_transformed,1.5
#NAME?,1.5
maxout,1.5
output_height,1.5
upcast,1.5
obj2,1.5
whats,1.5
max_pool_2d,1.5
train_x2,1.5
train_x2],1.5
_per_input_losses,1.5
extending,1.5
keras_version,1.5
cuinit,1.5
top1,1.5
] = rn,1.5
p5all[,1.5
gettop5acc,1.5
load_module,1.5
5/imp,1.5
img_t0,1.5
img_t1,1.5
[img_feature_t0,1.5
img_feature_t1],1.5
merge_images,1.5
`set_model`,1.5
l779,1.5
coremltools,1.5
coreml,1.5
image_save,1.5
nontrainable_model,1.5
input_style,1.5
y_true_batch,1.5
_1,1.5
num_files_0 *,1.5
num_files_1 *,1.5
list_data,1.5
img_dcc,1.5
/icc/,1.5
img_icc,1.5
img_dobl,1.5
img_iobl,1.5
x_arr_icc,1.5
x_arr_dobl,1.5
layer_conv2d_1_dcc,1.5
layer_maxpool_1_dcc,1.5
layer_conv2d_2_dcc,1.5
layer_conv2d_3_dcc,1.5
layer_maxpool_2_dcc,1.5
layer_conv2d_4_dcc,1.5
layer_conv2d_1_icc,1.5
layer_maxpool_1_icc,1.5
layer_conv2d_2_icc,1.5
layer_conv2d_3_icc,1.5
layer_maxpool_2_icc,1.5
layer_conv2d_4_icc,1.5
layer_conv2d_1_dobl,1.5
layer_maxpool_1_dobl,1.5
layer_conv2d_2_dobl,1.5
layer_conv2d_3_dobl,1.5
layer_maxpool_2_dobl,1.5
layer_conv2d_4_dobl,1.5
layer_conv2d_1_iobl,1.5
layer_maxpool_1_iobl,1.5
layer_conv2d_2_iobl,1.5
layer_conv2d_3_iobl,1.5
layer_maxpool_2_iobl,1.5
layer_conv2d_4_iobl,1.5
[output_dcc,1.5
output_icc,1.5
output_dobl,1.5
output_iobl],1.5
merge_branchs,1.5
layer_dense_1,1.5
layer_dropout,1.5
layer_dense_2,1.5
output_final,1.5
list_train_0,1.5
list_train_1,1.5
variable_13,1.5
@variable_13,1.5
efficiently,1.5
max_pooling2d_2,1.5
1 + tensoflow 1,1.5
slices = [],1.5
function_type,1.5
dirpath,1.5
"1111

warning",1.5
[recurrent_sentence,1.5
recurrent_sentence_and_info,1.5
encoded_model,1.5
lang_model,1.5
easiest,1.5
"[0]

    

    encoders",1.5
new_weights,1.5
b_output,1.5
prob,1.5
agree,1.5
2/resnet50_weights_th_dim_ordering_th_kernels,1.5
res2a_branch1,1.5
decent 75%,1.5
**_question 2,1.5
05d},1.5
graph1,1.5
graph2,1.5
allow_operation,1.5
y_tm1,1.5
wyh,1.5
confident,1.5
12 gb,1.5
h1,1.5
hold,1.5
y_train2,1.5
numberofrows,1.5
deterministic,1.5
g1,1.5
g2,1.5
consisted,1.5
tho,1.5
debugged,1.5
diffw,1.5
inputs1,1.5
[inputs1,1.5
win32gui,1.5
hwnd,1.5
datafile,1.5
ema_in_bn,1.5
ema_lstm1_bn,1.5
ema_lstm2_bn,1.5
ema_dense1_bn,1.5
ema_dense2_bn,1.5
ema_dense3_bn,1.5
flatten_layer_dec,1.5
"0         

**dense_6",1.5
max_sentence_length,1.5
word_input,1.5
expanded_embeddings,1.5
`tee`,1.5
longlong_as_double,1.5
gen_min_max_sequences,1.5
saves,1.5
n_epochs,1.5
stating,1.5
=2x,1.5
batch1,1.5
batch2,1.5
p_batch1,1.5
p_act1,1.5
p_flat1,1.5
v_batch1,1.5
v_act1,1.5
v_flat1,1.5
v_dense1,1.5
v_act2,1.5
v_dense2,1.5
v_output],1.5
positive_vect],1.5
negative_vect],1.5
ppl,1.5
revert,1.5
initial_lr,1.5
generate_negatives,1.5
generate_hard_negatives,1.5
[new_h,1.5
new_c],1.5
pydoc,1.5
x_validf,1.5
capsules],1.5
sorts,1.5
maxout ]**,1.5
affects,1.5
#NAME?,1.5
num=18,1.5
num,1.5
get_1st_layer_output =,1.5
rnn_],1.5
input_dict,1.5
output_dict,1.5
"`



**_you",1.5
ctc_interleave_blanks,1.5
_p_prev,1.5
b_skip_idxs,1.5
common_factor =,1.5
common_factor,1.5
_p_prev =,1.5
_p_prev[,1.5
_p_prev[1,1.5
updated_log_p_prev =,1.5
#NAME?,1.5
checkpoint_file,1.5
branching,1.5
incoming_layer,1.5
stack1_tensor,1.5
[stack2_tensor,1.5
shortcut_tensor],1.5
ct_2_1],1.5
difficulty,1.5
y_test_b,1.5
y_test_c,1.5
y_test_d],1.5
ticket,1.5
r_new1,1.5
wrongly,1.5
train_features,1.5
val_features,1.5
train_labels_one_hot[,1.5
validation_labels_one_hot[,1.5
2 minibatches,1.5
fan_out,1.5
formulation,1.5
pushing,1.5
unsure,1.5
batch_imgs,1.5
my_gen,1.5
silly,1.5
qry_vec,1.5
doc_vec =,1.5
doc_vec,1.5
qry_vec *,1.5
qry_emb,1.5
doc_emb_plus,1.5
doc_emb_minus,1.5
doc_rep_plus],1.5
doc_rep_minus],1.5
relative_distance,1.5
[plus_score,1.5
minus_score],1.5
in_out_neurons,1.5
arduino,1.5
gvs,1.5
combinations,1.5
eventually,1.5
launching,1.5
oldweights,1.5
"]

-> 1390         _check_array_lengths",1.5
"]

   1390         _check_array_lengths",1.5
pool5,1.5
conv6,1.5
pool6,1.5
get_encoding =,1.5
"981}





x_full",1.5
full_set,1.5
x_full,1.5
optimizer_function =,1.5
input_l,1.5
executable,1.5
centered,1.5
seq2seq_plain,1.5
fileio,1.5
efforts,1.5
target_column,1.5
input_dimi,1.5
serialized_example,1.5
cycles,1.5
spatially,1.5
[proposal],1.5
sm_model,1.5
secondlstm,1.5
careful,1.5
pc,1.5
conv_to_rnn_dims =,1.5
gru_1b],1.5
[gru_2,1.5
gru_2b],1.5
speeds,1.5
stop],1.5
stop +,1.5
`stop`,1.5
predict_sequences,1.5
predict_data,1.5
belongs,1.5
saved_model_builder,1.5
new_model,1.5
signature_def_map={,1.5
deployed,1.5
lane_drawn,1.5
lane_image,1.5
# location,1.5
vid_clip,1.5
get_initial_state,1.5
inner_input,1.5
old_inner_state,1.5
ret =,1.5
ret[1,1.5
propagate,1.5
embedding_vec,1.5
epooch,1.5
z1,1.5
z2,1.5
z3,1.5
diagram,1.5
[cdn],1.5
child_input_shape =,1.5
child_input_shape,1.5
concatstateaction,1.5
dimaction,1.5
obvious,1.5
logical,1.5
temp_model,1.5
company_vec_dict,1.5
title_vec_dict,1.5
skill_vec_dict,1.5
[company_vec,1.5
title_vec,1.5
skill_vec],1.5
test_iterator,1.5
max_epoch=30,1.5
head_embedding_file,1.5
head_embedding,1.5
doc_embedding_file,1.5
docs_embedding,1.5
docs_sent_encoder,1.5
docs_doc_encoder,1.5
docs_doc_lstm],1.5
u_regularizer=,1.5
u_regularizer,1.5
batch_input,1.5
"batch_output   

```",1.5
postprocess,1.5
reddit,1.5
input_fld =,1.5
upsampled,1.5
#    1 column,1.5
bottom_crop,1.5
tgen,1.5
poorly,1.5
conv3d_transpose_ngroup`,1.5
join_func,1.5
hidden2=,1.5
bbox_output],1.5
get_p_net,1.5
datas,1.5
raw_text,1.5
# raw_text,1.5
datays[,1.5
prun224,1.5
dramatically,1.5
globalmaxpool2d,1.5
xv,1.5
yv,1.5
total_samples,1.5
convout1,1.5
batchgenerator,1.5
train_file_fp,1.5
relevance,1.5
1236                                     output_shapes,1.5
replicas,1.5
generate_data_from_file,1.5
_initial_value,1.5
poses,1.5
dig,1.5
f1_base,1.5
rpn,1.5
[query_embedding,1.5
positive_embedding,1.5
negative_embedding],1.5
hear,1.5
count_vect,1.5
# count_vect,1.5
list_classes_test,1.5
elapsed_time,1.5
algorithms,1.5
om,1.5
253                                                      requestedcount,1.5
255                                                      &choosen_algo_perf,1.5
onward,1.5
373                                             upscale,1.5
&data_type,1.5
"389 

390       // ensure",1.5
#NAME?,1.5
nvcc,1.5
mod,1.5
y_test_pred=,1.5
y_test_pred_prob=,1.5
"y_test_pred_prob

```",1.5
"```

y_test_pred= 

[[  1",1.5
"99989152e-01]]

```",1.5
np_d_stepy,1.5
write_graph = 1,1.5
`imagefolder`,1.5
class_,1.5
class_imgs,1.5
class_imgs[,1.5
trainloader,1.5
resolves,1.5
w_conv1,1.5
model_working,1.5
model_broken,1.5
mask_generator,1.5
hasn,1.5
continuously,1.5
preferred,1.5
normalization_layer,1.5
expected_prediction,1.5
actual_prediction,1.5
expected_loss,1.5
actual_loss,1.5
expected_weights,1.5
actual_weights,1.5
expected_bias,1.5
actual_bias,1.5
expected_scales,1.5
constant_input,1.5
centers_batch,1.5
consume_less ==,1.5
tboard],1.5
my_range,1.5
my_range_repeated,1.5
full_indices,1.5
surely,1.5
beeing,1.5
arise,1.5
utilize,1.5
`_zero_debias`,1.5
intentionally,1.5
is_placeholder,1.5
maxwell,1.5
1430us  34,1.5
1170us         1  1,1.5
1170us  1,1.5
shuffled_dates,1.5
this_y,1.5
keras_nn_opt,1.5
data_generator_task,1.5
_feed_inputs +,1.5
checkpoint_path =,1.5
output_frozen_graph_name =,1.5
//mscoco,1.5
//gym,1.5
[mscoco,1.5
[locking,1.5
[mscoco],1.5
mscoco,1.5
miou,1.5
"metric_result

                    }",1.5
metric_result,1.5
counts,1.5
othermodel,1.5
var_names,1.5
portable,1.5
valueerrortraceback,1.5
demonstrates,1.5
longest_sequence,1.5
< longest_sequence,1.5
#word_test_token,1.5
word_test_token,1.5
word_traintokenint,1.5
word_testtokenint,1.5
[word_maximal_value_a,1.5
word_maximal_value_b],1.5
char_traintokenint,1.5
char_testtokenint,1.5
word_traintokenintpad[0,1.5
word_traintokenintpad,1.5
[word_traintokenintpad,1.5
test_y,1.5
recurrentshop,1.5
set_model,1.5
decay_mult,1.5
`decay_mult`,1.5
mydata,1.5
finalized,1.5
refactoring,1.5
centralized,1.5
trusted,1.5
codebases,1.5
cropping2d,1.5
add_inbound_node,1.5
emb_words,1.5
emb_sents,1.5
emb_docs,1.5
flbase,1.5
result1,1.5
sub_file,1.5
cache_path,1.5
validate_holdout,1.5
generator_queue,1.5
out_tmp,1.5
generator_from_array,1.5
encoded_frame_sequence,1.5
encoded_music,1.5
addressed,1.5
"```



due",1.5
x_masked,1.5
encoded_rows,1.5
encoded_columns,1.5
resetting,1.5
# amount,1.5
road,1.5
downloading,1.5
`val_gen`,1.5
click [,1.5
`graphviz`,1.5
"```
lr_init=0",1.5
lr_temp,1.5
unaware,1.5
dh,1.5
proba,1.5
encoding_1,1.5
encoding_2,1.5
underkategori_loss],1.5
test_num,1.5
test_y[,1.5
prob_,1.5
indexing,1.5
captions,1.5
girl,1.5
a0,1.5
aswell,1.5
graphics,1.5
to_translate,1.5
ord,1.5
translate_table,1.5
>>> translate_non_alphanumerics,1.5
dense,1.493736952
[dense,1.493736952
dense],1.493736952
#NAME?,1.493736952
#NAME?,1.493736952
[dense],1.493736952
"dense

4",1.493736952
"[

    dense",1.493736952
`dense,1.493736952
"[

       dense",1.493736952
"dense

#",1.493736952
"[

                    dense",1.493736952
exception,1.492957746
exception [,1.492957746
"```
exception",1.492957746
csv=,1.490909091
csv,1.490909091
"```

 plt",1.490196078
plt,1.490196078
16 plt,1.490196078
accuracy,1.487623762
accuracy {},1.487623762
accuracy 0,1.487623762
~10% accuracy,1.487623762
accuracy*100,1.487623762
93% accuracy,1.487623762
9% accuracy,1.487623762
33% accuracy,1.487623762
"82% accuracy

4",1.487623762
"75

accuracy = 0",1.487623762
accuracy%,1.487623762
90% accuracy,1.487623762
65% accuracy,1.487623762
95% accuracy,1.487623762
99% accuracy,1.487623762
"accuracy

                    #",1.487623762
"42%

* accuracy",1.487623762
accuracy = 0,1.487623762
added,1.487179487
# added,1.487179487
model2,1.486486486
> model2,1.486486486
"> 

> model2",1.486486486
[model2,1.486486486
model2],1.486486486
`model2`,1.486486486
**model2,1.486486486
`conv2dtranspose`,1.482758621
#NAME?,1.482758621
``conv2dtranspose``,1.482758621
conv2dtranspose,1.482758621
rgb,1.48
nb_filter,1.48
200 rgb,1.48
nb_filter=-1,1.48
nb_filter=16,1.48
nb_filter=128,1.48
point,1.479166667
``typeerror``,1.479166667
typeerror,1.479166667
"```

typeerror",1.479166667
`typeerror,1.479166667
"291 

    292 



typeerror",1.479166667
> typeerror,1.479166667
point 4,1.479166667
>  typeerror,1.479166667
"]

typeerror",1.479166667
>typeerror,1.479166667
point],1.479166667
"207 

    208 



typeerror",1.479166667
"typeerror 

```",1.479166667
point **,1.479166667
"303 

    304 



typeerror",1.479166667
parallel_model,1.47826087
`parallel_model,1.47826087
#parallel_model,1.47826087
seed,1.477477477
seed=1,1.477477477
seed=,1.477477477
seed=0,1.477477477
seed=7,1.477477477
seed],1.477477477
"> 

> **valueerror",1.47706422
`valueerror,1.47706422
valueerror,1.47706422
"```

valueerror",1.47706422
"``

``

valueerror",1.47706422
> valueerror,1.47706422
"5590 

   5591 



valueerror",1.47706422
"> 

> valueerror",1.47706422
"5221 

   5222 



valueerror",1.47706422
"]

valueerror",1.47706422
"```



```

valueerror",1.47706422
"```

```

valueerror",1.47706422
">





`valueerror",1.47706422
>> valueerror,1.47706422
"616 



valueerror",1.47706422
"`



`valueerror",1.47706422
**valueerror,1.47706422
"`

**valueerror",1.47706422
_run,1.476190476
"_run

    %",1.476190476
"_run

    +",1.476190476
optimizer=,1.475789474
optimizer,1.475789474
optimizer =,1.475789474
#               optimizer=,1.475789474
"optimizer

    826",1.475789474
#                 optimizer=,1.475789474
`optimizer`,1.475789474
`optimizer,1.475789474
`` returns ``,1.475409836
returns,1.475409836
# returns,1.475409836
initializer,1.475409836
"` returns

```

2379",1.475409836
` returns,1.475409836
`returns,1.475409836
initializer=,1.475409836
`initializer,1.475409836
1026                                       initializer=,1.475409836
reader,1.473684211
518         reader,1.473684211
load,1.472972973
load`,1.472972973
# load,1.472972973
"```

# load",1.472972973
/ load,1.472972973
unique,1.470588235
loc,1.470588235
----> 1 load_img,1.470588235
load_img,1.470588235
stddev,1.470588235
f1_score,1.470588235
loc=127,1.470588235
stddev=,1.470588235
loc=,1.470588235
stddev=0,1.470588235
f1_score],1.470588235
stddev = 1,1.470588235
stddev = 0,1.470588235
stddev=1,1.470588235
loc[,1.470588235
num_filters,1.466666667
dense_1_input,1.466666667
glorot_uniform,1.466666667
appears,1.466666667
`dense_1_input`,1.466666667
num_filters],1.466666667
working,1.464646465
evaluate_generator,1.464285714
sentences,1.464285714
empty,1.464285714
`evaluate_generator`,1.464285714
empty = [],1.464285714
8 sentences,1.464285714
aaron,1.461538462
cond,1.461538462
words,1.461538462
3 words,1.461538462
10 words,1.461538462
7s,1.461538462
repo],1.461538462
//repo,1.461538462
# words,1.461538462
>cond =,1.461538462
100000 words,1.461538462
6963200 words,1.461538462
32 words,1.461538462
nadam,1.461538462
repo,1.461538462
cond`,1.461538462
backends,1.461538462
200 words &,1.461538462
5 words,1.461538462
* backends,1.461538462
"words
#",1.461538462
batch_normalization`,1.454545455
batch_normalization,1.454545455
direct,1.454545455
sampling,1.454545455
_traceback =,1.454545455
_extract_stack,1.454545455
failure,1.454545455
equivalent,1.454545455
train_size,1.454545455
execution,1.454545455
nice,1.454545455
feeding,1.454545455
preprocessing_function,1.454545455
unet,1.454545455
[train_size,1.454545455
flags,1.454545455
/unet,1.454545455
#NAME?,1.454545455
[unet],1.454545455
"execution

208       //",1.454545455
question,1.453703704
question 1,1.453703704
question 2,1.453703704
"18526459]



**question",1.453703704
question**,1.453703704
[question],1.453703704
means,1.452380952
`0` means,1.452380952
means 2,1.452380952
implement,1.450980392
1 implement,1.450980392
class_weight,1.45
combine,1.45
details,1.45
vocabulary,1.45
class_weight=,1.45
google,1.45
spec,1.45
`class_weight`,1.45
class_weight  = {0,1.45
# combine,1.45
"vocabulary



2",1.45
vocabulary**,1.45
</details>,1.45
class_weight={,1.45
"1

class_weight {0",1.45
"```



details",1.45
class_weight={0,1.45
[class_weight],1.45
class_weight= {0,1.45
str,1.448598131
#NAME?,1.448598131
"+

--> 616                                      str",1.448598131
>     511                                              str,1.448598131
% str,1.448598131
-> str,1.448598131
"+

--> 220                          str",1.448598131
#NAME?,1.448598131
#NAME?,1.448598131
"+

--> 140                             str",1.448598131
"+

> -> 2943                          str",1.448598131
---> 55                                     printable_module_name=,1.448275862
printable_module_name,1.448275862
---> 99                                     printable_module_name=,1.448275862
"+ printable_module_name +

--> 164",1.448275862
**context**,1.448275862
context,1.448275862
--> 114                                     printable_module_name=,1.448275862
## context,1.448275862
---> 54                                     printable_module_name=,1.448275862
sess =,1.447368421
sess,1.447368421
sess=,1.447368421
merged],1.447368421
merged,1.447368421
merged`,1.447368421
sess ==,1.447368421
merged = [],1.447368421
#NAME?,1.447368421
block,1.446153846
# block 2,1.446153846
# block 3,1.446153846
# block 4,1.446153846
# block 5,1.446153846
+ block +,1.446153846
block=,1.446153846
input_img,1.444444444
data_format,1.444444444
piece,1.444444444
initialize,1.444444444
keyerror,1.444444444
get_activations =,1.444444444
get_activations,1.444444444
stopiteration,1.444444444
form `,1.444444444
train_gen,1.444444444
ytrain,1.444444444
input_tensors,1.444444444
data_format=,1.444444444
form,1.444444444
lstm1,1.444444444
shifted,1.444444444
processed_b],1.444444444
reasons,1.444444444
approximation,1.444444444
mismatch,1.444444444
input_tensors[0],1.444444444
convolutions,1.444444444
convolutions = [],1.444444444
y_trn,1.444444444
`y_trn `,1.444444444
renamed,1.444444444
# initialize,1.444444444
processed_b =,1.444444444
decrease,1.444444444
y2,1.444444444
y2],1.444444444
patches,1.444444444
decrease 0,1.444444444
`stopiteration,1.444444444
control_dependencies,1.444444444
renamed `,1.444444444
3 patches,1.444444444
"`

`gen_submission_test_batches",1.444444444
gen_submission_test_batches,1.444444444
`gen_submission_test_batches,1.444444444
batch_x_middle,1.444444444
`stopiteration`,1.444444444
119                 input_tensors,1.444444444
rnn_x,1.444444444
train_data,1.44
float64,1.44
pos,1.44
#NAME?,1.44
pos =,1.44
`float64`,1.44
#NAME?,1.44
pos + 1,1.44
lines,1.43902439
3 lines,1.43902439
5000 lines,1.43902439
lines[2*,1.43902439
1003 lines,1.43902439
lines = [],1.43902439
5 lines,1.43902439
`concatenate`,1.438356164
concatenate,1.438356164
concatenate`,1.438356164
#NAME?,1.438356164
`concatenate,1.438356164
#NAME?,1.438356164
"[

                        **concatenate",1.438356164
reference,1.4375
model_dir=,1.4375
compiling,1.4375
model_dir,1.4375
prelu,1.4375
# compiling,1.4375
"````



reference",1.4375
#NAME?,1.4375
approach,1.434782609
iteration,1.434782609
approach 1,1.434782609
approach 3,1.434782609
"```



## approach 2",1.434782609
"```

## approach 3",1.434782609
* approach 1,1.434782609
* approach 2,1.434782609
iteration {},1.434782609
metrics,1.43030303
metrics=[,1.43030303
metrics={,1.43030303
metrics = [,1.43030303
`metrics`,1.43030303
**metrics**,1.43030303
metrics =,1.43030303
#               metrics=[,1.43030303
metrics[,1.43030303
#                 metrics=[,1.43030303
`metrics=[,1.43030303
[metrics,1.43030303
metrics=,1.43030303
"`

`         metrics=[",1.43030303
config,1.428571429
errors,1.428571429
output_types,1.428571429
status,1.428571429
causing,1.428571429
receiving,1.428571429
2420         config[,1.428571429
collect,1.428571429
k1>=,1.428571429
k1,1.428571429
summarize=6,1.428571429
linked,1.428571429
# summarize,1.428571429
learning_rate,1.428571429
affect,1.428571429
2416         config[,1.428571429
"```



errors",1.428571429
finished,1.428571429
reset_states,1.428571429
config[,1.428571429
**config,1.428571429
dog,1.428571429
limit,1.428571429
causing [,1.428571429
**dont,1.428571429
tr_y[0,1.428571429
config = {,1.428571429
turns,1.428571429
dont,1.428571429
13s,1.428571429
#NAME?,1.428571429
hack,1.428571429
fast,1.428571429
exact,1.428571429
# hack,1.428571429
c2 =,1.428571429
dnn_model,1.428571429
"```

dnn_model",1.428571429
ac,1.428571429
c2,1.428571429
"**



btw",1.428571429
summarize,1.428571429
**config[,1.428571429
mu1,1.428571429
b1 =,1.428571429
b1,1.428571429
#REF!,1.428571429
learning_rate=0,1.428571429
h_tm12,1.428571429
8 btw,1.428571429
new_lr,1.428571429
tr_y,1.428571429
## errors,1.428571429
listcolumnsinputs,1.428571429
#NAME?,1.428571429
max_sent_length,1.428571429
256         config[,1.428571429
*exact*,1.428571429
dataparalleloptimizer,1.428571429
`dataparalleloptimizer`,1.428571429
#NAME?,1.428571429
btw,1.428571429
#word_train_token,1.428571429
word_train_token,1.428571429
mask,1.426966292
#NAME?,1.426966292
]  = mask,1.426966292
mask=,1.426966292
mask =,1.426966292
# mask,1.426966292
mask ==,1.426966292
on_epoch_end,1.425925926
`on_epoch_end`,1.425925926
option,1.424242424
title,1.423076923
factor,1.423076923
factor=0,1.423076923
%%title,1.423076923
title=,1.423076923
test_image,1.421052632
input_b,1.421052632
setup,1.421052632
# setup,1.421052632
input_b],1.421052632
"```

# setup",1.421052632
set_learning_phase,1.416666667
#NAME?,1.416666667
img_input,1.416666667
schedule,1.416666667
seq,1.416666667
passes,1.416666667
6 passes,1.416666667
7 passes,1.416666667
ae,1.416666667
timedistributed,1.416666667
"```

seq",1.416666667
"```

 seq",1.416666667
rho *,1.416666667
rho,1.416666667
#NAME?,1.416666667
--->> timedistributed,1.416666667
rho=0,1.416666667
[ae,1.416666667
#NAME?,1.416666667
`timedistributed`,1.416666667
`timedistributed,1.416666667
44                                                    cudandarray_host_dims,1.416666667
81                                                     cudandarray_host_dims,1.416666667
cudandarray_host_dims,1.416666667
#NAME?,1.416666667
"] =

306                                             cudandarray_host_dims",1.416666667
"] =

308                                             cudandarray_host_dims",1.416666667
equal,1.413793103
equal 256,1.413793103
equal 20573,1.413793103
filters=16,1.412280702
filters=32,1.412280702
filters=64,1.412280702
filters,1.412280702
filters=2,1.412280702
filters=1,1.412280702
filters = 100,1.412280702
filters=8,1.412280702
100 filters,1.412280702
filters=3,1.412280702
filters = 384,1.412280702
filters = 5,1.412280702
filters=,1.412280702
filters=40,1.412280702
filters=128,1.412280702
filters=256,1.412280702
filters=512,1.412280702
filters=1024,1.412280702
filters = 32,1.412280702
filters = 64,1.412280702
filters`,1.412280702
16 filters,1.412280702
filters = 2,1.412280702
filters=50,1.412280702
filters=6,1.412280702
# pylint,1.411764706
changing `~/,1.411764706
changing,1.411764706
set_session,1.411764706
349       # pylint,1.411764706
351       # pylint,1.411764706
thing,1.411764706
"22 

     23 # pylint",1.411764706
"73 

     74 # pylint",1.411764706
"1

set_session",1.411764706
bit,1.41025641
64-bit,1.41025641
1900 64 bit,1.41025641
change,1.409638554
###change,1.409638554
# change,1.409638554
zip],1.409090909
zip,1.409090909
# zip,1.409090909
idx,1.407407407
{idx},1.407407407
{idx *,1.407407407
idx + 1,1.407407407
[idx *,1.407407407
basically,1.407407407
basically 3,1.407407407
idx+1,1.407407407
idx = 0,1.407407407
idx >=,1.407407407
idx =,1.407407407
"```

basically",1.407407407
#basically 80,1.407407407
conv1,1.40625
passing,1.40625
loss=,1.404021938
loss,1.404021938
loss={,1.404021938
`loss`,1.404021938
`loss,1.404021938
[loss],1.404021938
"]

loss",1.404021938
loss =,1.404021938
/loss,1.404021938
loss=[,1.404021938
--> 960                         loss=,1.404021938
--> 990                         loss=,1.404021938
loss =  [ 4,1.404021938
loss =  [ 7,1.404021938
loss =  [ 2,1.404021938
#loss=,1.404021938
"loss]

    635",1.404021938
loss],1.404021938
#          loss={,1.404021938
"140394812572

```

loss",1.404021938
loss=8,1.404021938
loss = 25,1.404021938
loss = 0,1.404021938
loss ={,1.404021938
number,1.403726708
# number,1.403726708
#NAME?,1.403726708
number # 1,1.403726708
[number,1.403726708
"`

number",1.403726708
<number,1.403726708
"number

```",1.403726708
> number,1.403726708
"28

# number",1.403726708
"128

# number",1.403726708
cls,1.402597403
% cls,1.402597403
`cls`,1.402597403
x_test,1.401384083
x_test =,1.401384083
[x_test,1.401384083
x_test],1.401384083
x_test /= 128,1.401384083
x_test[,1.401384083
"] = 0

x_test[",1.401384083
sources,1.4
internet,1.4
"hdf5

2018-06-02 10",1.4
desp,1.4
glorot_normal,1.4
receives,1.4
decreasing,1.4
pool3,1.4
remove,1.4
newaxis,1.4
#NAME?,1.4
output_file,1.4
output_file +,1.4
crashes,1.4
understanding,1.4
model_input,1.4
my_layer,1.4
`my_layer`,1.4
answers,1.4
repeat,1.4
"5 



hardware",1.4
get_default_graph,1.4
copied,1.4
instantiate,1.4
attempting,1.4
sentence,1.4
crop_height,1.4
crop_width,1.4
train_spec,1.4
videos,1.4
50 videos,1.4
x_valid_cv,1.4
creation,1.4
newaxis],1.4
max_q_size=100,1.4
device_type,1.4
`device_type`,1.4
select,1.4
costs,1.4
hdf5,1.4
connect,1.4
maxsize,1.4
maxsize=,1.4
cudnnlstm,1.4
vgg16_model,1.4
cnn_model,1.4
test_labels,1.4
init_state =,1.4
init_state],1.4
cleanup,1.4
num_class=2,1.4
num_class,1.4
make_tensor_proto,1.4
maxpooling,1.4
**hardware,1.4
problematic,1.4
tells,1.4
# remove,1.4
# decode,1.4
expectation_2,1.4
helps,1.4
hidden1,1.4
decode,1.4
header=0,1.4
5.00E-06,1.4
pos_label,1.4
mix,1.4
%%pages,1.4
weight_decay,1.4
#sentence 1,1.4
4]]]    #sentence 2,1.4
1 sentence,1.4
emb,1.4
header=,1.4
body,1.4
file2,1.4
untrainable,1.4
coords],1.4
2 cudnnlstm</,1.4
out4 =,1.4
out4,1.4
out4],1.4
5.00E-04,1.4
_objects,1.4
array_dim,1.4
coords,1.4
coords[,1.4
produced,1.4
duplicate,1.4
trigger,1.4
net1,1.4
[net1,1.4
noofinstances,1.4
#decode,1.4
x_tensor,1.4
[x_tensor,1.4
x_train_tmp,1.4
[x_train_tmp],1.4
x_fc,1.4
ema_in,1.4
filter_size,1.4
% filter_size,1.4
filter_size + 1,1.4
ga_float *,1.4
trainindex,1.4
conv10,1.4
f_active,1.4
complains,1.4
"```

complains",1.4
radial,1.4
seq2,1.4
predict_text =,1.4
#NAME?,1.4
predict_text,1.4
=&space,1.4
&space,1.4
docs_word_lstm,1.4
input_mask=,1.4
pages,1.4
pb,1.4
"hdf5

1967/1967 [==============================]",1.4
"[  # sentence 2

        [0",1.4
input_mask,1.4
hidden1=,1.4
hardware,1.4
space,1.4
gpuallocempty,1.4
preferred_dtype,1.4
err2,1.4
"{

497             cleanup",1.4
top_k,1.4
saver,1.4
max_q_size=10,1.4
seq2],1.4
hidden_len,1.4
#remove,1.4
max_caption_len,1.4
ve,1.396694215
traceback,1.396226415
solution,1.396226415
"9983

traceback",1.396226415
> traceback,1.396226415
"}



traceback",1.396226415
"]]



```traceback",1.396226415
`traceback,1.396226415
"```

traceback",1.396226415
">  

> traceback",1.396226415
"00024976373759209717

traceback",1.396226415
"0

traceback",1.396226415
"6`









    traceback",1.396226415
"`

traceback",1.396226415
"**



traceback",1.396226415
"`



solution",1.396226415
% traceback,1.396226415
> `traceback,1.396226415
"```



traceback",1.396226415
"2939

> traceback",1.396226415
```traceback,1.396226415
"]]

traceback",1.396226415
"7



```

```traceback",1.396226415
"**



```

traceback",1.396226415
"```
traceback",1.396226415
document,1.393939394
/document/,1.393939394
0/task,1.393442623
task,1.393442623
task 1,1.393442623
"3393 

   3394       # note",1.392857143
passed,1.392857143
note,1.392857143
passed-,1.392857143
"```



note",1.392857143
# note,1.392857143
**note**,1.392857143
> note,1.392857143
"30 

     31 # note",1.392857143
`# note,1.392857143
**note,1.392857143
"```

# note",1.392857143
"138 

139 note",1.392857143
random,1.392694064
= [ [random,1.392694064
"]

                    random",1.392694064
dump,1.391304348
input_a,1.391304348
[input_a,1.391304348
effect,1.388888889
max_len,1.388888889
exists,1.388888889
"effect

#",1.388888889
] exists,1.388888889
` exists,1.388888889
x1,1.385964912
x1=,1.385964912
">0

                x1=",1.385964912
[x1,1.385964912
x1 =,1.385964912
x1],1.385964912
<x1,1.385964912
x1=0,1.385964912
parts,1.384615385
df,1.384615385
#NAME?,1.384615385
exist,1.384615385
put,1.384615385
cases,1.384615385
df[,1.384615385
# put,1.384615385
ll,1.384615385
closed,1.384615385
broken,1.384615385
exist /,1.384615385
"cases



1",1.384615385
47} exist,1.384615385
desc,1.384615385
251                                                      desc,1.384615385
285                                                     desc,1.384615385
413                                                   desc,1.384615385
425                                                     desc,1.384615385
445       desc,1.384615385
save,1.383419689
# save,1.383419689
save`,1.383419689
`save`,1.383419689
applied,1.380952381
resized,1.380952381
/resized/,1.380952381
__version__,1.379310345
give,1.379310345
__version__`,1.379310345
__version__ =,1.379310345
# give,1.379310345
give 92,1.379310345
test_data,1.378378378
[0] + [test_data],1.378378378
ys =,1.375
[inp] + [,1.375
progbarlogger,1.375
target_list,1.375
refer,1.375
pool1,1.375
conv2,1.375
dense1,1.375
l2_normalize,1.375
isn,1.375
ys,1.375
patch,1.375
"refer



```",1.375
inp,1.375
dimensionality,1.375
json_string,1.375
max_sequence_length,1.375
plan,1.375
dependency,1.375
num_layers,1.375
num_layers],1.375
do_validation,1.375
codebase,1.375
load_weights_from_hdf5_group,1.375
inference,1.375
vect = [],1.375
vect,1.375
decoder_outputs,1.375
scoring=,1.375
scoring,1.375
act,1.375
active,1.375
inp=,1.375
patch-1,1.375
max_sequence_length-5+1,1.375
max_sequence_length-4+1,1.375
max_sequence_length-3+1,1.375
combinedx,1.375
gates,1.375
dimensionality 3 [,1.375
active + 1,1.375
active],1.375
num_layers=5,1.375
act =,1.375
4 gates,1.375
40 * 4 gates,1.375
{inp,1.375
h5o,1.375
sampler,1.375
[ys,1.375
-> 1015                            target_list,1.375
x2,1.37037037
x2=,1.37037037
]=x2,1.37037037
output_dim,1.37037037
y_val,1.37037037
output_dim = 200,1.37037037
output_dim= 200,1.37037037
output_dim=5,1.37037037
output_dim=1,1.37037037
x2[,1.37037037
output_dim=600,1.37037037
output_dim=50,1.37037037
`y_val`,1.37037037
output_dim=256,1.37037037
output_dim=20,1.37037037
y_val =,1.37037037
`y_val `,1.37037037
output_dim =,1.37037037
output_dim=500,1.37037037
output_dim=300,1.37037037
output_dim=128,1.37037037
x2 =,1.37037037
x2],1.37037037
"]

    x2 =",1.37037037
> x2,1.37037037
output_dim=3,1.37037037
output_dim=64,1.37037037
output_dim =10,1.37037037
output_dim=1024,1.37037037
y_val],1.37037037
output_dim=2,1.37037037
output_dim=10,1.37037037
output_dim=,1.37037037
output_dim=4,1.37037037
feed,1.369230769
output_shape=,1.369047619
`output_shape`,1.369047619
output_shape,1.369047619
output_shape =,1.369047619
output_shape=[,1.369047619
output_shape=[512],1.369047619
output_shape[1,1.369047619
output_shape`,1.369047619
"output_shape



`",1.369047619
output_shape # =>,1.369047619
output_shape[-1],1.369047619
output_shape[-1] == 1,1.369047619
validation_data=,1.368932039
validation_data,1.368932039
5           validation_data=,1.368932039
validation_data =,1.368932039
validation_data = [,1.368932039
`validation_data=,1.368932039
validation_data`,1.368932039
`validation_data,1.368932039
>       4                     validation_data=,1.368932039
`validation_data`,1.368932039
finally,1.368421053
694         finally,1.368421053
submodel,1.368421053
masking,1.368421053
25             finally,1.368421053
#NAME?,1.368421053
"```

finally",1.368421053
#NAME?,1.368421053
condition,1.363636364
conv3,1.363636364
validation_labels,1.363636364
csv_logger],1.363636364
url,1.363636364
w1,1.363636364
euclidean_distance,1.363636364
url 1,1.363636364
weights_path =,1.363636364
csv_logger,1.363636364
w1 =,1.363636364
weights_path,1.363636364
]-w1[,1.363636364
gpudnnconv,1.363636364
weights_path=,1.363636364
test_size=0,1.36
multiply,1.36
made,1.36
test_size,1.36
#NAME?,1.36
test_size = 0,1.36
flatten,1.359649123
flatten],1.359649123
#NAME?,1.359649123
#NAME?,1.359649123
`flatten,1.359649123
# flatten,1.359649123
[flatten,1.359649123
input_tensor,1.359375
[input_tensor],1.359375
input_tensor=,1.359375
`input_tensor`,1.359375
input_tensor],1.359375
"```

# place",1.358974359
place,1.358974359
html,1.358974359
html],1.358974359
"html

  [2]",1.358974359
html ],1.358974359
"html



```",1.358974359
shape=,1.358490566
shape,1.358490566
shape[0],1.358490566
shape[1,1.358490566
shape=[1],1.358490566
shape[1],1.358490566
shape =,1.358490566
shape[2],1.358490566
shape [,1.358490566
shape=[,1.358490566
shape[131072,1.358490566
shape[3],1.358490566
shape `,1.358490566
shape=1,1.358490566
"shape

3",1.358490566
# shape,1.358490566
shape[0] = [9,1.358490566
shape[1] = [1,1.358490566
shape [1,1.358490566
shape[-2],1.358490566
#shape,1.358490566
shape[-1],1.358490566
shape 2048,1.358490566
"shape`

`",1.358490566
"shape

```",1.358490566
"shape

```

```",1.358490566
shape=[1,1.358490566
`shape,1.358490566
shape=[10],1.358490566
shape[1] > 1,1.358490566
**shape,1.358490566
shape[,1.358490566
shape=[14 * 14,1.358490566
shape=[2,1.358490566
shape[64000,1.358490566
shape[0] * 2 + 1,1.358490566
shape[1] ==,1.358490566
"shape[1]

```



###",1.358490566
shape[4],1.358490566
shape`,1.358490566
"shape 

#",1.358490566
shape[1] = 1,1.358490566
shape[1] = 16,1.358490566
shape=[2],1.358490566
shape = [1,1.358490566
shape[1] == 1,1.358490566
shape [-1,1.358490566
shape[0]`,1.358490566
shape ==,1.358490566
1030             shape=,1.358490566
290           shape =,1.358490566
shape #,1.358490566
shape [-1],1.358490566
shape=[],1.358490566
adadelta,1.357142857
_deepcopy_tuple,1.357142857
hey,1.357142857
submodels,1.357142857
"```

submodels= []",1.357142857
runtimeerror,1.357142857
max_features,1.357142857
max_features+1,1.357142857
> **runtimeerror,1.357142857
"]]`

```hey",1.357142857
"_deepcopy_tuple

>",1.357142857
"```

submodels = []",1.357142857
work,1.356807512
"work



#

#",1.356807512
"work

#



#",1.356807512
` work,1.356807512
work-,1.356807512
2 work,1.356807512
units=128,1.356521739
units=64,1.356521739
units=200,1.356521739
units= 200,1.356521739
units=14,1.356521739
units=5,1.356521739
units = 16,1.356521739
units = 1,1.356521739
units,1.356521739
units=100,1.356521739
units * 2,1.356521739
units = 128,1.356521739
units=33,1.356521739
units=1,1.356521739
units=256,1.356521739
units = 2,1.356521739
~4000 units,1.356521739
units=4000,1.356521739
units=1024,1.356521739
units=512,1.356521739
units=30,1.356521739
units=2,1.356521739
units = 11,1.356521739
units=20,1.356521739
units =,1.356521739
units * 4,1.356521739
units=25,1.356521739
units=,1.356521739
lr=0,1.355555556
lr = 0,1.355555556
lr *,1.355555556
lr =,1.355555556
lr,1.355555556
lr /,1.355555556
--> 574         lr =,1.355555556
lr= 0,1.355555556
lr=,1.355555556
lr=1,1.355555556
globalaveragepooling2d,1.35483871
#NAME?,1.35483871
float32,1.354385965
"float32

>",1.354385965
`float32`,1.354385965
float32],1.354385965
invalidargumenterror,1.354166667
"```

invalidargumenterror",1.354166667
"> 

invalidargumenterror",1.354166667
"> 

> invalidargumenterror",1.354166667
> invalidargumenterror,1.354166667
#NAME?,1.353191489
conv2d,1.353191489
"[

            conv2d",1.353191489
#NAME?,1.353191489
`conv2d,1.353191489
`conv2d`,1.353191489
z_log_var / 2,1.352941176
z_log_var],1.352941176
1 + z_log_var,1.352941176
z_log_var,1.352941176
save_weights,1.351351351
`save_weights`,1.351351351
fit,1.350701403
`fit,1.350701403
`fit`,1.350701403
# fit,1.350701403
fit`,1.350701403
">>> 

>>> # fit",1.350701403
"fit



2017-11-19 08",1.350701403
34 # fit,1.350701403
batchnormalization,1.35
----> 3 batchnormalization,1.35
"[

        batchnormalization",1.35
#NAME?,1.35
# divide,1.35
#NAME?,1.35
divide,1.35
dense2,1.35
batchnormalization`,1.35
problem,1.34870317
"############################################



problem",1.34870317
**problem,1.34870317
# problem,1.34870317
problem 1,1.34870317
problem 2,1.34870317
## problem,1.34870317
[problem],1.34870317
problem],1.34870317
kernel_initializer=,1.348623853
kernel_initializer,1.348623853
1 classes,1.347457627
4 classes,1.347457627
classes,1.347457627
classes=,1.347457627
1000 classes,1.347457627
5 classes,1.347457627
3 classes,1.347457627
34 classes,1.347457627
classes=8,1.347457627
classes =,1.347457627
classes=3,1.347457627
10 classes,1.347457627
`7 classes`,1.347457627
26 classes,1.347457627
classes=[,1.347457627
classes=10,1.347457627
12 classes,1.347457627
classes=1,1.347457627
230 classes,1.347457627
`classes= [,1.347457627
`classes = [ [,1.347457627
378 classes,1.347457627
classes {2,1.347457627
2 classes,1.347457627
8 classes,1.347457627
calculated,1.346153846
supported,1.346153846
90% supported,1.346153846
add_weight,1.34375
mean_squared_error,1.34
`mean_squared_error`,1.34
5 * mean_squared_error,1.34
run,1.33976834
6 run,1.33976834
run 100%,1.33976834
"run



```",1.33976834
run `,1.33976834
"run

>",1.33976834
"```

run",1.33976834
open,1.339130435
open %,1.339130435
/open,1.339130435
`open,1.339130435
#NAME?,1.339130435
info,1.338461538
input_encoded,1.333333333
_create_c_op,1.333333333
reduce,1.333333333
_cond,1.333333333
description,1.333333333
input_dim= 4,1.333333333
89                 warnings,1.333333333
train_function,1.333333333
behave,1.333333333
inception_feature1,1.333333333
processed,1.333333333
item_input,1.333333333
item_input],1.333333333
contribution,1.333333333
scales,1.333333333
crossentropy,1.333333333
assuming,1.333333333
description=,1.333333333
_io,1.333333333
## description,1.333333333
downloaded,1.333333333
dummy_y,1.333333333
persist,1.333333333
embeddings_initializer,1.333333333
input_dim,1.333333333
couldn,1.333333333
nets,1.333333333
warnings,1.333333333
expecting,1.333333333
gain,1.333333333
_deferredtensor,1.333333333
# [<_deferredtensor,1.333333333
_class=[,1.333333333
x_decoded_mean,1.333333333
#NAME?,1.333333333
input_dim=10000,1.333333333
world,1.333333333
matrix_layer,1.333333333
verbs,1.333333333
terms,1.333333333
train_and_evaluate,1.333333333
valid_spec,1.333333333
hooks,1.333333333
_parse_function,1.333333333
#NAME?,1.333333333
entries,1.333333333
switched,1.333333333
imagepatches,1.333333333
classzero[0,1.333333333
classone[0,1.333333333
classzero,1.333333333
classone,1.333333333
noticeable,1.333333333
classified,1.333333333
clone_keras_model,1.333333333
"processed

   2508",1.333333333
maximal,1.333333333
policy_out,1.333333333
value_out,1.333333333
[policy_out,1.333333333
value_out],1.333333333
**resourceexhaustederror,1.333333333
volume,1.333333333
testpredict,1.333333333
inverse_transform,1.333333333
2] = testpredict[,1.333333333
testy_extended[,1.333333333
testy_extended,1.333333333
image_dim,1.333333333
latent_vec,1.333333333
latent_vec],1.333333333
detect,1.333333333
kld,1.333333333
adapted,1.333333333
x_test1,1.333333333
val_score,1.333333333
unboundlocalerror,1.333333333
restarted,1.333333333
allowed,1.333333333
input_dim=10,1.333333333
face_encoder,1.333333333
x_conv_a,1.333333333
x_conv_b,1.333333333
year,1.333333333
manager,1.333333333
_recv_bytes,1.333333333
maxpool1,1.333333333
trainable_weights,1.333333333
msg,1.333333333
pdb},1.333333333
input_values,1.333333333
noise_shape,1.333333333
[input_values,1.333333333
`noise_shape=,1.333333333
o_t,1.333333333
train_labels,1.333333333
"````



ouput",1.333333333
image_path,1.333333333
misunderstanding,1.333333333
dummy_inp,1.333333333
relation,1.333333333
max_num_of_sentences_for_an_entity_pair,1.333333333
2 * max_num_of_sentences_for_an_entity_pair,1.333333333
gen_train,1.333333333
lack,1.333333333
splitting,1.333333333
discussion,1.333333333
chosen,1.333333333
responses,1.333333333
speed,1.333333333
circular,1.333333333
stores,1.333333333
conceptually,1.333333333
preds_test,1.333333333
convolution3d,1.333333333
episode,1.333333333
embed_size,1.333333333
sequence_len,1.333333333
attempted,1.333333333
85                 warnings,1.333333333
_make_test_function,1.333333333
dense_shape=,1.333333333
dense_shape,1.333333333
cropped,1.333333333
completed,1.333333333
sorted_voc,1.333333333
vram,1.333333333
input_pos,1.333333333
input_neg,1.333333333
input_positive,1.333333333
input_negative,1.333333333
pos_dist,1.333333333
[net_anchor,1.333333333
input_negative],1.333333333
x_e,1.333333333
x_d,1.333333333
y_d,1.333333333
=[x_e,1.333333333
x_d],1.333333333
#NAME?,1.333333333
20000  completed,1.333333333
nb_cl,1.333333333
32x32,1.333333333
input_layer2],1.333333333
input_layer2,1.333333333
m2_loaded,1.333333333
gpuarrayexception,1.333333333
_wrapfunc,1.333333333
y_category,1.333333333
predictions_valid,1.333333333
den_total_sample,1.333333333
/ den_total_sample,1.333333333
char_level,1.333333333
bottleneck_features_train,1.333333333
generator_valid,1.333333333
bottleneck_features_validation,1.333333333
train_labels[,1.333333333
predict_on_batch,1.333333333
meet,1.333333333
benefit,1.333333333
input_dim=2,1.333333333
target_data,1.333333333
_backend,1.333333333
dst_model,1.333333333
dst_model],1.333333333
visible2,1.333333333
visible2],1.333333333
#NAME?,1.333333333
probs2,1.333333333
essentially,1.333333333
rankdir,1.333333333
decoder_inputs,1.333333333
decoder_inputs],1.333333333
img_lst_train,1.333333333
label_lst_train,1.333333333
img_lst_test,1.333333333
label_lst_test,1.333333333
avg_image_test,1.333333333
input_dim=116,1.333333333
corrected,1.333333333
ncl,1.333333333
int8,1.333333333
tensorshape,1.333333333
[x_n,1.333333333
conv2dcustombackpropinput,1.333333333
train_flow,1.333333333
patches_true,1.333333333
patches_pred,1.333333333
denom =,1.333333333
input_dim=1,1.333333333
output_shape_[1,1.333333333
output_shape_,1.333333333
operate,1.333333333
inconsistent,1.333333333
_one_shot,1.333333333
caffenet_inputs_2,1.333333333
caffenet_inputs_2],1.333333333
return_train_score,1.333333333
rand_x,1.333333333
dense_list,1.333333333
"+1]

    dense_list",1.333333333
wikipedia,1.333333333
likewise,1.333333333
input_dim=4,1.333333333
input_dim=8,1.333333333
% hooks,1.333333333
bilinear,1.333333333
googled,1.333333333
nonzero,1.333333333
recurrent_model,1.333333333
#NAME?,1.333333333
model_all,1.333333333
net_a,1.333333333
[net_a],1.333333333
net_b_input_0,1.333333333
net_b_input_1,1.333333333
[net_b_input_0,1.333333333
net_b_input_1],1.333333333
model_b,1.333333333
sub_model,1.333333333
embeddings_initializer=,1.333333333
train_length,1.333333333
ide,1.333333333
`128x128`,1.333333333
stands,1.333333333
upsampling3d,1.333333333
tensorconstant{20},1.333333333
tensorconstant{51},1.333333333
tensorconstant{2},1.333333333
tensorconstant{5},1.333333333
dropout1,1.333333333
instantiated,1.333333333
input_dim=,1.333333333
input_signal,1.333333333
l3,1.333333333
[l3,1.333333333
"trainable_weights[0]



    #",1.333333333
trainable_weights[0]`,1.333333333
discussion],1.333333333
predict_signature_def,1.333333333
get_data,1.333333333
my_file,1.333333333
_init_from_args,1.333333333
`trainable_weights`,1.333333333
enc,1.333333333
writer,1.333333333
summary_str,1.333333333
uname,1.333333333
% subcallback,1.333333333
"02 2017



@author",1.333333333
input_dim=505,1.333333333
input_dim=2000,1.333333333
input_dim=1001,1.333333333
tt,1.333333333
suffix,1.333333333
y_true_f =,1.333333333
y_pred_f =,1.333333333
y_true_f,1.333333333
y_pred_f,1.333333333
test_label,1.333333333
"42 2017

> 

> @author",1.333333333
[input_x1,1.333333333
input_x2],1.333333333
conv_out,1.333333333
nmovies,1.333333333
nmovies+1,1.333333333
#pdb,1.333333333
pdb,1.333333333
#splitting,1.333333333
"]

                templist",1.333333333
documentsarray,1.333333333
templist,1.333333333
encode_seq,1.333333333
default_size=32,1.333333333
noise_shape=,1.333333333
flat_input,1.333333333
imutils,1.333333333
# detect,1.333333333
autoencoder_model,1.333333333
inputtensor,1.333333333
autoencoder_input,1.333333333
`noise_shape`,1.333333333
investigate,1.333333333
conv_out =,1.333333333
norm2,1.333333333
denom,1.333333333
=[dummy_y],1.333333333
"```



inspecting",1.333333333
conv_4,1.333333333
spatial_softargmax,1.333333333
spatial_softargmax},1.333333333
bid2,1.333333333
openai,1.333333333
"`

 

`tensorshape",1.333333333
int8},1.333333333
first_layer,1.333333333
input_dim=25,1.333333333
x_i,1.333333333
obj1,1.333333333
fully_connected,1.333333333
x_names,1.333333333
p1d,1.333333333
p5d,1.333333333
t2,1.333333333
ax,1.333333333
gen_handle,1.333333333
y_pred_batch,1.333333333
list_files,1.333333333
list_0,1.333333333
input_dcc,1.333333333
input_icc,1.333333333
input_dobl,1.333333333
input_iobl,1.333333333
[input_dcc,1.333333333
input_iobl],1.333333333
path_model+,1.333333333
"processed

   2489",1.333333333
in_info],1.333333333
seq_encoded,1.333333333
default_size=224,1.333333333
train_function =,1.333333333
consumer,1.333333333
a_input,1.333333333
xt,1.333333333
`input_dim`,1.333333333
handled,1.333333333
input_dim=23,1.333333333
7 stands,1.333333333
ema_lstm1,1.333333333
ema_lstm2,1.333333333
ema_dense1,1.333333333
ema_dense2,1.333333333
ema_dense3,1.333333333
ema_output,1.333333333
occupy,1.333333333
allocates **,1.333333333
y_pred_batch =,1.333333333
_generate_dropout_mask,1.333333333
#NAME?,1.333333333
spot,1.333333333
__float2half_rn,1.333333333
input_dim=20,1.333333333
allocates,1.333333333
act1,1.333333333
batch3,1.333333333
negative_d,1.333333333
[anchor_vect,1.333333333
negative_d],1.333333333
# reduce,1.333333333
trainable_weights`,1.333333333
num1,1.333333333
num1+112,1.333333333
num2,1.333333333
num2+112,1.333333333
#NAME?,1.333333333
skipvalidate,1.333333333
interesting,1.333333333
cross_entropy =,1.333333333
cross_entropy,1.333333333
layer_output[0][0][,1.333333333
tensorconstant{,1.333333333
p_prev =,1.333333333
p_prev,1.333333333
y_val_new,1.333333333
[y_test_a,1.333333333
y_test_a,1.333333333
input_frame,1.333333333
input_dim=80,1.333333333
#NAME?,1.333333333
#NAME?,1.333333333
load_test_data_traces,1.333333333
load_train_data_traces,1.333333333
r_new,1.333333333
ouput,1.333333333
la,1.333333333
inspecting,1.333333333
[x_test1,1.333333333
128x128,1.333333333
`top_img`,1.333333333
`bot_img`,1.333333333
[top_img,1.333333333
bot_img],1.333333333
inp_bot,1.333333333
inp_bot],1.333333333
doc_plus,1.333333333
doc_minus,1.333333333
kl_distance,1.333333333
[qry_rep,1.333333333
doc_minus],1.333333333
prepared,1.333333333
bp,1.333333333
input_dim=2440000,1.333333333
sig_eq,1.333333333
max_nb_words,1.333333333
>= max_nb_words,1.333333333
optimized,1.333333333
local_connect1,1.333333333
mean_squared_logarithmic_error,1.333333333
regularizerl2,1.333333333
restart,1.333333333
wordvec_size,1.333333333
favor,1.333333333
"`



assuming",1.333333333
resourceexhaustederror,1.333333333
gru1_merged,1.333333333
predict_fpath,1.333333333
x_predict,1.333333333
max_val,1.333333333
`max_val`,1.333333333
blanks,1.333333333
terminal,1.333333333
trainable_weights =,1.333333333
"trainable_weights

            #",1.333333333
inner_state,1.333333333
inner_state =,1.333333333
tfoptimizer,1.333333333
x_i =,1.333333333
x_i +,1.333333333
dimstate,1.333333333
actioninput],1.333333333
backward_layer,1.333333333
docs_sentence_input,1.333333333
b_regularizer=,1.333333333
b_constraint=,1.333333333
b_regularizer,1.333333333
b_constraint,1.333333333
]*num_output,1.333333333
num_output,1.333333333
sounds,1.333333333
tensorconstant{1},1.333333333
tensorconstant{[-1  6]},1.333333333
vary,1.333333333
duplicates,1.333333333
thankshi,1.333333333
#NAME?,1.333333333
input_dim =,1.333333333
input_dim[0],1.333333333
input_dim[1],1.333333333
sparse_categorical_cross_entropy,1.333333333
label_instance_shape,1.333333333
input_dim=5,1.333333333
conf,1.333333333
oss,1.333333333
f2_base,1.333333333
"[1]

        list_items",1.333333333
list_items,1.333333333
list_classes_train,1.333333333
* sizeof,1.333333333
416                                                   &worksize,1.333333333
428                                                     &worksize,1.333333333
worksize,1.333333333
sizeof,1.333333333
d_stepy,1.333333333
dataloader,1.333333333
trainset,1.333333333
centers,1.333333333
sparsify,1.333333333
#NAME?,1.333333333
k_val],1.333333333
lrn2d,1.333333333
lrn2d},1.333333333
centers=3,1.333333333
rgb_model,1.333333333
nir_model,1.333333333
multi_modal,1.333333333
[rgb_model,1.333333333
nir_model],1.333333333
--> 117 multi_modal,1.333333333
assign_moving_average,1.333333333
`assign_moving_average,1.333333333
update_delta =,1.333333333
update_delta,1.333333333
[resets,1.333333333
resets,1.333333333
rnn_y,1.333333333
#NAME?,1.333333333
sample_input,1.333333333
sample_output,1.333333333
collectavg,1.333333333
forkingpickler,1.333333333
>       forkingpickler,1.333333333
tf_graph,1.333333333
merge_average,1.333333333
"merge_average

  }",1.333333333
evals,1.333333333
input_dim=15,1.333333333
word_labelmap,1.333333333
word_trainlabelintpad],1.333333333
word_testlabelintpad],1.333333333
char_indices,1.333333333
lr_mult,1.333333333
`lr_mult`,1.333333333
integration,1.333333333
get_output_shape_for,1.333333333
+ suffix +,1.333333333
train_target,1.333333333
#NAME?,1.333333333
np_y_pred =,1.333333333
np_y_pred,1.333333333
zipped,1.333333333
*zipped,1.333333333
>   warnings,1.333333333
input_dim=100,1.333333333
datagen_gcn,1.333333333
max_1d,1.333333333
convs1,1.333333333
convs2,1.333333333
[*convs1,1.333333333
*convs2],1.333333333
pred_idx,1.333333333
pred_idx[,1.333333333
noise_input,1.333333333
"```
x_i = [[0",1.333333333
predict,1.326086957
predict 50,1.326086957
`predict`,1.326086957
predict 1-,1.326086957
predict`,1.326086957
* predict[,1.326086957
# predict,1.326086957
predict <,1.326086957
"9891

predict",1.326086957
timestep,1.324324324
timestep**,1.324324324
1 timestep,1.324324324
timestep = 2,1.324324324
1-dim,1.319148936
dim,1.319148936
dim 200,1.319148936
dim `,1.319148936
dim = 128,1.319148936
dim 1,1.319148936
dim 0,1.319148936
dim =,1.319148936
dim[0] < 0,1.319148936
dim[1] < 0,1.319148936
dim[2] <= 0,1.319148936
dim[3] <= 0,1.319148936
#NAME?,1.319148936
dim=%,1.319148936
80                                                     dim,1.319148936
wrong,1.317073171
_,1.317073171
54     _,1.317073171
_**,1.317073171
_ =,1.317073171
4566     _,1.317073171
]_,1.317073171
**_,1.317073171
`_,1.317073171
]^_`{,1.317073171
part,1.315789474
days,1.315789474
x_batch,1.315789474
[x_batch,1.315789474
5 days,1.315789474
l1,1.315789474
l1=0,1.315789474
l1],1.315789474
# part 2,1.315789474
# part 3,1.315789474
10 days,1.315789474
` part,1.315789474
/part-{0,1.315789474
"```

# part 1",1.315789474
x_batch=,1.315789474
>>> l1 =,1.315789474
len,1.315068493
> len,1.315068493
{len,1.315068493
== len,1.315068493
#NAME?,1.315068493
#NAME?,1.315068493
[len,1.315068493
]=len,1.315068493
[0]*len,1.315068493
% len,1.315068493
00*len,1.315068493
#NAME?,1.315068493
] = len,1.315068493
epochs=50,1.314917127
epochs=10,1.314917127
epochs,1.314917127
epochs= 100,1.314917127
epochs=21,1.314917127
epochs=5,1.314917127
epochs=80,1.314917127
epochs=3,1.314917127
epochs = 10,1.314917127
epochs=200,1.314917127
epochs = 20,1.314917127
epochs=2,1.314917127
100 epochs,1.314917127
epochs=100,1.314917127
epochs = 5,1.314917127
epochs=30,1.314917127
epochs=1,1.314917127
12 epochs,1.314917127
5 epochs,1.314917127
50 epochs,1.314917127
epochs=500,1.314917127
epochs = 1,1.314917127
1 + epochs,1.314917127
epochs=15,1.314917127
epochs=,1.314917127
epochs=20,1.314917127
epochs=5000,1.314917127
epochs = 50,1.314917127
30 epochs,1.314917127
epochs = 2,1.314917127
epochs=45,1.314917127
2 epochs,1.314917127
200 epochs,1.314917127
epochs = 1000,1.314917127
epochs=7,1.314917127
`epochs`,1.314917127
220 epochs,1.314917127
epochs 2,1.314917127
epochs=4,1.314917127
10 epochs,1.314917127
8 epochs,1.314917127
25 epochs,1.314917127
epochs--,1.314917127
250 epochs,1.314917127
2-3 epochs,1.314917127
epochs = 100,1.314917127
epochs=1000,1.314917127
epochs=128,1.314917127
epochs=13,1.314917127
11 epochs,1.314917127
epochs  = 1,1.314917127
20 epochs,1.314917127
epochs=260,1.314917127
epochs = 10000,1.314917127
epochs = 25,1.314917127
epochs=120,1.314917127
epochs=250,1.314917127
epochs=150,1.314917127
epochs = 500,1.314917127
6 epochs,1.314917127
1881             ins =,1.3125
ins,1.3125
mode=,1.3125
mode,1.3125
sample_weight_mode=,1.3125
ins =,1.3125
sample_weight_mode,1.3125
mode =,1.3125
mode ==,1.3125
`sample_weight_mode=,1.3125
1638             ins =,1.3125
mode=2,1.3125
mode=1,1.3125
ins[0],1.3125
&mode,1.3125
mode 1,1.3125
input_shape=,1.31092437
input_shape=[1],1.31092437
input_shape,1.31092437
*input_shape,1.31092437
input_shape =,1.31092437
"50

    input_shape =",1.31092437
input_shape=[3,1.31092437
"70

input_shape=",1.31092437
input_shape+,1.31092437
`input_shape`,1.31092437
input_shape[1],1.31092437
input_shape[0],1.31092437
input_shape=[2558,1.31092437
"#

    input_shape=",1.31092437
"0



input_shape =",1.31092437
input_shape[4],1.31092437
#input_shape=,1.31092437
input_shape[0][0],1.31092437
input_shape[0][1],1.31092437
input_shape=[150528],1.31092437
+ input_shape[2,1.31092437
input_shape[-1],1.31092437
#input_shape = [,1.31092437
"input_shape[-1]

```",1.31092437
input_shape[1] % 2 == 0,1.31092437
input_shape[2] % 2 == 0,1.31092437
input_shape[1]`,1.31092437
input_shape=[687,1.31092437
input_shape[,1.31092437
make,1.309090909
# make,1.309090909
% make,1.309090909
stored,1.307692308
important,1.307692308
appreciated,1.307692308
regularizer,1.307692308
loop,1.307692308
assert_input_compatibility,1.307692308
"assert_input_compatibility

2018-04-09 02",1.307692308
convert_to_tensor,1.307692308
encoder_inputs,1.307692308
1859                                         regularizer=,1.307692308
[encoder_inputs,1.307692308
# loop,1.307692308
encoder_inputs],1.307692308
133                                       regularizer=,1.307692308
1027                                       regularizer=,1.307692308
regularizer=,1.307692308
99             regularizer=,1.307692308
"{

15     void *",1.307692308
16     void *,1.307692308
17     void,1.307692308
void *,1.307692308
void,1.307692308
fix,1.304347826
label_length,1.304347826
label_length],1.304347826
embedding_dim,1.304347826
# freeze,1.304347826
freeze,1.304347826
"freeze

#",1.304347826
err,1.302325581
[err],1.302325581
*err = 1,1.302325581
implemented,1.3
"+ sample_weights

   1882",1.3
facing,1.3
suggest,1.3
solutions,1.3
mistake,1.3
sample_weights,1.3
nb_epochs=1,1.3
nb_epochs,1.3
nb_epochs=10,1.3
"153             batch_index = 0

    154",1.3
timesteps,1.3
[batch_index,1.3
batch_index,1.3
[batch_index[,1.3
mc =,1.3
mc,1.3
1000 timesteps,1.3
sample_weights[0],1.3
mistake =,1.3
dense_layer,1.3
21 timesteps,1.3
inputs2],1.3
130000 timesteps,1.3
inputs2,1.3
+ sample_weights + [1,1.3
inputs2=,1.3
200 timesteps,1.3
"timesteps

2",1.3
"batch_index`

20",1.3
"batch_index`

1",1.3
1559             sample_weights,1.3
moving_mean,1.3
moving_mean =,1.3
array,1.299771167
"```

array",1.299771167
"```

[array",1.299771167
[array,1.299771167
1 array,1.299771167
500 array,1.299771167
"```

```

array",1.299771167
array],1.299771167
>array,1.299771167
"```



```

array",1.299771167
array[0],1.299771167
array[1],1.299771167
= array[,1.299771167
#NAME?,1.299771167
#NAME?,1.298507463
height,1.298507463
height],1.298507463
height * 32,1.298507463
height/2,1.298507463
50 height,1.298507463
y_test,1.298342541
y_test <-,1.298342541
y_test],1.298342541
y_test[0],1.298342541
present,1.294117647
z_mean,1.294117647
[z_mean,1.294117647
evaluate,1.291666667
workaround,1.291666667
# evaluate,1.291666667
#evaluate,1.291666667
evaluate``,1.291666667
`evaluate,1.291666667
evaluate`,1.291666667
maxpooling1d,1.290322581
#NAME?,1.290322581
concat,1.288135593
dropout,1.287356322
dropout=0,1.287356322
#NAME?,1.287356322
`dropout`,1.287356322
#    dropout,1.287356322
#NAME?,1.287356322
"[

    dropout",1.287356322
dropout > 0,1.287356322
dropout = 0,1.287356322
dropout +,1.287356322
dropout =,1.287356322
network_1,1.285714286
ckpt,1.285714286
_make_train_function,1.285714286
differentiable,1.285714286
direction,1.285714286
conv4,1.285714286
syntax,1.285714286
min_delta=0,1.285714286
"== 1

assertionerror

```",1.285714286
_make_predict_function,1.285714286
assertionerror,1.285714286
xs,1.285714286
min_delta = 0,1.285714286
constructor,1.285714286
//pypi,1.285714286
sequence_input,1.285714286
kernel_constraint,1.285714286
machines,1.285714286
"assertionerror

```",1.285714286
kernel_constraint=,1.285714286
listed,1.285714286
x4,1.285714286
x4],1.285714286
paths,1.285714286
table,1.285714286
discuss,1.285714286
axes,1.285714286
`kernel_constraint`,1.285714286
fit_params,1.285714286
193             fit_params,1.285714286
intended,1.285714286
**fit_params,1.285714286
`_make_train_function` [,1.285714286
encoded_y,1.285714286
"_make_train_function

    **",1.285714286
axes=-1,1.285714286
`axes`,1.285714286
allowing,1.285714286
cache,1.285714286
bytesio,1.285714286
[sequence_input,1.285714286
`sequence_input`,1.285714286
stateful_model,1.285714286
final_model,1.285714286
` syntax,1.285714286
numdims,1.285714286
pypi,1.285714286
"3]`

`axes = [3",1.285714286
conv4-1,1.285714286
conv4-2,1.285714286
[discuss],1.285714286
moving_variance,1.285714286
n_days_back=100,1.285714286
n_days_back,1.285714286
#NAME?,1.285714286
ckpt-1,1.285714286
"```

assertionerror",1.285714286
`encoded_y`,1.285714286
"_make_predict_function
    **",1.285714286
std,1.282051282
/std,1.282051282
15 std,1.282051282
`std`,1.282051282
cc,1.281879195
attributeerror,1.280701754
"```

attributeerror",1.280701754
"```



`attributeerror",1.280701754
`attributeerror,1.280701754
"+ 1

attributeerror",1.280701754
"53



attributeerror",1.280701754
> attributeerror,1.280701754
logs=,1.280487805
logs,1.280487805
logs[,1.280487805
logs={},1.280487805
"}

        logs[",1.280487805
"7}

logs",1.280487805
"8}

logs",1.280487805
"9}

logs",1.280487805
/logs,1.280487805
logs/{},1.280487805
txt,1.279069767
txt],1.279069767
path,1.277777778
properties,1.277777778
#NAME?,1.277777778
picture],1.277777778
/path/,1.277777778
picture,1.277777778
path=,1.277777778
%path,1.277777778
path+,1.277777778
#path,1.277777778
path +,1.277777778
"#%%

path =",1.277777778
```/path/,1.277777778
path =,1.277777778
suggestion,1.272727273
callable,1.272727273
rows,1.272727273
needed,1.272727273
asarray,1.272727273
debugging,1.272727273
couple,1.272727273
latex,1.272727273
1 rows,1.272727273
5 rows,1.272727273
needed],1.272727273
ideal,1.272727273
groups,1.272727273
#NAME?,1.272727273
"callable



**",1.272727273
"`



debugging",1.272727273
100000 rows,1.272727273
3 rows,1.272727273
15 rows,1.272727273
//latex,1.272727273
latex=,1.272727273
//groups,1.272727273
20 rows,1.272727273
**needed,1.272727273
**needed**,1.272727273
2 rows,1.272727273
changed,1.27027027
changed `,1.27027027
"changed

```",1.27027027
changed [,1.27027027
written,1.269230769
validate,1.269230769
stage,1.269230769
stage 3,1.269230769
stage=2,1.269230769
stage=3,1.269230769
stage=4,1.269230769
stage=5,1.269230769
y_train,1.269090909
y_train <-,1.269090909
"]



y_train =",1.269090909
`y_train`,1.269090909
y_train =,1.269090909
y_train[,1.269090909
3     y_train,1.269090909
y_train-1,1.269090909
#NAME?,1.269090909
"32]= 0

y_train[32",1.269090909
"64]= 1

y_train[64",1.269090909
"96]= 2

y_train[96",1.269090909
"128]= 3

y_train[128",1.269090909
y_train[0],1.269090909
#NAME?,1.269090909
found,1.268518519
found [,1.268518519
found %,1.268518519
found #3057,1.268518519
//github,1.267904509
github,1.267904509
github][3],1.267904509
[github],1.267904509
reshape,1.266932271
**reshape,1.266932271
# reshape,1.266932271
#NAME?,1.266932271
#NAME?,1.266932271
reshape  [,1.266932271
[reshape,1.266932271
`reshape,1.266932271
reshape{2},1.266932271
produce,1.266666667
get_updates,1.266666667
41         wrap =,1.266666667
wrap,1.266666667
get_updates`,1.266666667
`get_updates,1.266666667
vision_model,1.266666667
# vision_model,1.266666667
#NAME?,1.266666667
print,1.264931087
# print,1.264931087
print `,1.264931087
#print,1.264931087
"```

print",1.264931087
"}

    print",1.264931087
"]

print",1.264931087
"2]  

# print",1.264931087
1 print,1.264931087
"]



print",1.264931087
"[0]

  print",1.264931087
"= 1

    print",1.264931087
"2593

--



`print",1.264931087
"]]

print",1.264931087
"]]



print",1.264931087
"0

print",1.264931087
"# #

print",1.264931087
"]

>>> print",1.264931087
43             print,1.264931087
"print



```",1.264931087
##print,1.264931087
> print,1.264931087
"3026

print",1.264931087
"]

    print",1.264931087
"1

        print",1.264931087
3 print,1.264931087
65 print,1.264931087
67 print,1.264931087
37 print,1.264931087
39 print,1.264931087
7 @@ print,1.264931087
`         print,1.264931087
`print,1.264931087
`print`,1.264931087
2 print,1.264931087
"+1]



print",1.264931087
"] = 1

print",1.264931087
shown,1.263157895
happening,1.263157895
answer,1.263157895
#NAME?,1.263157895
convolution1d,1.263157895
options,1.261904762
> -> 1317                            options,1.261904762
fit_generator,1.258883249
`fit_generator,1.258883249
`fit_generator`,1.258883249
"fit_generator

2018-06-02 11",1.258883249
fit_generator`,1.258883249
"fit_generator



2",1.258883249
```fit_generator```,1.258883249
"#fit_generator

        #",1.258883249
fit_generator],1.258883249
max_queue_size,1.258064516
max_queue_size=50,1.258064516
max_queue_size=10,1.258064516
max_queue_size=8,1.258064516
max_queue_size = 10,1.258064516
max_queue_size=1,1.258064516
max_queue_size=2,1.258064516
bias_initializer=,1.257142857
perplexity,1.257142857
bias_initializer,1.257142857
bias_initializer =,1.257142857
perplexity =,1.257142857
perplexity],1.257142857
compile,1.255623722
# compile,1.255623722
#compile,1.255623722
compile`,1.255623722
`compile,1.255623722
">>> 

>>> # compile",1.255623722
`compile`,1.255623722
``compile,1.255623722
binary_crossentropy,1.252252252
binary_crossentropy},1.252252252
`binary_crossentropy,1.252252252
```binary_crossentropy```,1.252252252
meaning,1.25
compute_mask,1.25
searched,1.25
documented,1.25
finish,1.25
timeout,1.25
prediction_1,1.25
modifications,1.25
recommended,1.25
freezing,1.25
pretrained_cnn1,1.25
pretrained_cnn2,1.25
gru1,1.25
integers,1.25
insert,1.25
drop,1.25
n_words+1,1.25
weighted_metrics=[,1.25
root_mean_squared_error,1.25
roll,1.25
embeddings_constraint,1.25
feats,1.25
`weighted_metrics`,1.25
ideally,1.25
binary_accuracy,1.25
pc_attention_vector,1.25
pc_attention_vector/,1.25
img_shape,1.25
class_weights,1.25
feedback,1.25
weighted_metrics,1.25
resize_images,1.25
detail,1.25
period=1,1.25
endoder_2_dropout,1.25
cut,1.25
/image_test,1.25
image_test,1.25
x_trainros,1.25
x_testros,1.25
margin,1.25
ytest,1.25
apply_gradients,1.25
/en-,1.25
reset_default_graph,1.25
kw,1.25
chars,1.25
printing,1.25
forced,1.25
a2,1.25
null,1.25
difference,1.25
initializing,1.25
path1,1.25
green,1.25
green],1.25
crashing,1.25
deleting,1.25
img_list,1.25
margin = 5#0,1.25
input_points,1.25
`ctrl-,1.25
failing,1.25
preds_test_fold,1.25
preds_test_fold[1],1.25
[la_dense1,1.25
la_dense1,1.25
"`

`#todo",1.25
difference < 0,1.25
"= 3

    difference =",1.25
managed,1.25
input_video,1.25
input_accel,1.25
"24 

     25 # todo",1.25
graphconv,1.25
graphconv},1.25
reserved,1.25
0 reserved,1.25
margin =,1.25
#NAME?,1.25
input_anchor,1.25
[input_anchor,1.25
genre,1.25
step_input_shape,1.25
--> 353       _assertcompatible,1.25
_assertcompatible,1.25
supermodel,1.25
`supermodel,1.25
adapt,1.25
embeddingdropout,1.25
texts,1.25
`cifar10_cnn_capsule,1.25
expectation_1,1.25
readinto,1.25
chunk,1.25
actions,1.25
x_bad_id,1.25
x_good_id,1.25
[x_good_id,1.25
x_bad_id],1.25
32 bits,1.25
nchannels,1.25
period=2,1.25
nameerror,1.25
> wheel,1.25
correspond,1.25
discriminator,1.25
#NAME?,1.25
calculating,1.25
dropout_w=0,1.25
leaky_relu,1.25
retrieve,1.25
**kw,1.25
--> 238         **kw,1.25
f1_micro,1.25
_dispatch,1.25
applicable,1.25
//en,1.25
678] chunk,1.25
"difference

#",1.25
embeddings_constraint=,1.25
visualise,1.25
y_classes =,1.25
directoryiterator,1.25
auto_encoder_embedding,1.25
`internalerror,1.25
#NAME?,1.25
>constensor =,1.25
constensor,1.25
ctrl+,1.25
interest,1.25
cropping,1.25
events,1.25
act_func =,1.25
act_func,1.25
virtualenv,1.25
optimize,1.25
csv_file,1.25
vec_y,1.25
user_in,1.25
movie_in,1.25
[user_in,1.25
movie_in],1.25
[trn,1.25
trn,1.25
minput,1.25
out3 =,1.25
out3],1.25
out3,1.25
en,1.25
parse,1.25
meaningful,1.25
fits,1.25
s2,1.25
norm12,1.25
sq12,1.25
img_true,1.25
trouble,1.25
# drop,1.25
describe,1.25
attach,1.25
activated =,1.25
activated,1.25
net2,1.25
net2],1.25
[null,1.25
"]-1]

    gtactual",1.25
gtactual,1.25
mentions,1.25
a_tensor,1.25
a_tensor == 1,1.25
t1,1.25
[a_tensor,1.25
a_tensor],1.25
origin_predict,1.25
style_predict,1.25
"512

origin_predict =",1.25
"512

style_predict =",1.25
test2,1.25
discriminator],1.25
texts = [,1.25
info_seq_input],1.25
`info_seq_input`,1.25
metrics_tensors,1.25
clas],1.25
data1,1.25
clas,1.25
ema_model,1.25
#ema_model,1.25
subsequently,1.25
internalerror,1.25
[data1,1.25
bits,1.25
base_model_output,1.25
act2,1.25
`step_input_shape =,1.25
x_trainf,1.25
pool4,1.25
hidden_dim,1.25
b_active,1.25
# adapt,1.25
test2],1.25
drop 2 %,1.25
"# null

            [0",1.25
"# null

           [[1",1.25
n_output,1.25
n_output],1.25
abval > 0,1.25
0 / abval,1.25
abval,1.25
2 integers,1.25
dense3_1 =,1.25
dense3_1,1.25
[dense3_1,1.25
[image_model,1.25
_loss =,1.25
filename_queue,1.25
predict_path,1.25
json_model,1.25
[actions,1.25
u_constraint=,1.25
u_constraint,1.25
expression 1,1.25
expression,1.25
#NAME?,1.25
embs,1.25
drop-,1.25
batchcount = 0,1.25
batchcount += 1,1.25
`masking_value`,1.25
masking_value=-1,1.25
masking_value=0,1.25
resize_target,1.25
h5file,1.25
h5file[,1.25
todo,1.25
7 virtualenv,1.25
wheel,1.25
cnmem,1.25
#NAME?,1.25
heuristics,1.25
--> 367       _assertcompatible,1.25
689us         1  13,1.25
689us  13,1.25
9810us         1  3,1.25
9810us  3,1.25
65ms         1  148,1.25
65ms  148,1.25
02ms         1  131,1.25
02ms  131,1.25
ctrl-,1.25
_loss,1.25
n_cases*,1.25
"2

    drop = 0",1.25
word_trainlabelint,1.25
word_testlabelint,1.25
word_maximal_value,1.25
longest_word,1.25
char_traintokenintpad[0,1.25
char_traintokenintpad,1.25
char_traintokenintpad],1.25
model0,1.25
[model0,1.25
cropping=,1.25
dropout_w =,1.25
dropout_w,1.25
fl,1.25
n_words,1.25
image_model,1.25
# image_model,1.25
next_words,1.25
"]
    partial_captions",1.25
partial_captions,1.25
next_words[,1.25
partial_captions],1.25
a2 =,1.25
conv1d,1.247191011
#NAME?,1.247191011
/ conv1d,1.247191011
#NAME?,1.247191011
order,1.246753247
order=,1.246753247
validation_split,1.245614035
validation_split=0,1.245614035
validation_split=1/10,1.245614035
validation_split=,1.245614035
case,1.244755245
# case,1.244755245
issue,1.244736842
issue],1.244736842
issue #2801,1.244736842
"issue

2",1.244736842
issue #7362 ],1.244736842
issue #6451,1.244736842
**issue**,1.244736842
**issue 1,1.244736842
**issue,1.244736842
* issue,1.244736842
issue #1163,1.244736842
`issue`,1.244736842
issue [824],1.244736842
patience=10,1.242424242
patience=5,1.242424242
patience=3,1.242424242
patience=1,1.242424242
patience,1.242424242
patience=7,1.242424242
patience=2,1.242424242
patience=20,1.242424242
patience=40,1.242424242
patience=50,1.242424242
removed,1.24137931
#NAME?,1.240223464
maxpooling2d,1.240223464
#NAME?,1.240223464
tuple,1.24
"tuple

```",1.24
tuple`,1.24
int32,1.23880597
predict_generator,1.238095238
[`predict_generator`],1.238095238
rank 1,1.235294118
rank 4,1.235294118
beta,1.235294118
confused,1.235294118
clear_session,1.235294118
assume,1.235294118
cast,1.235294118
rank > 2,1.235294118
num_samples = 1000`,1.235294118
assume `,1.235294118
`clear_session,1.235294118
num_samples,1.235294118
rank 3,1.235294118
rank >= 3,1.235294118
&beta,1.235294118
num_samples   =,1.235294118
% num_samples,1.235294118
rank 0,1.235294118
# cast,1.235294118
rank,1.235294118
"rank
```",1.235294118
"> 

>   file",1.234436343
file,1.234436343
"```

file",1.234436343
``  file,1.234436343
"``

``

  file",1.234436343
"]

  file",1.234436343
"```

  file",1.234436343
>   file,1.234436343
"]

>   file",1.234436343
"]

    file",1.234436343
"```

 file",1.234436343
>>>   file,1.234436343
"8

      file",1.234436343
>file,1.234436343
"3]

  file",1.234436343
> file,1.234436343
**file,1.234436343
"**

  file",1.234436343
>  file,1.234436343
`  file,1.234436343
"file

2",1.234436343
"]

file",1.234436343
"```



  file",1.234436343
`file,1.234436343
"`

`file",1.234436343
"]
  file",1.234436343
"```
file",1.234436343
split,1.234375
# split,1.234375
split=,1.234375
split `,1.234375
`split,1.234375
summary,1.234177215
summary`,1.234177215
"18

      summary",1.234177215
sigmoid,1.233576642
```sigmoid```,1.233576642
flow_from_directory,1.23255814
`flow_from_directory`,1.23255814
**flow_from_directory**,1.23255814
`flow_from_directory,1.23255814
y_true,1.232323232
y_true =,1.232323232
1-y_true,1.232323232
#         y_true,1.232323232
`y_true`,1.232323232
**y_true**,1.232323232
y_true[,1.232323232
y_true =[1,1.232323232
0-y_true,1.232323232
y_true *,1.232323232
channels,1.231884058
channels = 50,1.231884058
channels = [],1.231884058
3 channels,1.231884058
[channels,1.231884058
channels = 3,1.231884058
channels]`,1.231884058
channels = 1,1.231884058
4 channels,1.231884058
1 channels,1.231884058
shouldn,1.230769231
area,1.230769231
mylayer,1.230769231
#NAME?,1.230769231
y1 =,1.230769231
y1,1.230769231
shouldn�,1.230769231
model_arousal,1.230769231
`y1 = [,1.230769231
`y1 = [01,1.230769231
`y1 = [[1,1.230769231
y1=0,1.230769231
[y1,1.230769231
3s,1.230769231
mylayer},1.230769231
"mylayer

`",1.230769231
#NAME?,1.227272727
scope,1.227272727
scope=,1.227272727
ran,1.225806452
key,1.225
` key,1.225
key +,1.225
situation,1.222222222
creates,1.222222222
serialize,1.222222222
cheers,1.222222222
environ[,1.222222222
consistent,1.222222222
6-py3,1.222222222
early_stopper,1.222222222
happen,1.222222222
big_model,1.222222222
resolve,1.222222222
fc1,1.222222222
consistent ~5%,1.222222222
model3,1.222222222
t-1,1.222222222
cheers~,1.222222222
programs,1.222222222
3-py3,1.222222222
c1 =,1.222222222
#REF!,1.222222222
c1,1.222222222
0*ngaussians,1.222222222
1*ngaussians,1.222222222
2*ngaussians,1.222222222
3*ngaussians,1.222222222
4*ngaussians,1.222222222
5*ngaussians,1.222222222
6*ngaussians,1.222222222
ngaussians,1.222222222
ascii,1.222222222
t-10,1.222222222
9-py3,1.222222222
addr & ~2,1.222222222
addr & 2,1.222222222
model3],1.222222222
8-py3,1.222222222
s_t,1.222222222
a_t,1.222222222
alpha,1.21875
`alpha =,1.21875
alpha=,1.21875
alpha=0,1.21875
alpha=1,1.21875
&alpha,1.21875
alpha =,1.21875
axis=1,1.217741935
164                     axis=,1.217741935
axis,1.217741935
axis=-1,1.217741935
axis= 1,1.217741935
axis=0,1.217741935
axis=3,1.217741935
axis = -1,1.217741935
axis = 0,1.217741935
axis=2,1.217741935
axis = 1,1.217741935
axis 1,1.217741935
axis 2,1.217741935
axis=,1.217741935
axis 3,1.217741935
{}/squeeze,1.214285714
squeeze,1.214285714
y_pred,1.212851406
[y_pred,1.212851406
y_pred},1.212851406
[y_pred],1.212851406
y_pred =,1.212851406
#         y_pred,1.212851406
`y_pred`,1.212851406
y_pred[,1.212851406
0] < y_pred[,1.212851406
"1]

**y_pred**",1.212851406
*y_pred,1.212851406
y_pred < 0,1.212851406
"```

y_pred",1.212851406
` y_pred `,1.212851406
* y_pred,1.212851406
0] y_pred = [-3,1.212851406
0-y_pred,1.212851406
"]

            y_pred =",1.212851406
scalar,1.212121212
scalar `0,1.212121212
running,1.210743802
"```

running",1.210743802
"4

running",1.210743802
8 running,1.210743802
"```

 running",1.210743802
running [,1.210743802
get_session,1.210526316
eye,1.210526316
7613 mb,1.210526316
100 mb,1.210526316
77 mb/,1.210526316
29 mb/,1.210526316
82 mb/,1.210526316
32 mb/,1.210526316
58 mb/,1.210526316
36 mb/,1.210526316
03 mb/,1.210526316
68 mb/,1.210526316
recall,1.210526316
237 mb,1.210526316
445 mb,1.210526316
mb=16,1.210526316
mb,1.210526316
#NAME?,1.210526316
`eye =,1.210526316
>   eye =,1.210526316
"eye

>",1.210526316
"= 72 

eye =",1.210526316
bug,1.209876543
bug #7297,1.209876543
set_weights,1.208333333
set_weights`,1.208333333
/set_weights`,1.208333333
`set_weights,1.208333333
mse,1.207792208
mse 0,1.207792208
eval,1.206896552
#NAME?,1.2
switch,1.2
**keywords,1.2
py_func``,1.2
searching,1.2
gru2,1.2
formula,1.2
knowledge,1.2
looked,1.2
dims,1.2
embed,1.2
walk,1.2
sparse_categorical_crossentropy,1.2
"sparse_categorical_crossentropy

```",1.2
observation,1.2
_as_variant_tensor,1.2
keywords,1.2
n_classes,1.2
datadir,1.2
input_len,1.2
mind,1.2
grucell,1.2
send,1.2
smooth,1.2
included,1.2
10 cols,1.2
5 cols,1.2
lstm2,1.2
clear,1.2
ipynb,1.2
referring,1.2
confusing,1.2
`grucell`,1.2
measures,1.2
#     measures,1.2
cols,1.2
explanation,1.2
`sparse_categorical_crossentropy`,1.2
pick,1.2
opening,1.2
oov_token,1.2
cikis,1.2
`oov_token`,1.2
oov_token=,1.2
mapped,1.2
3151                                                        weight_values,1.2
weight_values,1.2
determine,1.2
trial_batch_1,1.2
imgur,1.2
# keeping,1.2
w_shape =,1.2
--> 199         chunks =,1.2
chunks,1.2
fusion,1.2
feedforward_model,1.2
#NAME?,1.2
model_a,1.2
[model_a,1.2
w_shape,1.2
random_uniform,1.2
street,1.2
"```

smooth = 1",1.2
#NAME?,1.2
vec_x,1.2
x0 = 2*[,1.2
x0,1.2
[x0,1.2
train_set[,1.2
out1 =,1.2
out2 =,1.2
out1,1.2
out2,1.2
[out1,1.2
# out1,1.2
train_set,1.2
normalized,1.2
timestamp,1.2
= [x0,1.2
s1s2,1.2
dense2_out,1.2
y_,1.2
keeping,1.2
<pick,1.2
mapped = [],1.2
leave,1.2
y_},1.2
y_ =,1.2
y_[,1.2
[x_sum,1.2
x_sum,1.2
x0},1.2
x0 =,1.2
reshaped,1.2
typically,1.2
**smooth**,1.2
ipynb],1.2
data_in,1.2
"```

data_in",1.2
nb_traces_train,1.2
[nb_traces_train,1.2
[nb_traces_train],1.2
split_at,1.2
"8

searching",1.2
w_constraint=,1.2
w_constraint,1.2
output_fld,1.2
batchsz = 64,1.2
batchsz,1.2
batchsz = 128,1.2
100% clear,1.2
dims= %,1.2
324       switch,1.2
py_func,1.2
#NAME?,1.2
current_class_imgs[,1.2
2898                                                        weight_values,1.2
word_tokenmap,1.2
char_list,1.2
compiled,1.196078431
3 compiled,1.196078431
rv,1.195652174
target_size,1.195121951
target_size=,1.195121951
target_size[1],1.195121951
target_size[0],1.195121951
"```

                           target_size=",1.195121951
target_size =,1.195121951
`target_size=,1.195121951
reason,1.194444444
items,1.194029851
128 items,1.194029851
10000 items,1.194029851
83 items,1.194029851
workers=4,1.192982456
workers,1.192982456
workers=1,1.192982456
workers = 0,1.192982456
workers >= 1,1.192982456
workers = 1,1.192982456
`workers = 1`,1.192982456
`workers`,1.192982456
workers=8,1.192982456
workers = 120,1.192982456
workers=12,1.192982456
workers > 1,1.192982456
"```

resnet_50",1.191176471
resnet_50,1.191176471
2f%%,1.19047619
tested,1.19047619
2f},1.19047619
2f}%,1.19047619
"`



tested",1.19047619
glob,1.189189189
channels_first,1.189189189
`channels_first`,1.189189189
epoch,1.188929001
"epoch 1/50

2018-06-02 10",1.188929001
epoch 00001,1.188929001
"epoch 2/50

2018-06-02 11",1.188929001
"3737

epoch 2/3

200000/200000 [==============================]",1.188929001
"3256

epoch 3/3

200000/200000 [==============================]",1.188929001
"0570 

epoch 2/20",1.188929001
"0570 

epoch 3/20",1.188929001
"0570 

epoch 4/20",1.188929001
"```

epoch 1/15

1/1 [==============================]",1.188929001
"9000

epoch 2/15

1/1 [==============================]",1.188929001
"9000

epoch 3/15

1/1 [==============================]",1.188929001
"9000

epoch 4/15

1/1 [==============================]",1.188929001
"9000

epoch 5/15

1/1 [==============================]",1.188929001
"9000

epoch 6/15

1/1 [==============================]",1.188929001
"9000

epoch 7/15

1/1 [==============================]",1.188929001
"9000

epoch 8/15

1/1 [==============================]",1.188929001
"9000

epoch 9/15

1/1 [==============================]",1.188929001
"9000

epoch 10/15

1/1 [==============================]",1.188929001
"9000

epoch 11/15

1/1 [==============================]",1.188929001
"9000

epoch 12/15

1/1 [==============================]",1.188929001
"9000

epoch 13/15

1/1 [==============================]",1.188929001
"9000

epoch 14/15

1/1 [==============================]",1.188929001
"9000

epoch 15/15

1/1 [==============================]",1.188929001
"```

epoch 1/15

2/2 [==============================]",1.188929001
"9000

epoch 2/15

2/2 [==============================]",1.188929001
"9000

epoch 3/15

2/2 [==============================]",1.188929001
"9000

epoch 4/15

2/2 [==============================]",1.188929001
"9000

epoch 5/15

2/2 [==============================]",1.188929001
"9000

epoch 6/15

2/2 [==============================]",1.188929001
"9000

epoch 7/15

2/2 [==============================]",1.188929001
"9000

epoch 8/15

2/2 [==============================]",1.188929001
"}



epoch 1/2

2018-05-16 12",1.188929001
epoch 1,1.188929001
"10505]

epoch 2",1.188929001
"epoch 1/100

26/26 [==============================]",1.188929001
"5077

epoch 2/100

26/26 [==============================]",1.188929001
"7846

epoch 3/100

26/26 [==============================]",1.188929001
"8000

epoch 4/100

26/26 [==============================]",1.188929001
"7769

epoch 5/100

26/26 [==============================]",1.188929001
"8385

epoch 6/100

26/26 [==============================]",1.188929001
"8231

epoch 7/100

26/26 [==============================]",1.188929001
"8846

epoch 8/100

26/26 [==============================]",1.188929001
"9000

epoch 9/100

26/26 [==============================]",1.188929001
"8769

epoch 10/100

26/26 [==============================]",1.188929001
"8769

epoch 11/100

26/26 [==============================]",1.188929001
"8923

epoch 12/100

26/26 [==============================]",1.188929001
"9000

epoch 13/100

26/26 [==============================]",1.188929001
"8769

epoch 14/100

26/26 [==============================]",1.188929001
"9538

epoch 15/100

26/26 [==============================]",1.188929001
"9538

epoch 16/100

26/26 [==============================]",1.188929001
"9538

epoch 17/100

26/26 [==============================]",1.188929001
"9615

epoch 18/100

26/26 [==============================]",1.188929001
"9615

epoch 19/100

26/26 [==============================]",1.188929001
"9769

epoch 20/100

26/26 [==============================]",1.188929001
"9769

epoch 21/100

26/26 [==============================]",1.188929001
"9923

epoch 22/100

26/26 [==============================]",1.188929001
"9769

epoch 23/100

26/26 [==============================]",1.188929001
"9923

epoch 24/100

26/26 [==============================]",1.188929001
"0000

epoch 25/100

26/26 [==============================]",1.188929001
"0000

epoch 26/100

26/26 [==============================]",1.188929001
"0000

epoch 27/100

26/26 [==============================]",1.188929001
"0000

epoch 28/100

26/26 [==============================]",1.188929001
"9923

epoch 29/100

26/26 [==============================]",1.188929001
"0000

epoch 30/100

26/26 [==============================]",1.188929001
"0000

epoch 31/100

26/26 [==============================]",1.188929001
"0000

epoch 32/100

26/26 [==============================]",1.188929001
"0000

epoch 33/100

26/26 [==============================]",1.188929001
"0000

epoch 34/100

26/26 [==============================]",1.188929001
"0000

epoch 35/100

26/26 [==============================]",1.188929001
"9923

epoch 36/100

26/26 [==============================]",1.188929001
"0000

epoch 37/100

26/26 [==============================]",1.188929001
"0000

epoch 38/100

26/26 [==============================]",1.188929001
"0000

epoch 39/100

26/26 [==============================]",1.188929001
"0000

epoch 40/100

26/26 [==============================]",1.188929001
"0000

epoch 41/100

26/26 [==============================]",1.188929001
"0000

epoch 42/100

26/26 [==============================]",1.188929001
"0000

epoch 43/100

26/26 [==============================]",1.188929001
"0000

epoch 44/100

26/26 [==============================]",1.188929001
"0000

epoch 45/100

26/26 [==============================]",1.188929001
"0000

epoch 46/100

26/26 [==============================]",1.188929001
"0000

epoch 47/100

26/26 [==============================]",1.188929001
"0000

epoch 48/100

26/26 [==============================]",1.188929001
"0000

epoch 49/100

26/26 [==============================]",1.188929001
"0000

epoch 50/100

26/26 [==============================]",1.188929001
"0000

epoch 51/100

26/26 [==============================]",1.188929001
"0000

epoch 52/100

26/26 [==============================]",1.188929001
"0000

epoch 53/100

26/26 [==============================]",1.188929001
"0000

epoch 54/100

26/26 [==============================]",1.188929001
"0000

epoch 55/100

26/26 [==============================]",1.188929001
"0000

epoch 56/100

26/26 [==============================]",1.188929001
"0000

epoch 57/100

26/26 [==============================]",1.188929001
"0000

epoch 58/100

26/26 [==============================]",1.188929001
"0000

epoch 59/100

26/26 [==============================]",1.188929001
"0000

epoch 60/100

26/26 [==============================]",1.188929001
"0000

epoch 61/100

26/26 [==============================]",1.188929001
"0000

epoch 62/100

26/26 [==============================]",1.188929001
"0000

epoch 63/100

26/26 [==============================]",1.188929001
"0000

epoch 64/100

26/26 [==============================]",1.188929001
"0000

epoch 65/100

26/26 [==============================]",1.188929001
"0000

epoch 66/100

26/26 [==============================]",1.188929001
"0000

epoch 67/100

26/26 [==============================]",1.188929001
"0000

epoch 68/100

26/26 [==============================]",1.188929001
"0000

epoch 69/100

26/26 [==============================]",1.188929001
"0000

epoch 70/100

26/26 [==============================]",1.188929001
"0000

epoch 71/100

26/26 [==============================]",1.188929001
"0000

epoch 72/100

26/26 [==============================]",1.188929001
"0000

epoch 73/100

26/26 [==============================]",1.188929001
"0000

epoch 74/100

26/26 [==============================]",1.188929001
"0000

epoch 75/100

26/26 [==============================]",1.188929001
"0000

epoch 76/100

26/26 [==============================]",1.188929001
"0000

epoch 77/100

26/26 [==============================]",1.188929001
"0000

epoch 78/100

26/26 [==============================]",1.188929001
"0000

epoch 79/100

26/26 [==============================]",1.188929001
"0000

epoch 80/100

26/26 [==============================]",1.188929001
"0000

epoch 81/100

26/26 [==============================]",1.188929001
"0000

epoch 82/100

26/26 [==============================]",1.188929001
"0000

epoch 83/100

26/26 [==============================]",1.188929001
"0000

epoch 84/100

26/26 [==============================]",1.188929001
"0000

epoch 85/100

26/26 [==============================]",1.188929001
"0000

epoch 86/100

26/26 [==============================]",1.188929001
"0000

epoch 87/100

26/26 [==============================]",1.188929001
"0000

epoch 88/100

26/26 [==============================]",1.188929001
"0000

epoch 89/100

26/26 [==============================]",1.188929001
"0000

epoch 90/100

26/26 [==============================]",1.188929001
"0000

epoch 91/100

26/26 [==============================]",1.188929001
"0000

epoch 92/100

26/26 [==============================]",1.188929001
"0000

epoch 93/100

26/26 [==============================]",1.188929001
"0000

epoch 94/100

26/26 [==============================]",1.188929001
"0000

epoch 95/100

26/26 [==============================]",1.188929001
"0000

epoch 96/100

26/26 [==============================]",1.188929001
"0000

epoch 97/100

26/26 [==============================]",1.188929001
"0000

epoch 98/100

26/26 [==============================]",1.188929001
"0000

epoch 99/100

26/26 [==============================]",1.188929001
"0000

epoch 100/100

26/26 [==============================]",1.188929001
epoch + 1,1.188929001
1 epoch,1.188929001
"epoch 1/8

1299/1298 [==============================]",1.188929001
"7386

epoch 2/8

1299/1298 [==============================]",1.188929001
"7298

epoch 3/8

1299/1298 [==============================]",1.188929001
"7412

epoch 4/8

1299/1298 [==============================]",1.188929001
"7528

epoch 5/8

1299/1298 [==============================]",1.188929001
"7572

epoch 6/8

1299/1298 [==============================]",1.188929001
"7515

epoch 7/8

1299/1298 [==============================]",1.188929001
"7611

epoch 8/8

1299/1298 [==============================]",1.188929001
"epoch 48/50

49/49 [==============================]",1.188929001
"6923

epoch 49/50

49/49 [==============================]",1.188929001
"6923

epoch 50/50

49/49 [==============================]",1.188929001
epoch %,1.188929001
"8719

epoch 2/20

15000/15000 [==============================]",1.188929001
"8902

epoch 3/20

15000/15000 [==============================]",1.188929001
"8827

epoch 4/20

15000/15000 [==============================]",1.188929001
"```

epoch 1/10

74/74 [==============================]",1.188929001
"6018



epoch 00001",1.188929001
"6018



epoch 00002",1.188929001
"-------------------------------------------------------------------------------------------------------------

epoch",1.188929001
"00024978623984333654



epoch",1.188929001
"00024977498874587285



epoch",1.188929001
epoch 1/1,1.188929001
"8447

epoch 2/15

25000/25000 [==============================]",1.188929001
"8412

epoch 3/15

25000/25000 [==============================]",1.188929001
"8299

epoch 4/15

25000/25000 [==============================]",1.188929001
"8269

epoch 5/15

25000/25000 [==============================]",1.188929001
"8214

epoch 6/15

25000/25000 [==============================]",1.188929001
"8116

epoch 7/15

25000/25000 [==============================]",1.188929001
"8220

epoch 8/15

25000/25000 [==============================]",1.188929001
"8152

epoch 9/15

25000/25000 [==============================]",1.188929001
"8030

epoch 10/15

25000/25000 [==============================]",1.188929001
"8175

epoch 11/15

25000/25000 [==============================]",1.188929001
"8026

epoch 12/15

25000/25000 [==============================]",1.188929001
"8130

epoch 13/15

25000/25000 [==============================]",1.188929001
"8038

epoch 14/15

25000/25000 [==============================]",1.188929001
"7916

epoch 15/15

25000/25000 [==============================]",1.188929001
"7180

epoch 2/15

25000/25000 [==============================]",1.188929001
"7412

epoch 3/15

25000/25000 [==============================]",1.188929001
"7008

epoch 4/15

25000/25000 [==============================]",1.188929001
"7182

epoch 5/15

25000/25000 [==============================]",1.188929001
"6766

epoch 6/15

25000/25000 [==============================]",1.188929001
"7116

epoch 7/15

25000/25000 [==============================]",1.188929001
"7080

epoch 8/15

25000/25000 [==============================]",1.188929001
"7139

epoch 9/15

25000/25000 [==============================]",1.188929001
"7047

epoch 10/15

25000/25000 [==============================]",1.188929001
"7054

epoch 11/15

25000/25000 [==============================]",1.188929001
"7054

epoch 12/15

25000/25000 [==============================]",1.188929001
"7097

epoch 13/15

25000/25000 [==============================]",1.188929001
"7080

epoch 14/15

25000/25000 [==============================]",1.188929001
"7054

epoch 15/15

25000/25000 [==============================]",1.188929001
"7174

epoch 2/15

25000/25000 [==============================]",1.188929001
"7380

epoch 3/15

25000/25000 [==============================]",1.188929001
"7146

epoch 4/15

25000/25000 [==============================]",1.188929001
"7164

epoch 5/15

25000/25000 [==============================]",1.188929001
"6769

epoch 6/15

25000/25000 [==============================]",1.188929001
"6608

epoch 7/15

25000/25000 [==============================]",1.188929001
"7222

epoch 8/15

25000/25000 [==============================]",1.188929001
"7156

epoch 9/15

25000/25000 [==============================]",1.188929001
"7137

epoch 10/15

25000/25000 [==============================]",1.188929001
"7425

epoch 11/15

25000/25000 [==============================]",1.188929001
"5000

epoch 12/15

25000/25000 [==============================]",1.188929001
"5000

epoch 13/15

25000/25000 [==============================]",1.188929001
"5007

epoch 14/15

25000/25000 [==============================]",1.188929001
"5007

epoch 15/15

25000/25000 [==============================]",1.188929001
"epoch 1/10

796/796 [==============================]",1.188929001
"6947

epoch 2/10

796/796 [==============================]",1.188929001
"7525

epoch 3/10

796/796 [==============================]",1.188929001
"7525

epoch 4/10

796/796 [==============================]",1.188929001
"7525

epoch 5/10

796/796 [==============================]",1.188929001
"7525

epoch 6/10

796/796 [==============================]",1.188929001
"7525

epoch 7/10

796/796 [==============================]",1.188929001
"7525

epoch 8/10

796/796 [==============================]",1.188929001
"7525

epoch 9/10

796/796 [==============================]",1.188929001
"7525

epoch 10/10

796/796 [==============================]",1.188929001
"1809

epoch 2/10

249/249 [==============================]",1.188929001
"1809

epoch 3/10

249/249 [==============================]",1.188929001
"1809

epoch 4/10

249/249 [==============================]",1.188929001
"1809

epoch 5/10

249/249 [==============================]",1.188929001
"`epoch 1/2

2356/2356 [==============================]",1.188929001
"9320

 epoch 2/2

2356/2356 [==============================]",1.188929001
{epoch,1.188929001
"epoch 1/1000

6003/6003 [==============================]",1.188929001
"1437

epoch 2/1000

6003/6003 [==============================]",1.188929001
"1257

epoch 3/1000

6003/6003 [==============================]",1.188929001
"1018

epoch 4/1000

6003/6003 [==============================]",1.188929001
"0928

epoch 5/1000

6003/6003 [==============================]",1.188929001
"epoch 100/1000

6003/6003 [==============================]",1.188929001
"0943

epoch 101/1000

6003/6003 [==============================]",1.188929001
"1018

epoch 102/1000

6003/6003 [==============================]",1.188929001
"1003

epoch 103/1000

6003/6003 [==============================]",1.188929001
"0913

epoch 104/1000

6003/6003 [==============================]",1.188929001
"0973

epoch 105/1000

6003/6003 [==============================]",1.188929001
"epoch 280/1000

6003/6003 [==============================]",1.188929001
"2036

epoch 281/1000

6003/6003 [==============================]",1.188929001
"1961

epoch 282/1000

6003/6003 [==============================]",1.188929001
"2021

epoch 283/1000

6003/6003 [==============================]",1.188929001
"1976

epoch 284/1000

6003/6003 [==============================]",1.188929001
"2066

epoch 285/1000

6003/6003 [==============================]",1.188929001
epoch 80,1.188929001
epoch 81,1.188929001
epoch 5,1.188929001
"```

epoch 1/10

1/1 [==============================]",1.188929001
"0000

epoch 3/10

1/1 [==============================]",1.188929001
"0000

epoch 4/10

1/1 [==============================]",1.188929001
"0000

epoch 8/10

1/1 [==============================]",1.188929001
"0000

epoch 9/10

1/1 [==============================]",1.188929001
"0000

epoch 10/10

1/1 [==============================]",1.188929001
"9720

epoch 2/4

8/8 [==============================]",1.188929001
100 epoch,1.188929001
10-12 epoch,1.188929001
epoch=1,1.188929001
"epoch 1/200

2017-10-30 21",1.188929001
"4383

epoch 2/200

1562/1562 [==============================]",1.188929001
"5224

epoch 3/200

1562/1562 [==============================]",1.188929001
"5614

epoch 4/200

1562/1562 [==============================]",1.188929001
"5910

epoch 5/200

1562/1562 [==============================]",1.188929001
"6163

epoch 6/200

1562/1562 [==============================]",1.188929001
"6110

epoch 7/200

1562/1562 [==============================]",1.188929001
"6472

epoch 8/200

1562/1562 [==============================]",1.188929001
"6623

epoch 9/200

1562/1562 [==============================]",1.188929001
"6704

epoch 10/200

1562/1562 [==============================]",1.188929001
"6877

epoch 11/200

1562/1562 [==============================]",1.188929001
"7015

epoch 12/200

1562/1562 [==============================]",1.188929001
"7081

epoch 13/200

1562/1562 [==============================]",1.188929001
"7120

epoch 14/200

1562/1562 [==============================]",1.188929001
"7112

epoch 15/200

1562/1562 [==============================]",1.188929001
"7247

epoch 16/200

1562/1562 [==============================]",1.188929001
"7240

epoch 17/200

1562/1562 [==============================]",1.188929001
"7373

epoch 18/200

1562/1562 [==============================]",1.188929001
"7347

epoch 19/200

1562/1562 [==============================]",1.188929001
"7473

epoch 20/200

1562/1562 [==============================]",1.188929001
"7464

epoch 21/200

1562/1562 [==============================]",1.188929001
"7443

epoch 22/200

1562/1562 [==============================]",1.188929001
"7521

epoch 23/200

1562/1562 [==============================]",1.188929001
"7521

epoch 24/200

1562/1562 [==============================]",1.188929001
"7624

epoch 25/200

1562/1562 [==============================]",1.188929001
"7575

epoch 26/200

1562/1562 [==============================]",1.188929001
"7611

epoch 27/200

1562/1562 [==============================]",1.188929001
"7665

epoch 28/200

1562/1562 [==============================]",1.188929001
"7613

epoch 29/200

1562/1562 [==============================]",1.188929001
"7707

epoch 30/200

1562/1562 [==============================]",1.188929001
"7567

epoch 31/200

1562/1562 [==============================]",1.188929001
"7725

epoch 32/200

1562/1562 [==============================]",1.188929001
"7753

epoch 33/200

1562/1562 [==============================]",1.188929001
"7654

epoch 34/200

1562/1562 [==============================]",1.188929001
"7770

epoch 35/200

1562/1562 [==============================]",1.188929001
"7816

epoch 36/200

1562/1562 [==============================]",1.188929001
"7815

epoch 37/200

1562/1562 [==============================]",1.188929001
"7689

epoch 38/200

1562/1562 [==============================]",1.188929001
"7719

epoch 39/200

1562/1562 [==============================]",1.188929001
"7737

epoch 40/200

1562/1562 [==============================]",1.188929001
"7800

epoch 41/200

1562/1562 [==============================]",1.188929001
"7727

epoch 42/200

1562/1562 [==============================]",1.188929001
"7848

epoch 43/200

1562/1562 [==============================]",1.188929001
"7709

epoch 44/200

1562/1562 [==============================]",1.188929001
"7860

epoch 45/200

1562/1562 [==============================]",1.188929001
"7906

epoch 46/200

1562/1562 [==============================]",1.188929001
"7758

epoch 47/200

1562/1562 [==============================]",1.188929001
"7767

epoch 48/200

1562/1562 [==============================]",1.188929001
"7818

epoch 49/200

1562/1562 [==============================]",1.188929001
"7807

epoch 50/200

1562/1562 [==============================]",1.188929001
"7787

epoch 51/200

1562/1562 [==============================]",1.188929001
"7821

epoch 52/200

1562/1562 [==============================]",1.188929001
"7611

epoch 53/200

1562/1562 [==============================]",1.188929001
"7917

epoch 54/200

1562/1562 [==============================]",1.188929001
"7947

epoch 55/200

1562/1562 [==============================]",1.188929001
"7873

epoch 56/200

1562/1562 [==============================]",1.188929001
"7928

epoch 57/200

1562/1562 [==============================]",1.188929001
"7937

epoch 58/200

1562/1562 [==============================]",1.188929001
"7854

epoch 59/200

1562/1562 [==============================]",1.188929001
"7918

epoch 60/200

1562/1562 [==============================]",1.188929001
"7977

epoch 61/200

1562/1562 [==============================]",1.188929001
"7939

epoch 62/200

1562/1562 [==============================]",1.188929001
"7959

epoch 63/200

1562/1562 [==============================]",1.188929001
"7784

epoch 64/200

1562/1562 [==============================]",1.188929001
"7973

epoch 65/200

1562/1562 [==============================]",1.188929001
"7779

epoch 66/200

1562/1562 [==============================]",1.188929001
"7892

epoch 67/200

1562/1562 [==============================]",1.188929001
"7863

epoch 68/200

1562/1562 [==============================]",1.188929001
"7896

epoch 69/200

1562/1562 [==============================]",1.188929001
"7897

epoch 70/200

1562/1562 [==============================]",1.188929001
"7965

epoch 71/200

1562/1562 [==============================]",1.188929001
"7971

epoch 72/200

1562/1562 [==============================]",1.188929001
"7896

epoch 73/200

1562/1562 [==============================]",1.188929001
"7828

epoch 74/200

1562/1562 [==============================]",1.188929001
"7919

epoch 75/200

1562/1562 [==============================]",1.188929001
"7883

epoch 76/200

1562/1562 [==============================]",1.188929001
"7964

epoch 77/200

1562/1562 [==============================]",1.188929001
"7940

epoch 78/200

1562/1562 [==============================]",1.188929001
"7964

epoch 79/200

1562/1562 [==============================]",1.188929001
"7732

epoch 80/200

1562/1562 [==============================]",1.188929001
"7893

epoch 81/200

1562/1562 [==============================]",1.188929001
"7868

epoch 82/200

1562/1562 [==============================]",1.188929001
"7987

epoch 83/200

1562/1562 [==============================]",1.188929001
"7954

epoch 84/200

1562/1562 [==============================]",1.188929001
"7733

epoch 85/200

1562/1562 [==============================]",1.188929001
"7808

epoch 86/200

1562/1562 [==============================]",1.188929001
"7959

epoch 87/200

1562/1562 [==============================]",1.188929001
"7864

epoch 88/200

1562/1562 [==============================]",1.188929001
"7872

epoch 89/200

1562/1562 [==============================]",1.188929001
"7778

epoch 90/200

1562/1562 [==============================]",1.188929001
"7834

epoch 91/200

1562/1562 [==============================]",1.188929001
"7881

epoch 92/200

1562/1562 [==============================]",1.188929001
"7917

epoch 93/200

1562/1562 [==============================]",1.188929001
"7859

epoch 94/200

1562/1562 [==============================]",1.188929001
"7873

epoch 95/200

1562/1562 [==============================]",1.188929001
"7860

epoch 96/200

1562/1562 [==============================]",1.188929001
"7961

epoch 97/200

1562/1562 [==============================]",1.188929001
"7745

epoch 98/200

1562/1562 [==============================]",1.188929001
"7828

epoch 99/200

1562/1562 [==============================]",1.188929001
"7684

epoch 100/200

1562/1562 [==============================]",1.188929001
"7861

epoch 101/200

1562/1562 [==============================]",1.188929001
"7510

epoch 102/200

1562/1562 [==============================]",1.188929001
"7867

epoch 103/200

1562/1562 [==============================]",1.188929001
"7938

epoch 104/200

1562/1562 [==============================]",1.188929001
"7906

epoch 105/200

1562/1562 [==============================]",1.188929001
"7717

epoch 106/200

1562/1562 [==============================]",1.188929001
"7746

epoch 107/200

1562/1562 [==============================]",1.188929001
"8009

epoch 108/200

1562/1562 [==============================]",1.188929001
"7789

epoch 109/200

1562/1562 [==============================]",1.188929001
"7766

epoch 110/200

1562/1562 [==============================]",1.188929001
"7804

epoch 111/200

1562/1562 [==============================]",1.188929001
"7894

epoch 112/200

1562/1562 [==============================]",1.188929001
"7919

epoch 113/200

1562/1562 [==============================]",1.188929001
"7881

epoch 114/200

1562/1562 [==============================]",1.188929001
"7790

epoch 115/200

1562/1562 [==============================]",1.188929001
"7584

epoch 116/200

1562/1562 [==============================]",1.188929001
"7785

epoch 117/200

1562/1562 [==============================]",1.188929001
"7694

epoch 118/200

1562/1562 [==============================]",1.188929001
"7456

epoch 119/200

1562/1562 [==============================]",1.188929001
"7275

epoch 120/200

1562/1562 [==============================]",1.188929001
"7740

epoch 121/200

1562/1562 [==============================]",1.188929001
"7750

epoch 122/200

1562/1562 [==============================]",1.188929001
"7539

epoch 123/200

1562/1562 [==============================]",1.188929001
"7746

epoch 124/200

1562/1562 [==============================]",1.188929001
"7474

epoch 125/200

1562/1562 [==============================]",1.188929001
"7673

epoch 126/200

1562/1562 [==============================]",1.188929001
"7776

epoch 127/200

1562/1562 [==============================]",1.188929001
"7847

epoch 128/200

1562/1562 [==============================]",1.188929001
"7486

epoch 129/200

1562/1562 [==============================]",1.188929001
"7592

epoch 130/200

1562/1562 [==============================]",1.188929001
"7323

epoch 131/200

1562/1562 [==============================]",1.188929001
"7600

epoch 132/200

1562/1562 [==============================]",1.188929001
"7666

epoch 133/200

1562/1562 [==============================]",1.188929001
"7766

epoch 134/200

1562/1562 [==============================]",1.188929001
"7614

epoch 135/200

1562/1562 [==============================]",1.188929001
"7683

epoch 136/200

1562/1562 [==============================]",1.188929001
"7391

epoch 137/200

1562/1562 [==============================]",1.188929001
"7627

epoch 138/200

1562/1562 [==============================]",1.188929001
"7517

epoch 139/200

1562/1562 [==============================]",1.188929001
"7340

epoch 140/200

1562/1562 [==============================]",1.188929001
"7531

epoch 141/200

1562/1562 [==============================]",1.188929001
"7539

epoch 142/200

1562/1562 [==============================]",1.188929001
"6964

epoch 143/200

1562/1562 [==============================]",1.188929001
"7112

epoch 144/200

1562/1562 [==============================]",1.188929001
"7315

epoch 145/200

1562/1562 [==============================]",1.188929001
"7695

epoch 146/200

1562/1562 [==============================]",1.188929001
"7336

epoch 147/200

1562/1562 [==============================]",1.188929001
"7411

epoch 148/200

1562/1562 [==============================]",1.188929001
"7590

epoch 149/200

1562/1562 [==============================]",1.188929001
"7411

epoch 150/200

1562/1562 [==============================]",1.188929001
"7579

epoch 151/200

1562/1562 [==============================]",1.188929001
"7293

epoch 152/200

1562/1562 [==============================]",1.188929001
"7065

epoch 153/200

1562/1562 [==============================]",1.188929001
"7419

epoch 154/200

1562/1562 [==============================]",1.188929001
"7277

epoch 155/200

1562/1562 [==============================]",1.188929001
"7353

epoch 156/200

1562/1562 [==============================]",1.188929001
"7360

epoch 157/200

1562/1562 [==============================]",1.188929001
"6967

epoch 158/200

1562/1562 [==============================]",1.188929001
"7312

epoch 159/200

1562/1562 [==============================]",1.188929001
"6908

epoch 160/200

1562/1562 [==============================]",1.188929001
"7231

epoch 161/200

1562/1562 [==============================]",1.188929001
"6549

epoch 162/200

1562/1562 [==============================]",1.188929001
"7058

epoch 163/200

1562/1562 [==============================]",1.188929001
"7086

epoch 164/200

1562/1562 [==============================]",1.188929001
"7013

epoch 165/200

1562/1562 [==============================]",1.188929001
"7051

epoch 166/200

1562/1562 [==============================]",1.188929001
"6985

epoch 167/200

1562/1562 [==============================]",1.188929001
"7025

epoch 168/200

1562/1562 [==============================]",1.188929001
"6540

epoch 169/200

1562/1562 [==============================]",1.188929001
"7008

epoch 170/200

1562/1562 [==============================]",1.188929001
"6467

epoch 171/200

1562/1562 [==============================]",1.188929001
"7303

epoch 172/200

1562/1562 [==============================]",1.188929001
"6574

epoch 173/200

1562/1562 [==============================]",1.188929001
"6733

epoch 174/200

1562/1562 [==============================]",1.188929001
"7261

epoch 175/200

1562/1562 [==============================]",1.188929001
"7302

epoch 176/200

1562/1562 [==============================]",1.188929001
"6773

epoch 177/200

1562/1562 [==============================]",1.188929001
"7130

epoch 178/200

1562/1562 [==============================]",1.188929001
"7155

epoch 179/200

1562/1562 [==============================]",1.188929001
"6206

epoch 180/200

1562/1562 [==============================]",1.188929001
"6814

epoch 181/200

1562/1562 [==============================]",1.188929001
"6986

epoch 182/200

1562/1562 [==============================]",1.188929001
"6158

epoch 183/200

1562/1562 [==============================]",1.188929001
"6611

epoch 184/200

1562/1562 [==============================]",1.188929001
"6832

epoch 185/200

1562/1562 [==============================]",1.188929001
"6946

epoch 186/200

1562/1562 [==============================]",1.188929001
"6448

epoch 187/200

1562/1562 [==============================]",1.188929001
"6089

epoch 188/200

1562/1562 [==============================]",1.188929001
"5785

epoch 189/200

1562/1562 [==============================]",1.188929001
"5921

epoch 190/200

1562/1562 [==============================]",1.188929001
"6715

epoch 191/200

1562/1562 [==============================]",1.188929001
"6439

epoch 192/200

1562/1562 [==============================]",1.188929001
"6397

epoch 193/200

1562/1562 [==============================]",1.188929001
"6517

epoch 194/200

1562/1562 [==============================]",1.188929001
"6024

epoch 195/200

1562/1562 [==============================]",1.188929001
"5567

epoch 196/200

1562/1562 [==============================]",1.188929001
"5852

epoch 197/200

1562/1562 [==============================]",1.188929001
"6351

epoch 198/200

1562/1562 [==============================]",1.188929001
"6247

epoch 199/200

1562/1562 [==============================]",1.188929001
"5599

epoch 200/200

1562/1562 [==============================]",1.188929001
"0633

epoch 2/10

50000/50000 [==============================]",1.188929001
"0568

epoch 3/10

50000/50000 [==============================]",1.188929001
"0558

epoch 4/10

50000/50000 [==============================]",1.188929001
"0545

epoch 5/10

50000/50000 [==============================]",1.188929001
"0518

epoch 6/10

50000/50000 [==============================]",1.188929001
"0461

epoch 7/10

50000/50000 [==============================]",1.188929001
"0412

epoch 8/10

50000/50000 [==============================]",1.188929001
"0397

epoch 9/10

50000/50000 [==============================]",1.188929001
"0371

epoch 10/10

50000/50000 [==============================]",1.188929001
"1000

epoch 2/10

50000/50000 [==============================]",1.188929001
"1000

epoch 3/10

50000/50000 [==============================]",1.188929001
"1000

epoch 4/10

50000/50000 [==============================]",1.188929001
"1000

epoch 5/10

50000/50000 [==============================]",1.188929001
"1000

epoch 6/10

50000/50000 [==============================]",1.188929001
"1000

epoch 7/10

50000/50000 [==============================]",1.188929001
"1000

epoch 8/10

50000/50000 [==============================]",1.188929001
"1000

epoch 9/10

50000/50000 [==============================]",1.188929001
"1000

epoch 10/10

50000/50000 [==============================]",1.188929001
"`

epoch 1/5



 1/20 [>",1.188929001
"3026120662689209]

epoch 1/4",1.188929001
"3026

epoch 2/4",1.188929001
"2567

epoch 3/4",1.188929001
"2142

epoch 4/4",1.188929001
"3026120662689209]

epoch 1/1",1.188929001
epoch 2,1.188929001
epoch 3,1.188929001
"9590





epoch 2/10

1/8856 [",1.188929001
"6876



epoch 3/10

1/8856 [",1.188929001
"epoch 1/2

1",1.188929001
"2118                 epoch += 1

   2119",1.188929001
"3098

epoch 2/100

1604/1604 [==============================]",1.188929001
"3098

epoch 3/100

1604/1604 [==============================]",1.188929001
"3098

epoch 4/100

1604/1604 [==============================]",1.188929001
"**

```

epoch",1.188929001
9 epoch,1.188929001
epoch 15,1.188929001
"0**

```

epoch",1.188929001
"epoch

2",1.188929001
#NAME?,1.188929001
"2229

epoch",1.188929001
"1623

epoch",1.188929001
"1814

epoch",1.188929001
"1333

epoch",1.188929001
"epoch 1/10

518/519 [============================>",1.188929001
"8810

epoch 2/5

  16/6000 [",1.188929001
"8931

epoch 3/5

  16/6000 [",1.188929001
"9244

epoch 4/5

  16/6000 [",1.188929001
"9214

epoch 5/5

  16/6000 [",1.188929001
epoch=8,1.188929001
8 epoch,1.188929001
"```

epoch 1/15",1.188929001
"0156

epoch 1/15",1.188929001
"0312

epoch 1/15",1.188929001
"0859

epoch 1/15",1.188929001
"0234

epoch 1/15",1.188929001
epoch 9/15,1.188929001
"9688

epoch 9/15",1.188929001
"9141

epoch 9/15",1.188929001
"9531

epoch 9/15",1.188929001
"epoch 1/20

2017-09-12 12",1.188929001
"`epoch 1/20000

62/62 [============================>",1.188929001
"6641

epoch 2/20000`",1.188929001
"```

epoch 150/150

1944/1967 [============================>",1.188929001
"9900

epoch 2/3

7090/7090 [==============================]",1.188929001
"9900

epoch 3/3

7090/7090 [==============================]",1.188929001
"9767

epoch 2/12

  128/60000 [",1.188929001
"1507    

epoch 2/2

1000/1000 [==============================]",1.188929001
"1503    

epoch 2/2

1000/1000 [==============================]",1.188929001
"epoch 9/10

15998/15998 [==============================]",1.188929001
"7112

epoch 10/10

15998/15998 [==============================]",1.188929001
"epoch 15/100

11/11 [==============================]",1.188929001
"0759

epoch 2/15

582/582 [==============================]",1.188929001
"0655

epoch 3/15

582/582 [==============================]",1.188929001
"0655

epoch 4/15

582/582 [==============================]",1.188929001
"0655

epoch 5/15

582/582 [==============================]",1.188929001
"0655

epoch 6/15

582/582 [==============================]",1.188929001
"0759

epoch 7/15

582/582 [==============================]",1.188929001
"0862

epoch 8/15

582/582 [==============================]",1.188929001
"0862

epoch 9/15

582/582 [==============================]",1.188929001
"0897

epoch 10/15

582/582 [==============================]",1.188929001
"0966

epoch 11/15

582/582 [==============================]",1.188929001
"1000

epoch 12/15

582/582 [==============================]",1.188929001
"1207

epoch 13/15

582/582 [==============================]",1.188929001
"1207

epoch 14/15

582/582 [==============================]",1.188929001
"1000

epoch 15/15

582/582 [==============================]",1.188929001
"640000

epoch 1/1

160/160 [==============================]",1.188929001
"640000

epoch 1/1

640000/640000 [==============================]",1.188929001
1+epoch,1.188929001
# epoch,1.188929001
"```

epoch 2/100

   64/50000 [",1.188929001
"9743

epoch 2/8

60000/60000 [==============================]",1.188929001
"9806

epoch 3/8

60000/60000 [==============================]",1.188929001
"9833

epoch 4/8

60000/60000 [==============================]",1.188929001
"9852

epoch 5/8

60000/60000 [==============================]",1.188929001
"9861

epoch 6/8

60000/60000 [==============================]",1.188929001
"9870

epoch 7/8

60000/60000 [==============================]",1.188929001
"9867

epoch 8/8

60000/60000 [==============================]",1.188929001
"0422
epoch 2/50
2804/2804 [==============================]",1.188929001
"0318
epoch 3/50
2804/2804 [==============================]",1.188929001
"0274
epoch 4/50
2804/2804 [==============================]",1.188929001
"0249
epoch 5/50
2804/2804 [==============================]",1.188929001
"0232
epoch 6/50
2804/2804 [==============================]",1.188929001
"0219
epoch 7/50
2804/2804 [==============================]",1.188929001
"0211
epoch 8/50
2804/2804 [==============================]",1.188929001
"0205
epoch 9/50
2804/2804 [==============================]",1.188929001
"0199
epoch 10/50
2804/2804 [==============================]",1.188929001
"0192
epoch 11/50
2804/2804 [==============================]",1.188929001
"0186
epoch 12/50

```",1.188929001
apply_specific,1.188679245
"] ==

227                           apply_specific",1.188679245
"] ==

229                           apply_specific",1.188679245
249                                                      apply_specific,1.188679245
250                                                      apply_specific,1.188679245
252                                                      apply_specific,1.188679245
283                                                     apply_specific,1.188679245
284                                                     apply_specific,1.188679245
286                                                     apply_specific,1.188679245
301         apply_specific,1.188679245
302         apply_specific,1.188679245
"304         {

305             apply_specific",1.188679245
307             apply_specific,1.188679245
411                                                   apply_specific,1.188679245
412                                                   apply_specific,1.188679245
414                                                   apply_specific,1.188679245
423                                                     apply_specific,1.188679245
424                                                     apply_specific,1.188679245
426                                                     apply_specific,1.188679245
443       apply_specific,1.188679245
444       apply_specific,1.188679245
449       apply_specific,1.188679245
559 apply_specific,1.188679245
560 apply_specific,1.188679245
561 apply_specific,1.188679245
&apply_specific,1.188679245
"579 {

580   apply_specific",1.188679245
581   apply_specific,1.188679245
582   apply_specific,1.188679245
"583 }

584 

585 apply_specific",1.188679245
589 apply_specific,1.188679245
590 apply_specific,1.188679245
591 apply_specific,1.188679245
filepath=,1.188405797
filepath,1.188405797
filepath =,1.188405797
filepath +,1.188405797
softmax,1.188073394
#NAME?,1.188073394
`softmax `,1.188073394
parser,1.1875
future,1.1875
idea,1.186666667
*args,1.186335404
202                                       args,1.186335404
args,1.186335404
args[0],1.186335404
expect,1.185185185
"expect

------------",1.185185185
int64,1.183098592
"int64

```",1.183098592
find,1.182692308
port,1.181818182
num_words,1.181818182
`load_weights`,1.181818182
occur,1.181818182
inputlayer,1.181818182
load_weights,1.181818182
imagine,1.181818182
num_words=10000,1.181818182
num_words = 10000,1.181818182
hand,1.181818182
num_words=100,1.181818182
num_words =,1.181818182
>= num_words,1.181818182
mean_absolute_error,1.181818182
num_words=2,1.181818182
num_words = 3,1.181818182
#NAME?,1.181818182
`num_words + 1`,1.181818182
num_words + 1,1.181818182
num_words = 1000,1.181818182
load_weights=,1.181818182
"```
imagine",1.181818182
copier,1.179190751
#NAME?,1.179190751
read_csv,1.176470588
word_index,1.173913043
pygpu,1.173913043
nb_filter3,1.173913043
"word_index

      >>> {",1.173913043
deepcopy,1.172151899
[deepcopy,1.172151899
] = deepcopy,1.172151899
= [deepcopy,1.172151899
"deepcopy

>",1.172151899
verbose=1,1.167259786
verbose=0,1.167259786
verbose=2,1.167259786
verbose= 0,1.167259786
verbose,1.167259786
verbose > 0,1.167259786
verbose = 2,1.167259786
verbose = 1,1.167259786
verbose =1,1.167259786
verbose=,1.167259786
---> 16     verbose=2,1.167259786
attrs,1.166666667
pad_sequences,1.166666667
categorical_accuracy,1.166666667
attrs[,1.166666667
discussed,1.166666667
fail,1.166666667
get_layer,1.166666667
prediction1 =,1.166666667
prediction1,1.166666667
meant,1.166666667
pyplot,1.166666667
exp,1.166666667
text_to_word_sequence,1.166666667
sep=,1.166666667
profiler,1.166666667
license,1.166666667
posted,1.166666667
easier,1.166666667
contribute,1.166666667
testx,1.166666667
trainpredict,1.166666667
trainpredict[,1.166666667
2] = trainpredict[,1.166666667
exe,1.166666667
purpose,1.166666667
introduced,1.166666667
8xlarge,1.166666667
count_params,1.166666667
* maxlen_of_sentences,1.166666667
maxlen_of_sentences],1.166666667
bias_constraint=,1.166666667
_keras_shape],1.166666667
dropout_u,1.166666667
nhwc,1.166666667
coordinates,1.166666667
bias_constraint,1.166666667
ap,1.166666667
assigned,1.166666667
gpuarray,1.166666667
_keras_shape,1.166666667
mu,1.166666667
reproduced,1.166666667
> attrs,1.166666667
x_a],1.166666667
`x_a`,1.166666667
dropout_u=0,1.166666667
initial_value,1.166666667
}}[]<gpuarray>,1.166666667
input_dims=,1.166666667
input_dims,1.166666667
input_dims//2,1.166666667
input_dims//4,1.166666667
#NAME?,1.166666667
norm1,1.166666667
seq_length,1.166666667
host,1.166666667
y_batch,1.166666667
~/profiler,1.166666667
target_shape=,1.166666667
#NAME?,1.166666667
target_shape,1.166666667
te_y,1.166666667
numbatches,1.166666667
state_initializer=,1.166666667
state_initializer,1.166666667
recent_fit = [],1.166666667
recent_fit,1.166666667
recent_fit[1,1.166666667
recent_fit],1.166666667
y_batch},1.166666667
_keras_shape`,1.166666667
pred_node_names[,1.166666667
=pred_node_names[,1.166666667
pred_node_names,1.166666667
hdf5data,1.166666667
hdf5data[,1.166666667
_keras_shape =,1.166666667
--> 289               initial_value,1.166666667
565   fail,1.166666667
570   fail,1.166666667
575   fail,1.166666667
moving_average_update,1.166666667
moving_average_update`,1.166666667
//host,1.166666667
"categorical_accuracy

     47",1.166666667
dropout_u =,1.166666667
test_id,1.166666667
valid,1.162162162
valid/,1.162162162
x_valid,1.16
#NAME?,1.16
signature,1.16
"signature    

    }",1.16
x_valid[,1.16
signature},1.16
` signature,1.16
y_valid,1.157894737
attribute,1.157894737
beta_1=0,1.157894737
beta_1,1.157894737
` attribute,1.157894737
"8]= 0

y_valid[8",1.157894737
"16]= 1

y_valid[16",1.157894737
"24]= 2

y_valid[24",1.157894737
"32]= 3

y_valid[32",1.157894737
dot,1.15625
58     dot,1.15625
embedding_size,1.153846154
monitor=,1.153846154
----> 7                                      monitor=,1.153846154
raised,1.153846154
imread,1.153846154
fit_on_texts,1.153846154
monitor =,1.153846154
min_lr=0,1.153846154
3*embedding_size,1.153846154
min_lr,1.153846154
monitor,1.153846154
identity_block,1.153846154
#NAME?,1.153846154
uint8,1.153846154
num_classes,1.152777778
num_classes=10,1.152777778
num_classes = 2,1.152777778
num_classes=2,1.152777778
num_classes=26,1.152777778
num_classes=5,1.152777778
num_classes = 7,1.152777778
num_classes=,1.152777778
vocab_size,1.151515152
vocab_size 40000+,1.151515152
vocab_size + 1,1.151515152
vocab_size],1.151515152
vocab_size+1,1.151515152
achieve,1.15
item,1.15
nb_filters,1.15
nb_filters*2,1.15
1 item,1.15
h5,1.148387097
"h5

 9984/10000 [============================>",1.148387097
"h5
2",1.148387097
"h5
3",1.148387097
h5`,1.148387097
categorical_crossentropy,1.147368421
`categorical_crossentropy`,1.147368421
`categorical_crossentropy `,1.147368421
categorical_crossentropy],1.147368421
categorical_crossentropy = 3,1.147368421
categorical_crossentropy = 0,1.147368421
shuffled,1.142857143
follow,1.142857143
output_generator,1.142857143
attempt,1.142857143
extend,1.142857143
lstm_out,1.142857143
interested,1.142857143
log_dir=,1.142857143
globalmaxpooling1d,1.142857143
encoder_sampled,1.142857143
* encoder_sampled,1.142857143
lead,1.142857143
learned,1.142857143
figured,1.142857143
fixed_cnn_model,1.142857143
per_process_gpu_memory_fraction = 0,1.142857143
subsample,1.142857143
+ subsample +,1.142857143
goal,1.142857143
`action_prob`,1.142857143
action_prob =,1.142857143
action_prob,1.142857143
#NAME?,1.142857143
movieid,1.142857143
movieid],1.142857143
xtrue,1.142857143
xtrue[,1.142857143
starty,1.142857143
#NAME?,1.142857143
subsample=,1.142857143
`stride`,1.142857143
col = 3,1.142857143
col,1.142857143
follow-,1.142857143
stride,1.142857143
stride[0],1.142857143
stride[1],1.142857143
[attempt,1.142857143
per_process_gpu_memory_fraction=0,1.142857143
convolution2d,1.14084507
# convolution2d,1.14084507
#NAME?,1.14084507
deprecated,1.137931034
floatx=,1.137931034
floatx,1.137931034
floatx={1},1.137931034
floatx =,1.137931034
to_json,1.136363636
didn,1.136363636
row,1.136363636
row[0],1.136363636
row[1],1.136363636
#    1 row,1.136363636
`to_json`,1.136363636
7 minor,1.133333333
kind,1.133333333
maxpool2d,1.133333333
fraction,1.133333333
file_name,1.133333333
6 minor,1.133333333
#NAME?,1.133333333
#NAME?,1.133333333
5 minor,1.133333333
3 minor,1.133333333
minor,1.133333333
0001     train_loss= 0,1.133333333
train_loss= 0,1.133333333
0002     train_loss= 0,1.133333333
0003     train_loss= 0,1.133333333
0001     train_loss= 2,1.133333333
train_loss= 2,1.133333333
0002     train_loss= 1,1.133333333
train_loss= 1,1.133333333
0003     train_loss= 1,1.133333333
train_loss = 0,1.133333333
fed,1.130434783
conv3d,1.130434783
link,1.130208333
[link],1.130208333
[link,1.130208333
kernel_size=3,1.129032258
`kernel_size`,1.129032258
kernel_size,1.129032258
kernel_size=,1.129032258
kernel_size=1,1.129032258
kernel_size = 5,1.129032258
kernel_size=5,1.129032258
kernel_size = 3,1.129032258
kernel_size[0] *,1.129032258
kernel_size[1],1.129032258
kernel_size =,1.129032258
kernel_size=4,1.129032258
kernel_size=40,1.129032258
kernel_size=400,1.129032258
kernel_size=2,1.129032258
kernel_size = 1,1.129032258
`kernel_size,1.129032258
kernel_size +,1.129032258
kernel_size[0],1.129032258
understand,1.127906977
update,1.126984127
-----------update-------------------,1.126984127
update**,1.126984127
[update,1.126984127
**update,1.126984127
width_shift_range,1.125
height_shift_range,1.125
moment,1.125
explain,1.125
include_optimizer,1.125
`image_data_format`,1.125
max_value=1,1.125
max_value,1.125
width_shift_range=0,1.125
height_shift_range=0,1.125
input_size,1.125
img_to_array,1.125
image_data_format,1.125
#NAME?,1.125
reshaping,1.125
bbox,1.125
cnnmodel,1.125
includes_bool,1.125
model_path,1.125
sort,1.125
height_shift_range = 0,1.125
width_shift_range = 0,1.125
embed_dim,1.125
max_value=,1.125
minval=-1,1.125
maxval=1,1.125
minval=0,1.125
maxval=100,1.125
embed_dim=30,1.125
% model_path,1.125
[img_to_array,1.125
top_dim,1.125
bot_dim,1.125
bot_dim =,1.125
numsamples,1.125
minval,1.125
maxval,1.125
#NAME?,1.125
activation=,1.122393472
activation,1.122393472
activation =,1.122393472
#NAME?,1.122393472
#                  activation=,1.122393472
range,1.121212121
"range

```",1.121212121
1] range,1.121212121
range [-1,1.121212121
range**,1.121212121
range [,1.121212121
#NAME?,1.12
load_data,1.12
latent_dim,1.117647059
batch_shape=,1.117647059
batch_shape=[64,1.117647059
batch_shape =,1.117647059
sum,1.115789474
>     sum =,1.115789474
"sum

        *",1.115789474
class_mode=,1.115384615
recurrent_dropout=0,1.115384615
identifier,1.115384615
class_mode =,1.115384615
recurrent_dropout,1.115384615
#class_mode =,1.115384615
`recurrent_dropout`,1.115384615
recurrent_dropout > 0,1.115384615
"`
        class_mode=",1.115384615
img_width,1.114754098
"01

    img_width",1.114754098
https,1.114490161
# https,1.114490161
[https,1.114490161
"** 

https",1.114490161
`https,1.114490161
"```



https",1.114490161
"```

# https",1.114490161
```https,1.114490161
#https,1.114490161
"17 

     18 # https",1.114490161
"`
https",1.114490161
boxes,1.114285714
tips,1.111111111
batch_y =,1.111111111
batch_y,1.111111111
n_hidden,1.111111111
momentum= 0,1.111111111
move,1.111111111
fetches,1.111111111
batch_y[,1.111111111
batch_y`,1.111111111
throw,1.111111111
vae_loss =,1.111111111
vae_loss,1.111111111
momentum=0,1.111111111
momentum = 0,1.111111111
img_size,1.111111111
i0,1.111111111
predict_proba,1.111111111
i0 *,1.111111111
inp2,1.111111111
inp2=,1.111111111
`momentum`,1.111111111
** `momentum`,1.111111111
momentum,1.111111111
"```

`momentum`",1.111111111
momentum 0,1.111111111
predict_proba**,1.111111111
py,1.109225413
py`,1.109225413
py],1.109225413
0-py-3,1.109225413
"py

+++",1.109225413
"py

@@ -3319",1.109225413
```py,1.109225413
> py,1.109225413
"```

py",1.109225413
"py

```",1.109225413
"py



```

            #",1.109225413
"py



```",1.109225413
py                                                                                                           [16,1.109225413
"py

@@ -106",1.109225413
"py**



```",1.109225413
py#161,1.109225413
"py



>",1.109225413
strides=,1.107843137
`strides`,1.107843137
strides,1.107843137
strides=1,1.107843137
strides=2,1.107843137
strides = 1,1.107843137
strides = 3,1.107843137
strides =,1.107843137
strides = 2,1.107843137
strides=[1,1.107843137
+ strides +,1.107843137
strides=5,1.107843137
strides=3,1.107843137
strides=4,1.107843137
strides = 5,1.107843137
37         strides[,1.107843137
39         strides[,1.107843137
45                                                    strides,1.107843137
zoom_range,1.107142857
zoom_range=0,1.107142857
#zoom_range=0,1.107142857
zoom_range = 0,1.107142857
zoom_range[0],1.107142857
zoom_range[1],1.107142857
suggestions,1.105263158
model_config,1.105263158
"2694 

-> 2695         model_config =",1.105263158
"2663         model_config = {

   2664",1.105263158
## suggestions,1.105263158
noticed,1.103448276
transpose,1.103448276
obj,1.103448276
-> obj,1.103448276
% obj,1.103448276
# noticed,1.103448276
texts_to_sequences,1.1
thought,1.1
clipnorm=1,1.1
`clipnorm`,1.1
idc,1.1
1 = idc,1.1
[capture],1.1
look_back=1,1.1
look_back,1.1
#NAME?,1.1
encoder_input,1.1
choose,1.1
capture,1.1
inp1,1.1
conv_block,1.1
#NAME?,1.1
act3,1.1
clipnorm=5,1.1
# clipnorm,1.1
inp1=,1.1
clipnorm=100,1.1
solve,1.097560976
solve [,1.097560976
don,1.097014925
330         # don,1.097014925
# don,1.097014925
"```

don",1.097014925
/job,1.096774194
__main__,1.096774194
--> 588         job =,1.096774194
job,1.096774194
"0



__main__",1.096774194
"1



__main__",1.096774194
wrote,1.095238095
pool_size=,1.093023256
pool_size=2,1.093023256
pool_size,1.093023256
pool_size= 5,1.093023256
pool_size = 3,1.093023256
pool_size =,1.093023256
pool_size=3,1.093023256
pool_size=20,1.093023256
pool_size ** 2,1.093023256
img_rows,1.092307692
"2

img_rows",1.092307692
img_rows=224,1.092307692
img_rows *,1.092307692
padding=,1.091743119
padding,1.091743119
"padding

#",1.091743119
padding=0,1.091743119
` padding,1.091743119
padding =,1.091743119
#padding,1.091743119
#                  padding=,1.091743119
padding ==,1.091743119
#NAME?,1.091743119
greater,1.090909091
run_metadata,1.090909091
-> 1316                            run_metadata,1.090909091
hope,1.090909091
haven,1.090909091
rand,1.090909091
predict_classes,1.090909091
add_loss,1.090909091
arg,1.090909091
addition,1.090909091
][arg +,1.090909091
gpu_options,1.090909091
1/3 addition,1.090909091
# greater,1.090909091
arg 5,1.090909091
arg 4,1.090909091
predict_classes**,1.090909091
suppose,1.083333333
ceil,1.083333333
train_x,1.083333333
thoughts,1.083333333
img_path,1.083333333
[train_x],1.083333333
img_path =,1.083333333
data2,1.083333333
data2},1.083333333
data2],1.083333333
"0 



data2",1.083333333
"991576 



data2",1.083333333
add,1.082199882
#NAME?,1.082199882
`add`,1.082199882
# add,1.082199882
add],1.082199882
"add

>",1.082199882
# <--- add,1.082199882
add-,1.082199882
add `,1.082199882
#NAME?,1.08
upsampling2d,1.08
fact,1.08
train_on_batch,1.08
#NAME?,1.08
`train_on_batch,1.08
`upsampling2d,1.08
train_on_batch`,1.08
`train_on_batch`,1.08
sqrt,1.078947368
sqrt`,1.078947368
checked,1.077419355
constants,1.076923077
`constants`,1.076923077
clip,1.076923077
csvfile,1.076923077
constants=0,1.076923077
secde,1.076923077
square,1.075471698
0] square,1.075471698
short,1.074712644
round,1.074074074
round 3 --,1.074074074
nan,1.072202166
nan],1.072202166
nan]],1.072202166
[[        nan,1.072202166
[        nan,1.072202166
[ nan,1.072202166
[[ nan,1.072202166
"nan

```",1.072202166
argmax,1.071428571
6/threading,1.071428571
sequence_length,1.071428571
nb_classes,1.071428571
sequence_length=,1.071428571
dt,1.071428571
setidentifier,1.071428571
# setidentifier,1.071428571
7/threading,1.071428571
rest,1.066666667
# rest,1.066666667
rest 30,1.066666667
jpg,1.065789474
"jpg

1/1 [==============================]",1.065789474
filename,1.064516129
zeros,1.063829787
#NAME?,1.063829787
zeros =,1.063829787
zeros[,1.063829787
//arxiv,1.0625
n_features,1.0625
n_features=20,1.0625
n_features = 300],1.0625
n_features = 4],1.0625
ideas,1.060606061
elu,1.060606061
=conv_name_base +,1.060606061
helpful,1.058823529
copy,1.052930057
5/copy,1.052930057
7/copy,1.052930057
`copy,1.052930057
copy=,1.052930057
6/copy,1.052930057
get_weights,1.052631579
<listcomp>,1.052631579
npy,1.052631579
"<listcomp>

>",1.052631579
kerns,1.052631579
memo,1.048449612
batch_input_shape=,1.047619048
batch_input_shape,1.047619048
histogram_freq,1.047619048
histogram_freq=1,1.047619048
histogram_freq=0,1.047619048
histogram_freq > 0`,1.047619048
histogram_freq=25,1.047619048
histogram_freq = 1,1.047619048
] provide,1.046391753
[ ] provide,1.046391753
provide,1.046391753
[ +] provide,1.046391753
]  provide,1.046391753
[*] provide,1.046391753
# provide,1.046391753
[] provide,1.046391753
continuum,1.045454545
isinstance,1.043478261
hasattr,1.043478261
close,1.043478261
enumerate,1.041666667
rescale=1,1.041666667
rescale,1.041666667
rescale = 1,1.041666667
`rescale`,1.041666667
rescale=0,1.041666667
`rescale=1,1.041666667
line 1,1.041031653
line 880,1.041031653
line 102,1.041031653
line 80,1.041031653
line 87,1.041031653
line 1840,1.041031653
line 1559,1.041031653
line 1234,1.041031653
line 140,1.041031653
line 135,1.041031653
line 2661,1.041031653
line 2630,1.041031653
line 2582,1.041031653
line 1480,1.041031653
line 1441,1.041031653
line 519,1.041031653
line 498,1.041031653
line 91,1.041031653
line 2194,1.041031653
line 578,1.041031653
line 638,1.041031653
line 635,1.041031653
line 551,1.041031653
line 295,1.041031653
line 56,1.041031653
line 2662,1.041031653
line 492,1.041031653
line,1.041031653
line 555,1.041031653
line 608,1.041031653
line 119,1.041031653
line 392,1.041031653
line 800,1.041031653
line 124,1.041031653
line 993,1.041031653
line 127,1.041031653
line 28,1.041031653
line 64,1.041031653
line 2145,1.041031653
line 561,1.041031653
line 3,1.041031653
line 21,1.041031653
line 1008,1.041031653
line 497,1.041031653
line 367,1.041031653
line 86,1.041031653
line 1473,1.041031653
line 460,1.041031653
line 406,1.041031653
line 2136,1.041031653
line 73,1.041031653
line 414,1.041031653
line 2556,1.041031653
line 108,1.041031653
line 2397,1.041031653
line 163,1.041031653
line 257,1.041031653
line 230,1.041031653
line 237,1.041031653
line 190,1.041031653
line 334,1.041031653
line 182,1.041031653
line 16,1.041031653
line 950,1.041031653
line 676,1.041031653
line 574,1.041031653
line 588,1.041031653
line 594,1.041031653
line 74,1.041031653
line 1322,1.041031653
line 1307,1.041031653
line 1409,1.041031653
line 94,1.041031653
line 1705,1.041031653
line 1236,1.041031653
line 2482,1.041031653
line 900,1.041031653
line 1135,1.041031653
line 1316,1.041031653
line 1335,1.041031653
line 1682,1.041031653
line 992,1.041031653
line 244,1.041031653
line 78,1.041031653
line 2519,1.041031653
line 494,1.041031653
line 636,1.041031653
line 385,1.041031653
line 842,1.041031653
line 674,1.041031653
line 787,1.041031653
line 3392,1.041031653
line 1718,1.041031653
line 830,1.041031653
line 429,1.041031653
line 66,1.041031653
line 979,1.041031653
line 297,1.041031653
line 68,1.041031653
line 1630,1.041031653
line 1487,1.041031653
line 1486,1.041031653
line 540,1.041031653
line 627,1.041031653
line 691,1.041031653
line 60,1.041031653
line 439,1.041031653
line 518,1.041031653
line 650,1.041031653
line 363,1.041031653
line 843,1.041031653
line 856,1.041031653
line 831,1.041031653
line 330,1.041031653
line 286,1.041031653
line 263,1.041031653
line 156,1.041031653
line 314,1.041031653
line 699,1.041031653
line 133,1.041031653
line 7,1.041031653
line 4,1.041031653
line 8,1.041031653
line 13,1.041031653
line 161,1.041031653
line 37,1.041031653
line 53,1.041031653
line 188,1.041031653
line 10,1.041031653
line 25,1.041031653
line 1216,1.041031653
line 269,1.041031653
line 95,1.041031653
line 799,1.041031653
line 273,1.041031653
line 177,1.041031653
line 134,1.041031653
line 116,1.041031653
line 619,1.041031653
line 213,1.041031653
line 579,1.041031653
line 2085,1.041031653
line 2235,1.041031653
line 168,1.041031653
line 3341,1.041031653
line 781,1.041031653
line 532,1.041031653
line 176,1.041031653
line 640,1.041031653
line 238,1.041031653
line 183,1.041031653
line 153,1.041031653
line 1269,1.041031653
line 2506,1.041031653
line 767,1.041031653
`[ line 254]`,1.041031653
line 11,1.041031653
line 262,1.041031653
line 552,1.041031653
line 451,1.041031653
line 27,1.041031653
line 592,1.041031653
line 864,1.041031653
line 413,1.041031653
line 2327,1.041031653
line 1071,1.041031653
line 2130,1.041031653
line 615,1.041031653
line 419,1.041031653
line 352,1.041031653
line 852,1.041031653
line 117,1.041031653
line 2251,1.041031653
line 113,1.041031653
line 331,1.041031653
line 358,1.041031653
line 644,1.041031653
line 401,1.041031653
line 827,1.041031653
line 1235,1.041031653
line 129,1.041031653
line 1276,1.041031653
line 2192,1.041031653
line 584,1.041031653
line 32,1.041031653
line 411,1.041031653
line 467,1.041031653
line 76,1.041031653
line 29,1.041031653
line 324,1.041031653
line 573,1.041031653
line 472,1.041031653
line 319,1.041031653
line 496,1.041031653
line 655,1.041031653
line 489,1.041031653
line 576,1.041031653
line 328,1.041031653
line 69,1.041031653
line 2,1.041031653
line 144,1.041031653
line 719,1.041031653
line 132,1.041031653
line 500,1.041031653
line 470,1.041031653
line 468,1.041031653
line 75,1.041031653
line 169,1.041031653
line 1637,1.041031653
line 123,1.041031653
line 209,1.041031653
line 18,1.041031653
line 288,1.041031653
line 261,1.041031653
line 167,1.041031653
line 99,1.041031653
line 243,1.041031653
line 317,1.041031653
line 55,1.041031653
line 2524,1.041031653
line 2481,1.041031653
line 663,1.041031653
line 6,1.041031653
line 617,1.041031653
line 181,1.041031653
line 1824,1.041031653
line 1799,1.041031653
line 2296,1.041031653
line 609,1.041031653
line 316,1.041031653
line 112,1.041031653
line 1601,1.041031653
line 1183,1.041031653
line 1223,1.041031653
line 917,1.041031653
line 325,1.041031653
line 903,1.041031653
line 693,1.041031653
line 301,1.041031653
line 973,1.041031653
line 820,1.041031653
line 639,1.041031653
line 704,1.041031653
line 370,1.041031653
line 302,1.041031653
line 38,1.041031653
line 146,1.041031653
line 590,1.041031653
line 154,1.041031653
line 268,1.041031653
line 54,1.041031653
line 1004,1.041031653
line 1779,1.041031653
line 1426,1.041031653
line 2478,1.041031653
line 895,1.041031653
line 1128,1.041031653
line 1344,1.041031653
line 1363,1.041031653
line 52,1.041031653
line 138,1.041031653
line 1211,1.041031653
line 2585,1.041031653
line 1864,1.041031653
line 3160,1.041031653
line 1625,1.041031653
line 232,1.041031653
line 448,1.041031653
line 488,1.041031653
line 575,1.041031653
line 929,1.041031653
line 791,1.041031653
line 357,1.041031653
line 77,1.041031653
line 250,1.041031653
line 431,1.041031653
line 679,1.041031653
line 405,1.041031653
line 643,1.041031653
line 47,1.041031653
line 450,1.041031653
line 479,1.041031653
line 145,1.041031653
line 422,1.041031653
line 420,1.041031653
line 1935,1.041031653
line 1459,1.041031653
line 1167,1.041031653
line 604,1.041031653
line 31,1.041031653
line 866,1.041031653
line 59,1.041031653
line 963,1.041031653
line 1483,1.041031653
line 438,1.041031653
#NAME?,1.041031653
line 323,1.041031653
line 2078,1.041031653
line 2268,1.041031653
line 369,1.041031653
line 884,1.041031653
line 916,1.041031653
line 61,1.041031653
line 1848,1.041031653
line 970,1.041031653
line 434,1.041031653
line 2512,1.041031653
line 375,1.041031653
line 499,1.041031653
line 817,1.041031653
line 19,1.041031653
line 20,1.041031653
line 2229,1.041031653
line 3332,1.041031653
line 754,1.041031653
line 838,1.041031653
line 502,1.041031653
line 227,1.041031653
line 2088,1.041031653
line 965,1.041031653
line 1646,1.041031653
line 162,1.041031653
line 733,1.041031653
line 33,1.041031653
line 432,1.041031653
line 220,1.041031653
line 625,1.041031653
line 458,1.041031653
line 1231,1.041031653
line 3478,1.041031653
line 486,1.041031653
line 2918,1.041031653
line 1323,1.041031653
line 1302,1.041031653
line 473,1.041031653
line 160,1.041031653
line 3294,1.041031653
line 762,1.041031653
line 808,1.041031653
line 521,1.041031653
line 654,1.041031653
line 1669,1.041031653
line 1226,1.041031653
line 418,1.041031653
line 2573,1.041031653
line 111,1.041031653
line 2414,1.041031653
line 329,1.041031653
line 93,1.041031653
line 1350,1.041031653
line 1329,1.041031653
line 67,1.041031653
line 1028,1.041031653
line 1803,1.041031653
line 1303,1.041031653
line 2475,1.041031653
line 40,1.041031653
line 1455,1.041031653
line 1364,1.041031653
line 504,1.041031653
line 1680,1.041031653
line 3141,1.041031653
line 118,1.041031653
line 569,1.041031653
line 35,1.041031653
line 391,1.041031653
line 321,1.041031653
line 200,1.041031653
line 278,1.041031653
line 1298,1.041031653
line 2289,1.041031653
line 2310,1.041031653
line 770,1.041031653
line 1027,1.041031653
line 1782,1.041031653
line 380,1.041031653
line 2213,1.041031653
line 155,1.041031653
line 218,1.041031653
line 223,1.041031653
line 306,1.041031653
[line],1.041031653
line 50,1.041031653
line 416,1.041031653
line 541,1.041031653
line 758,1.041031653
line 571,1.041031653
line 109,1.041031653
line 322,1.041031653
line 131,1.041031653
line 203,1.041031653
line],1.041031653
line 960,1.041031653
line 1581,1.041031653
line 1418,1.041031653
line 670,1.041031653
line 546,1.041031653
line 400,1.041031653
line 107,1.041031653
line 2329,1.041031653
line 660,1.041031653
line 175,1.041031653
line 860,1.041031653
line 459,1.041031653
line 100,1.041031653
line 3819,1.041031653
line 409,1.041031653
line 2961,1.041031653
line 2725,1.041031653
line 2667,1.041031653
line 399,1.041031653
line 737,1.041031653
line 229,1.041031653
line 342,1.041031653
line 174,1.041031653
line 72,1.041031653
line 658,1.041031653
line 477,1.041031653
line 888,1.041031653
line 277,1.041031653
line 440,1.041031653
line 283,1.041031653
line 235,1.041031653
line 196,1.041031653
line 533,1.041031653
line 2718,1.041031653
line 2822,1.041031653
line 2882,1.041031653
line 1439,1.041031653
line 1348,1.041031653
line 1599,1.041031653
line 3091,1.041031653
line 2956,1.041031653
line 1470,1.041031653
line 1657,1.041031653
line 1233,1.041031653
line 307,1.041031653
line 1598,1.041031653
line 1222,1.041031653
line 222,1.041031653
line 607,1.041031653
line 2252,1.041031653
line 531,1.041031653
line 1728,1.041031653
line 1398,1.041031653
line 394,1.041031653
line 2315,1.041031653
line 1523,1.041031653
line 1378,1.041031653
line 1252,1.041031653
line 159,1.041031653
line 275,1.041031653
line 2620,1.041031653
line 3206,1.041031653
line 889,1.041031653
line 1096,1.041031653
line 2851,1.041031653
line 151,1.041031653
line 128,1.041031653
line 934,1.041031653
line 931,1.041031653
line 877,1.041031653
line 2553,1.041031653
line 2390,1.041031653
line 240,1.041031653
line 2490,1.041031653
line 2476,1.041031653
line 224,1.041031653
line 85,1.041031653
line 2500,1.041031653
line 2457,1.041031653
line 603,1.041031653
line 651,1.041031653
line 280,1.041031653
line 49,1.041031653
line 1634,1.041031653
line 997,1.041031653
line 1219,1.041031653
line 1841,1.041031653
line 1715,1.041031653
line 1084,1.041031653
line 955,1.041031653
line 858,1.041031653
line 1217,1.041031653
line 1157,1.041031653
line 1620,1.041031653
line 1174,1.041031653
line 2368,1.041031653
line 464,1.041031653
line 397,1.041031653
line 208,1.041031653
line 2267,1.041031653
line 197,1.041031653
line 682,1.041031653
line 801,1.041031653
line 568,1.041031653
line 1036,1.041031653
line 23,1.041031653
line 346,1.041031653
line 58,1.041031653
line 24,1.041031653
line 343,1.041031653
line 872,1.041031653
line 1626,1.041031653
line 1531,1.041031653
line 558,1.041031653
line 1574,1.041031653
line 1419,1.041031653
line 233,1.041031653
line 2532,1.041031653
line 271,1.041031653
line 101,1.041031653
line 180,1.041031653
line 148,1.041031653
line 2616,1.041031653
"line

```",1.041031653
line 1064,1.041031653
line 3035,1.041031653
line 3114,1.041031653
line 15,1.041031653
line 3142,1.041031653
line 2247,1.041031653
line 1067,1.041031653
line 12,1.041031653
line 30,1.041031653
line 2622,1.041031653
line 3115,1.041031653
line 139,1.041031653
line 206,1.041031653
line 1503,1.041031653
line 1268,1.041031653
#line 1,1.041031653
line 389,1.041031653
line 441,1.041031653
line 2895],1.041031653
line 1100,1.041031653
line 505,1.041031653
line 371,1.041031653
line 103,1.041031653
line 1710,1.041031653
line 999,1.041031653
line 2297,1.041031653
line 2246,1.041031653
line 3936,1.041031653
line 3665,1.041031653
line 2708,1.041031653
line 2787,1.041031653
line 2011,1.041031653
line 510,1.041031653
line 727,1.041031653
line 3008,1.041031653
line 2184,1.041031653
line 512,1.041031653
line 270,1.041031653
line 768,1.041031653
line 2338,1.041031653
line 1719,1.041031653
line 610,1.041031653
line 2394,1.041031653
line 26,1.041031653
line 88,1.041031653
line 657,1.041031653
line 2385,1.041031653
line 773,1.041031653
line 2379,1.041031653
line 2352,1.041031653
line 2343,1.041031653
line 2337,1.041031653
line 2308,1.041031653
line 43,1.041031653
line 2555,1.041031653
line 2396,1.041031653
line 150,1.041031653
line 215,1.041031653
line 1603,1.041031653
line 1093,1.041031653
line 1031,1.041031653
line 1155,1.041031653
line 1332,1.041031653
line 374,1.041031653
line 913,1.041031653
line 1713,1.041031653
line 2273,1.041031653
line 1124,1.041031653
line 1321,1.041031653
line 1340,1.041031653
"line 



//",1.041031653
line 122,1.041031653
line 239,1.041031653
line 313,1.041031653
line 1214,1.041031653
line 442,1.041031653
line 602,1.041031653
line 42,1.041031653
line 83,1.041031653
line 2031,1.041031653
line 723,1.041031653
line 1202,1.041031653
line 130,1.041031653
line 582,1.041031653
line 1200,1.041031653
line 348,1.041031653
line 1333,1.041031653
line 2249,1.041031653
line 2137,1.041031653
line 425,1.041031653
line 403,1.041031653
line 245,1.041031653
line 600,1.041031653
line 480,1.041031653
line 266,1.041031653
line 44,1.041031653
line 847,1.041031653
line 844,1.041031653
line 198,1.041031653
line 2429,1.041031653
line 41,1.041031653
line 2881,1.041031653
line 457,1.041031653
line 90,1.041031653
line 327,1.041031653
line 543,1.041031653
line 763,1.041031653
line 1061,1.041031653
line 611,1.041031653
line 121,1.041031653
line 376,1.041031653
line 433,1.041031653
line 143,1.041031653
line 516,1.041031653
line 326,1.041031653
line 1795,1.041031653
line 1661,1.041031653
line 1047,1.041031653
line 935,1.041031653
line 839,1.041031653
line 1190,1.041031653
line 1131,1.041031653
line 1586,1.041031653
line 1159,1.041031653
line 1489,1.041031653
line 2325,1.041031653
` line,1.041031653
line 698,1.041031653
line 1186,1.041031653
line 867,1.041031653
line 1522,1.041031653
line 1382,1.041031653
` line 969`,1.041031653
line 1026,1.041031653
line 172,1.041031653
line 814,1.041031653
line 332,1.041031653
line 1709,1.041031653
line 1066,1.041031653
line 493,1.041031653
line 2632,1.041031653
line 1911,1.041031653
line 1861,1.041031653
line 595,1.041031653
line 659,1.041031653
line 70,1.041031653
line 210,1.041031653
line 1074,1.041031653
line 1058,1.041031653
line 1016,1.041031653
line 79,1.041031653
line 461,1.041031653
line[1],1.041031653
# line[1],1.041031653
line 1501,1.041031653
line 427,1.041031653
line 1430,1.041031653
line 1079,1.041031653
line 1197,1.041031653
line 898,1.041031653
line 685,1.041031653
line 863,1.041031653
line 1358,1.041031653
line 2270,1.041031653
line 9,1.041031653
line 2518,1.041031653
line 1034,1.041031653
line 290,1.041031653
line 63,1.041031653
line 1653,1.041031653
line 309,1.041031653
line 728,1.041031653
line 2572,1.041031653
line 2972,1.041031653
line 166,1.041031653
line 2462,1.041031653
line 697,1.041031653
line 1507,1.041031653
line 1176,1.041031653
line 789,1.041031653
line 1132,1.041031653
line 1152,1.041031653
line 870,1.041031653
line 1530,1.041031653
line 1954,1.041031653
line 585,1.041031653
line 164,1.041031653
line 3089,1.041031653
line 46,1.041031653
line 1199,1.041031653
line 141,1.041031653
line 1210,1.041031653
line 1014,1.041031653
line 36,1.041031653
line 81,1.041031653
"line

 1426",1.041031653
"line

 1305",1.041031653
"line

 118",1.041031653
line 65,1.041031653
line 2395,1.041031653
line 1726,1.041031653
line 911,1.041031653
line 436,1.041031653
line 2472,1.041031653
line 276,1.041031653
line 202,1.041031653
line 114,1.041031653
line 921,1.041031653
line 1998,1.041031653
line 2502,1.041031653
line 1039,1.041031653
line 1021,1.041031653
line 466,1.041031653
line 1573,1.041031653
line 1203,1.041031653
line 2103,1.041031653
line 778,1.041031653
line 982,1.041031653
line 1032,1.041031653
line 1052,1.041031653
line 1392,1.041031653
line 351,1.041031653
line 1997,1.041031653
line 2336,1.041031653
line 1228,1.041031653
line 2318,1.041031653
line 382,1.041031653
line 1532,1.041031653
line 474,1.041031653
line 887,1.041031653
line 228,1.041031653
line 390,1.041031653
line 501,1.041031653
line 2717,1.041031653
line 2827,1.041031653
line 845,1.041031653
line 1485,1.041031653
line 1101,1.041031653
line 171,1.041031653
line 1143,1.041031653
line 766,1.041031653
line 964,1.041031653
line 524,1.041031653
line 1193,1.041031653
line 1111,1.041031653
line 310,1.041031653
line 1587,1.041031653
line 2043,1.041031653
line 759,1.041031653
line 2240,1.041031653
line 142,1.041031653
line 193,1.041031653
line 1090,1.041031653
line 1069,1.041031653
line 189,1.041031653
line 157,1.041031653
line 92,1.041031653
line 632,1.041031653
line 336,1.041031653
line 672,1.041031653
line 1117,1.041031653
line 1030,1.041031653
line 105,1.041031653
line 212,1.041031653
line 179,1.041031653
line 664,1.041031653
line 849,1.041031653
line 192,1.041031653
line 34,1.041031653
line 517,1.041031653
line 97,1.041031653
line 597,1.041031653
line 1035,1.041031653
line 387,1.041031653
line 17,1.041031653
line 589,1.041031653
line 3192,1.041031653
line 2993,1.041031653
line 2291,1.041031653
line 104,1.041031653
] check,1.040201005
check,1.040201005
[ ] check,1.040201005
[+ ] check,1.040201005
225     # check,1.040201005
# check,1.040201005
] [] check,1.040201005
355       # check,1.040201005
[ +] check,1.040201005
[*] check,1.040201005
[/ ] check,1.040201005
369       # check,1.040201005
guess,1.04
guess **,1.04
expand_dims,1.039215686
border_mode=,1.039215686
border_mode,1.039215686
"`

  border_mode=",1.039215686
[stackoverflow],1.03654485
//stackoverflow,1.03654485
stackoverflow,1.03654485
// stackoverflow,1.03654485
**kwargs,1.036199095
--> 824                            **kwargs,1.036199095
kwargs,1.036199095
kwargs = {},1.036199095
kwargs[,1.036199095
reproduce,1.034653465
"1

reproduce",1.034653465
acc,1.032934132
`acc`,1.032934132
acc=0,1.032934132
acc=1,1.032934132
acc = 0,1.032934132
% acc,1.032934132
randint,1.032258065
wanted,1.03125
figure,1.03125
figure 1,1.03125
figure 3,1.03125
figure 2,1.03125
img_cols,1.026666667
img_cols=50,1.026666667
img_cols = 28,1.026666667
img_cols=280,1.026666667
img_cols = 128,1.026666667
img_cols = 256,1.026666667
img_cols = 299,1.026666667
img_cols=224,1.026666667
img_cols = 224,1.026666667
img_cols = 96,1.026666667
png,1.026315789
__name__,1.025
__name__==,1.025
__name__ ==,1.025
`val_loss`,1.0248307
val_loss,1.0248307
he_normal,1.024390244
http,1.023121387
"06

    http",1.023121387
[http,1.023121387
[1] http,1.023121387
advance,1.019607843
tanh,1.017241379
val_acc,1.012690355
val_acc 0,1.012690355
25 val_acc,1.012690355
{val_acc,1.012690355
relu,1.011744966
userwarning,1.010416667
"```

userwarning",1.010416667
#userwarning,1.010416667
> userwarning,1.010416667
append,1.006097561
# append,1.006097561
[join,1.005780347
join,1.005780347
githubusercontent,1
submit,1
herokuapp,1
filing,1
//www,1
hd_sh =,1
hd_sh[0],1
hd_sh[1],1
hd_sh,1
astype,1
1507688448 exceeds 10%,1
[accessing,1
maintaining [,1
relies,1
wink,1
img_height = 256,1
"256



train_data_dir =",1
ai_painter,1
images_download,1
validation_data_dir =,1
img_height,1
train_data_dir,1
validation_data_dir,1
semantics,1
wdir=,1
sitecustomize,1
namespace,1
programdata,1
node_def,1
control_inputs,1
tf_finishoperation,1
op_desc,1
461             output_mask =,1
previous_mask,1
in_train_phase,1
normed_training,1
203                                 normalize_inference,1
uses_learning_phase,1
then_expression,1
else_expression,1
3003                     then_expression_fn,1
-> 3004                     else_expression_fn,1
new_func,1
make_decorator,1
434                                        _add_deprecated_arg_notice_to_docstring,1
true_fn,1
false_fn,1
fn1,1
fn2,1
pivot_2,1
-> 2072     orig_res_f,1
buildcondbranch,1
orig_res_f,1
get_collection,1
graphkeys,1
_summary_collection,1
normalize_inference,1
163                     broadcast_gamma,1
batch_mean,1
"batch_var

    906",1
_fused_batch_norm,1
op_type_name,1
is_stateful,1
op_type,1
compute_shapes,1
compute_device,1
_default_original_op,1
attr,1
_graph,1
grouped_inputs,1
-> 1734                                 control_input_ops,1
isola,1
investigated,1
investigation,1
observe,1
nprediction 1,1
commenting,1
investigating,1
domain,1
"domain

>",1
rich,1
overtraining,1
indata,1
skewed,1
limiting,1
separation,1
model_inputs,1
learning_phase ==,1
== layer_name,1
layer_name,1
learning_phase,1
list_inputs,1
/visualization_tools,1
callable_opts,1
callable_options,1
_session,1
options_ptr,1
tf_getcode,1
input_1_1,1
fetched,1
__del__,1
0x7f35b1f20a10>>,1
encourage,1
categorial_crossentropy,1
luck,1
choosing,1
impossible,1
plans,1
ivan,1
max_decoder_output_length,1
occurrence,1
**decoder_target_output**,1
xe2,1
x80,1
xaf,1
**predicted_decoder_output**,1
xc3,1
xa9,1
"] 



keras_accuracy = 11/63",1
gpu_id,1
target_gpu_ids,1
% gpu_id,1
name_scope,1
replica_%,1
get_shape,1
as_list,1
num_gpus},1
all_outputs[,1
bias_scale = 2 =>,1
instanciating,1
count_mode=,1
stateful_metrics=,1
kill,1
waiting,1
1227s,1
57/keras_nn_0,1
wait,1
"wait

2018-06-02 11",1
_event,1
signaled =,1
"wait 

2018-06-02 11",1
waiter,1
acquire,1
y_set=,1
y_set,1
im_id,1
rlrop],1
trian,1
snip,1
number_neurons,1
xtrain_data_1_t60,1
enc_ytrain_data_1_t60,1
xvalidation_data_1_v40,1
enc_yvalidation_data_1_v40,1
3 lithofacies,1
recall_score,1
yvalidation_data_1_v40,1
micro,1
accuracy_score,1
configured,1
practices,1
adjusting,1
sagemaker,1
kappa,1
evaluated,1
pelu,1
decided,1
tensorflow_serving,1
possibility,1
max_pooling2d,1
the_input,1
lecun_normal,1
merge_mode=,1
the_labels,1
ctc_lambda_func,1
invalidargumenterrortraceback,1
"59 

     60 test_func =",1
pyc,1
warn,1
"+ object_name +

     90",1
stacklevel=2,1
session_kwargs,1
tf_getbuffer,1
final_fetches,1
final_targets,1
fetch_list,1
_prun_fn,1
_device=,1
wondering,1
instinct,1
usable,1
discovering,1
trial,1
discarding,1
advice,1
ave,1
developing,1
//vict0rsch,1
createdataframe,1
tolist,1
outputcol=,1
clarification,1
num_users,1
num_items,1
userlayers=[512,1
itemlayers=[1024,1
reg_layers=[0,1
userlayers,1
reg_layers,1
itemlayers,1
user_latent_vector =,1
item_latent_vector =,1
=user_matirx[,1
locate,1
ellipsis,1
pyhton_-,1
heads,1
minimize,1
expense,1
remedy,1
importance,1
valence,1
arousal,1
dominance,1
age,1
emotions,1
baselogger,1
m_i,1
w_i,1
stateful_metrics,1
totals[,1
totals,1
dived,1
encountering,1
//pastebin,1
/vxvfscwy,1
pytohn 3,1
//transcranial,1
disallowed,1
boarder_mode,1
number_filters,1
row_size,1
column_size,1
number_channels,1
img_row,1
img_col,1
thak,1
pbtxt,1
graphdef,1
argumentparser,1
add_argument,1
dest=,1
parse_args,1
set_image_dim_ordering,1
strip,1
global_variables_initializer,1
as_graph_def,1
multiplied,1
restrict,1
weights_array,1
hidden_layers,1
filter_width,1
filter_height,1
training_images,1
training_labels,1
validation_images,1
face_detector,1
checkpointing,1
out_labels,1
val_outs,1
1254                                 epoch_logs[,1
val_,1
epoch_logs,1
callback_model,1
stop_training,1
dumps,1
class_name,1
__class__,1
utf8,1
2419             model_outputs,1
output_layers,1
_nil,1
memoize,1
__setstate__,1
__reduce_ex__,1
__reduce__,1
textiowrapper,1
rid,1
set_value,1
/exit_2,1
xm-0,1
gui,1
c_1_in_fw_in,1
c_1_in_fw_out,1
"set_value

``

``",1
pillow,1
contributing,1
ability,1
output_a,1
output_b,1
output_c,1
output_d,1
output_e,1
mfile,1
"`

`test_func =",1
8vcpus,1
screenshot,1
uesful,1
analogy,1
set_parameters,1
receive,1
finishing,1
stuck,1
swing,1
6-py2,1
455             output_mask =,1
step_function,1
2927             parallel_iterations=32,1
dropbox,1
tif,1
path_to_tiff,1
355         width_height_tuple =,1
dither,1
use_load_libtiff,1
_load_libtiff,1
tiffimagefile,1
decoderconfig,1
203                 seek,1
setimage,1
extents,1
pulls_fd,1
setfd,1
fp,1
tile,1
transparency,1
affected,1
futurewarning,1
issubdtype,1
treated,1
**kwds,1
sysfs,1
0 memoryclockrate,1
ghz,1
"455

> pcibusid",1
"0

> totalmemory",1
"76gib

> 2018-05-22 09",1
0980this,1
index_array,1
image_data_generator,1
random_transform,1
60  iterations,1
eta,1
data_preparation2,1
mtrand,1
pyx,1
randomstate,1
main2,1
dataset_path,1
grateful,1
train_y,1
valid_x,1
valid_y,1
val_root_mean_squared_error,1
"0x53064490>

```",1
test_x,1
snap,1
category_name,1
city,1
dow,1
image_top_1,1
item_seq_number,1
param_1,1
param_2,1
param_3,1
parent_category_name,1
price,1
title_description,1
user_type,1
firstly,1
signup,1
login,1
iam,1
kerasis,1
activating,1
clipnorm_issue,1
base_dtype,1
kurtosis,1
skewness,1
pitch,1
yaw,1
loadtxt,1
featwithsignalstrain,1
delimiter=,1
featwithsignalstest,1
63s,1
60s,1
0570adds,1
conv3d_transpose`,1
posting,1
recieve,1
train_dense_scaled,1
train_embed,1
=[train_dense_scaled,1
train_embed],1
#NAME?,1
signiture,1
n_folds=10,1
executing,1
0i,1
subdivided,1
preferences,1
no_samples,1
emb_size,1
aclweb,1
clues,1
embedding_skill_id,1
embeddings_regularizer,1
l1l2,1
respect,1
bins=50,1
reproducing,1
from_tensor_slices,1
modekeys,1
adamoptimizer,1
reduce_sum,1
estimatorspec,1
get_or_create_global_step,1
evolving,1
realizing,1
account,1
filenames,1
capitalised,1
n02504013_2859,1
jpeg,1
ext=,1
bmp,1
ppm,1
+ ext +,1
fyi,1
"0

ubuntu16",1
weight_path,1
nturgbd_train_datagen,1
va_train,1
discovered,1
verified,1
** observe,1
culprit,1
albeit,1
subversions,1
we35016,1
digraph,1
dense_2_input,1
merge_1,1
1.92E-04,1
subclass,1
subbranch,1
wasting,1
hours,1
surprise,1
compares,1
ce,1
judge,1
is_sparse,1
outnumbered,1
youversions,1
"5

* libgpuarray",1
he_uniform,1
attained,1
//stanford,1
succeed,1
opt1,1
opt2,1
_keras_history,1
input_shapes,1
enable_eager_execution,1
beginning,1
3 onwards,1
/cmdline,1
configproto,1
intra_op_parallelism_threads=1,1
inter_op_parallelism_threads=1,1
beta_2=0,1
primary,1
scatter,1
regressor,1
spam,1
weights19,1
ffi,1
cooijmans,1
generalize,1
inserting,1
imo,1
inserted,1
[pc_attention_vector_before_activation],1
pc_attention_vector_before_activation,1
reloaded,1
pc_attention_vector_5/,1
/anujshah1003/,1
cvtcolor,1
color_bgr2gray,1
resize,1
num_channel==1,1
image_dim_ordering,1
rollaxis,1
padded_docs,1
maxpooling1,1
clarity,1
locked,1
door,1
views &,1
cbadaf00e28f7fe42762b55f52294e3a7bb90515,1
a637960fab61b66848a36e6a5caf0204c155af01,1
[pastebin],1
/ntgy7ivs,1
deadline,1
altering,1
ilsvrcs2012,1
published 78,1
shear_range=0,1
fill_mode=,1
nearest,1
save_to_dir=,1
augmenteddata,1
stderr,1
stdout,1
`contextlib,1
redirect_stdout,1
as_default,1
num_actions,1
interaction_generator,1
replay_memory,1
interaction_counter,1
interaction_lock,1
6s,1
intermediate_dim,1
random_normal,1
time_step,1
prod,1
timedistrib,1
ins_batch,1
aggregation_method,1
stop_gradients,1
*out_grads,1
broadcast_gradient_args,1
sx,1
sy,1
vae_mnist,1
_feed_sample_weight_modes,1
ref,1
cw,1
nonetype,1
partially,1
/predict_base,1
imshow,1
waitkey,1
maxpooling3d,1
aa,1
color_mode=,1
imitate,1
indexed,1
quiet,1
suspect,1
designing,1
#NAME?,1
pool_mode ==,1
max_pool3d,1
respond,1
alok,1
_updated_config,1
2415             model_outputs,1
__func__,1
__self__,1
reporting,1
determining,1
tonality,1
films,1
verification,1
film,1
iterable,1
types_to_flatten=,1
types_to_flatten,1
index_col=0,1
train_,1
tsv*,1
test_,1
texts_to_matrix,1
tfidf,1
"```

rev=[",1
rev,1
55x64284,1
max_lenght,1
verb,1
cinema,1
5g,1
0g,1
to_file=,1
seq_plot,1
hd5,1
keys,1
output_names,1
reloading,1
spatialdropout1d,1
subtracting 3,1
implication 4-,1
profile,1
runmeta,1
profileoptionbuilder,1
float_operation,1
getcwd,1
model_to_estimator,1
trainspec,1
img_input_fn,1
train_filenames,1
repeat_count = 1,1
max_steps = 500,1
evalspec,1
valid_filenames,1
saving_listeners,1
model_fn_lib,1
_model_fn,1
advancetried,1
faced,1
oct 13 2017,1
> [gcc 7,1
copyright,1
credits,1
"_register_converters

>",1
<stdin>,1
ndinterpolatorbase,1
img_channels = 224,1
img_channels,1
shouldnt,1
read_file,1
decode_jpeg,1
make_initializable_iterator,1
get_next,1
train_df[,1
[labels_dict[,1
valid_df[,1
num_elements,1
791             success,1
success,1
__traceback__,1
with_traceback,1
_generator,1
shared_name,1
as_dense_shapes,1
colocate_with,1
iterator_resource,1
make_iterator,1
109                                                   iterator_resource,1
repeat_dataset,1
_input_dataset,1
_count,1
as_dense_types,1
batch_dataset,1
batchdataset,1
_get_graph_from_inputs,1
_flatten,1
op_input_list,1
-> 5653         _assert_same_graph,1
_assert_same_graph,1
original_item,1
-> 5589                                                                 original_item,1
mapdataset_3,1
brings,1
worries,1
#9796hi,1
model_file,1
valid_accuracy,1
spearec,1
stupid,1
overfiting,1
plants,1
img_paths,1
img_paths] #,1
vstack,1
structured,1
ndarray,1
#fill_mode=,1
shaped,1
avg_pool_2,1
n_splits=5,1
train_to_integer,1
# train_to_integer,1
train_idx,1
val_idx,1
nfold,1
"]

    

    load_name_weights =",1
_weights,1
save_name_weights =,1
save_name_weights,1
load_name_weights,1
scratch,1
history_file =,1
history_file,1
yielding,1
consecutively,1
10m0s,1
indicating,1
isolation,1
opinion,1
suffer,1
reverting,1
by24,1
by17,1
enhance,1
1.00E-05,1
subprocess,1
z_dim+,1
action_dim,1
hidden_units,1
n_mixtures *,1
z_dim,1
subprocesses,1
model_b_input,1
model_b_output,1
x_c_e,1
newing,1
inefficient,1
merge_all,1
omitting,1
convenient,1
l1_l2,1
_keras_mask,1
rois],1
"__________________

`",1
pegs,1
proceed,1
kicks,1
mpi,1
race,1
hang,1
catches,1
cache_subdir,1
makedirs,1
untar,1
fname,1
catch,1
nuked,1
composed,1
reproduces,1
in_dim,1
out_dim,1
requisite,1
reinstall,1
output_cols=[,1
value1,1
value2,1
output_cols,1
seperator,1
redd,1
/sz9g2v4fjvr01,1
optimise,1
inter_area,1
pylab,1
learning_curve,1
make_scorer,1
linearsvc,1
adagrad,1
image_name =,1
*class0,1
patternone =,1
*class1,1
patternone,1
upperindex,1
upperindex],1
inter_cubic,1
value_counts,1
countplot,1
dict_characters,1
imblearn,1
fit_sample,1
degrees,1
map_characters = {0,1
map_characters,1
class_weight2,1
uglier,1
inactivity,1
lot,1
comprise,1
"6

window10",1
rock,1
number_img_channels,1
petrophysicists,1
mistaken,1
number_of_samples,1
`xbatch =,1
arange,1
xbatch[,1
resnetbuilder,1
build_resnet_18,1
__m__,1
__n__,1
data_augmentation,1
w_names =,1
get_names,1
get_shapes,1
layer_map,1
layer_data,1
customobjectscope,1
string_types,1
#NAME?,1
e2,1
]*e2[,1
notice,1
signs,1
">



practically",1
db,1
flow_from_url_list,1
flow_from_filepath_list,1
bahdanau,1
cho,1
align,1
lstmcell,1
attngru,1
attnlstm,1
//jmvalin,1
9% claimed,1
website,1
inflexibility,1
**lossess**,1
natural,1
express,1
aware,1
opinions,1
kmow,1
deal,1
uploaded,1
mine,1
agents,1
histogram,1
julia,1
_register_converters,1
githi,1
logo,1
infer,1
complex64,1
imag,1
complex128from,1
advantage,1
suited,1
[capture2],1
freeing,1
thinking,1
assumes,1
pred_class_ids,1
permission,1
everytime,1
----> 1 pm,1
pm,1
#NAME?,1
fire2,1
fire3,1
fire4,1
fire_module,1
number_squeeze_1x1,1
number_expand_1x1,1
number_expand_3x3,1
620             output_mask =,1
179         normed_training,1
reduction_axes,1
_has_nchw_support,1
1823                                                           reduction_axes,1
_get_available_gpus,1
_apply_device_functions,1
device_function,1
_set_device,1
from_string,1
merge_from,1
parse_from_string,1
_clear,1
--> 148     splits = [,1
splits,1
entrance,1
hoping,1
cnn_filter_num,1
cnn_filter_size,1
l2_reg,1
8x8,1
enemy,1
res_layer_num,1
res_out =,1
res_out,1
value_fc_size,1
reversi_model,1
defaulti,1
unable,1
recv_device=,1
send_device=,1
send_device_incarnation=1,1
tensor_name=,1
utilized,1
wanting,1
`local_conv3d`,1
datax,1
datay = [],1
"]

        datax",1
datay,1
skiprows=0,1
feature_range=,1
fit_transform,1
trainy_extended[,1
trainy_extended,1
[model_plot],1
` treated,1
recurrent_activation=,1
hard_sigmoid,1
nb_conv,1
dim_ordering=,1
modelfilename,1
deeplearningtest,1
n_epoch = 50,1
computed_tensor,1
matthias,1
launcher,1
flask,1
y_dev,1
weights_dev,1
sublist,1
0` appended,1
hacks,1
matter,1
child,1
reduce_mean,1
vector_length,1
output_size,1
[screenshot,1
40x32,1
answered,1
@wxs,1
confess,1
leo,1
unluckily,1
en_input,1
conv_01,1
bn_01,1
conv_02,1
bn_02,1
mp_01,1
bn_11,1
bn_12,1
mp_11,1
conv_21,1
bn_21,1
conv_22,1
bn_22,1
mp_21,1
dense_31,1
de_input,1
dense_41,1
dense_42,1
r_41,1
up_51,1
convt_51,1
bn_51,1
convt_52,1
bn_52,1
us_61,1
convt_61,1
bn_61,1
convt_62,1
bn_62,1
us_71,1
convt_71,1
bn_71,1
convt_72,1
contributes,1
overwhelm,1
clarify,1
input_layers,1
hidden_size,1
amount_of_dropout,1
001e-5`,1
agost,1
solved,1
prefer,1
accordance,1
image_ordering =,1
channels_last,1
[ph1],1
[ph2],1
obtaining,1
param_l2,1
[save_error],1
best_weights,1
x_vals_train,1
x_vals_test,1
nan_to_num,1
normalize_cols,1
googling,1
device_count={,1
intra_op_parallelism_threads=2,1
inter_op_parallelism_threads=2,1
randn,1
variations,1
cpus,1
5i,1
val_data,1
`sampling_rate`,1
submitted,1
enhancements,1
"tanguy



```",1
sampling_rate=3,1
sampling_rate,1
attentionhi,1
futhermore,1
yaml,1
jiawen,1
zeros_like,1
hat_inputs[,1
routings,1
batch_dot,1
hat_inputs,1
**ihello**,1
**helloi**,1
/exit_3,1
phrased,1
isdir,1
wb,1
file_,1
varscope,1
adminvale,1
block1_conv1_new,1
nesting,1
container,1
dot22,1
/sequential_3_input,1
[tensortype,1
tensortype,1
inplacedimshuffle{,1
0x7fe85f8c8610>,1
0x7fe846170390>,1
nn_blocks,1
batchrenormalization,1
0x7fe85f8910d0>,1
0x7fe84611a450>,1
0x7fe8476c93d0>,1
0x7fe845f99fd0>,1
0x7fe845ee2e50>,1
0x7fe845ef5ed0>,1
0x7fe845ea8c10>,1
0x7fe845e44c10>,1
0x7fe845e93a50>,1
globalmaxpooling2d,1
0x7fe845e5b690>,1
0x7fe845e5b9d0>,1
0x7fe845e02610>,1
0x7fe845dc3e90>,1
0x7fe845dd4250>,1
0x7fe845dd41d0>,1
0x7fe845d1c590>,1
0x7fe845d832d0>,1
0x7fe845c00310>,1
0x7fe845c65350>,1
0x7fe845bbdd90>,1
0x7fe845c2a390>],1
clustering,1
planning,1
input_tweet,1
"3299400   

    enc_do_0_layer",1
"0         

    enc_c_1",1
"9616      

    enc_mp_1",1
"0         

    enc_c_2",1
"392       

    enc_mp_2",1
"0         

    enc_c_3",1
"200       

    enc_mp_3",1
"0         

    reshape_2",1
"0         

    dec_c_1",1
"200       

    dec_ups_1",1
upsampling1d,1
"0         

    dec_c_2",1
"200       

    dec_ups_2",1
"0         

    dec_c_3",1
"400       

    dec_ups_3",1
"0         

    conv1d_2",1
conv1d_2,1
enc_do_0_layer,1
enc_c_1,1
enc_mp_1,1
enc_c_2,1
enc_mp_2,1
enc_c_3,1
enc_mp_3,1
dec_c_1,1
#NAME?,1
dec_ups_1,1
dec_c_2,1
dec_ups_2,1
dec_c_3,1
dec_ups_3,1
#NAME?,1
stanford,1
scopewhen,1
ddpg,1
nb,1
test_ffts,1
test_targets,1
sampling_rate=1,1
compensate,1
kinds,1
video_input,1
vgg2_mobilenet,1
multiclassifier,1
sry,1
[``deconv_length``],1
ambigous,1
int_shape,1
supply,1
ambiguity,1
cleaning,1
frustration,1
[graphlayer],1
chance,1
smart,1
marked,1
labeled,1
peaches,1
contributor,1
au,1
labelbox,1
date_created,1
2018-04-07t10,1
cjfp6vz7xfwz20198ixce9la4,1
//firebasestorage,1
googleapis,1
/labelbox-193903,1
appspot,1
flickr_url,1
coco_url,1
date_captured,1
cjfp6wqfhfwyu0107il09db3p,1
annotations,1
image_id,1
category_id,1
iscrowd,1
licenses,1
categories,1
supercategory,1
peach,1
rotated,1
//cocodataset,1
image_index = -1 #,1
image_index =,1
image_index + 1,1
image_index == 0,1
permutation,1
generatorexit,1
train_img,1
train_mask,1
ntraining,1
_use_multiprocessing,1
get_context,1
initargs,1
recv,1
_check_closed,1
_check_readable,1
--> 250         buf =,1
buf,1
getbuffer,1
--> 407         buf =,1
#NAME?,1
unpack,1
getvalue,1
"```

additionally",1
work_element_count > 0,1
g3,1
ecc,1
forum,1
decomposed,1
interestingly,1
unfortunate,1
messed,1
adrian,1
thisi,1
conducted,1
stability,1
froze,1
ktf`,1
path2,1
"expectations

*",1
resolved,1
cuda_device_order,1
pci_bus_id,1
cuda_visible_devices,1
weight_path=,1
keras_cnn_weights,1
ktf,1
fhandler,1
rb,1
w_1,1
6f,1
g1fbea14,1
input_shapes[0],1
as_tensor_variable,1
add_tag_trace,1
tensorvariable,1
compress_1,1
compress_2,1
compress_3,1
batchno,1
non_trainable_weights,1
total_memory = 4,1
total_memory /,1
980ti,1
6gb,1
noise_shapes=[,1
noise_shapes,1
conv_lstm,1
convlstm,1
[conv_lstm,1
pyt],1
reality,1
__,1
orange,1
[orange,1
nb_samples,1
statuses,1
globalaveragepooling1d,1
numpoints,1
#NAME?,1
meanings,1
`validation_step,1
`step_based_generator`,1
tf_cudnn_use_autotune,1
indirect,1
docks,1
__very__,1
careless,1
xd,1
1 hour,1
install_keras,1
chollet,1
"**

````

rm",1
"%>% 

  layer_dense",1
partial_y_train,1
1 memoryclockrate,1
"721

pcibusid",1
"0

totalmemory",1
"06gib

2018-04-01 21",1
plz,1
text_path =,1
listdir,1
%ssteering_data,1
% text_path,1
splitlines,1
initializer_fun,1
dim_lstm_state,1
n_units,1
mimlcnn,1
maxlen_of_setences,1
assignments,1
iterate,1
wreck,1
effectively,1
get_no_of_batches,1
greeted,1
batch_logs,1
log_values,1
floor,1
log10,1
zeropadding2d,1
# compling,1
testign,1
"```



hwoever",1
teh,1
kathanashmodel,1
requesting,1
convs = [],1
local_conv2d,1
convs,1
kernel_shape =,1
classes_output,1
valid_data,1
chose,1
unfreeze,1
recompile,1
model_weights_path,1
a1,1
apis,1
"56b114d 100644

---",1
tsgen,1
deserve,1
absolutely,1
noob,1
clubbed,1
save_weight,1
batch_get_value,1
symbolic_weights,1
intuition,1
digging,1
recurrent_initializer],1
0x0000000014e10d90>,1
pieces,1
v9,1
resnet50_eager,1
mib,1
synthetic,1
**18sec,1
**33sec,1
word_dim,1
class_size,1
word_dim],1
rnn_size,1
stackedrnncells,1
n_vocab,1
bdclstrm,1
annoconda3,1
300 featureshould,1
convlstm2dtest,1
convrnn2d,1
full_input,1
counterintuitive,1
unmagnify,1
zoom_keep_ar,1
satisfied,1
709f791af201caaab4aa180bda259989087cfe47hello,1
block5_pool,1
block5_conv5,1
block5_conv6,1
block5_conv7,1
numpoints = 1,1
shape1,1
shape1[0],1
//yann,1
eq,1
mat_mul,1
batc,1
rethinking,1
szegedy,1
allowance,1
stick,1
backpropagation,1
traininglabels,1
eliminates,1
slide,1
neural_network,1
mlpclassifier,1
bias_regularizer=,1
"`



benefits",1
"```



disadvantages",1
busy,1
clicking,1
usability,1
lists,1
inconvenient,1
num_label,1
n_fold,1
kf,1
valid_scores = [],1
cooldown=1,1
fold_,1
tr_p[0,1
iterations,1
role,1
intending,1
archive,1
first_log =,1
second_log =,1
first_log,1
second_log,1
x5,1
x6,1
x5],1
x6],1
[y6],1
episodes,1
sleeping,1
distribute,1
dynamic_partition`,1
country_partitions,1
spread,1
rec_dim,1
inputs_,1
dynamic_partition,1
helphey,1
pairloader,1
moved,1
specificity,1
sensitivity,1
jjallaire�,1
//jjallaire,1
row_numbers,1
22 electrodes,1
`lstmcell`,1
literature,1
filling,1
doable,1
evaluategenerator,1
fitgenerator,1
evalutegenerator,1
evidently,1
on_epoch_begine,1
fill,1
builded,1
weightedmodel,1
setted,1
analyzing,1
_callback_,1
_make,1
features_,1
approximates,1
yan,1
dodier,1
mozer,1
& wolniewicz,1
rocaucscore,1
boolean_mask,1
robust,1
pow,1
baidu,1
/12yjcwdfvvw1tekufeu34rq,1
password,1
#     approximates,1
#     yan,1
img_height = 512,1
"512



train_data_dir =",1
mae,1
"+ object_name +

     86",1
_collected_trainable_weights,1
accumulators,1
new_a,1
239             new_p =,1
_ctx,1
in_graph_mode,1
reply,1
clean_text,1
iloc[,1
coord_pred,1
present_pred,1
coord_expected,1
acceleromters,1
practical,1
chans,1
xyz,1
blablablu,1
video_training,1
descendants,1
assign_mul,1
21                                                              cooldown=0,1
"metrics_updates

    992                 #",1
beta_2,1
clip_by_value,1
clip_value_min,1
clip_value_max,1
clip_value_max],1
__enter__,1
_values,1
"_values = []

-> 5616",1
#NAME?,1
_g_manager =,1
_g_manager,1
-> 5284         _assert_same_graph,1
-> 5220                                                                 original_item,1
rating,1
``accuracy_score,1
realized,1
switching,1
assumes `,1
data_size,1
places,1
//faroit,1
experimented,1
"`



therefor",1
num_neighbors,1
neighbors_ix_mat,1
bias_regularizer,1
recursionerror,1
`recursionerror,1
setrecursionlimit`,1
gcn,1
graph_convolution,1
conda36,1
el,1
args_el,1
abc,1
__instancecheck__,1
_abc_cache,1
_weakrefset,1
thx,1
denoted,1
imgs_train,1
imgs_mask_train,1
data_shape,1
rookie,1
lr_with_decay,1
intention,1
learningratescheduler,1
random_uniform_variable,1
offered,1
covers,1
situations,1
ndarray`,1
byewhen,1
tr_auc,1
va_ap,1
ii,1
heres,1
parallelization,1
substitute,1
substitutes,1
device_lib,1
list_visible_devices`,1
occupied,1
word_counts,1
implied,1
1 + word_count,1
phrase,1
attaching,1
aftre,1
posible,1
deallocated,1
shear_range = 0,1
fill_mode =,1
core_idg,1
image_dir,1
pngimagefile,1
interpreted,1
19                              color_mode =,1
1235                 width_height_tuple =,1
pops,1
embded,1
triple_siamese,1
datapath,1
model_test,1
convlayers2d,1
number_of_feature_maps,1
_41,1
41*number_of_feature_maps,1
ecran 2018-03-11,1
">



**notice",1
mini_batch,1
behaviors,1
painters,1
paintings,1
"paintings    





------                     ---------------",1
no_classes_style,1
no_classes_genre,1
no_classes_painter,1
traingenredatagenerator,1
trainpainterdatagenerator],1
validationgenredatagenerator,1
validationpainterdatagenerator],1
peeks,1
enc_input,1
enc_emb,1
enc_output,1
enc_h,1
[enc_h,1
dec_input,1
dec_emb,1
decoder_output,1
x_dec,1
x_dec[0],1
concatop,1
intx,1
n_values,1
encounter,1
proxymodel,1
tensorflow1,1
uniform,1
post4,1
1 --iterations,1
train_msc,1
retain_graph,1
create_graph,1
retain_variables,1
grad_variables,1
cudnn_status_mapping_error,1
output_sequence_length,1
english_vocab_size,1
french_vocab_size,1
preproc_english_sentences,1
max_french_sequence_length,1
preproc_french_sentences,1
final_mask =,1
y_pred_max =,1
y_pred_max,1
final_mask +=,1
"* final_mask

```",1
num_encoder_tokens,1
sparse_concat,1
[to_dense,1
concat_dim,1
assert_is_compatible_with,1
base_type,1
funcs_at_priority,1
notimplemented,1
attrvalue,1
copyfrom,1
165   const_tensor =,1
_message,1
systemerror,1
node_data,1
triggered,1
advices,1
youhere,1
contributed,1
@greggovit,1
chairconfidence,1
plastic,1
metal,1
converters,1
input_names=[,1
output_names=[,1
class_labels=[,1
image_input_names=[,1
my_model,1
mlmodel,1
leaving,1
preserved,1
consequence,1
additionally,1
finetuning,1
felt,1
strangeness,1
train_acc,1
train_acc 1,1
training_acc,1
#�giris,1
val_categorical_accuracy,1
giris,1
giris/255,1
compute_gradients,1
mark,1
simpler,1
set_floatx,1
suppress,1
test_bn_fp16,1
"_satisfiestypeconstraint

>",1
as_dtype,1
allowed_list,1
preprocessor,1
downgrade,1
tokenize,1
recreate,1
duplicated,1
inability,1
dense_size,1
pointer,1
differenthi,1
0 container,1
cudnn_version 7,1
para_dict,1
[aud_valid,1
vid_valid],1
valid_truth_mem,1
valid_weight,1
exc_type,1
exc_value,1
exc_trace,1
output_subset,1
pygpu_empty,1
array_empty,1
cumemalloc,1
cuda_error_out_of_memory,1
context_name=,1
i4,1
shape_i{0},1
shape_i{1},1
rebroadcast{0},1
"]]



hint",1
hint,1
debugprint,1
intentional,1
advancei,1
final_weights,1
modelfile =,1
2dcnn_model,1
modelfile,1
maxpooling2,1
num_timewins,1
imsize,1
n_colors,1
timedist,1
0-rc0,1
model_weights,1
3152                                                        original_keras_version,1
preprocess_weights_for_loading,1
original_keras_version,1
convert_kernel,1
honestly,1
_embeddings_with_dropout =,1
_embeddings_with_dropout,1
apologies,1
5gb,1
550ms,1
20mins,1
missed,1
difficult,1
"`



surprisingly",1
#get_ipython,1
magic,1
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr,1
pathname,1
base_path,1
cancer,1
as_matrix,1
hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh,1
not_cancer,1
/224x224/%,1
trn_dataset,1
test_dataset,1
trn_labels,1
#calc_features,1
unusual,1
freezed,1
displaying,1
recieved,1
heading,1
block5_conv2,1
block5_conv3,1
fc2,1
python_installation,1
discrepancy,1
nans,1
impute,1
strategy,1
is_nan,1
sigmoidal,1
"30]

**unique_classes**",1
unique_classes,1
text_to_seq,1
text_to_sequence,1
sse4,1
1 sse4,1
"7335

pcibusid",1
0b,1
"46gib

2018-03-02 09",1
2.29E-02,1
17m45,1
25m25,1
1m21,1
"46gib

2018-03-02 10",1
17m21,1
23m48,1
1m8,1
"412s

```",1
top_model_weights_path =,1
fc_model,1
img_height = 150,1
"150



train_data_dir =",1
top_model_weights_path,1
playing,1
tensor_constructor,1
elephant,1
acts,1
//datascience,1
stackexchange,1
models_location +,1
/bottleneck_f_train_inception,1
/bottleneck_f_validation_inception,1
avg_pool,1
top_model_weights_path_modelsdg,1
disables,1
normalizes,1
test_on_batch,1
visualization,1
"5

> temsorflow 1",1
tf_jenkins,1
"cudnn_status_internal_error

> 2018-02-27 22",1
"cudnn_status_bad_param

> 2018-02-27 22",1
conv_ops,1
->getconvolvealgorithms,1
conv_parameters,1
shouldincludewinogradnonfusedalgo<,1
overcome,1
thousands,1
~30gb,1
compelled,1
dirname,1
lifesaver,1
son,1
encodings,1
wordsi,1
plane,1
file_helper,1
unpackdata,1
weigth_file=,1
4f},1
weigth_file,1
//openreview,1
y_training,1
"]



# truncate",1
embedding_vector_length,1
0straceback,1
floydhub,1
mislabeled,1
supposed,1
alphabet,1
vacab_size 500+,1
input_lenght,1
solustion,1
collapse_dim,1
[x_left,1
x_right],1
30mins+,1
priori,1
feasible,1
40x40,1
80x80,1
libffi-3,1
asn1crypto-0,1
certifi-2016,1
idna-2,1
6-py36_ 100%,1
pycosat-0,1
pycparser-2,1
pycrypto-2,1
pyparsing-2,1
writable,1
_fp,1
_sock,1
5/ssl,1
nbytes,1
buffer,1
_sslobj,1
connectionreseterror,1
peer,1
chunk_size,1
5/contextlib,1
resp,1
iter_content,1
tar,1
bz2,1
2-py36_0,1
exiting,1
recipe,1
y_input,1
x_input,1
cumsum,1
deeplearningbook,1
wonderful,1
bake,1
reduces,1
smile,1
test_this_bug,1
moveaxis,1
best_model_name =,1
%s_best,1
best_model_name,1
test_this_bug_best,1
_global_custom_objects,1
unprocessed_nodes,1
618             output_mask =,1
has_arg,1
el7,1
[lattices,1
cool,1
love,1
stucked,1
crazy,1
necessarily,1
finetune,1
custom_metric],1
[acc_value,1
"custom_value]

```",1
danieletraceback,1
simon,1
appdata,1
python35,1
[comb_agent_arg],1
entity_args,1
target_network =,1
`pydotprint`,1
thanksi,1
timer,1
symmetric,1
credible,1
//dawn,1
/matmul_4,1
numerai_training_data,1
numerai_tournament_data,1
x_prediction,1
to_csv,1
demonstrate,1
> appdirs,1
> bleach,1
> html5lib,1
> markdown,1
> packaging,1
> pluggy,1
> protobuf,1
> pyparsing,1
> pyyaml,1
> setuptools,1
> werkzeug,1
data_dim,1
whl,1
max_digit,1
/yzgxzwx,1
lstm_4,1
top_only,1
confirm,1
advanceconsider,1
line_length=100,1
# subtract,1
cooldown=0,1
resnet18_cifar10,1
x_source,1
y_source,1
avg_image_train,1
[encoded_sentence,1
skipped,1
0 feature_map_count,1
149 149  value_min,1
000000 value_max,1
000000 layout,1
batchdepthyx},1
1khz,1
quantity,1
ecg_hr,1
ecg_hrv,1
ecg_zcr,1
ecg_fft_1,1
lable1,1
"label2

0",1
understood,1
demonstration,1
defaulted,1
"daniel



```",1
densenet169,1
densenet201,1
# uncomment,1
default_shape,1
propagated,1
[ref],1
image_dim1,1
image_dim2,1
image_dim3,1
nb_of_classes,1
converge,1
usefull,1
lightweight,1
impementation,1
[p_z,1
computed_tensors],1
"-

`p_z`",1
tantrum,1
//anonfile,1
anonfile,1
_kernel=,1
mklop,1
_bootstrap_inner,1
_target,1
_args,1
_kwargs,1
save_iteration,1
save_now,1
warped_a,1
target_a,1
func_call,1
get_folder,1
initmodel,1
decoder_a,1
conv_op,1
familiar,1
pinpoint,1
centroids,1
released,1
shed,1
light,1
reload,1
`learning_phase,1
participate,1
migrating,1
count_mode,1
infoing,1
show_metrics = [,1
decoder_ler,1
val_decoder_ler,1
extract_image_patches,1
u_true =,1
u_pred =,1
std_pred =,1
u_true,1
u_pred,1
test_1,1
test_2,1
initialize_all_variables,1
kerasmodel_const_init_customloss,1
training_data_lr,1
training_data_mc,1
training_data_hr,1
validation_data_lr,1
validation_data_mc,1
validation_data_hr,1
checkpoint_callback],1
atm,1
specifiy,1
bogus,1
notion,1
`get_input_at,1
node_index,1
get_input_at,1
timeseriessequence,1
trick,1
stem_1,1
reduction_1_%,1
refusing,1
subtract,1
importantly,1
unfortunaly,1
greetingsi,1
5 hours,1
max_fatures,1
problemwould,1
anaconda30,1
slope,1
{}_w,1
{}_b,1
conv3d_transpose,1
conv3dbackpropinput,1
out_backprop,1
ndhwc,1
responsible,1
ship,1
comparable,1
reached,1
standstill,1
limitations,1
packing,1
cumbersome,1
python_ver = 3,1
tensorflow_ver = 1,1
6-rc0,1
transfer_len,1
#NAME?,1
#NAME?,1
"```

output_path =",1
output_path,1
"134 

    135     model_weights_group =",1
skipkeys,1
ensure_ascii,1
pysequence_fast,1
iterencode,1
key_separator,1
item_separator,1
markers,1
_default,1
_encoder,1
_indent,1
_floatstr,1
fc6,1
caffenet_inputs1,1
caffenet_inputs2,1
patchsize,1
paperthanks,1
tensorflowhi,1
n_sample,1
n_label,1
5s,1
test_score,1
dispatched,1
dispatch_one_batch,1
_jobs,1
return_parameters,1
return_n_test_samples,1
error_score,1
is_multimetric,1
scorers,1
_sign *,1
_score_func,1
827                                                  warn_for=,1
precision_recall_fscore_support,1
warn_for,1
"1024 

-> 1025     y_type",1
y_type,1
type_true,1
type_pred,1
y_type =>,1
n_labels,1
decisiontreeclassiifer,1
max_depth=3,1
decisiontree,1
advise,1
ahmed,1
h5_path,1
weights_name,1
train_num,1
one_epoch,1
epoch_num,1
flag_random,1
42             rank1s,1
cmc,1
rank1s,1
x86,1
worried,1
sufficient,1
n_tasks,1
appended,1
withni,1
gists,1
read_dset,1
winograd_nonfused,1
tf_enable_winograd_nonfused,1
unnecessary,1
experimentation,1
data_training,1
data_testing,1
notset,1
notsets,1
binary_classifier,1
leakyrelus,1
approving,1
labelling,1
plottted,1
codei,1
16 categories,1
16 catogories,1
mat,1
overthinking,1
x_tr,1
y_tr,1
xdev,1
ydev,1
xxxxxxxxxxxxxxx,1
filehello,1
model_nn,1
prog=,1
caught,1
apt,1
mysef,1
%%creator,1
atend,1
%%boundingbox,1
%%endcomments,1
nsave,1
%%beginprolog,1
/setuplatin1 {,1
nmark,1
} forall,1
ncleartomark,1
%%beginresource,1
/invscalefactor 1,1
/set_scale {,1
% styles,1
tgsave,1
tgrestore,1
/alignedtext {,1
[] 0 setdash,1
/boxprim {,1
tmoveto,1
tclosepath,1
/ellipse_path {,1
tnewpath,1
tx,1
tsetmatrix,1
darkest,1
lightest,1
ndef,1
/onlayers {,1
tor,1
%%endresource,1
%%endprolog,1
%%beginsetup,1
pdfmark,1
harmless,1
distiller,1
/pdfmark,1
userdict,1
%%endsetup,1
nsetuplatin1,1
%%pageboundingbox,1
%%pageorientation,1
portrait,1
ngsave,1
nendpage,1
nshowpage,1
ngrestore,1
%%pagetrailer,1
%%endpage,1
%%trailer,1
nend,1
nrestore,1
%%eof,1
examine,1
batchnormaliza,1
cutoff,1
idle,1
apologize,1
banana,1
apple,1
happenstance,1
comfortable,1
ocuring,1
no0b</,1
1dconvtest,1
macosx-10,1
anaconda4,1
hour,1
infact,1
employ,1
block4_conv3,1
persists,1
retval[0],1
tf_cpp_min_log_level,1
interactivesession,1
save_weights_to_hdf5_group,1
flush,1
`save_weights_to_hdf5_group,1
idiomatic,1
io_utils_test,1
`tarfile,1
load_batch,1
get_word_index,1
reuters,1
repositories,1
discussing,1
email,1
committers,1
**specs**,1
bfc_allocator,1
gpu_0_bfc,1
69mib,1
caller,1
06gib,1
05gib,1
67mib,1
"43gib

2018-02-01 12",1
"1563249868

inuse",1
"1538762752

maxinuse",1
"1538762752

numallocs",1
"2008

maxallocsize",1
/edsc6vme,1
letter,1
fyip,1
debhello,1
//mega,1
nz/#,1
npotzibj,1
u5l8toqgcj6xif2tmjirxuace3skhrtwledeowe_fkm,1
i8ptnbyr,1
topqcyor,1
isql5nxc2stjrxenygs8rokz_yh8nb8d05e0kaja7rw,1
averagepooling1d,1
meas,1
all_pred_data,1
ytest_all,1
patches_imgs_train,1
[patches_masks_train,1
patches_masks_train2],1
7/copy_reg,1
__new__,1
curated,1
openu,1
megaface,1
//ibug,1
ic,1
sphereface,1
deepsense,1
gatech,1
combines,1
conclude,1
premise,1
illustrated,1
concerned,1
n_hidden_states,1
n_timesteps,1
n_inputs,1
commented,1
illustrative,1
_placeholder,1
"10

bleach==1",1
"0

futures==3",1
"1

html5lib==0",1
"3

markdown==2",1
"0

protobuf==3",1
"1

pyyaml==3",1
"1

werkzeug==0",1
reiterate,1
stderr],1
configure,1
handlers,1
originates,1
afraid,1
burden,1
strided_slice_7,1
choice,1
attentive_convlstm,1
nb_filters_out,1
nb_filters_in,1
operationhi,1
prelu_5_1,1
chapter 4,1
_epsilon,1
resnetv2,1
resnext,1
subtracting 5,1
glove_dir,1
6b,1
100d,1
l_flat,1
labels_index,1
_logs[,1
collar=,1
acc_tr =,1
acc_tr,1
212s,1
191s,1
177s,1
162s,1
concatenating,1
embeddings_regularizer=,1
embeddings_freq=0,1
embeddings_layer_names=,1
embeddings_metadata=,1
informed,1
sequence_lengths =,1
sequence_lengths,1
*5+seq_len,1
"```



[1] wang",1
clark,1
wen,1
& trigoni,1
proceedings,1
robotics,1
automation,1
corrected_jpeg_xception2,1
model_names =,1
model_names,1
img_channels = 3,1
xception_weights_tf_dim_ordering_tf_kernels_notop,1
x_validation,1
y_validation,1
train_merge_jpg_images_random,1
validation_merge_jpg_images_random,1
"150



top_model_weights_path =",1
bottleneck_model_weights,1
top_model_path =,1
bottleneck_model,1
train_data_dir =,1
validation_length = [],1
validation_length,1
top_model_path,1
save_bottlebeck_features,1
number_of_images_in_validation_directory,1
effort,1
"150

test_directory =",1
test_directory,1
bottleneck_features_test,1
runtimewarning,1
fast_tensor_util,1
prediction_from_file,1
replaced,1
to_hdf,1
conclusive,1
timehello,1
logcat,1
java,1
lang,1
illegalargumentexception,1
opkernel,1
hypothesis,1
__dict__,1
alright,1
fitness,1
wraps,1
traindatasetfinal,1
testdatasetfinal,1
millisecond,1
spectrogram,1
684i,1
reinstantiate,1
generate_batches,1
restarting,1
`model_save`,1
resuming,1
determined,1
clearer,1
pierrei,1
`x_trn,1
number_of_image_patches,1
image_rows,1
image_columns,1
number_of_image_channels,1
`160x128x128`,1
x_trn,1
insights,1
welcomeif,1
mismatches,1
sliced,1
lstm_stateful,1
localclidebugwrappersession,1
tfdbg,1
disturb,1
"```

x_patched_train_h5",1
x_patched_valid_h5,1
[gpuarraytype<,1
[[gpureshape{5},1
aidin,1
max_seq_length,1
trimming,1
approximate,1
`recurrent_kernel`,1
argued,1
sean,1
input_239,1
delimited,1
commas,1
2gb,1
appreciable,1
`backend_test,1
testbackend,1
test_batchnorm`,1
directoryiterators,1
dirs,1
convinced,1
n_channel,1
ebnodb_train / 10,1
* ebno_train,1
ini`,1
`unknownerror,1
skipif`,1
950e5d0,1
batch_num,1
outer_concat_1,1
implies,1
lazyleaf,1
n_timestep,1
n_emb,1
d0,1
[att_vec3,1
att_vec4],1
att_vec7,1
att_vec8,1
c0,1
n_class,1
news20,1
gz,1
reg_norm =,1
reg_norm,1
#NAME?,1
`randomtensor =,1
binarize,1
>randomtensor =,1
randomvalues,1
randomtensor,1
greater_equal,1
simplernn,1
baseline,1
curious,1
mnist_denoising_autoencoder,1
imgdim,1
outpath,1
outputpath,1
signature_def_utils,1
savedmodelbuilder,1
add_meta_graph_and_variables,1
serving],1
signature_constants,1
default_serving_signature_def_key,1
wondered,1
guidelines,1
[_weighted_masked_objective],1
interrupted,1
supercomputer,1
4ghz,1
memories,1
60gb,1
240gb,1
mmd,1
grad_ys,1
`upds = [,1
`grad_ys`,1
labelled,1
smth,1
120x130000x2=31,1
recommendations,1
res_model,1
train_nn,1
get_batches_fn,1
save_checkpoint,1
__code__,1
raw_unicode_escape,1
unicodedecodeerror,1
rawunicodeescape,1
codec,1
skew_true,1
skew_pred,1
angle_true,1
angle_pred,1
sin,1
cos,1
r2 =,1
r2,1
my_metric,1
elems,1
loop_vars,1
shape_invariants,1
original_loop_vars,1
*packed_vars_for_body,1
packed_values,1
`zeromean`,1
"instantiation

*",1
`new_p =,1
canceling,1
bmw 750,1
guessed,1
kias,1
hondas,1
vws,1
buses,1
youhi,1
isntructions,1
vector_dim,1
abstracts,1
max_encoder_words,1
titles,1
max_decoder_words,1
guessing,1
remedied,1
hidden_dims=,1
hidden_dims,1
hidden_dims = [32,1
h_dim,1
train_fn,1
discount_reward],1
action_onehot,1
discount_reward,1
train_fn =,1
state_dimension,1
n_actions,1
9.73E+05,1
5.33E+05,1
8.33E+05,1
6.71E+05,1
4.05E+05,1
1.94E+05,1
6.23E+04,1
9.08E+05,1
3.44E+05,1
1.76E+05,1
2.40E+05,1
1.34E+06,1
5.30E+06,1
3.52E+05,1
8.13E+04,1
2.02E+04,1
6.50E+05,1
4.29E+05,1
3.26E+05,1
6.25E+05,1
6.29E+05,1
9.38E+04,1
4.53E+05,1
8.14E+05,1
4.33E+05,1
2.54E+03,1
3.93E+04,1
9.04E+05,1
8.48E+05,1
2.50E+05,1
8.28E+05,1
2.89E+02,1
1.48E+06,1
5.35E+05,1
1.18E+06,1
4.07E+05,1
2.55E+05,1
3.72E+05,1
1.79E+03,1
1.20E+05,1
9.68E+04,1
9.83E+04,1
2.43E+04,1
6.15E+05,1
4.46E+05,1
9.78E+05,1
8.04E+04,1
9.91E+05,1
1.69E+05,1
7.93E+05,1
4.90E+04,1
9.60E+03,1
3.88E+04,1
2.91E+05,1
5.94E+05,1
9.47E+05,1
4.20E+02,1
5.87E+04,1
3.56E+05,1
2.01E+05,1
8.87E+05,1
5.51E+04,1
6.10E+05,1
6.02E+05,1
8.96E+05,1
5.57E+05,1
6.95E+05,1
4.43E+05,1
3.99E+05,1
2.49E+04,1
2.90E+05,1
2.04E+05,1
2.64E+04,1
4.41E+04,1
3.16E+05,1
5.90E+05,1
4.83E+04,1
7.00E+04,1
4.32E+05,1
6.96E+05,1
2.67E+04,1
5.93E+05,1
9.12E+04,1
6.48E+05,1
3.67E+05,1
2.26E+05,1
8.31E+05,1
6.21E+05,1
2.50E+04,1
3.93E+05,1
7.16E+05,1
5.13E+05,1
3.01E+05,1
9.52E+05,1
9.63E+05,1
6.79E+05,1
1.98E+05,1
2.58E+04,1
3.69E+04,1
8.48E+05,1
1.22E+05,1
9.09E+05,1
2.38E+05,1
5.44E+04,1
7.15E+05,1
3.91E+05,1
5.42E+05,1
8.29E+04,1
4.80E+05,1
9.04E+03,1
3.79E+04,1
9.44E+05,1
8.57E+05,1
9.87E+05,1
3.64E+04,1
6.10E+05,1
1.86E+04,1
5.98E+05,1
5.29E+04,1
5.00E+05,1
8.84E+05,1
7.10E+04,1
2.95E+05,1
9.63E+04,1
3.00E+05,1
3.89E+05,1
8.22E+05,1
5.37E+05,1
2.88E+04,1
9.71E+05,1
3.04E+05,1
7.76E+05,1
2.75E+05,1
7.03E+05,1
4.09E+04,1
4.77E+04,1
9.27E+03,1
8.58E+05,1
9.05E+05,1
3.33E+05,1
1.09E+05,1
7.36E+04,1
2.39E+04,1
5.35E+05,1
7.49E+04,1
4.13E+04,1
2.40E+04,1
2.90E+05,1
5.38E+04,1
3.89E+05,1
9.44E+05,1
2.82E+04,1
8.60E+05,1
3.21E+05,1
7.98E+04,1
9.61E+05,1
7.45E+04,1
5.41E+04,1
5.55E+05,1
8.98E+05,1
7.11E+04,1
4.75E+05,1
2.64E+05,1
4.62E+05,1
2.10E+04,1
8.75E+04,1
2.23E+04,1
5.85E+05,1
4.54E+04,1
8.81E+04,1
6.07E+05,1
7.61E+05,1
3.60E+06,1
1.27E+05,1
7.03E+05,1
9.53E+04,1
2.18E+05,1
1.80E+05,1
1.55E+05,1
3.44E+05,1
9.70E+05,1
3.64E+04,1
8.00E+04,1
5.29E+05,1
5.61E+05,1
2.62E+05,1
1.81E+04,1
1.49E+05,1
3.04E+05,1
5.64E+05,1
3.81E+05,1
5.08E+05,1
5.13E+05,1
4.49E+05,1
9.73E+05,1
2.85E+04,1
8.40E+05,1
2.36E+05,1
3.01E+04,1
9.73E+05,1
9.40E+04,1
2.42E+05,1
8.64E+05,1
6.13E+05,1
5.28E+05,1
1.06E+05,1
4.63E+05,1
1.99E+05,1
2.64E+05,1
7.72E+05,1
2.34E+05,1
1.97E+05,1
9.70E+05,1
9.37E+04,1
4.35E+05,1
8.97E+05,1
4.65E+05,1
4.11E+05,1
6.40E+05,1
3.95E+04,1
4.09E+05,1
8.58E+05,1
9.67E+05,1
1.64E+05,1
3.24E+04,1
4.79E+05,1
1.11E+05,1
5.58E+05,1
6.07E+05,1
2.14E+05,1
1.27E+05,1
5.29E+05,1
1.52E+04,1
5.57E+05,1
6.75E+05,1
1.35E+05,1
8.67E+05,1
9.16E+05,1
8.39E+04,1
9.07E+05,1
5.73E+05,1
4.15E+05,1
6.10E+05,1
5.08E+05,1
7.60E+05,1
2.75E+05,1
6.42E+05,1
6.45E+05,1
3.12E+05,1
4.51E+04,1
8.14E+04,1
6.83E+05,1
4.49E+05,1
5.63E+05,1
1.11E+06,1
3.48E+05,1
6.14E+04,1
8.09E+05,1
8.73E+04,1
9.78E+05,1
9.61E+05,1
4.75E+05,1
7.85E+05,1
7.42E+04,1
8.83E+05,1
2.37E+04,1
9.94E+05,1
9.46E+05,1
4.54E+06,1
3.90E+04,1
5.99E+05,1
3.97E+05,1
3.45E+05,1
4.78E+05,1
6.56E+04,1
5.02E+05,1
9.91E+05,1
7.54E+05,1
9.17E+05,1
8.17E+05,1
3.05E+05,1
2.20E+04,1
4.35E+05,1
7.35E+05,1
9.75E+05,1
8.45E+03,1
2.74E+05,1
6.54E+05,1
6.32E+05,1
7.58E+05,1
1.90E+05,1
5.27E+05,1
1.41E+04,1
8.99E+05,1
4.64E+05,1
8.60E+05,1
5.03E+04,1
5.09E+05,1
2.45E+05,1
3.40E+05,1
4.55E+05,1
9.10E+05,1
1.90E+05,1
8.90E+05,1
6.87E+04,1
9.49E+04,1
3.94E+04,1
4.61E+04,1
1.31E+05,1
4.55E+05,1
8.21E+04,1
6.75E+05,1
3.48E+05,1
6.59E+05,1
6.32E+04,1
5.43E+05,1
2.47E+05,1
2.56E+05,1
7.59E+05,1
6.11E+04,1
8.61E+05,1
4.85E+05,1
5.85E+05,1
3.60E+05,1
2.29E+05,1
5.97E+04,1
2.59E+05,1
2.48E+05,1
4.59E+03,1
8.51E+05,1
4.31E+05,1
5.73E+05,1
9.98E+03,1
2.39E+05,1
9.06E+05,1
6.44E+04,1
5.42E+05,1
3.80E+05,1
3.91E+04,1
5.97E+05,1
8.08E+05,1
4.92E+05,1
8.42E+05,1
1.12E+05,1
7.42E+05,1
4.86E+04,1
9.67E+05,1
7.45E+05,1
2.18E+05,1
5.31E+05,1
5.78E+05,1
7.01E+05,1
4.99E+05,1
8.82E+05,1
4.32E+04,1
3.55E+04,1
7.51E+05,1
2.40E+06,1
2.78E+05,1
4.17E+04,1
7.90E+05,1
6.07E+05,1
7.60E+04,1
8.09E+03,1
4.09E+06,1
5.91E+04,1
8.72E+05,1
4.94E+05,1
1.86E+04,1
1.09E+04,1
9.64E+04,1
5.85E+05,1
2.67E+04,1
3.09E+05,1
imagegenerator,1
array_to_img,1
numbers_train,1
numbers_train/02,1
uncommenting,1
cleared,1
>    1232                                 epoch_logs[,1
batch_val,1
add_summary,1
7/runpy,1
"_run_module_as_main

>",1
pkg_name,1
launch_new_instance,1
zmqioloop,1
fd_obj,1
"_handle_events

>",1
_handle_recv,1
"_handle_recv

>",1
idents,1
allow_stdin,1
zmqinteractiveshell,1
"run_ast_nodes

>",1
code_obj,1
user_global_ns,1
user_ns,1
"_placeholder

>",1
~4k,1
128i,1
darwin,1
macos,1
sciencedirect,1
reached 30%,1
sobel,1
seq_samples,1
mkdir,1
callbackpath +,1
abspath,1
cublas,1
recommends,1
peak,1
cnnlstm,1
ctc_decode,1
get_value,1
lenght = 32,1
spend,1
sadly,1
y_0,1
y_1,1
__foo__,1
-> m_1 ->,1
-> m_2,1
/identity_2,1
seq_len,1
flowing,1
mape,1
seis,1
dat,1
stu,1
xy_time,1
stu1,1
one_hot_labels,1
my_seis_model,1
ylabel,1
xlabel,1
legend,1
wolframalpha,1
nominator,1
thanking,1
pretrain_model_filename,1
pretrain_model_filename +,1
metrics_names[1],1
num_output_categories,1
wights,1
bidirection,1
xiph,1
mycost,1
msse,1
msse},1
tracked,1
serializer,1
patching,1
varargs,1
varkw,1
getargspec,1
existence,1
test_img,1
backpropagate,1
**_this,1
"shreyans

>",1
"simplernn

>",1
setdefaultencoding,1
> #conversation,1
chatbot,1
inner_init=,1
cosine_proximity,1
lstm5000,1
most_similar,1
chatbotlstmtrain,1
1324         _check_loss_and_target_compatibility,1
_feed_loss_fns,1
y_lengths,1
inappropriate,1
disappointing,1
suspicion,1
messy,1
clueless,1
witch,1
"batch_data

2",1
batch_data,1
[msc,1
amd64,1
userid,1
ts,1
nusers,1
nunique,1
nusers+1,1
edmond,1
env36,1
gpuarrayconstant{%,1
cumemcpydtohasync,1
sz,1
cuda_error_unknown,1
[website][2],1
whithout,1
set_trace,1
sentimenttext,1
groupby,1
train_label,1
#buidling,1
unk,1
dictionnary,1
train_label[,1
//thinknook,1
hundreds,1
sump,1
eveyone,1
0x7f295e0bbbd0>],1
preprocesses,1
bgr,1
distort,1
aspects,1
convert_image_dtype`,1
num_boxes,1
[ymin,1
xmin,1
ymax,1
xmax],1
random_hue,1
random_contrast,1
documenting,1
member,1
irreproducibility,1
writeable,1
redownload,1
mounting,1
rearranging,1
suffice,1
input_seq,1
25 categories,1
category_nums,1
rowspan=,1
colspan=,1
6ghz</,1
4ghz</,1
continuation,1
[loss_2,1
[loss_4,1
metric_4_1,1
metric_4_2],1
loss_2,1
loss_4],1
[metric_4_1,1
metric_4_2]],1
conveys,1
poisson,1
vanishing,1
convnet2d,1
hight],1
4gig/16 =,1
noticing,1
coherent,1
temperature 0,1
spirits,1
conscious,1
mystery,1
disguise,1
sp,1
eot,1
thetn,1
ft,1
nteet,1
aeesn,1
~7m,1
exhibiting,1
struggling,1
nb_dense_block=3,1
growth_rate=12,1
nb_layers_per_block=-1,1
dropout_rate=0,1
own_data=,1
min_size=8,1
#NAME?,1
nb_dense_block,1
growth_rate,1
nb_layers_per_block,1
dropout_rate,1
"account

    #",1
3.00E-04,1
pre_model,1
mere,1
6 hours,1
exeption,1
problam,1
inner_weights,1
weight_value_tuples,1
assign_ops,1
np_val,1
subfeed_t,1
placeholder_24,1
"```

notice",1
1hi,1
layer01,1
fire05,1
layer02,1
fire05_bn,1
ssd_squeezenet_trainer,1
sfdsf,1
model_weights_group,1
model_layers,1
with_phil,1
v7,1
output_metrics,1
_mean_,1
awkward,1
linspace`,1
welcomed,1
gif,1
stdev,1
reciprocal,1
knowing,1
linspace,1
set_ydata,1
funcanimation,1
concat_axis=1,1
fileclosed = 0,1
readnetfromcaffe,1
warmup,1
vdeocapture,1
videocapture,1
youtube,1
segment1,1
mp4,1
sleep,1
cordinate,1
startx,1
endx,1
endy,1
linesep,1
blobfromimage,1
setinput,1
ensuring,1
rectangle,1
puttext,1
font_hershey_simplex,1
"& 0xff



    #",1
pressed,1
fileclosed = 1,1
fileclosed == 0,1
destroyallwindows,1
"demand

2017-11-06 00",1
x7,1
x8,1
x9,1
x10,1
x11,1
x12,1
pile,1
negrho = 1,1
negrho,1
2*negrho,1
* image_w,1
* image_h,1
meshgrid,1
image_w,1
image_h,1
image_d,1
disappear,1
_x_,1
_y_,1
input_2_1,1
input_1_3,1
lr_epsilon =,1
accomplished,1
lr_epsilon,1
lots,1
bounce,1
resave,1
no_softargmax_,1
spati,1
weight_chopper,1
34pts_94percent,1
reshape_1_ib-0,1
referencing,1
convince,1
preferably,1
mask_value= -1,1
thanksfirst,1
statefulness,1
collapsing,1
rehape,1
reaching,1
deadend,1
openml,1
meddling_model,1
emb_doc1,1
emb_doc2,1
aim,1
tinkering,1
std_dev,1
ease,1
constrains,1
deserialized,1
boil,1
base64,1
x8f,1
ordinal,1
testprivate,1
x_pixels,1
isnull,1
canal = 1,1
subtracting 100,1
5882v2,1
pdfif,1
num_filts,1
decremented,1
theoretically,1
timedistributedlayer,1
"```

ourput

```

0",1
cross_modality_pretrain,1
weight_conv2d_1,1
colleagues,1
nns,1
increment,1
evolution,1
las 8 58 07,1
las 8 59 04,1
xe3,1
pyspark,1
picklingerror,1
//zachmoshe,1
_feed_input_names,1
tun,1
madam,1
//s3,1
amazonaws,1
"npz

17473536/17464789 [==============================]",1
_function_kwargs,1
lib_filename,1
module_name,1
[module_name],1
forall_inplace,1
scan_fn},1
alloc,1
<tensortype,1
_gfortran_st_write_done,1
[dot22,1
possesion,1
time_steps,1
merry,1
y_predi,1
delving,1
delve,1
flipping,1
matters,1
_transform_,1
mess,1
checkpointpath,1
val_func,1
bunch,1
"```

possible_characters = [",1
abcd,1
maxout_out =,1
maxout_out],1
output_width,1
//proceedings,1
mlr,1
pdfhi,1
intermedia,1
serialisation,1
disclosing,1
published,1
erro,1
relu_s,1
forward_layer,1
subject,1
initialiers,1
num_vectors,1
dim_vector,1
transponse,1
kernel_activation,1
promising,1
unstack,1
`dim_vector`,1
gripper_status>,1
gripper_status,1
gripper_status=1,1
grasped,1
x_target,1
y_target,1
rand_y,1
std_normalization,1
v1_first_train,1
flat_x,1
/ flat_x,1
__bootstrap_inner,1
__target,1
__args,1
__kwargs,1
flatx,1
principal_components,1
aligned,1
consume,1
francois,1
"@jwgu

>",1
train_y1,1
train_y2,1
tensorboard_verbose=3,1
[train_y1,1
train_y2],1
n_epoch=1,1
x_np = [[0,1
x_np,1
y_np = [[1,1
y_np,1
callbacklist,1
accessible,1
accessing,1
"�

@jiajiechen",1
scalability,1
@piiswrong,1
@kevinthesun,1
@yajiedesign,1
@howard0su,1
summation,1
second-,1
inbound_nodes,1
resnet50_arch,1
resnet50_weight,1
save_resnet_model,1
suddenly,1
mask_value,1
mask_value=0,1
inaccessible,1
completing,1
schedule_decay=0,1
uda_driver,1
"cuda_error_unknown

2017-10-30 21",1
uda_diagnostics,1
165] hostname,1
"<--omitted-->

1562/1562 [==============================]",1
701s,1
522s,1
516s,1
531s,1
506s,1
490s,1
487s,1
481s,1
482s,1
537s,1
553s,1
548s,1
480s,1
483s,1
488s,1
489s,1
492s,1
478s,1
479s,1
484s,1
477s,1
476s,1
475s,1
485s,1
474s,1
486s,1
539s,1
636s,1
521s,1
524s,1
505s,1
511s,1
532s,1
527s,1
512s,1
502s,1
518s,1
540s,1
507s,1
491s,1
500s,1
33314s,1
529s,1
832s,1
469s,1
8731s,1
535s,1
omitted,1
keras_cifar10_trained_model,1
underfitting,1
save_dir,1
queue_size,1
straightforward,1
effected,1
clue,1
predictions5,1
predictions5[,1
ilsvrc2015_clsloc_validation_ground_truth,1
readlines,1
map_clsloc,1
groundtruth,1
ssd_utils,1
6gb ],1
5gb/15,1
tldr,1
pleasant,1
libcuda,1
format_exc,1
led,1
apnamodel,1
label_train_tranformed,1
label_val_tranformed,1
label_test_tranformed,1
score1,1
score2,1
cobbled,1
kern,1
filter_dilation,1
im0,1
bounds,1
2are,1
gigabytes,1
equate,1
bafflingly,1
moondra,1
keras_transfer_learning_inception_without_image_generator,1
python36,1
ufunc,1
true_divide,1
typecode,1
coerced,1
same_kind,1
bests,1
embededfc,1
lstm_size,1
0x7fdddb8e1150>,1
0x7fdddafad4d0>],1
training_op,1
rhs,1
captures,1
guidance,1
[y1_targets,1
y2_targets],1
axel,1
tensorboardcallback,1
deserves,1
gathered,1
reflect,1
reliable,1
overlapping,1
one_input,1
cleans,1
allocations,1
thunk,1
destructor,1
destructors,1
advancethis,1
mode_test,1
my_model_architecture,1
my_model_weights,1
amout,1
pca,1
evalute,1
num_train,1
num_test,1
# reporting,1
photos,1
a_reshape =,1
f_reshape =,1
e_a =,1
a_reshape,1
e_f =,1
f_reshape,1
e_l =,1
e_a,1
e_f,1
image_arr,1
fromarray,1
image_arr[0],1
image_arr[1],1
image_arr[2],1
y_mean,1
y_predict =,1
y_predict,1
"3

input_origin_img_arr =",1
input_origin,1
input_style_img_arr =,1
model_vgg,1
input_origin_img_arr,1
input_style_img_arr,1
hood,1
list_directory,1
path_data +,1
endswith,1
_2,1
_3,1
percent_dataset_validation,1
list_1,1
height_image_target,1
width_image_target,1
num_channels],1
num_clases],1
read_file_to_string,1
file_icc,1
/dobl/,1
file_dobl,1
/iobl/,1
file_iobl,1
[x_arr_dcc,1
conv2d_1_shared_cc,1
conv2d_2_shared_cc,1
conv2d_3_shared_cc,1
conv2d_4_shared_cc,1
conv2d_1_shared_obl,1
conv2d_2_shared_obl,1
conv2d_3_shared_obl,1
conv2d_4_shared_obl,1
num_channels,1
inputdcc,1
maxpool2d_1_dcc,1
maxpool2d_2_dcc,1
globalmaxpooling2d_dcc,1
inputicc,1
maxpool2d_1_icc,1
maxpool2d_2_cc,1
globalmaxpooling2d_icc,1
inputdobl,1
maxpool2d_1_dobl,1
maxpool2d_2_dobl,1
globalmaxpooling2d_dobl,1
inputiobl,1
maxpool2d_1_iobl,1
maxpool2d_2_iobl,1
globalmaxpooling2d_iobl,1
resultado,1
/checkpointmodel,1
install_,1
plat,1
strangest,1
i_var,1
variables_initializer,1
[tensor_op],1
"```

failedpreconditionerror",1
uninitialized,1
edge_1461_mul_32,1
charm,1
obviusly,1
heatmap,1
softmaxmap,1
youi,1
slice_,1
concat_all,1
slice_test,1
/slice_test2,1
co_name,1
artifacts,1
distortions,1
emptied,1
[149_resized],1
[149_0x3generated],1
149_resized,1
newx = [255,1
newx[0],1
tweaks,1
img_height = 299,1
"299

train_data_dir =",1
keras_transfer_learning_inception_problem_one_epoch,1
38s,1
12s,1
`recurrent_dp_mask`,1
incorrectif,1
appeared,1
intend,1
conditions,1
lstmcould,1
discusses,1
info_length,1
in_sentence,1
hidden_dim_1,1
embedded_sentence,1
[in_sentence,1
max_sentences,1
hidden_dim_2,1
#stuck,1
normalizing,1
datapoints,1
shifting,1
formated,1
leed,1
epchs=100,1
reccomend,1
greatfull,1
illustrations,1
youhello,1
snip2code,1
n_in,1
n_out,1
nb_hidden_layers[,1
nb_hidden_layers[1,1
%s_model,1
%s_w,1
nb_hidden_layers[-1],1
weights_ckpt1,1
color_type=1,1
csvlog],1
weights_ckpt2,1
pickled,1
`weights_ckpt1`,1
dependence,1
3dconv,1
medels,1
alani,1
terrain,1
lastly,1
min_size=48,1
block1_conv2,1
block1_pool,1
block2_conv1,1
block2_conv2,1
block2_pool,1
block3_conv1,1
block3_conv2,1
block3_conv3,1
block3_pool,1
block4_conv1,1
block4_conv2,1
block4_pool,1
regression_dense,1
interests,1
coordinating,1
replacement,1
_consumers,1
consumer_inputs = [,1
swap_inputs,1
consumer_inputs,1
pl_a,1
_feed_loss_fns[0],1
_feed_outputs[0],1
reward_if_correct,1
punishment_if_false,1
substracts,1
grasp,1
lotrunning,1
validity,1
2 48 53 pm],1
h_t-1,1
var_exists =,1
locals,1
var_exists,1
iv3,1
userblock_size,1
/m6ynh3bn6tq06h7xr3js0z7r0000gn/,1
eof = 1458176,1
stored_eoa = 58889256,1
defualt 3,1
nb_filter1,1
nb_filter2,1
_branch,1
bn_name_base =,1
2a,1
=bn_name_base +,1
2b,1
2c,1
color_type,1
#NAME?,1
fc1000,1
# truncate,1
fc10,1
res5b_branch2b,1
res5b_branch2c,1
res5c_branch2a,1
res5c_branch2b,1
res5c_branch2c,1
eof = 98304,1
stored_eoa = 102853048,1
deleted,1
"3285

pcibusid 0000",1
"65gib

2017-11-20 21",1
976] dma,1
res2a_branch2a,1
res2a_branch2b,1
res2a_branch2c,1
res2b_branch2a,1
res2b_branch2b,1
res2b_branch2c,1
res2c_branch2a,1
res2c_branch2b,1
res2c_branch2c,1
res3a_branch2a,1
res3a_branch2b,1
res3a_branch2c,1
res3a_branch1,1
res3b_branch2a,1
res3b_branch2b,1
res3b_branch2c,1
res3c_branch2a,1
res3c_branch2b,1
res3c_branch2c,1
res3d_branch2a,1
res3d_branch2b,1
res3d_branch2c,1
res4a_branch2a,1
res4a_branch2b,1
res4a_branch2c,1
res4a_branch1,1
res4b_branch2a,1
res4b_branch2b,1
res4b_branch2c,1
res4c_branch2a,1
res4c_branch2b,1
res4c_branch2c,1
res4d_branch2a,1
res4d_branch2b,1
res4d_branch2c,1
res4e_branch2a,1
res4e_branch2b,1
res4e_branch2c,1
res4f_branch2a,1
res4f_branch2b,1
res4f_branch2c,1
res5a_branch2a,1
res5a_branch2b,1
res5a_branch2c,1
res5a_branch1,1
res5b_branch2a,1
producer,1
grabbed,1
quoting=3,1
textfile,1
ev,1
todf,1
topandas,1
cid,1
train_seq,1
sequencer,1
1880cb95a742,1
jan 16 2017,1
model1_arch,1
arch_file,1
model2_arch,1
model1_weights,1
"928

pcibusid",1
"35gib

2017-11-19 17",1
model2_weights,1
allow_tensor,1
p2,1
dominated,1
7 memoryclockrate,1
"8235

pcibusid",1
"11gib

2017-11-19 08",1
"53

pcibusid",1
"36gib

2017-11-19 08",1
576s,1
getlogger,1
basicconfig,1
asctime,1
levelname,1
dump_stats,1
expanduser,1
pstats,1
newbie,1
acquired,1
recurrent_kernel,1
cell_state,1
xn,1
yn,1
y0,1
convlutional_recurrent,1
all_outputs,1
constructs,1
pointers,1
c3 =,1
c3 == 0,1
e4,1
involves,1
file1,1
test_error =,1
persisting,1
filtered_layers,1
gridsearcv,1
12l,1
3l,1
256l,1
65536l,1
4l,1
numberofimages,1
numberoflabels,1
8l,1
talking,1
5l,1
seeding,1
array_equal,1
layers_name,1
train_img_path,1
iteritems,1
hundrands,1
killed,1
mask_value=-1,1
input_dimension,1
hidden_neurons_number,1
hidden_layers-1,1
output_dimension,1
expected_output,1
generated_performance =,1
[obraz],1
stabilized,1
generations,1
conv_output,1
boosting,1
inspection,1
`test_on_batch`,1
resulted,1
`make_train_function,1
learns,1
292s,1
290s,1
293s,1
291s,1
toc,1
anchors,1
sequen,1
disc,1
assumption,1
shr,1
preference,1
ypred,1
supplied,1
ylabel},1
get_pred,1
get_true,1
smarter,1
achieving,1
surprised,1
kerras,1
interpreting,1
phased_lstm_keras,1
pathsep +,1
/graphviz2,1
getforegroundwindow,1
showwindow,1
win32con,1
sw_maximize,1
xema_,1
rnn_csv_toxy,1
atr,1
max_momentum=0,1
training_log3_209_lstm_sgd,1
gpu0,1
xema_},1
"val_mean_absolute_error



0",1
superior,1
cuboid_dim[0],1
cuboid_dim[1],1
cuboid_dim[2],1
reduced_data =,1
reduced_data,1
getdata,1
embedding_6,1
"0         

conv1d_4",1
"37750     

global_max_pooling1d_5",1
"0         

activation_5",1
"0         

dense_7",1
"251       

activation_6",1
assumed,1
minute_,1
150x150x3,1
my_input_dir,1
traindata,1
tgz,1
bottleneck_tensor_name =,1
truncated_normal_initializer,1
variable_scope,1
conv_maxpool_%,1
# [filter_height,1
get_variable,1
constant_initializer,1
bias_add,1
max_pool,1
ksize=[1,1
tty,1
redirected,1
isatty,1
56s,1
32s,1
23s,1
11s,1
10s,1
9s,1
avoided,1
identified,1
set_subtensor,1
costs_embd_size,1
h_search,1
ones_like,1
gpureshape{2},1
gpureshape{1},1
n0001,1
syncthreads,1
n0002,1
n0003,1
n0004,1
n0005,1
n0006,1
n0007,1
n0008,1
n0009,1
#endif,1
n0010,1
0x7fffffff,1
n0011,1
n0012,1
n0013,1
n0014,1
0x7f800000,1
n0015,1
n0016,1
n0017,1
n0018,1
n0019,1
n0020,1
n0021,1
n0022,1
n0023,1
n0024,1
n0025,1
n0026,1
n0027,1
n0028,1
n0029,1
n0030,1
n0031,1
n0032,1
n0033,1
n0034,1
n0035,1
n0036,1
n0037,1
n0038,1
n0039,1
n0040,1
n0041,1
__half2float,1
n0042,1
n0043,1
n0044,1
n0045,1
n0046,1
n0047,1
n0048,1
n0049,1
doubles,1
n0050,1
n0051,1
n0052,1
n0053,1
n0054,1
n0055,1
= *address_as_ull,1
n0056,1
n0057,1
assumed =,1
n0058,1
#NAME?,1
address_as_ull,1
n0059,1
_double_as_longlong,1
n0060,1
n0061,1
n0062,1
n0063,1
n0064,1
n0065,1
n0066,1
n0067,1
__double_as_longlong,1
n0068,1
n0069,1
n0070,1
n0071,1
n0072,1
n0073,1
n0074,1
n0075,1
n0076,1
n0077,1
n0078,1
n0079,1
n0080,1
n0081,1
n0082,1
n0083,1
n0084,1
n0085,1
byte_perm,1
n0086,1
0x4432,1
0x4410,1
n0087,1
#NAME?,1
0x5410,1
0x3254,1
n0088,1
n0089,1
n0090,1
n0091,1
n0092,1
n0093,1
n0094,1
n0095,1
n0096,1
n0097,1
n0098,1
n0099,1
n0100,1
#NAME?,1
n0101,1
n0102,1
n0103,1
__byte_perm,1
n0104,1
n0105,1
n0106,1
n0107,1
n0108,1
n0109,1
n0110,1
n0111,1
n0112,1
n0113,1
n0114,1
n0115,1
n0116,1
n0117,1
n0118,1
n0119,1
n0120,1
n0121,1
n0122,1
n0123,1
n0124,1
n0125,1
n0126,1
n0127,1
n0128,1
n0129,1
n0130,1
n0131,1
n0132,1
n0133,1
n0134,1
n0135,1
n0136,1
n0137,1
n0138,1
n0139,1
n0140,1
n0141,1
n0142,1
n0143,1
n0144,1
n0145,1
n0146,1
n0147,1
n0148,1
n0149,1
n0150,1
n0151,1
n0152,1
ndefault_program,1
default_program,1
compulsory,1
`batch_input_size`,1
hardwire,1
num_dim,1
make_classification,1
n_informative=2,1
n_redundant=10,1
terminate,1
"__bootstrap_inner

>",1
ft_generator,1
153m,1
trainging,1
15m,1
150m,1
"15n

734/55522 [",1
getrusage,1
rusage_self,1
ru_maxrss,1
testindex,1
inputvalue,1
inputvalue[,1
physics,1
regardsi,1
n_steps,1
= [ [elem],1
elem,1
intent,1
maxpooling4d,1
xyzt,1
pity,1
random_zoom,1
distortion,1
zooming,1
index_generator,1
predhis`,1
predhis = [],1
predhis,1
stale,1
august,1
closest,1
circumvent,1
convent,1
derivative,1
chuan,1
# replicates,1
test_multi,1
imagedatageneratori,1
4.30E+03,1
4.21E+03,1
8.78E+04,1
9.92E+04,1
1.45E+04,1
4.26E+04,1
9.42E+04,1
6.03E+04,1
7.00E+04,1
1.63E+04,1
4.32E+04,1
4.36E+04,1
1.37E+04,1
4.63E+03,1
7.84E+04,1
7.19E+03,1
7.77E+03,1
3.52E+04,1
3.66E+04,1
9.48E+04,1
7.09E+04,1
7.68E+04,1
9.89E+03,1
1.04E+04,1
1.37E+04,1
1.56E+04,1
3.14E+04,1
6.17E+04,1
5.33E+04,1
3.24E+04,1
4.23E+04,1
3.14E+04,1
9.68E+04,1
1.45E+03,1
9.65E+04,1
5.56E+04,1
8.07E+04,1
6.96E+04,1
1.20E+04,1
7.61E+04,1
9.88E+04,1
1.41E+04,1
1.56E+04,1
2.72E+02,1
9.23E+03,1
9.34E+04,1
3.09E+04,1
2.01E+03,1
8.97E+03,1
4.12E+04,1
2.08E+04,1
4.11E+04,1
6.22E+03,1
6.37E+04,1
4.59E+04,1
5.79E+03,1
1.49E+04,1
1.01E+04,1
5.68E+03,1
6.16E+04,1
7.61E+04,1
3.39E+04,1
6.31E+04,1
54670889e-03]],1
p_conv1,1
to_file =,1
[train_y_p,1
train_y_v],1
thwhat,1
scene,1
debugger,1
0xa**,1
impacting,1
replicated,1
0x7f836c66f4d0>],1
0x7f836c61cfd0>],1
imgs,1
dealing,1
bucketing,1
upd,1
loops,1
0-dev20171031,1
obscure,1
cosine_distance,1
stacks,1
">

apologies",1
deals,1
backs,1
"stopped

3",1
backup,1
enthusiasm,1
stat,1
startswith,1
fmeasure,1
isnan,1
isinf,1
begining,1
inclusion,1
invest,1
enhancement,1
offer,1
avoiding,1
exploit,1
dropout_keep_prob,1
47s,1
consideration,1
39 feautres,1
dimensionalty,1
affecting,1
/aeec5b2a6efb1090375d4211aabbed6f,1
90mb,1
180mb,1
duplicating,1
noisy,1
oversample,1
tdnn,1
proportional,1
train_loc,1
"````

```

model_final",1
__getitem___,1
/002test/*,1
pred_acc,1
## intro,1
[`recurrentattentioncellwrapperabc`],1
_loss_,1
_layer,1
injected,1
another_,1
consist,1
compose,1
[`functionalrnncell`],1
`mixtureofgaussian1dattention`,1
regularisers,1
_inject_,1
motivate,1
boilerplate,1
cascading,1
attended,1
solving,1
todos,1
`recurrentattentioncellwrapperabc`,1
rectify,1
assign_placeholder,1
_variable,1
time_len=1,1
ch,1
#NAME?,1
#NAME?,1
store_true,1
set_defaults,1
val_port,1
outfile,1
w_min =,1
w_max =,1
w_avg =,1
w_std =,1
4f %,1
4f,1
w_min,1
w_max,1
w_avg,1
w_std,1
"0556

    batch_normalization_2

    0",1
"0003

    batch_normalization_3

    1",1
sub_sequence_length,1
seq_len =,1
sub_sequence_length*,1
seq_len*,1
train_resnet50_video,1
code311016,1
resnet50video,1
koko,1
expressions,1
_frame,1
map_partitions,1
set_use_numexpr,1
inconsistency,1
**noisy**,1
tweaking,1
[zaremba,1
exercise,1
[icoxfog417,1
_crossentropy_,1
slipping,1
pow`,1
vocab_len,1
train_file,1
valid_file,1
test_file,1
validx,1
validy,1
traini,1
npz,1
validi,1
testi,1
4rc1,1
eye_like,1
get_variable_shape,1
ergys,1
twodim_base,1
hardcode,1
infer `,1
locations,1
conditionally,1
regrouped,1
remplace,1
polynomials,1
thankshello,1
permute_dimensions,1
hints,1
residuals,1
flow_from_dir,1
cars,1
communitysince,1
pansharpening,1
5504                          valid_loss= 0,1
2316 train_loss_numpy= 0,1
2316 valid_loss= 0,1
2229 valid_loss_numpy= 0,1
1728                          valid_loss= 0,1
1607 train_loss_numpy= 0,1
1607 valid_loss= 0,1
1623 valid_loss_numpy= 0,1
1588                          valid_loss= 0,1
1427 train_loss_numpy= 0,1
1427 valid_loss= 0,1
1447 valid_loss_numpy= 0,1
2506                          valid_loss= 2,1
0028 train_loss_numpy= 0,1
1761 valid_loss= 2,1
0081 valid_loss_numpy= 0,1
8969                          valid_loss= 1,1
7805 train_loss_numpy= 0,1
1294 valid_loss= 1,1
7843 valid_loss_numpy= 0,1
6961                          valid_loss= 1,1
5888 train_loss_numpy= 0,1
1191 valid_loss= 1,1
5916 valid_loss_numpy= 0,1
usages,1
approximating,1
consistency,1
get_size,1
analogous,1
adjusted,1
ben,1
[/image_input,1
n_rnn,1
image_input,1
json_model_definition_path,1
0x00000000103b3b38,1
"`



**_hi",1
critical,1
nb_feat,1
inner_dim,1
nb_output,1
nb_class,1
clipvalue=0,1
get_updates_and_outputs,1
y_pred_step,1
y_true_step,1
f_skip_idxs,1
log_f_curr,1
log_f_prev,1
smoothed_predict =,1
smoothed_predict,1
log_b_curr,1
log_b_prev,1
b_active_next,1
log_f_probs,1
log_b_probs],1
log_first,1
log_first],1
dimshuffle,1
log_p_curr,1
log_p_prev,1
log_p_prev[,1
inc_subtensor,1
log_p_curr[,1
tf_deletestatus,1
my_command],1
/ hacks,1
//ydwen,1
update_centers],1
keep_prob,1
diagramming,1
foundation,1
tweak,1
orders,1
1000x1,1
10x1,1
/2deev,1
epoch_len,1
y_train_new,1
x_train_new,1
x_val_new,1
make_parallel,1
helping,1
transcribed,1
nonstateful_model,1
incoming_tensor =,1
incoming_tensor,1
2 hops,1
cad60,1
dog_,1
_fox,1
lazy_,1
//aclweb,1
unstable,1
newcomers,1
clarified,1
explaining,1
liberty,1
prototyping,1
explode,1
regarded,1
patch1,1
patch2,1
patch3,1
degree,1
presenten,1
becouse,1
kreas,1
cbk,1
valueable,1
dilates,1
pardon,1
correlations,1
sequence_1,1
sequence_2,1
correlate,1
analyzed,1
credit,1
presently,1
predicted_data,1
true_data,1
facecolor=,1
white,1
add_subplot,1
seq_len = 30,1
x_train_a,1
y_train_a,1
x_test_a,1
sequence_a,1
x_train_b,1
y_train_b,1
x_test_b,1
sequence_b,1
x_train_c,1
y_train_c,1
x_test_c,1
sequence_c,1
x_train_d,1
y_train_d,1
x_test_d,1
sequence_d,1
[x_train_a,1
x_train_d],1
[y_train_a,1
y_train_d],1
[x_test_a,1
x_test_d],1
filterwarnings,1
normalise_window,1
window_data,1
normalised_window = [,1
normalised_window,1
plenty,1
#NAME?,1
wanna,1
convolve,1
#NAME?,1
theano_flags=,1
regularization_coef,1
assistance,1
[padding_strides_transposed],1
curves,1
nb_samples],1
training_label,1
training_traces,1
nb_traces_test,1
key_id,1
[nb_traces_test,1
[nb_traces_test],1
testing_label,1
testing_traces,1
nb_traces_test],1
to_categorical_y_train,1
to_categorical_y_test,1
classe,1
examoe,1
[input_img_1,1
input_img_2],1
colliculus_proto,1
train_dir_1,1
train_dir_2,1
test_dir_1,1
test_dir_2,1
0x7f824c5080f0>,1
randomwindowinputfn,1
"12

seconde",1
custom_crossentropy,1
categorical_crossentrop,1
basicly,1
input_node,1
index_second,1
"tensorvariable

2",1
coding_dist,1
utilise,1
val_dir =,1
features_train,1
val_dir,1
features_val,1
get_bottleneck_features,1
train_path,1
sd,1
144s,1
"00       600

       c_16       0",1
"00       600

       c_24       0",1
"00       600

       c_25       0",1
"00       600

       c_28       0",1
"00       600

        c_3       0",1
"00       600

       c_30       0",1
"00       600

       c_32       0",1
"00       600

       c_33       0",1
"00       600

       c_35       0",1
fantastic,1
keiron,1
feature_map,1
feature_map_size=8,1
kernerl_size=,1
feature_map_size,1
kernerl_size,1
univariate,1
timestep_overlap,1
timestep_overlap =,1
encoding_dim = 2,1
encoding_dim,1
20x20,1
[tr_pairs[,1
tr_pairs[,1
[te_pairs[,1
te_pairs[,1
defaulting,1
preproccesing,1
notfounderror,1
prunefortargets,1
"group_deps 

```",1
multithreading,1
reformulate,1
"+ object_name +

         86",1
kernel_arr,1
bias_arr,1
104   const_tensor =,1
"]

      tk",1
>>> tk,1
[xtest1,1
xtest2],1
x_xtest2],1
signify,1
involuntarily,1
ceiled,1
merit,1
drives,1
correction,1
propose,1
runned,1
abhijith,1
bhat,1
onedrive,1
accenture,1
udacitydlnd,1
knowi,1
packed,1
rand_pix,1
unify,1
test_keras_fit_generator,1
embedding_dimensionality,1
vocabulary_size,1
qry_input,1
doc_plus_input,1
doc_minus_input,1
qry_plus,1
qry_minus,1
confuse,1
hidden_neurons,1
salt,1
visualizing,1
time_stamp,1
eliminate,1
`pretrained_word_embedding`,1
stopped,1
validating,1
experienced,1
einsum,1
incompatibilities,1
8in,1
desirable,1
unexplainable,1
gradientdescentoptimizer,1
xavier_initializer,1
sparsetensor,1
sparse_tensor_dense_matmul,1
logit,1
train_error = -,1
train_error,1
"```



tl",1
tocoo,1
resort,1
phenomena,1
//devblogs,1
excited,1
~11s,1
destructive,1
essential,1
discussions,1
**wordy**,1
ruuning,1
rdd,1
threw,1
heavily,1
stress,1
proved,1
sign,1
aborting,1
devil,1
glad,1
organized,1
batchindex,1
timestepindex,1
dimentionindex,1
//machinelearningmastery,1
0-py2,1
essence,1
output_binary,1
intermediate_dense,1
1391         _check_loss_and_target_compatibility,1
existing_classes,1
existing_class_weight,1
traced,1
y_in_service_indicator,1
o_,1
"```

y_s_binary = []",1
y_s_binary,1
y_in_service_indicator[,1
x_intervals,1
feels,1
outpus,1
0c,1
"99074af 100644

---",1
docstring,1
advances,1
30 secs,1
5h,1
concatenates,1
num_batch,1
deep_classifier,1
metrics_names[0],1
loss_train[0],1
loss_train[1],1
metrics_names[2],1
loss_train[2],1
miss,1
local_connect,1
dense3_2 =,1
dense3_2,1
dense3_3 =,1
dense3_3,1
dense3_4 =,1
dense3_4,1
dense3_5 =,1
dense3_5,1
dense3_6 =,1
dense3_6,1
dense3_7 =,1
dense3_7,1
dense3_7],1
dense3_7`,1
mothed],1
letting,1
udemy,1
get_output_at,1
`val_categorical_accuracy`,1
`val_weighted_categorical_accuracy`,1
represented,1
rapported,1
"0

regularizerl1 =",1
num_h,1
regularizerl1,1
numerolayers,1
1.00E+07,1
e-6,1
advancehi,1
cntk_reverse,1
cntk_axes,1
begin_index,1
end_index,1
splice100_output_0,1
primitivefunction,1
inferoutputs,1
initoutputs,1
compositefunction,1
ascomposite,1
unaryop,1
primitiveoptype,1
outcomes,1
caption_model],1
0x7f8ba413e9e8>,1
0x7f8b9dcddf28>],1
dataset_train_directory,1
subdir,1
_map_async,1
chunksize,1
_count_valid_files_in_directory,1
subpath,1
memoryerrori,1
scenes,1
confirmed,1
awry,1
ultimately,1
enlarge,1
setrecursionlimit,1
30 mins,1
wd,1
0beta2,1
dnnrect_vc_vc_challenge,1
/dnnerect_25/,1
doc_words,1
lstm_in,1
label_train,1
data_test,1
label_test,1
reconstructed,1
originals,1
variability,1
jitters,1
jitter,1
pypermute,1
lenovo,1
friends,1
cero,1
accomplishing,1
models_path,1
w_f,1
w_c,1
w_o],1
lstm_1_w_i,1
"logf4

>>>```",1
gcs,1
workaroud,1
mitigate,1
thanksis,1
hours  =,1
load_mnist,1
x_train_batch,1
num_threads=8,1
tfrecordreader,1
parse_single_example,1
fixedlenfeature,1
tfrecords,1
string_input_producer,1
randomshufflequeue,1
dt_int64],1
timeout_ms=-1,1
beginnings,1
setups,1
#NAME?,1
averaged,1
inoperable,1
val_sample_weights,1
bcolz,1
hd5store,1
actor_target_weights =,1
critic_target,1
actor_target_weights,1
actor_target_weights[,1
] = actor_model_weights[,1
nb_param],1
pv,1
raw_data,1
smooted_data,1
downsampled_data,1
n_smooth,1
history_length,1
n_stock,1
nb_row=,1
k_w,1
nb_col=1,1
n_down,1
firstclstmv2,1
dim1,1
dim2,1
outvectorlen,1
colour,1
communicate,1
suggets,1
truncating=,1
p_i,1
p_j,1
d_kl,1
//ideone,1
/qwqdvf,1
_units_,1
caffee,1
berkeleyvision,1
inputting,1
truncating,1
train_image_generator,1
train_mask_generator,1
current_batch_size,1
image_shape,1
0001tp_006690_raw,1
0001tp_006690_mask,1
pyi,1
scrath,1
256x256,1
upped,1
"10198757376

inuse",1
"10029289984

maxinuse",1
"10029289984

numallocs",1
"149

maxallocsize",1
3506470912suppose,1
context_num,1
context_num * 262],1
[context_num * 262,1
lstm_training_data,1
nb_worker=1,1
247] poolallocator,1
32661942s,1
30636020s,1
img_height = 350,1
00000000e+00   1,1
00000000e+00   2,1
"31831675e-26]]

[[  1",1
00000000e+00   4,1
"62001088e-27]]

[[  1",1
"61389520e-27]]

[[  1",1
"85950715e-27]]

[[  1",1
"34395772e-27]]

[[  1",1
00000000e+00   6,1
"68413629e-25]]

[[  1",1
00000000e+00   5,1
"57866408e-28]]

[[  1",1
"55804569e-22]]

[[  1",1
00000000e+00   9,1
"38219268e-26]]

[[  1",1
"81696856e-27]]

[[  1",1
00000000e+00   3,1
"03054745e-27]]

[[  1",1
"63251077e-27]]

[[  1",1
"44115877e-27]]

[[  1",1
"06371315e-25]]

[[  1",1
"67070906e-27]]

[[  1",1
"45051359e-26]]

[[  1",1
"16351225e-23]]

[[  1",1
hinting,1
_concat_v2,1
input_ib-0,1
superceded,1
projected,1
words_per_epoch *,1
val_split,1
img_w,1
img_h,1
conv_filters,1
max1,1
max2,1
img_w //,1
img_h //,1
* conv_filters,1
# cuts,1
time_dense_size,1
gru1_b,1
gru2_b,1
img_gen,1
get_output_size,1
test_func =,1
run_name,1
test_func,1
next_val,1
train_input_length,1
train_labels_length,1
test_input_length,1
test_labels_length,1
#NAME?,1
/ocr_bangladata,1
pkl,1
my_data,1
my_labels,1
val_x =,1
_slice_arrays,1
val_y =,1
val_sample_weights =,1
predict_name,1
predict_text_data_dir,1
predict_fname,1
isdigit,1
version_info <,1
"]

                predict_texts",1
predict_texts,1
inner-,1
leaves,1
"299 

export_path =",1
tf_weights_path =,1
/top_model_weights-00-0,1
tf_weights_path,1
export_path,1
serving,1
serving 1,1
vijay,1
ffmpeg,1
moviepy,1
full_cnn_model,1
dstack,1
addweighted,1
proj_reg_vid,1
project_video,1
fl_image,1
write_videofile,1
draw_detected_lanes,1
kwarg,1
8-py2,1
misspelled,1
"1

statsmodels",1
user_data[,1
resize_image_to,1
pyfpe_jbuf,1
posts,1
slurm,1
imported,1
surprises,1
redefine,1
"`



thankshello",1
wrapper_input,1
wrapper_step,1
refered,1
exploring,1
snag,1
rebuilding,1
guts,1
paramshi,1
influence,1
random_integers,1
xrange,1
bonus,1
outdated,1
z0 =,1
recurrent_activation,1
z0,1
* c_tm1 +,1
kernel_i,1
kernel_f,1
kernel_c,1
kernel_o,1
bias_o,1
recurrent_kernel_i,1
recurrent_kernel_f,1
recurrent_kernel_c,1
recurrent_kernel_o,1
href=,1
codecogs,1
/eqnedit,1
php,1
_blank,1
/gif,1
actiondim,1
batchsisze,1
clildinputdim,1
statetensor,1
stateplaceholder],1
_step,1
actionprofile,1
initialstate,1
child_output_shape =,1
child_output_shape[0],1
+ child_output_shape[1,1
acitoninput,1
n_batch_size,1
num_features,1
`metrics_test,1
y_a =,1
y_b =,1
all_metrics,1
y_a,1
y_b,1
hadi,1
years,1
googleblog,1
act4,1
compilable,1
interpretation,1
converse,1
diverse,1
`shape1 = [,1
resporistory,1
ld_library_path,1
risk,1
hdf5_disable_version_check,1
headers,1
"18

                  configured",1
"2017-03-06

                  configured",1
cmake 3,1
am_cflags,1
cppflags,1
h5_cppflags,1
am_cppflags,1
ldflags,1
ranlib,1
languages,1
threadsafety,1
v18,1
dmalloc,1
bye,1
permutations,1
elementary,1
data_set,1
company_id,1
title_id,1
skill_id,1
train_iterator,1
activation_49,1
concat_axis=-1,1
timedistribu,1
recurrent_kernel =,1
nstreams,1
headline,1
attend,1
headlines,1
head_input,1
docs_word_input,1
max_sents_docs,1
kullback_leibler_divergence,1
[x_train_head,1
x_train_doc],1
sums,1
w_s =,1
{}_w_s,1
w_topic =,1
{}_w_topic,1
w_m =,1
{}_w_m,1
w_s,1
w_topic,1
#NAME?,1
outputted,1
scripting,1
6588epoch 00000,1
"hd5

63/62 [==============================]",1
159s,1
961] dma,1
"cudnn_status_not_initialized

2017-08-30 11",1
unimplemented,1
"cudnn_status_bad_param

2017-08-30 11",1
0xc0000409,1
_solved_,1
approaching,1
cut_size*2,1
cut_size,1
mean_absolute_percentage_error,1
yesterday,1
~3000s,1
processor,1
mkl,1
ipynbhi,1
focus,1
osp,1
weight_file =,1
output_graph_name =,1
age_weight_two,1
tensorflow_model/,1
write_graph_def_ascii_flag,1
only_the_graph_def,1
convert_variables_to_constants,1
graph_io,1
constant_graph,1
output_graph_name,1
"]]

unable",1
dm,1
merge_mode,1
forward_,1
drill,1
outx,1
embdim,1
outx =,1
[outx,1
tensorsharedvariable,1
spirit,1
mikolov,1
vutbr,1
voc_size,1
reckon,1
producing,1
wished,1
sake,1
simplicity,1
proving,1
/vwpwx,1
0048epoch 00149,1
art_daily_no_noise,1
[lstm_artificial],1
alyways,1
get_default_session`,1
default_session,1
blow,1
global_session,1
worry,1
"1

right_crop  = 0",1
right_crop,1
float_data,1
reorganise,1
temp_image,1
measurement,1
seek,1
x_all,1
y_all,1
27737s,1
27723s,1
27709s,1
27696s,1
stochastically,1
naive,1
abstractconv3d_gradinputs`,1
donglaii,1
_do,1
want_,1
gpujoin,1
gpufromhost<,1
gpuarraytype<,1
[[gpureshape{2},1
img_height = 300,1
"225

train_data_dir =",1
val_data_dir =,1
val_data_dir,1
150808x218,1
complain,1
model_height,1
model_width,1
conv1_1,1
conv1_2,1
tensorflow_py35,1
remib,1
zero_padding2d_1_input,1
theano_py35,1
concatenate_71,1
up_sampling2d_30,1
illustrate,1
remembered,1
tim,1
randomize,1
lables,1
phasing,1
62276675e-03  -4,1
01115604e-03   5,1
02156140e-03   1,1
"97147974e-03

         7",1
38522829e-03   5,1
62763307e-03   2,1
18000403e-03   8,1
"19381850e-04

         7",1
11255067e-04  -5,1
42447111e-03   4,1
71341610e-03  -9,1
"23852995e-03

         8",1
90769251e-03   5,1
24031650e-03   5,1
27720852e-03   5,1
"26314508e-03

         6",1
20147912e-03   3,1
62612633e-03   4,1
85892594e-03  -2,1
"66220560e-03]

      [ -6",1
73649739e-03  -2,1
59472057e-04   5,1
75539097e-03   6,1
"66894065e-03

         1",1
10127367e-02   2,1
46753707e-03  -2,1
99500511e-03  -3,1
"73128545e-03

        -5",1
83201367e-03  -4,1
31951787e-03   1,1
44616829e-03  -6,1
"58686040e-03

         4",1
14082780e-03   1,1
14090310e-03  -8,1
29242985e-04   5,1
"53416228e-03

        -4",1
11105895e-04   2,1
87892064e-03   3,1
62366205e-04  -7,1
"94248248e-04]

      [ -5",1
54567296e-03   1,1
15430041e-03   3,1
27830086e-03   4,1
"12886823e-03

         6",1
78183092e-03   1,1
79559551e-03  -1,1
80174352e-03  -3,1
"33251758e-03

        -5",1
29490225e-03  -3,1
05411895e-03   0,1
00000000e+00   0,1
"00000000e+00

         0",1
"00000000e+00]]

    

     [[ -4",1
98074247e-03   9,1
01466759e-04   3,1
40987043e-03  -3,1
"25349579e-03

         9",1
21981584e-04   5,1
99770434e-03   1,1
67222356e-03   2,1
"20844080e-03

         4",1
45439760e-03  -3,1
40889138e-03   7,1
48059654e-04  -7,1
"22813362e-04

        -8",1
83788511e-04  -6,1
78786746e-05   2,1
53343279e-03   6,1
"05521607e-04

        -1",1
31173420e-03   2,1
08991882e-03  -1,1
15431065e-03   2,1
"35650165e-04]

      [ -3",1
34386993e-03   1,1
24489667e-03   1,1
97105715e-03  -2,1
"06982507e-03

         9",1
56661941e-04   4,1
27589752e-03   9,1
54369374e-04   1,1
"84580882e-03

         2",1
93672620e-03  -2,1
59263976e-03   0,1
"00000000e+00]

      [ -2",1
26694648e-03   1,1
35568588e-03   1,1
10661483e-03  -1,1
"33866596e-03

         8",1
82549793e-04   3,1
03406548e-03   4,1
88151883e-04   1,1
"53438631e-03

         1",1
89515646e-03  -2,1
01789290e-03   0,1
"00000000e+00]]]

```",1
prelu1,1
alpha_constraint=,1
prelu2,1
prelu3,1
prob1,1
p_net,1
alpha_constraint,1
_methods,1
atrticles,1
rapidly,1
dir_path,1
dataxs,1
dataxs[,1
dadahi,1
n_timestamp = 100,1
[n_timestamp = 100,1
samp,1
# => samp,1
"```



filing",1
min_siam,1
#NAME?,1
pic_dir,1
pr_type,1
/wpxmwsr,1
pic_dir =,1
tr_pairs,1
te_pairs,1
recurrent_initializer=,1
pls,1
seemingly,1
studying #439,1
`model_to_json`,1
workstation,1
faqs,1
vaes,1
//dm,1
snu,1
deeplearning4j,1
flattens,1
categorical_cross_entropy,1
[_20170815163337],1
18707s,1
5729s,1
3840s,1
3082s,1
2701s,1
2447s,1
resorted,1
load_size,1
sm_446217920,1
cuda8,1
outout,1
squash,1
iterating,1
gpucontiguous,1
conv_mode=,1
[cudandarraytype,1
cudandarraytype,1
0x7fe361684e50>,1
0x7fe351dcef60>,1
[[gpureshape{6},1
cnmem_status_out_of_memory,1
hogs,1
11gb,1
/forum/#,1
img_frame = 100,1
"15



train_file_name =",1
val_file_name =,1
img_frame,1
reshaped_c0_y,1
reshaped_and_scaled_image_x,1
feature_instance_shape,1
train_file_name,1
`~11gb`,1
millions,1
breakdown,1
2dconv,1
`img_frame`,1
input_encoded_c,1
input_encoded_c],1
story_maxlen,1
query_maxlen,1
overflows,1
dumb,1
possibilities,1
#NAME?,1
_timesteps_,1
788c56b,1
2 iterations,1
modelpath,1
weightspath,1
thanksthis,1
rebased,1
incorporated,1
indented,1
opens,1
writes,1
_feed_output_names,1
towers,1
examining,1
1 hour],1
warm-,1
aggregated,1
dataparallelmodel,1
derive,1
synchronization,1
`make_parallel,1
`dataparallelmodel`,1
route,1
inject,1
proxied,1
`*_on_batch,1
tsteps,1
nfeats,1
nclass,1
met,1
target_tensor =,1
target_tensor,1
#NAME?,1
5 + m2_loss * 0,1
m1_loss,1
m2_loss,1
minimized,1
tsv,1
binarizer,1
caching_device,1
variable_def,1
import_scope,1
unknown_shape,1
_tensortensorconversionfunction,1
herewith,1
h5py_objects,1
minonda,1
h5py_1474482825505,1
h5py_hl,1
_e,1
lapl=,1
_lapl,1
rectifying,1
lambdamodel,1
py2keras,1
weakref,1
0rc1,1
bleach,1
funcsigs,1
html5lib,1
markdown,1
mock,1
pbr,1
protobuf,1
pyyaml,1
setuptools,1
werkzeug,1
meantime,1
channel_axis],1
admissible,1
0tf,1
nader,1
mixed0,1
trainy_buy,1
`output_info`,1
borrowed,1
03832v1,1
circumvented,1
`identity_loss`,1
finds,1
proposals,1
restrictions,1
rsplit,1
list_item_to_convert,1
test_file =,1
list_item_train,1
list_item_test,1
theano_mod_helper,1
cuda_ndarray,1
cuh,1
cudnn_helper,1
#NAME?,1
#NAME?,1
malloc,1
cudandarray_host_strides,1
] = cudandarray_host_strides,1
cudnn_data_float,1
#NAME?,1
"{

49       pyerr_format",1
pyexc_runtimeerror,1
cudnngeterrorstring,1
"{

57     pyerr_format",1
pyexc_memoryerror,1
cudandarray_is_c_contiguous,1
"{

72     pyerr_setstring",1
pyexc_valueerror,1
78                                                     cudnn_data_float,1
79                                                     cudnn_tensor_nchw,1
"{

83     pyerr_format",1
previous_input_shape,1
previous_kerns_shape,1
previous_output_shape,1
previous_algo_set,1
previous_algo,1
previous_bwd_f_algo,1
previous_bwd_d_algo,1
conv_fwd,1
"{

159     pyerr_setstring",1
169   py_incref,1
cudandarray_prep_output,1
nb_dim,1
0 && cudandarray_copyfromcudandarray,1
"175 #endif

176 

177",1
cudandarray_dims,1
->devdata,1
179                                   cudandarray_size,1
#NAME?,1
"{

181       pyerr_format",1
183                    cudageterrorstring,1
c_set_tensornd,1
c_set_filternd,1
choose_algo,1
choose_algo_once,1
< nb_dim,1
&& same_shapes,1
"225         {

226           same_shapes &=",1
228           same_shapes &=,1
choose_algo_time,1
_handle,1
"{

257             pyerr_format",1
259                          cudnngeterrorstring,1
275             fprintf,1
cudageterrorstring,1
287                                                     cudnn_convolution_fwd_specify_workspace_limit,1
"{

292             pyerr_format",1
294                          cudnngeterrorstring,1
winograd,1
&& nb_dim == 4,1
"{

376         pyerr_format",1
378                      cudnngeterrorstring,1
input_h > 1024,1
"{

418       // fallback",1
"{

431       pyerr_format",1
433                    cudnngeterrorstring,1
441       _handle,1
cudandarray_dev_data,1
"{

452     pyerr_format",1
"members

488             //  3",1
pod,1
"pointers

489 

490             //",1
revise,1
tired,1
junk,1
494             memset,1
"495         }

496         ~__struct_compiled_op_ea4e203b6529466794536f8a1bfa77ae",1
"{

501             py_xincref",1
502 py_xincref,1
503 py_xincref,1
504 py_xincref,1
505 py_xincref,1
506 py_xincref,1
507 py_xincref,1
pyerr_occurred,1
550             pyerr_setstring,1
#NAME?,1
"{

563   pyerr_format",1
"{

568   pyerr_format",1
#NAME?,1
"{

573   pyerr_format",1
#NAME?,1
#NAME?,1
#REF!,1
#NAME?,1
#NAME?,1
#REF!,1
#NAME?,1
#NAME?,1
12-64/cuda_ndarray,1
cu,1
#NAME?,1
#NAME?,1
#NAME?,1
#NAME?,1
#NAME?,1
"{

623             __label_1",1
626 __label_3,1
629 __label_5,1
632 __label_7,1
635 __label_9,1
638 __label_11,1
641 __label_13,1
644 __label_16,1
predict_prob,1
"67232875e-09]

 [  9",1
"60892352e-06]

 [  2",1
02931948e-02   9,1
79706764e-01],1
89197075e-01   1,1
"08029414e-02]

 [  5",1
81803790e-04   9,1
"99418259e-01]

 [  1",1
08823024e-05   9,1
custom_activation,1
vectorize,1
# derivative,1
tout,1
rnd_name =,1
pyfuncgrad,1
registergradient,1
rnd_name,1
_mysquaregrad,1
gradient_override_map,1
pyfunc,1
rnd_name},1
op_scope,1
np_d_stepy_32,1
np_stepy_32,1
errror,1
ax_train,1
[ay_train_p,1
ay_train_s],1
ax_test,1
[ay_test_p,1
ay_test_s],1
output_power_loss,1
output_slack_loss,1
tf_keras,1
_sample_weights,1
abstractions,1
visit,1
dataloaders,1
impressed,1
img_idx,1
randomcrop,1
randomhorizontalflip,1
num_workers=8,1
`to_yaml`,1
publication,1
ncbi,1
nlm,1
nih,1
//dirko,1
hfjn,1
numpy_data,1
acces,1
declares,1
disclaimer,1
recommending,1
cheersrunning,1
train_frcnn,1
nn_base,1
channel_axis = 3,1
{}_gamma,1
channel_axis,1
allclose,1
atol=0,1
gpuarraysharedvariable,1
221s,1
219s,1
[packages_path],1
attachment,1
bitwise_and,1
bitwise_or,1
bitwise_xor,1
tensorfolw,1
bitwisexor,1
logicand,1
alfa,1
scatter_sub,1
[0] * b_w[0],1
inner_activation,1
[0] * b_w[1],1
[0] * b_w[2],1
[0] * b_w[3],1
w_o,1
b_o,1
u_i,1
u_f,1
u_c,1
w_y,1
u_o,1
nb_words,1
lstm_units,1
num_labels,1
layer_names,1
imagefiltercnn,1
file_path,1
5568it,1
circumenstance,1
first_try,1
= [label2id[,1
percent_zero_dims,1
percent_zero_dims / 100,1
sparse_to_dense,1
default_value=0,1
sparse_perc,1
tyring,1
specs,1
[dense_with_lstm1],1
paul,1
dufort,1
paulhow,1
uriel,1
guth,1
miniconda,1
ba_guth,1
arrise,1
lr_n2d_1,1
lr_n2d_6,1
softplus,1
recon_error = 0,1
center_box=,1
rgb_args,1
nir_args,1
label_args,1
conv_rgb1,1
conv_rgb2,1
pool_rgb2,1
conv_nir1,1
conv_nir2,1
pool_nir2,1
# conactenate,1
unimodal,1
115 # conactenate,1
[pool_rgb1,1
pool_nir1],1
concat_axis,1
dot_axes,1
output_mask,1
node_indices,1
tensor_indices,1
inbound_node,1
586             output_mask =,1
167   const_tensor =,1
weeks,1
8 k40s,1
modeldir,1
m48da_acdcrt,1
yl,1
h5py_1490029245709,1
snippets,1
add_update,1
assignsub,1
0-intialized,1
unbias,1
assignmovingavg,1
assign_sub,1
"722



`kernel_shape =",1
`kernel_shape =,1
_train,1
stumbled,1
_through_,1
recordings,1
perspective,1
lifespan,1
personally,1
[afaiu],1
_nice_,1
patched,1
_feed_input_names == [],1
infos,1
tipsandtricks,1
pin,1
replicates,1
nvprof,1
"```

$theano_flags=",1
160s,1
308s    637313  169,1
94us  3,1
6789s   2466108  8,1
6957s    637482  26,1
38032s    637315  13,1
73604s    507873  11,1
294us  3,1
3530us  30,1
48032s   2466108  1,1
07ms       754  397,1
97us  259,1
74us  5,1
35ms      5126  20,1
860ms     10240  4,1
3800us  1,1
6070us  1,1
654ms     10240  1,1
9572ms       356  5,1
2343ms         4  308,1
58us  98,1
618us  543,1
19us       751  1,1
92us         4  40,1
229us  33,1
804us  46,1
895us        16  2,1
0550us  1,1
7460us  4,1
140us        16  1,1
3830us  1,1
1870us  2,1
899us         5  2,1
505us        11  1,1
686us         8  1,1
0760us         4  1,1
0760us         2  3,1
0380us  1,1
6760us  4,1
114s,1
6606s    445918  142,1
7547s    495331  62,1
089us  1,1
6680us  41,1
7882s   1995842  8,1
4110us  6,1
0480us  2,1
48816s    495736  17,1
122us  6,1
5550us  2,1
40081s    495333  8,1
8840us  4,1
7850us  145,1
97ms       833  182,1
44us  157,1
84us  6,1
257ms      6080  12,1
542us  7,1
6150us  160,1
903ms      1618  13,1
537us  7,1
9420us  53,1
517ms      6400  2,1
8930us  1,1
2720us  109,1
597ms      6080  2,1
0710us  1,1
3090us  15,1
3868ms      6080  1,1
7764ms      6400  1,1
18us         2  190,1
09us  188,1
24us  191,1
60us       166  2,1
472us  19,1
485us  23,1
617us        16  1,1
158us        16  1,1
784us         2  7,1
3920us  1,1
5910us  13,1
638us         5  2,1
3750us         3  1,1
slight,1
lstm_n_units,1
by_date_generator,1
invoked,1
isolated,1
invocations,1
process_obj,1
popen_spawn_win32,1
to_child,1
bufferedwriter,1
"=17>

protocol =",1
protocol=,1
protocol,1
generatorenqueuer,1
<locals>,1
ohem,1
"```

step1",1
step2,1
skip_indices,1
metrics_names,1
output_names[,1
_feed_targets +,1
_feed_sample_weights,1
_top_kv2,1
topkv2,1
n_time_steps,1
har,1
input_graph_path =,1
restore_op_name =,1
filename_tensor_name =,1
frozen_,1
input_graph_path,1
input_saver=,1
output_node_names=,1
restore_op_name=,1
filename_tensor_name=,1
initializer_nodes=,1
develop,1
volunteers,1
robots,1
ox,1
[refcoco],1
[resnetv2],1
[wider,1
revisiting,1
daniil,1
fcns,1
upsample,1
intesection,1
union,1
[densenetfcn],1
extended,1
internal_output_shapes[,1
append_metric,1
"proportional

            #",1
lstmdense,1
0hello,1
"150

train_data_dir =",1
shine,1
output3,1
clinical_patient_ids,1
clinical_var_names,1
clinical_data,1
indication,1
2899                                                        original_keras_version,1
conv_layers,1
"]

     84     no_flip =",1
new_steps,1
proprieties,1
initial_lrate = 0,1
"5

    epochs_drop = 10",1
/epochs_drop,1
book1,1
step_decay,1
minmaxscale,1
n_splits=2,1
standardized,1
0x0000000042582ac8>,1
origins,1
set_printoptions,1
sout=[],1
wout=[],1
wout,1
sout,1
out_s = [],1
out_s,1
aout=[],1
sout = [],1
aout,1
en_train,1
en_test,1
loadcorpus,1
western,1
sharp,1
margins,1
quarter,1
company,1
earning,1
funds,1
sale,1
provision,1
loan,1
held,1
earnings,1
nnp,1
vbd,1
prp,1
jj,1
vbp,1
vbg,1
prp$,1
rp,1
===== epoche,1
`train_y`,1
complaining,1
functionalities,1
caveats,1
@nouiz,1
* teacherforcing,1
rename,1
my_desired_name,1
"scratch 

*",1
nb_samples = 100000,1
[sigmoidcrossentropylosslayer],1
eecs,1
berkeley,1
ambiguous,1
not_equal,1
savepath,1
h5py_1490030958306,1
illegal,1
1159                             epoch_logs[,1
max_images=3,1
expanddims_26,1
_run_module_as_main,1
_handle_events,1
run_ast_nodes,1
w_img,1
_image_summary,1
embedding_layer1,1
embedding_layer2,1
#NAME?,1
`frame_sequence`,1
frame_sequence,1
incase,1
//ethereon,1
noted,1
323s,1
181s,1
133s,1
110s,1
86s,1
66s,1
59s,1
53s,1
pycharm 2016,1
* prev_total_width,1
"activity_l1

     43",1
convolution2d_1_w,1
convolution2d_1_w_0,1
`addition_rnn,1
afaict,1
evaluationfrom,1
subtracted,1
cnn_weights,1
train_lstm_resnet_batchnorm,1
{}_weights,1
cnn_name,1
f1score,1
5 memoryclockrate,1
"98

pcibusid 0000",1
85gib,1
906] dma,1
1686s,1
567s,1
343s,1
217s,1
126s,1
evolving *,1
lot*,1
ported,1
declaring,1
lifted,1
reviewed,1
differed,1
rare,1
month,1
authority,1
ensures,1
concretely,1
bringing,1
increasingly,1
cloudml,1
merrier,1
cr_top,1
cr_bot,1
cr_lef,1
cr_rig,1
in_row,1
in_col,1
res_row,1
res_col,1
buying,1
decouple,1
unsuccessful,1
alphabet_size,1
em_drop,1
cell_dim,1
inbound_layers,1
outbound_layer,1
max_sents,1
embeddings_layer,1
`max_sents=10`,1
deprecationwarning,1
basename,1
isfile,1
x_holdout,1
c3,1
c4,1
c5,1
c6,1
c7,1
c8,1
c9,1
#NAME?,1
datetime,1
subm,1
strftime,1
submission_,1
model_from_cache = 0,1
model_from_cache == 1,1
nb_pool,1
main_generator,1
3qt5,1
faillog,1
nb_worker=4,1
"405

pcibusid 0000",1
61gib,1
126] dma,1
61985781e-07   9,1
81094581e-06   9,1
99989748e-01   2,1
"69348943e-09

    1",1
97990360e-10   8,1
48836210e-11   4,1
53296529e-08   7,1
"74509276e-11

    2",1
23150167e-07   2,1
"99653670e-11]]

[[  9",1
75747753e-06   2,1
34337261e-09   5,1
09917042e-09   1,1
"79785129e-08

    6",1
84200643e-08   6,1
34509252e-06   9,1
99983668e-01   4,1
"00663530e-11

    1",1
21496996e-07   1,1
"95249289e-10]]

[[  9",1
69054281e-10   1,1
05993847e-09   1,1
87508320e-09   1,1
"94809417e-07

    1",1
49762297e-06   4,1
11489260e-08   8,1
54344595e-10   8,1
"08601499e-07

    1",1
35151751e-07   9,1
"69348943e-09

   1",1
"74509276e-11

   2",1
"99653670e-11]

[  9",1
99998927e-01   6,1
84537635e-11   4,1
53024768e-07   9,1
"15579487e-11

   1",1
19156296e-10   1,1
37983824e-09   6,1
24313543e-08   5,1
"71949954e-09

   1",1
34752597e-07   4,1
"58147241e-07]

[  6",1
04119035e-04   2,1
68195297e-08   1,1
23279997e-05   2,1
"34821496e-10

   9",1
99363124e-01   1,1
72202430e-08   1,1
96394576e-05   6,1
"58836768e-07

   1",1
14492806e-07   3,1
"96185520e-08]



```",1
secen,1
data_dim/8,1
midinet_0110,1
optimizer_weight_values,1
275l,1
complicacy,1
preparation,1
docstrings,1
841                 batch_logs[,1
batch_ids,1
updates_op],1
subfeed_val,1
is_compatible_with,1
tryed,1
hosdays_mlp,1
labels_train,1
feature_set,1
naccuracy,1
fitter,1
x_,1
benefits,1
redundancy,1
usecase,1
col_hidden,1
dl4j,1
contact,1
somethingelse,1
0dev4,1
np_y_true =,1
np_y_true,1
k_list = [,1
np_y_true[,1
k_list,1
rethink,1
[`sk_params`,1
`sk_params`,1
brevity,1
nce,1
lample,1
nltk,1
refactor,1
left_branch,1
right_branch,1
`left_branch,1
`right_branch,1
number_of_batches =,1
number_of_batches,1
todense,1
x_size,1
moh,1
keras_env,1
keras__init__,1
backend__init__,1
define_float,1
define_integer,1
max_steps,1
define_string,1
define_boolean,1
fake_data,1
pretaining,1
40gb,1
sample_weight_modes,1
number_of_training_samples=10000,1
number_of_pixels_in_patch=16384,1
number_of_classes=2,1
grabs,1
scratch**,1
apt-,1
upgraded,1
0rc,1
> cleaning,1
edited,1
equipped,1
exhaust,1
/vivek-,1
find_graphviz,1
ensured,1
`pydotplus`,1
linalg,1
lr_record=[],1
lr_record,1
`lr_record`,1
counted,1
x_test_mat,1
rising,1
n_examples,1
#NAME?,1
blstm,1
[pic],1
channel_index,1
batch_count = 0,1
x_batch1,1
y_batch1,1
batch_count += 1,1
batch_count >= 1,1
x_1,1
x_2,1
x_3,1
a_3,1
make_predict_function,1
sigmoid_2,1
input_text,1
input_titles,1
filter_lengths = [1,1
filter_lengths,1
subsample_length=1,1
#NAME?,1
labshovedkat,1
hovedkategori,1
labsunderkat,1
underkategori,1
opencl,1
leaf,1
torch7,1
timedistributeddense,1
dev_x,1
dev_y,1
save_file,1
appending,1
weight_file,1
nb_channels=3,1
bushes,1
staring,1
fire,1
watch,1
667626_18933d713e,1
3637013_c675de7705,1
10815824_2997e03d76,1
12830823_87d2654e31,1
17273391_55cfc7d3d4,1
index_word[,1
afterwords,1
cndnn,1
fixed_seed_num,1
v10,1
= wx +,1
add_input,1
add_node,1
add_output,1
liking,1
assert_same_rank,1
parametrized,1
vggnet,1
ciao,1
"```
y_i = [[1",1
gpuoptions,1
device_count = {,1
clinorm,1
poblem,1
maketrans,1
translate_to=,1
not_letters_or_digits =,1
translate_to,1
not_letters_or_digits,1
_foo__,1
overlooking,1
inits,1
recompiling,1
like-,1
[],0
```,0
/,0
[,0
],0
[ ],0
1,0
128,0
7,0
2,0
32,0
=,0
/ 255,0
28,0
> 2018-06-09 23,0
59,0
16,0
234583,0
6,0
0,0
3,0
8,0
#,0
4,0
80,0
256,0
**,0
2],0
[1,0
1],0
`,0
#10207,0
1566,0
1568,0
458             #,0
462,0
"3067 

   3068     #",0
-> 3069,0
3070,0
3071,0
3002,0
3005,0
430,0
%,0
2073,0
1911,0
166,0
--> 904,0
3772,0
1733,0
1735,0
1736,0
2017,0
5,0
>,0
>0,0
]  #,0
[0],0
30,0
``,0
9,0
1969,0
1,0
204-227,0
32,0
-------------------------------------------------------------,0
0%,0
"```

2018-06-02 10",0
8,0
448699,0
21,0
519,0
"259

2018-06-02 10",0
448710,0
514,0
"965

2018-06-02 10",0
448718,0
20,0
4,0
"294

2018-06-02 10",0
10,0
959486,0
38,0
247401,0
2332,0
2218,0
"2218

2018-06-02 10",0
248712,0
22183,0
3,0
40,0
6534,0
23,0
44,0
784851,0
"```

2018-06-02 11",0
785217,0
803122,0
2018-06-02 11,0
803174,0
803383,0
803390,0
803792,0
803800,0
805133,0
805141,0
805721,0
805728,0
805851,0
805857,0
805962,0
805969,0
806527,0
806534,0
806606,0
806620,0
{,0
*,0
},0
+,0
"+ 1

    

    #",0
== 3,0
0,0
&,0
++,0
784,0
[ +],0
1000,0
1586,0
56,0
64,0
1,0
"2231 

   2232",0
1884,0
== 1,0
-> 2482                               **,0
898,0
901,0
1133,0
1136,0
1314,0
1317,0
1333,0
<= 1584,0
]],0
400,0
50,0
398,0
250,0
[0,0
1024,0
1,0
-5],0
0-49,0
64],0
0],0
#10120,0
25,0
"}

```",0
] =,0
] +=,0
] /,0
120,0
25,0
84,0
<>,0
5,0
1253,0
1256,0
"{}

         76",0
445,0
446,0
--> 447,0
448,0
449,0
2578,0
2579,0
109,0
"{

        110",0
--> 111,0
112         },0
154,0
--> 155,0
156,0
157,0
242,0
--> 243,0
245,0
217,0
--> 218,0
220,0
--> 223,0
"]

        224     #",0
181,0
--> 182,0
"183 

        184     #",0
295,0
296,0
298,0
299,0
173,0
175,0
224,0
331,0
14,0
1200,0
"}

```



**",0
#2412,0
12,0
30-40,0
80-100,0
##,0
8100,0
[-1,0
-12,0
-4,0
164                     #,0
"498 

    499",0
"501 

    502         #",0
452             #,0
610,0
351,0
352,0
354,0
"856 

--> 857",0
"858 

    859",0
1009,0
205,0
"= [

    [1",0
[2,0
"0]

]",0
[[[0,0
0,0
"60%

#",0
{},0
3.1558E+14,0
6E+15,0
321,0
60000,0
55,0
4,0
288476,0
140],0
452269,0
-1,0
> 2018-05-22 09,0
452738,0
0,0
1,0
11,0
452755,0
"0

> 2018-05-22 09",0
636799,0
636842,0
"929]      0

> 2018-05-22 09",0
636847,0
942] 0,0
637045,0
> 60000/60000 [==============================],0
1031,0
987,0
60,0
3],0
][,0
][1]=1,0
60/30000 [,0
51,0
5406,0
1681,0
4094,0
1396,0
1231,0
3506,0
1060,0
981,0
3130,0
877,0
2961,0
[13],0
[14],0
10000/10000 [==============================],0
225514/225514 [==============================],0
200000/200000 [==============================],0
[[ 0,0
28298143],0
[ 0,0
28298143]],0
"```

{",0
[40,0
22,0
15,0
41,0
[1290,0
730,0
1414,0
1059,0
330,0
1743],0
4],0
[2616,0
1508,0
1428,0
1107,0
2926,0
[ 220,0
624,0
33,0
2144],0
[125,0
308,0
284,0
278,0
278],0
[112,0
112,0
193,0
106,0
124],0
[1217,0
1217,0
81,0
599,0
51],0
[8,0
6],0
[  6,0
90775633,0
39266205,0
2103405,0
10071182,0
98719692,0
69107151],0
[16,0
27],0
[[ 64913,0
109886,0
[ 16600,0
1340,0
35945,0
[    14,0
27,0
[  1982,0
10075,0
357,0
[  3633,0
16769,0
[   275,0
3980,0
1634,0
0]],0
26,0
24,0
9216,0
100,0
"```



* * *",0
] ~~,0
"> 

> 1",0
0,0
2.4801E+11,0
3.78336E+11,0
1.52548E+11,0
-86,0
3738760481,0
8.72322E+11,0
-3,0
51314800063,0
"0

> 

> 1",0
31,0
46,0
2.67423E+11,0
51143782875,0
1.91247E+11,0
-85,0
7662354031,0
928406847,0
8015176908,0
62,0
343,0
#9883,0
1415684,0
502203,0
*100,0
668,0
677,0
676,0
[5],0
#7096,0
200,0
-----,0
]`,0
0}},0
300,0
30064,0
1}},0
"1}

 ```",0
#4471,0
#6646,0
10000,0
[[-176,0
963181 -178,0
108612 -179,0
35141 -175,0
689926 -180,0
10643 -166,0
333939],0
[-11203,0
967072 -178,0
112488 -179,0
355301 -175,0
693817 -180,0
110306 -166,0
33783],0
971039 -178,0
116455 -179,0
359253 -175,0
697784 -180,0
114288 -166,0
341797],0
975098 -178,0
120499 -179,0
363327 -175,0
701843 -180,0
118332 -166,0
34584],0
979248 -178,0
124664 -179,0
367462 -175,0
705963 -180,0
122482 -166,0
349991],0
[-11204,0
983459 -178,0
12883 -179,0
371643 -175,0
710175 -180,0
126694 -166,0
354172],0
987686 -178,0
133102 -179,0
375931 -175,0
714447 -180,0
130951 -166,0
358444],0
99202 -178,0
137421 -179,0
380219 -175,0
71875 -180,0
135254 -166,0
362762],0
996399 -178,0
141815 -179,0
384613 -175,0
723129 -180,0
139633 -166,0
367142],0
"]

```",0
]+,0
16544,0
165,0
###,0
50%,0
3417,0
9000,0
4247,0
3285,0
4036,0
3043,0
4024,0
4049,0
4053,0
4022,0
3679,0
4021,0
4048,0
4052,0
4056,0
4055,0
3296,0
3875,0
3871,0
"9000

```",0
6`,0
[[1]],0
Aug-17,0
4697463056 -> 4697462800,0
4697597392 -> 4697463568,0
4697462800 -> 4697598608,0
4697463568 -> 4697598608,0
4697598608 -> 4697705616,0
43,0
713797,0
87,0
2%,0
9%,0
12936,0
751,0
`751`,0
12944,0
`8,0
12936= 8`,0
`12936`,0
85 / 7,0
47,0
0228 / 0,0
0223 / 0,0
9933 / 0,0
9936 / 0,0
"9944



-------------------",0
1,0
3224406,0
12029,0
44036666],0
1158938,0
4/,0
999,0
/255,0
512,0
9025,0
20],0
==,0
"```

#",0
2,0
74,0
52,0
7892,0
5610,0
5927,0
5305,0
4810,0
5221,0
4109,0
3562,0
3441,0
3325,0
3200,0
3517,0
3245,0
2413,0
2014,0
2050,0
1949,0
1667,0
1662,0
1578,0
1470,0
1363,0
1287,0
1148,0
1180,0
1078,0
984,0
996,0
891,0
833,0
839,0
799,0
715,0
701,0
817,0
753,0
613,0
601,0
686,0
560,0
551,0
505,0
566,0
494,0
510,0
478,0
490,0
473,0
452,0
463,0
413,0
402,0
395,0
401,0
380,0
376,0
405,0
353,0
349,0
332,0
321,0
339,0
350,0
365,0
317,0
316,0
331,0
307,0
319,0
295,0
354,0
299,0
311,0
289,0
302,0
273,0
304,0
256,0
296,0
238,0
268,0
280,0
265,0
303,0
249,0
228,0
285,0
229,0
227,0
233,0
247,0
257,0
230,0
"0000

26/26 [==============================]",0
0,0
945,0
8234,0
76,0
93,0
94,0
> 2,0
> 1,0
5],0
[2],0
"]]

```",0
43080,0
"3672

2/4 [==============>",0
42773,0
"6367

3/4 [=====================>",0
42599,0
"2396

4/4 [==============================]",0
42735,0
"5234

```",0
0,0
5 *,0
[3],0
[4]],0
[[1],0
408,0
13,0
724251,0
18,0
- [,0
###########################################,0
[11],0
2660,0
"]

    224     #",0
"183 

    184     #",0
14146,0
#14146,0
240,0
320,0
614,0
615,0
1,0
128],0
49,0
34,0
25088,0
127,0
[224,0
224],0
"156 

    157",0
792,0
--> 793,0
691,0
695,0
659,0
660,0
107,0
-> 1404,0
348       #,0
5587,0
#3358,0
#8554,0
>}`,0
442,0
01 07 20,0
-2],0
>=1,0
24,0
17,0
70,0
3*,0
[[[[255,0
255,0
[255,0
[[255,0
]]]],0
[[[5000,0
1313,0
333,0
1768,0
540,0
113,0
426,0
148,0
[1420,0
1291,0
[1313,0
[4095,0
669,0
899,0
1167,0
2309,0
997,0
1669,0
397,0
2240,0
[ 350,0
2409,0
2019,0
773,0
[2198,0
182,0
[ 631,0
932,0
92,0
1108,0
630,0
631,0
3226,0
[ 177,0
[ 151,0
1174,0
641,0
[  26,0
]]],0
[[[18],0
[18],0
[18]]],0
[[[36],0
[36],0
[36]]],0
2018-04-30 23,0
6,0
"888596666 -0500

@@ -3",0
6 +3,0
7 @@,0
7 +180,0
10],0
[[1,0
1]],0
[[[1,0
"]

[[[0",0
"33333334]

  [0",0
"33333334]]]

```",0
//,0
460,0
840,0
`[[1,0
]]`,0
-,0
= [],0
90000,0
]=,0
0 =,0
180,0
/ 32,0
> 0,0
[1],0
"```

`--------------------------------------------------------------------------------------------------------------`",0
5580,0
7216,0
5227,0
5260,0
7466,0
5321,0
5175,0
7512,0
5170,0
5166,0
7556,0
5086,0
5141,0
7562,0
5017,0
5119,0
7602,0
5061,0
5090,0
7591,0
4999,0
5100,0
7624,0
5043,0
7.53899E+15,0
99,0
"28



#",0
�,0
---> 10,0
---> 23,0
1535,0
2507         #,0
2510         #,0
145,0
147,0
148             #,0
1266,0
1267,0
105,0
162,0
] +,0
636,0
2018-04-26 11 20 25,0
2015,0
79%,0
75,0
1783,0
36,0
#7055 #7983 #7125 #2375,0
90,0
5986,0
9796,0
3064,0
186,0
3164,0
150,0
3186,0
6923,0
[4,0
5.52013E+14,0
44897958636283875],0
"8 

----> 9",0
"617 

    618             #",0
"182 

    183",0
1819,0
1820,0
== 4,0
[[0,0
3]],0
-> 1821,0
== [0,0
257,0
238,0
--> 240,0
4215,0
228,0
229,0
146,0
"]

    149",0
# [,0
"]



        #",0
8*8,0
2048],0
]]**,0
2048,0
"131 100 100

```",0
1,0
360,0
15],0
150,0
/49832560/932818,0
2018-04-17 18-41-40],0
880,0
48,0
32*32*64,0
<---,0
1%,0
"```

[[[[ 5",0
"]

   [ 5",0
"]]



  [[ 5",0
`1,0
`0,0
001`,0
192,0
27134/27134 [==============================],0
9.44829E+15,0
1},0
[[,0
99%,0
<,0
75-80%,0
"`

`",0
9]],0
0},0
"** 

*",0
***,0
"0         

    -----------------------------------------------------------------",0
31552997 -0,0
53272009 -0,0
60824025 -1,0
14802313 -1,0
14597917 -1,0
08642125 -1,0
10040164 -1,0
19442761 -1,0
19560885 -1,0
19008029 -1,0
19456315 -1,0
2288748 -1,0
22721946 -1,0
20107424 -1,0
20624077 -1,0
24017036 -1,0
24014354 -1,0
2400831 -1,0
24004364 -1,0
23963416 -1,0
23968709 -1,0
24039733 -1,0
24027216 -1,0
23946059 -1,0
14516866 -1,0
20557368 -1,0
5288837 -1,0
48179781 -1,0
05906188 -1,0
17691648 -1,0
94568193 -1,0
85741842 -1,0
30418646 -0,0
83358657 -1,0
61638248 -1,0
17812908 0,0
53077424 0,0
79578459 -0,0
40937367 0,0
35088596 1,0
29912627 -5,0
49394751 -27,0
1003418 -1,0
06875408 33,0
78763962 109,0
41391754 242,0
43798828 251,0
05577087 300,0
13430786 267,0
90420532 178,0
17596436 132,0
06596375 60,0
63394928 82,0
10819244 91,0
"**

*",0
"*



  [1]",0
[[[[ 0,0
10519278]],0
[[-0,0
09711087]],0
1125772 ]]],0
[[[-0,0
18705219]],0
13889125]],0
21000636]]],0
[[[ 0,0
24378067]],0
46328533]],0
15319693]]]],0
[[[[-0,0
15856814]]]],0
1637,0
5118,0
1606,0
<--,0
96572,0
"```

2018-04-09 02",0
2018-04-09 02,0
170,0
> 3000,0
<=1000,0
2018,0
409340+00,0
[{,0
274,0
184,0
275,0
183,0
}],0
[ {,0
[31,0
72,0
63,0
67,0
134,0
68,0
158,0
174,0
178,0
172,0
82,0
6301,0
73,0
[75,0
103,0
108,0
137,0
89,0
104,0
188,0
179,0
171,0
167,0
10652,0
[68,0
[169,0
66,0
211,0
53,0
246,0
262,0
268,0
95,0
261,0
129,0
241,0
216,0
153,0
143,0
169,0
6838,0
[86,0
54,0
119,0
101,0
77,0
71,0
86,0
1715,0
[70,0
[117,0
123,0
110,0
136,0
118,0
159,0
79,0
132,0
117,0
1260,0
65,0
42,0
[109,0
115,0
133,0
161,0
58,0
152,0
1660,0
"}]

}",0
== 0,0
+= 1,0
2178,0
701,0
--> 703,0
704,0
705,0
---> 56,0
515         #,0
--> 517,0
248,0
249,0
409,0
381,0
382,0
"```

+-----------------------------------------------------------------------------+",0
384,0
-------------------------------+----------------------+----------------------+,0
===============================+======================+======================,0
0,0
+-------------------------------+----------------------+----------------------+,0
"+-------------------------------+----------------------+----------------------+



+-----------------------------------------------------------------------------+",0
=============================================================================,0
0     10772,0
1     10772,0
"+-----------------------------------------------------------------------------+

```",0
84%,0
[0]+,0
//2,0
2%,0
```- [,0
1+72,0
13],0
16],0
21],0
528,0
39,0
28800,0
822,0
812,0
4096,0
"624



```",0
0 ** 3,0
-10,0
[[ -0,0
-18,0
"]

 [-16",0
"]

 [ -0",0
"]

 [ -8",0
"]

 [ -4",0
-2,0
"]

 [  0",0
"]

 [  8",0
"]

 [ 12",0
"]

 [ 16",0
-14,0
-6,0
6 ],0
2,0
3,0
4000,0
500,0
------------,0
-------------,0
"-------------

=",0
#9816,0
100%,0
30%,0
5074,0
7834,0
3790,0
3012,0
9033,0
2172,0
9296,0
2971,0
1746,0
9424,0
2791,0
"8882

```",0
651   1,0
040  15,0
023   3,0
909  19,0
719,0
"```

2018-04-01 21",0
809946,0
921300,0
2018-04-01 21,0
921582,0
921595,0
"0

2018-04-01 21",0
72285,0
72307,0
"917]      0 

2018-04-01 21",0
72312,0
930] 0,0
72502,0
280,0
640,0
25`,0
1852,0
*0,0
2 *,0
600,0
225,0
96,0
">  

>",0
"> 



```",0
11600,0
93%,0
42%,0
// 32,0
= {,0
7 +3319,0
"]

+",0
= 33`,0
= 3`,0
5%,0
176,0
** 2,0
** 1,0
----------,0
----,0
---------,0
-------------------,0
--------------------------------,0
--------------,0
-----------,0
50000,0
15360,0
15410,0
97%,0
127],0
3-Jan,0
"```

```",0
480,0
0-1,0
5*,0
[256,0
9],0
64 * 64,0
64 * 64],0
151,0
"688

```",0
3432,0
5959,0
2431,0
24310,0
5390,0
6018,0
590,0
5902,0
8114,0
"6036

```",0
[[0],0
[0]],0
6}`,0
6]`,0
`0`,0
**1,0
"```

[ 0",0
10360018  0,0
06169706  0,0
11487333  0,0
07720207  0,0
44261318  0,0
"19750018

   0",0
08600973  0,0
"22325319]

 [ 0",0
06560849  0,0
06978489  0,0
21796258  0,0
05673849  0,0
16526021  0,0
"21255994

   0",0
09830733  0,0
"24837734]

 [ 0",0
19014663  0,0
13065062  0,0
1236735   0,0
10173705  0,0
46399561  0,0
"10760699

   0",0
05958129  0,0
12666202]],0
50],0
>       2,0
>     491,0
>     493,0
> --> 603,0
>     512,0
"+

> --> 513",0
>     515,0
10840,0
>= 0,0
1+,0
11 54 19],0
"```

[",0
"]

[0",0
3.73352E+16,0
9.25641E+15,0
"9256410256410257]

```",0
27%,0
2558,0
1000],0
[3,0
32],0
2046,0
------,0
~0,0
7.5201E+15,0
5263203440548537],0
5118,0
"`

`[",0
"`

`               [",0
"` 

`               [",0
] `,0
2003,0
"```





**",0
~,0
"```



**",0
"** 

 **",0
"2

#",0
255],0
"```

**",0
**+1,0
-> 1926,0
1927,0
1928,0
235,0
1356,0
1357,0
4565,0
-> 4567,0
527,0
"%

--> 528",0
"%

    530",0
-> 2080,0
2081,0
2082,0
"452 

    453",0
"/

    455",0
1459,0
-> 1461,0
---> 60                       [,0
61,0
5614,0
5615,0
5617,0
5618,0
5218,0
[#4871],0
------------------------------------------------------------------------------------------------------------------,0
=======================,0
[100],0
1328,0
2560,0
1339,0
3712,0
8012,0
912`,0
3712`,0
256],0
/=,0
1281         #,0
1232,0
1234,0
"113 

    114",0
--> 115,0
/= 127,0
"5

    116",0
-= 1,0
197*197,0
737,0
~1,0
4,0
5,0
"#    

#",0
482,0
14 42 26,0
1207,0
15 20 12,0
1085,0
14 45 25,0
572,0
575,0
1,0
1**,0
288,0
2,0
"6



```",0
20,0
19366646],0
21,0
06229877],0
22,0
3464725],0
344,0
"0



```",0
130 #,0
"497 

    498",0
"500 

    501         #",0
590,0
591,0
--> 592,0
593,0
594,0
459,0
--> 461,0
1861,0
1862,0
411,0
415,0
1850,0
-> 1852,0
1853                     ],0
1854,0
1880,0
753,0
755,0
619,0
620,0
622,0
"%

--> 290",0
---,0
2593,0
2/1 [===================================],0
6554,0
8935,0
2233,0
~7%,0
"**



1",0
3`,0
"**

**2",0
`1563/1563 [==============================],0
3354,0
5213,0
1781,0
"5857`

**2",0
2962,0
5376,0
1254,0
6036`,0
7%,0
[  0,0
429,0
47] = 429,0
7101,0
7004,0
9893,0
5694,0
}},0
2722,0
2721,0
160,0
912,0
10,0
"]

   2289",0
391,0
[6],0
3154,0
3049,0
3051,0
"573

    574",0
60     #,0
0 <,0
[-1],0
2,0
2359808,0
102764544,0
16781312,0
8194,0
=================================================================,0
529,0
282,0
738,0
260,0
544,0
50/1107 [>,0
7271,0
6800,0
100/1107 [=>,0
3602,0
5300,0
150/1107 [===>,0
7642,0
4267,0
200/1107 [====>,0
8050,0
3850,0
250/1107 [=====>,0
1716,0
3760,0
300/1107 [=======>,0
8458,0
3433,0
350/1107 [========>,0
37,0
2353,0
3257,0
400/1107 [=========>,0
19,0
4468,0
3175,0
450/1107 [===========>,0
6829,0
3067,0
500/1107 [============>,0
7429,0
3060,0
*1,0
12*1,0
[10,0
1/,0
# <====,0
25000,0
45,0
516518,0
137],0
623399,0
2018-03-02 09,0
623738,0
623754,0
->,0
25000/25000 [==============================],0
4200,0
8025,0
3546,0
2392,0
9042,0
4031,0
1305,0
9511,0
4752,0
718,0
9744,0
6039,0
370,0
9874,0
6446,0
237,0
9924,0
7529,0
189,0
9940,0
9219,0
152,0
9951,0
9994,0
77,0
9978,0
55,0
9982,0
1877,0
115,0
9960,0
7,0
75,0
2552,0
13,0
9996,0
5579,0
9999,0
5907,0
41,0
9987,0
3391,0
"8083

25000/25000 [==============================]",0
69482,0
191941,0
192276,0
192293,0
4979,0
7564,0
5457,0
3256,0
8671,0
5148,0
2588,0
9008,0
5735,0
2107,0
9224,0
5902,0
3652,0
8934,0
6459,0
2289,0
9118,0
6240,0
1401,0
9524,0
6863,0
1215,0
9606,0
7088,0
964,0
9689,0
7735,0
894,0
9725,0
8051,0
784,0
9752,0
8321,0
472,0
9856,0
8837,0
504,0
9859,0
8971,0
1002,0
9747,0
8644,0
585,0
9854,0
9164,0
"7102

25000/25000 [==============================]",0
15340,0
130512,0
2018-03-02 10,0
130897,0
130914,0
5095,0
7490,0
5471,0
3661,0
8537,0
5211,0
3816,0
8479,0
5544,0
2686,0
8952,0
5859,0
1995,0
6678,0
3239,0
9098,0
6644,0
2243,0
6562,0
9586,0
7291,0
9584,0
7506,0
2946,0
9623,0
253,0
7563,0
5759,0
172,0
8312,0
3248,0
5412,0
1609,0
1620,0
5516,0
1780,0
5506,0
"5007

25000/25000 [==============================]",0
25],0
20-30,0
"```

[0",0
"6749178]

[0",0
8031555],0
# = 0,0
# [[ 1,0
][ 1,0
# [[ 2,0
][ 2,0
# 0,0
# 1,0
# 2,0
> 2018-02-27 22,0
29,0
415988,0
35,0
7079,0
385],0
352],0
1,0
"10 

     11",0
---> 83,0
"17 

---> 18",0
90-95%,0
11250,0
# # #,0
800,0
350,0
][-1],0
102,0
8643,0
3730,0
3340,0
3298,0
3209,0
3082,0
2685,0
2027,0
1172,0
438,0
"7525

 32/200 [===>",0
44] = 1419,0
1419,0
]]```,0
1/255,0
1/1020,0
Jan-80,0
1-1 100%,0
###############################,0
00 503,0
2-0 100%,0
01  10,0
2 100%,0
00   1,0
2- 100%,0
00   5,0
18 100%,0
1 100%,0
00   4,0
00 856,0
##########,0
00   3,0
2.00E+14,0
+`,0
`+,0
1600,0
803,0
>100,0
315,0
316,0
2518,0
2519,0
"2521

   2522",0
2475,0
2476,0
2478,0
"615

    616             #",0
661,0
1611,0
0-514,0
/64,0
"```



#",0
249],0
5,0
[32,0
"]]

```

32",0
```[8,0
128]```,0
"4



#8976",0
393613,0
9999999,0
`[0,0
7`,0
440,0
~/,0
/= 128,0
98%,0
18%,0
8813,0
3803,0
4564,0
6728,0
5057,0
2680,0
6796,0
5300,0
4486,0
6507,0
8906,0
1915,0
7097,0
3898,0
"1809



```",0
256*256,0
14],0
--,0
444],0
116,0
85,0
5319,0
70766,0
30986,0
680075,0
"855641

0",0
42985,0
81092,0
29256,0
281092,0
581092,0
3]`,0
299]`,0
3237,0
]==1,0
= 1/,0
**2+0,0
10^-10,0
1786,0
] #,0
+=,0
9},0
"```

2018-02-13 11",0
915521,0
"3 



```",0
----> 1,0
1270,0
1271,0
1273,0
1274,0
825,0
"]

    638",0
= 1`,0
01 ** 2,0
03 ** 2,0
/ 2,0
"2         

=================================================================

```",0
939,0
779,0
68],0
111,0
== 5,0
1044,0
1045,0
131,0
132         },0
"239 

    240 



~",0
"116 

    117",0
5192,0
`[,0
10004,0
"`



```",0
2030,0
"9277     

4864/5002 [============================>",0
--> 195,0
"196 

    197",0
777             #,0
--> 779,0
780,0
--> 625,0
589,0
501,0
503,0
504,0
531,0
"533 

    534",0
--> 108                                                  **,0
{0},0
---> 81,0
"82 

     83     #",0
2296,0
"9110     

5002/5002 [==============================]",0
2104,0
"9221     

4864/5002 [============================>",0
[63],0
94524857,0
93333329],0
63451777,0
59030837],0
2026,0
[0][,0
100],0
[1][,0
[29][,0
[0][0],0
#2408,0
#2594,0
1164,0
65,0
6754,0
"8899

`",0
5,0
26         #,0
30         #,0
"---------------------------------------------------------------------------

```",0
20140413,0
2041,0
[0 0 0],0
8],0
<<,0
>>,0
1 1,0
36 36 44 44,0
= [,0
] * 2,0
463,0
75%,0
936312,0
2018-02-01 12,0
868931,0
1542,0
2057,0
141207,0
186631,0
141392,0
847800,0
912210,0
955746,0
"```

2018-02-01 12",0
93282,0
506849200,0
433569,0
434027,0
"1009509632



2018-02-01 12",0
434625,0
"277] ****************************************************************************************************

2018-02-01 12",0
434959,0
126,0
"192]

```",0
0-9,0
87%,0
****,0
1-Oct,0
-24,0
24*,0
25-1,0
7,0
1494,0
2018-01-31 21,0
760287,0
"]]



```",0
==1,0
"1

```",0
5]*2],0
5]*4],0
238885,0
79] [1 2][[0,0
428904474 0,0
"404625893]]

1/1 [==============================]",0
<-----------,0
2018-01-31 15,0
316702,0
79] [1 10][[0,0
0351491123 0,0
158800021 0,0
0662884936],0
"]

2018-01-31 15",0
316705,0
"]

1/1 [==============================]",0
"102012455463

```",0
100*32*128,0
100*32,0
2] = 127,0
519,0
/48486775/1348273,0
~~~,0
20846,0
2198,0
2198,0
8.16143E+11,0
"594060283688

> 512/7895 [>",0
6975,0
7.3319E+11,0
"594060283688

> 

> 1024/7895 [==>",0
6907,0
6.69601E+11,0
"594060283688

> 

> 1536/7895 [====>",0
6856,0
6.46701E+11,0
"66054964539

> 

> 2048/7895 [======>",0
6806,0
6.41691E+11,0
"481826241135

>",0
964,0
69,0
[2018-01-29 6 23 38],0
1730,0
*5,0
# >>,0
2043�2050,0
8429,0
"299

#",0
/*,0
219,0
"`

```",0
3]},0
1]*25,0
57460,0
"```

1",0
-970,0
947321,0
5.96768E+14,0
"0

1",0
6.12883E+14,0
-960,0
927601,0
6.0218E+14,0
8.08021E+14,0
78,0
925621,0
7.26155E+14,0
"0

```",0
= [[[1,0
7],0
[5,0
= [[0,0
4800000,0
2,0
2399981,0
1199990,0
599796,0
29989,0
3838592,0
698,0
2621440,0
`2621440 `,0
"```

2018-01-24 20",0
466550,0
[4],0
[79],0
[81],0
204,0
[83],0
83328,0
[84],0
27776,0
149760,0
7488,0
144,0
000+,0
74666,0
689,0
1 /,0
[20000,0
"]]



>",0
`-,0
2`,0
=2`,0
0`,0
1`,0
[2594],0
[7120],0
[7497],0
2.00E+15,0
73%,0
>>>,0
130000,0
9,0
[0] +,0
[1] +,0
####,0
750,0
[49%,0
51%],0
8%,0
1%,0
01%],0
2242,0
1-,0
2-,0
= {},0
== 2,0
[[  1,0
-5,0
-8,0
-7,0
[  3,0
-9,0
[  1,0
[  9,0
[  2,0
[ -1,0
[ -6,0
[ -7,0
[  8,0
[  5,0
[  4,0
[ -5,0
[ -9,0
[ -4,0
08562656],0
03227361],0
1371294 ],0
01600872],0
0156843 ],0
036583  ]],0
89%,0
/2,0
>    1231,0
>    1234,0
"{}

>      72",0
>     887,0
>     890,0
>    1118,0
>    1121,0
>    1315,0
>    1318,0
>    1334,0
"10]

>",0
1440,0
253,0
112],0
113],0
$,0
4660,0
816,0
3885,0
4488,0
900,0
3917,0
4411,0
906,0
3970,0
4321,0
866,0
3991,0
4222,0
903,0
3992,0
1003,0
6579,0
3848,0
4183,0
6551,0
3870,0
4136,0
6224,0
3951,0
4257,0
6196,0
3978,0
4426,0
6029,0
3958,0
4291,0
5826,0
4083,0
4287,0
1048,0
1454,0
9589,0
9661,0
1427,0
9609,0
9746,0
1407,0
9612,0
9613,0
1404,0
9624,0
9734,0
1367,0
9632,0
9716,0
9649,0
9724,0
1976,0
6963200,0
9585,0
[[[1]],0
[1]]],0
"]]

###",0
2000,0
1001,0
363,0
<501,0
505,0
<505,0
----------------,0
9165,0
2834,0
7378,0
11192,0
9005,0
2993,0
14755,0
22384,0
6591,0
118030,0
179064,0
196,0
"51%



```",0
"```

    #",0
**{,0
7,0
[1]],0
[-1]],0
[[-1],0
1321,0
1322,0
1325,0
222,0
"]

-------------------------------------------------------------------------------------------------------------------------------------------",0
# 3,0
1 --,0
<0,0
6000,0
40,0
*3/2,0
*1/2,0
458,0
50000],0
"5882

  [2]",0
5000,0
`[-1,0
1]`,0
3-,0
8/16/1932,0
61598885]],0
></,0
">

    <",0
</,0
#6640,0
980,0
[[ 100,0
"]]

[[98]]

[[ 100",0
"]]

[[152]]

[[ 200",0
"]]

[[197]]



```",0
10501,0
292,0
435,0
428,0
648,0
25%,0
416,0
} -> {,0
[235200],0
[1215000],0
"**



**2",0
"**



**3",0
[-0,0
1+0,0
+0],0
+1],0
#34570714,0
00_00_44,0
166-00_00_49,0
775,0
======================,0
7843,0
15 > 15,0
252,0
"0

2017-11-06 00",0
"1

2017-11-06 00",0
"2

2017-11-06 00",0
"3

2017-11-06 00",0
"1

2017-11-06 01",0
"0

2017-11-06 01",0
"1

2017-11-06 02",0
"0

2017-11-06 02",0
"1

2017-11-06 05",0
"0

2017-11-06 05",0
"0

2017-11-06 06",0
"1

2017-11-06 06",0
"0

2017-11-06 07",0
"1

2017-11-06 07",0
"3

2017-11-06 07",0
"2

2017-11-06 07",0
"0

2017-11-06 08",0
"2

2017-11-06 08",0
"3

2017-11-06 08",0
"2

2017-11-06 09",0
"4

2017-11-06 09",0
"3

2017-11-06 09",0
"1

2017-11-06 10",0
"4

2017-11-06 10",0
"7

2017-11-06 10",0
"2

2017-11-06 10",0
"1

2017-11-06 11",0
"13

2017-11-06 11",0
"6

2017-11-06 11",0
"11

2017-11-06 11",0
"15

2017-11-06 11",0
"14

2017-11-06 11",0
"15

2017-11-06 12",0
"11

2017-11-06 12",0
"13

2017-11-06 12",0
"10

2017-11-06 12",0
"14

2017-11-06 13",0
"9

2017-11-06 13",0
"6

2017-11-06 13",0
"7

2017-11-06 13",0
"10

2017-11-06 13",0
"8

2017-11-06 13",0
"17

2017-11-06 14",0
"9

2017-11-06 14",0
"4

2017-11-06 14",0
"14

2017-11-06 14",0
"8

2017-11-06 14",0
"12

2017-11-06 14",0
"18

2017-11-06 15",0
"9

2017-11-06 15",0
"8

2017-11-06 15",0
"6

2017-11-06 15",0
"12

2017-11-06 15",0
"13

2017-11-06 15",0
"12

2017-11-06 16",0
"17

2017-11-06 16",0
"10

2017-11-06 16",0
"13

2017-11-06 16",0
"13

2017-11-06 17",0
"12

2017-11-06 17",0
"10

2017-11-06 17",0
"20

2017-11-06 17",0
"16

2017-11-06 17",0
"18

2017-11-06 17",0
"20

2017-11-06 18",0
"27

2017-11-06 18",0
"17

2017-11-06 18",0
"24

2017-11-06 18",0
"18

2017-11-06 18",0
"15

2017-11-06 19",0
"20

2017-11-06 19",0
"29

2017-11-06 19",0
"17

2017-11-06 19",0
"21

2017-11-06 19",0
"21

2017-11-06 20",0
"16

2017-11-06 20",0
"17

2017-11-06 20",0
"12

2017-11-06 20",0
"24

2017-11-06 20",0
"15

2017-11-06 20",0
"21

2017-11-06 21",0
"164

2017-11-06 21",0
"68

2017-11-06 21",0
"65

2017-11-06 21",0
"52

2017-11-06 21",0
"42

2017-11-06 21",0
"34

2017-11-06 22",0
"50

2017-11-06 22",0
"56

2017-11-06 22",0
"36

2017-11-06 22",0
"23

2017-11-06 22",0
"22

2017-11-06 22",0
"11

2017-11-06 23",0
"27

2017-11-06 23",0
"15

2017-11-06 23",0
"13

2017-11-06 23",0
"7

2017-11-06 23",0
"10

2017-11-06 23",0
"10

2017-11-07 00",0
"0

2017-11-07 00",0
"8

2017-11-07 00",0
"7

2017-11-07 00",0
"2

2017-11-07 00",0
"4

2017-11-07 00",0
"1

2017-11-07 01",0
"4

2017-11-07 01",0
"5

2017-11-07 01",0
"3

2017-11-07 01",0
"1

2017-11-07 02",0
"1

2017-11-07 03",0
"0

2017-11-07 04",0
"1

2017-11-07 05",0
"1

2017-11-07 06",0
"0

2017-11-07 06",0
"1

2017-11-07 07",0
"0

2017-11-07 07",0
"2

2017-11-07 07",0
"4

2017-11-07 08",0
"2

2017-11-07 08",0
"1

2017-11-07 08",0
"0

2017-11-07 08",0
"2

2017-11-07 09",0
"4

2017-11-07 09",0
"3

2017-11-07 09",0
"4

2017-11-07 10",0
"8

2017-11-07 10",0
"5

2017-11-07 10",0
"10

2017-11-07 10",0
"9

2017-11-07 10",0
"10

2017-11-07 11",0
"6

2017-11-07 11",0
"7

2017-11-07 11",0
"8

2017-11-07 11",0
"22

2017-11-07 11",0
"20

2017-11-07 11",0
"9

2017-11-07 12",0
"27

2017-11-07 12",0
"13

2017-11-07 12",0
"14

2017-11-07 12",0
"16

2017-11-07 12",0
"12

2017-11-07 13",0
"11

2017-11-07 13",0
"4

2017-11-07 13",0
"2

2017-11-07 13",0
"10

2017-11-07 13",0
"17

2017-11-07 14",0
"11

2017-11-07 14",0
"14

2017-11-07 14",0
"6

2017-11-07 14",0
"8

2017-11-07 14",0
"4

2017-11-07 14",0
"14

2017-11-07 15",0
"5

2017-11-07 15",0
"11

2017-11-07 15",0
"16

2017-11-07 15",0
"18

2017-11-07 15",0
"12

2017-11-07 16",0
"23

2017-11-07 16",0
"9

2017-11-07 16",0
"15

2017-11-07 16",0
"19

2017-11-07 17",0
"16

2017-11-07 17",0
"17

2017-11-07 17",0
"20

2017-11-07 17",0
"18

2017-11-07 17",0
"19

2017-11-07 18",0
"27

2017-11-07 18",0
"25

2017-11-07 18",0
"23

2017-11-07 18",0
"21

2017-11-07 18",0
"21

2017-11-07 19",0
"19

2017-11-07 19",0
"29

2017-11-07 19",0
"17

2017-11-07 19",0
"23

2017-11-07 19",0
"16

2017-11-07 19",0
"19

2017-11-07 20",0
"17

2017-11-07 20",0
"13

2017-11-07 20",0
"14

2017-11-07 20",0
"19

2017-11-07 21",0
"176

2017-11-07 21",0
"63

2017-11-07 21",0
"61

2017-11-07 21",0
"48

2017-11-07 21",0
"47

2017-11-07 21",0
"38

2017-11-07 22",0
"50

2017-11-07 22",0
"30

2017-11-07 22",0
"36

2017-11-07 22",0
"27

2017-11-07 22",0
"23

2017-11-07 22",0
"25

2017-11-07 23",0
"20

2017-11-07 23",0
"15

2017-11-07 23",0
"13

2017-11-07 23",0
"21

2017-11-07 23",0
"18

2017-11-07 23",0
"12

2017-11-08 00",0
"0

2017-11-08 00",0
"2

2017-11-08 00",0
"5

2017-11-08 00",0
"3

2017-11-08 00",0
"8

2017-11-08 00",0
"1

2017-11-08 01",0
"6

2017-11-08 01",0
"4

2017-11-08 01",0
"3

2017-11-08 01",0
"2

2017-11-08 02",0
"1

2017-11-08 02",0
"4

2017-11-08 03",0
"2

2017-11-08 03",0
"1

2017-11-08 03",0
"0

2017-11-08 06",0
"1

2017-11-08 06",0
"0

2017-11-08 07",0
"1

2017-11-08 07",0
"5

2017-11-08 07",0
"2

2017-11-08 08",0
"3

2017-11-08 08",0
"5

2017-11-08 08",0
"0

2017-11-08 08",0
"1

2017-11-08 08",0
"5

2017-11-08 09",0
"4

2017-11-08 09",0
"2

2017-11-08 09",0
"3

2017-11-08 09",0
"3

2017-11-08 10",0
"6

2017-11-08 10",0
"7

2017-11-08 10",0
"4

2017-11-08 10",0
"8

2017-11-08 10",0
"1

2017-11-08 11",0
"9

2017-11-08 11",0
"8

2017-11-08 11",0
"17

2017-11-08 11",0
"12

2017-11-08 11",0
"9

2017-11-08 12",0
"15

2017-11-08 12",0
"16

2017-11-08 12",0
"11

2017-11-08 12",0
"17

2017-11-08 12",0
"7

2017-11-08 13",0
"13

2017-11-08 13",0
"9

2017-11-08 13",0
"5

2017-11-08 13",0
"12

2017-11-08 13",0
"8

2017-11-08 14",0
"9

2017-11-08 14",0
"11

2017-11-08 14",0
"6

2017-11-08 14",0
"11

2017-11-08 15",0
"12

2017-11-08 15",0
"6

2017-11-08 15",0
"7

2017-11-08 15",0
"15

2017-11-08 15",0
"12

2017-11-08 16",0
"17

2017-11-08 16",0
"15

2017-11-08 16",0
"22

2017-11-08 16",0
"14

2017-11-08 16",0
"19

2017-11-08 17",0
"29

2017-11-08 17",0
"17

2017-11-08 17",0
"14

2017-11-08 17",0
"26

2017-11-08 17",0
"23

2017-11-08 17",0
"19

2017-11-08 18",0
"17

2017-11-08 18",0
"27

2017-11-08 18",0
"23

2017-11-08 18",0
"21

2017-11-08 18",0
"19

2017-11-08 19",0
"23

2017-11-08 19",0
"26

2017-11-08 19",0
"24

2017-11-08 19",0
"16

2017-11-08 19",0
"23

2017-11-08 20",0
"19

2017-11-08 20",0
"22

2017-11-08 20",0
"21

2017-11-08 20",0
"10

2017-11-08 20",0
"14

2017-11-08 20",0
"27

2017-11-08 21",0
"170

2017-11-08 21",0
"68

2017-11-08 21",0
"62

2017-11-08 21",0
"69

2017-11-08 21",0
"41

2017-11-08 21",0
"41

2017-11-08 22",0
"48

2017-11-08 22",0
"43

2017-11-08 22",0
"31

2017-11-08 22",0
"15

2017-11-08 22",0
"17

2017-11-08 22",0
"9

2017-11-08 23",0
"19

2017-11-08 23",0
"20

2017-11-08 23",0
"18

2017-11-08 23",0
"5

2017-11-08 23",0
"11

2017-11-08 23",0
"16

2017-11-09 00",0
"0

2017-11-09 00",0
"10

2017-11-09 00",0
"7

2017-11-09 00",0
"6

2017-11-09 00",0
"3

2017-11-09 00",0
"3

2017-11-09 01",0
"7

2017-11-09 01",0
"6

2017-11-09 01",0
"2

2017-11-09 01",0
"2

2017-11-09 02",0
"1

2017-11-09 03",0
"1

2017-11-09 05",0
"0

2017-11-09 05",0
"1

2017-11-09 06",0
"0

2017-11-09 06",0
"0

2017-11-09 07",0
"1

2017-11-09 07",0
"2

2017-11-09 07",0
"4

2017-11-09 08",0
"1

2017-11-09 08",0
"2

2017-11-09 08",0
"3

2017-11-09 08",0
"3

2017-11-09 09",0
"7

2017-11-09 09",0
"4

2017-11-09 09",0
"6

2017-11-09 09",0
"5

2017-11-09 10",0
"3

2017-11-09 10",0
"6

2017-11-09 10",0
"4

2017-11-09 10",0
"7

2017-11-09 10",0
"7

2017-11-09 11",0
"6

2017-11-09 11",0
"13

2017-11-09 11",0
"14

2017-11-09 11",0
"22

2017-11-09 12",0
"21

2017-11-09 12",0
"17

2017-11-09 12",0
"10

2017-11-09 12",0
"6

2017-11-09 12",0
"12

2017-11-09 12",0
"9

2017-11-09 13",0
"3

2017-11-09 13",0
"6

2017-11-09 13",0
"14

2017-11-09 13",0
"12

2017-11-09 13",0
"17

2017-11-09 14",0
"14

2017-11-09 14",0
"11

2017-11-09 14",0
"7

2017-11-09 14",0
"8

2017-11-09 14",0
"12

2017-11-09 14",0
"8

2017-11-09 15",0
"9

2017-11-09 15",0
"10

2017-11-09 15",0
"5

2017-11-09 15",0
"14

2017-11-09 16",0
"16

2017-11-09 16",0
"10

2017-11-09 16",0
"11

2017-11-09 16",0
"17

2017-11-09 17",0
"19

2017-11-09 17",0
"14

2017-11-09 17",0
"24

2017-11-09 17",0
"16

2017-11-09 18",0
"19

2017-11-09 18",0
"23

2017-11-09 18",0
"17

2017-11-09 18",0
"25

2017-11-09 18",0
"18

2017-11-09 18",0
"28

2017-11-09 19",0
"25

2017-11-09 19",0
"18

2017-11-09 19",0
"22

2017-11-09 19",0
"27

2017-11-09 19",0
"32

2017-11-09 19",0
"19

2017-11-09 20",0
"26

2017-11-09 20",0
"16

2017-11-09 20",0
"17

2017-11-09 20",0
"14

2017-11-09 20",0
"15

2017-11-09 20",0
"21

2017-11-09 21",0
"151

2017-11-09 21",0
"53

2017-11-09 21",0
"50

2017-11-09 21",0
"41

2017-11-09 21",0
"41

2017-11-09 22",0
"65

2017-11-09 22",0
"35

2017-11-09 22",0
"22

2017-11-09 22",0
"26

2017-11-09 22",0
"17

2017-11-09 23",0
"14

2017-11-09 23",0
"18

2017-11-09 23",0
"8

2017-11-09 23",0
"11

2017-11-09 23",0
"13

2017-11-09 23",0
"9

2017-11-10 00",0
"0

2017-11-10 00",0
"7

2017-11-10 00",0
"5

2017-11-10 00",0
"3

2017-11-10 00",0
"3

2017-11-10 01",0
"1

2017-11-10 01",0
"0

2017-11-10 01",0
"2

2017-11-10 02",0
"1

2017-11-10 02",0
"3

2017-11-10 02",0
"3

2017-11-10 03",0
"1

2017-11-10 03",0
"1

2017-11-10 04",0
"1

2017-11-10 06",0
"0

2017-11-10 06",0
"0

2017-11-10 07",0
"3

2017-11-10 07",0
"1

2017-11-10 07",0
"0

2017-11-10 08",0
"1

2017-11-10 08",0
"4

2017-11-10 08",0
"2

2017-11-10 08",0
"5

2017-11-10 08",0
"2

2017-11-10 09",0
"5

2017-11-10 09",0
"0

2017-11-10 09",0
"4

2017-11-10 09",0
"6

2017-11-10 10",0
"2

2017-11-10 10",0
"8

2017-11-10 10",0
"10

2017-11-10 10",0
"9

2017-11-10 10",0
"7

2017-11-10 11",0
"8

2017-11-10 11",0
"17

2017-11-10 11",0
"16

2017-11-10 11",0
"14

2017-11-10 11",0
"21

2017-11-10 12",0
"20

2017-11-10 12",0
"18

2017-11-10 12",0
"14

2017-11-10 12",0
"16

2017-11-10 12",0
"19

2017-11-10 13",0
"7

2017-11-10 13",0
"12

2017-11-10 13",0
"5

2017-11-10 13",0
"13

2017-11-10 13",0
"18

2017-11-10 13",0
"16

2017-11-10 14",0
"9

2017-11-10 14",0
"11

2017-11-10 14",0
"18

2017-11-10 14",0
"18

2017-11-10 15",0
"17

2017-11-10 15",0
"6

2017-11-10 15",0
"14

2017-11-10 15",0
"13

2017-11-10 15",0
"12

2017-11-10 15",0
"14

2017-11-10 16",0
"16

2017-11-10 16",0
"15

2017-11-10 16",0
"13

2017-11-10 16",0
"18

2017-11-10 16",0
"23

2017-11-10 17",0
"15

2017-11-10 17",0
"30

2017-11-10 17",0
"31

2017-11-10 17",0
"24

2017-11-10 17",0
"19

2017-11-10 18",0
"33

2017-11-10 18",0
"28

2017-11-10 18",0
"32

2017-11-10 18",0
"39

2017-11-10 18",0
"32

2017-11-10 19",0
"22

2017-11-10 19",0
"25

2017-11-10 19",0
"30

2017-11-10 19",0
"39

2017-11-10 19",0
"28

2017-11-10 19",0
"25

2017-11-10 20",0
"22

2017-11-10 20",0
"29

2017-11-10 20",0
"14

2017-11-10 20",0
"16

2017-11-10 20",0
"24

2017-11-10 21",0
"118

2017-11-10 21",0
"55

2017-11-10 21",0
"49

2017-11-10 21",0
"40

2017-11-10 21",0
"38

2017-11-10 21",0
"30

2017-11-10 22",0
"40

2017-11-10 22",0
"32

2017-11-10 22",0
"23

2017-11-10 22",0
"21

2017-11-10 22",0
"16

2017-11-10 23",0
"20

2017-11-10 23",0
"11

2017-11-10 23",0
"24

2017-11-10 23",0
"4

2017-11-10 23",0
"3

2017-11-11 00",0
"0

2017-11-11 00",0
"9

2017-11-11 00",0
"2

2017-11-11 00",0
"6

2017-11-11 00",0
"3

2017-11-11 01",0
"2

2017-11-11 01",0
"4

2017-11-11 01",0
"1

2017-11-11 02",0
"2

2017-11-11 02",0
"0

2017-11-11 02",0
"1

2017-11-11 03",0
"2

2017-11-11 04",0
"0

2017-11-11 04",0
"0

2017-11-11 05",0
"1

2017-11-11 06",0
"2

2017-11-11 06",0
"1

2017-11-11 07",0
"0

2017-11-11 07",0
"0

2017-11-11 08",0
"1

2017-11-11 08",0
"2

2017-11-11 08",0
"2

2017-11-11 09",0
"1

2017-11-11 09",0
"4

2017-11-11 09",0
"0

2017-11-11 09",0
"2

2017-11-11 10",0
"1

2017-11-11 10",0
"2

2017-11-11 11",0
"1

2017-11-11 11",0
"1

2017-11-11 12",0
"7

2017-11-11 12",0
"3

2017-11-11 12",0
"5

2017-11-11 12",0
"1

2017-11-11 13",0
"4

2017-11-11 13",0
"3

2017-11-11 13",0
"2

2017-11-11 13",0
"2

2017-11-11 14",0
"10

2017-11-11 14",0
"1

2017-11-11 14",0
"4

2017-11-11 14",0
"3

2017-11-11 14",0
"6

2017-11-11 15",0
"4

2017-11-11 15",0
"3

2017-11-11 15",0
"3

2017-11-11 16",0
"4

2017-11-11 16",0
"7

2017-11-11 16",0
"11

2017-11-11 16",0
"5

2017-11-11 16",0
"10

2017-11-11 16",0
"6

2017-11-11 17",0
"12

2017-11-11 17",0
"13

2017-11-11 17",0
"9

2017-11-11 17",0
"8

2017-11-11 17",0
"0

2017-11-11 17",0
"10

2017-11-11 18",0
"7

2017-11-11 18",0
"12

2017-11-11 18",0
"16

2017-11-11 18",0
"8

2017-11-11 19",0
"11

2017-11-11 19",0
"7

2017-11-11 19",0
"12

2017-11-11 19",0
"4

2017-11-11 19",0
"8

2017-11-11 20",0
"5

2017-11-11 20",0
"4

2017-11-11 20",0
"1

2017-11-11 20",0
"3

2017-11-11 21",0
"16

2017-11-11 21",0
"9

2017-11-11 21",0
"8

2017-11-11 21",0
"13

2017-11-11 22",0
"9

2017-11-11 22",0
"6

2017-11-11 22",0
"12

2017-11-11 22",0
"1

2017-11-11 22",0
"5

2017-11-11 22",0
"5

2017-11-11 23",0
"12

2017-11-11 23",0
"6

2017-11-11 23",0
"3

2017-11-11 23",0
"7

2017-11-11 23",0
"9

2017-11-12 00",0
"0

2017-11-12 00",0
"7

2017-11-12 00",0
"1

2017-11-12 00",0
"3

2017-11-12 00",0
"1

2017-11-12 02",0
"0

2017-11-12 02",0
"0

2017-11-12 03",0
"1

2017-11-12 03",0
"1

2017-11-12 04",0
"0

2017-11-12 04",0
"0

2017-11-12 05",0
"1

2017-11-12 05",0
"0

2017-11-12 06",0
"1

2017-11-12 06",0
"1

2017-11-12 07",0
"0

2017-11-12 07",0
"2

2017-11-12 07",0
"1

2017-11-12 08",0
"0

2017-11-12 08",0
"1

2017-11-12 09",0
"0

2017-11-12 09",0
"3

2017-11-12 09",0
"2

2017-11-12 10",0
"3

2017-11-12 10",0
"0

2017-11-12 10",0
"1

2017-11-12 10",0
"1

2017-11-12 11",0
"0

2017-11-12 11",0
"2

2017-11-12 11",0
"2

2017-11-12 12",0
"3

2017-11-12 12",0
"1

2017-11-12 12",0
"6

2017-11-12 12",0
"2

2017-11-12 13",0
"1

2017-11-12 13",0
"0

2017-11-12 13",0
"3

2017-11-12 13",0
"4

2017-11-12 14",0
"3

2017-11-12 14",0
"2

2017-11-12 14",0
"0

2017-11-12 14",0
"1

2017-11-12 14",0
"2

2017-11-12 15",0
"4

2017-11-12 15",0
"3

2017-11-12 15",0
"4

2017-11-12 16",0
"5

2017-11-12 16",0
"1

2017-11-12 16",0
"6

2017-11-12 16",0
"2

2017-11-12 16",0
"4

2017-11-12 17",0
"5

2017-11-12 17",0
"10

2017-11-12 17",0
"6

2017-11-12 17",0
"3

2017-11-12 17",0
"7

2017-11-12 18",0
"12

2017-11-12 18",0
"11

2017-11-12 18",0
"3

2017-11-12 19",0
"4

2017-11-12 19",0
"2

2017-11-12 19",0
"5

2017-11-12 19",0
"7

2017-11-12 19",0
"4

2017-11-12 20",0
"1

2017-11-12 20",0
"5

2017-11-12 20",0
"7

2017-11-12 21",0
"4

2017-11-12 21",0
"5

2017-11-12 21",0
"3

2017-11-12 21",0
"8

2017-11-12 21",0
"8

2017-11-12 22",0
"6

2017-11-12 22",0
"2

2017-11-12 22",0
"5

2017-11-12 22",0
"3

2017-11-12 22",0
"2

2017-11-12 23",0
"11

2017-11-12 23",0
"1

2017-11-12 23",0
"3

2017-11-13 00",0
"0

2017-11-13 00",0
"1

2017-11-13 00",0
"4

2017-11-13 01",0
"2

2017-11-13 01",0
"0

2017-11-13 01",0
"1

2017-11-13 02",0
"1

2017-11-13 03",0
"1

2017-11-13 05",0
"0

2017-11-13 05",0
"0

2017-11-13 06",0
"1

2017-11-13 06",0
"1

2017-11-13 07",0
"2

2017-11-13 07",0
"0

2017-11-13 07",0
"3

2017-11-13 07",0
"2

2017-11-13 08",0
"3

2017-11-13 08",0
"1

2017-11-13 08",0
"2

2017-11-13 09",0
"1

2017-11-13 09",0
"4

2017-11-13 09",0
"5

2017-11-13 09",0
"0

2017-11-13 09",0
"9

2017-11-13 10",0
"6

2017-11-13 10",0
"2

2017-11-13 10",0
"4

2017-11-13 10",0
"10

2017-11-13 11",0
"13

2017-11-13 11",0
"12

2017-11-13 11",0
"7

2017-11-13 12",0
"17

2017-11-13 12",0
"18

2017-11-13 12",0
"10

2017-11-13 12",0
"16

2017-11-13 12",0
"13

2017-11-13 12",0
"6

2017-11-13 13",0
"9

2017-11-13 13",0
"10

2017-11-13 13",0
"8

2017-11-13 13",0
"12

2017-11-13 13",0
"10

2017-11-13 14",0
"20

2017-11-13 14",0
"9

2017-11-13 14",0
"7

2017-11-13 14",0
"13

2017-11-13 14",0
"14

2017-11-13 15",0
"12

2017-11-13 15",0
"8

2017-11-13 15",0
"20

2017-11-13 15",0
"19

2017-11-13 15",0
"13

2017-11-13 16",0
"12

2017-11-13 16",0
"8

2017-11-13 16",0
"9

2017-11-13 16",0
"15

2017-11-13 17",0
"18

2017-11-13 17",0
"16

2017-11-13 17",0
"10

2017-11-13 17",0
"19

2017-11-13 17",0
"20

2017-11-13 17",0
"22

2017-11-13 18",0
"19

2017-11-13 18",0
"26

2017-11-13 18",0
"20

2017-11-13 18",0
"23

2017-11-13 18",0
"21

2017-11-13 19",0
"23

2017-11-13 19",0
"32

2017-11-13 19",0
"24

2017-11-13 19",0
"25

2017-11-13 19",0
"12

2017-11-13 20",0
"28

2017-11-13 20",0
"29

2017-11-13 20",0
"16

2017-11-13 20",0
"30

2017-11-13 20",0
"26

2017-11-13 20",0
"26

2017-11-13 21",0
"188

2017-11-13 21",0
"70

2017-11-13 21",0
"63

2017-11-13 21",0
"53

2017-11-13 21",0
"59

2017-11-13 21",0
"33

2017-11-13 22",0
"56

2017-11-13 22",0
"37

2017-11-13 22",0
"32

2017-11-13 22",0
"23

2017-11-13 22",0
"25

2017-11-13 23",0
"19

2017-11-13 23",0
"11

2017-11-13 23",0
"9

2017-11-13 23",0
"10

2017-11-13 23",0
"15

2017-11-13 23",0
"17

2017-11-14 00",0
"5

2017-11-14 00",0
"4

2017-11-14 00",0
"1

2017-11-14 00",0
"2

2017-11-14 01",0
"1

2017-11-14 01",0
"3

2017-11-14 01",0
"0

2017-11-14 01",0
"0

2017-11-14 02",0
"1

2017-11-14 02",0
"4

2017-11-14 02",0
"1

2017-11-14 03",0
"1

2017-11-14 04",0
"1

2017-11-14 05",0
"1

2017-11-14 06",0
"0

2017-11-14 06",0
"3

2017-11-14 07",0
"0

2017-11-14 07",0
"1

2017-11-14 07",0
"2

2017-11-14 07",0
"2

2017-11-14 08",0
"1

2017-11-14 08",0
"3

2017-11-14 09",0
"2

2017-11-14 09",0
"6

2017-11-14 09",0
"1

2017-11-14 09",0
"2

2017-11-14 10",0
"4

2017-11-14 10",0
"5

2017-11-14 10",0
"6

2017-11-14 10",0
"11

2017-11-14 11",0
"12

2017-11-14 11",0
"10

2017-11-14 11",0
"15

2017-11-14 11",0
"18

2017-11-14 11",0
"28

2017-11-14 11",0
"23

2017-11-14 12",0
"17

2017-11-14 12",0
"11

2017-11-14 12",0
"7

2017-11-14 12",0
"16

2017-11-14 12",0
"13

2017-11-14 12",0
"10

2017-11-14 13",0
"12

2017-11-14 13",0
"13

2017-11-14 13",0
"24

2017-11-14 13",0
"20

2017-11-14 13",0
"12

2017-11-14 14",0
"10

2017-11-14 14",0
"17

2017-11-14 14",0
"14

2017-11-14 14",0
"9

2017-11-14 14",0
"15

2017-11-14 15",0
"11

2017-11-14 15",0
"16

2017-11-14 15",0
"12

2017-11-14 15",0
"8

2017-11-14 15",0
"10

2017-11-14 16",0
"18

2017-11-14 16",0
"12

2017-11-14 16",0
"14

2017-11-14 16",0
"16

2017-11-14 17",0
"21

2017-11-14 17",0
"22

2017-11-14 17",0
"23

2017-11-14 17",0
"20

2017-11-14 17",0
"19

2017-11-14 18",0
"27

2017-11-14 18",0
"24

2017-11-14 18",0
"25

2017-11-14 18",0
"23

2017-11-14 18",0
"26

2017-11-14 19",0
"38

2017-11-14 19",0
"22

2017-11-14 19",0
"20

2017-11-14 19",0
"34

2017-11-14 19",0
"20

2017-11-14 20",0
"36

2017-11-14 20",0
"28

2017-11-14 20",0
"19

2017-11-14 20",0
"21

2017-11-14 20",0
"16

2017-11-14 20",0
"24

2017-11-14 21",0
"175

2017-11-14 21",0
"70

2017-11-14 21",0
"55

2017-11-14 21",0
"52

2017-11-14 21",0
"39

2017-11-14 22",0
"48

2017-11-14 22",0
"36

2017-11-14 22",0
"44

2017-11-14 22",0
"35

2017-11-14 22",0
"34

2017-11-14 22",0
"13

2017-11-14 23",0
"29

2017-11-14 23",0
"12

2017-11-14 23",0
"15

2017-11-14 23",0
"9

2017-11-14 23",0
"7

2017-11-15 00",0
"0

2017-11-15 00",0
"9

2017-11-15 00",0
"6

2017-11-15 00",0
"2

2017-11-15 00",0
"4

2017-11-15 00",0
"3

2017-11-15 01",0
"2

2017-11-15 01",0
"4

2017-11-15 01",0
"5

2017-11-15 01",0
"3

2017-11-15 02",0
"4

2017-11-15 02",0
"2

2017-11-15 02",0
"1

2017-11-15 04",0
"0

2017-11-15 05",0
"0

2017-11-15 06",0
"1

2017-11-15 06",0
"0

2017-11-15 07",0
"1

2017-11-15 07",0
"4

2017-11-15 07",0
"2

2017-11-15 07",0
"1

2017-11-15 08",0
"2

2017-11-15 08",0
"0

2017-11-15 08",0
"3

2017-11-15 08",0
"0

2017-11-15 09",0
"4

2017-11-15 09",0
"1

2017-11-15 09",0
"6

2017-11-15 10",0
"3

2017-11-15 10",0
"0

2017-11-15 10",0
"7

2017-11-15 10",0
"2

2017-11-15 10",0
"11

2017-11-15 10",0
"11

2017-11-15 11",0
"9

2017-11-15 11",0
"6

2017-11-15 11",0
"18

2017-11-15 11",0
"15

2017-11-15 11",0
"18

2017-11-15 12",0
"24

2017-11-15 12",0
"22

2017-11-15 12",0
"13

2017-11-15 12",0
"16

2017-11-15 12",0
"6

2017-11-15 13",0
"14

2017-11-15 13",0
"8

2017-11-15 13",0
"11

2017-11-15 13",0
"15

2017-11-15 13",0
"8

2017-11-15 14",0
"11

2017-11-15 14",0
"9

2017-11-15 14",0
"22

2017-11-15 14",0
"13

2017-11-15 15",0
"10

2017-11-15 15",0
"11

2017-11-15 15",0
"13

2017-11-15 16",0
"14

2017-11-15 16",0
"18

2017-11-15 16",0
"15

2017-11-15 16",0
"23

2017-11-15 17",0
"25

2017-11-15 17",0
"14

2017-11-15 17",0
"15

2017-11-15 17",0
"31

2017-11-15 17",0
"23

2017-11-15 18",0
"38

2017-11-15 18",0
"25

2017-11-15 18",0
"21

2017-11-15 18",0
"24

2017-11-15 18",0
"22

2017-11-15 19",0
"16

2017-11-15 19",0
"24

2017-11-15 19",0
"27

2017-11-15 19",0
"20

2017-11-15 20",0
"17

2017-11-15 20",0
"22

2017-11-15 20",0
"19

2017-11-15 20",0
"29

2017-11-15 20",0
"27

2017-11-15 20",0
"19

2017-11-15 21",0
"194

2017-11-15 21",0
"78

2017-11-15 21",0
"66

2017-11-15 21",0
"56

2017-11-15 21",0
"57

2017-11-15 21",0
"48

2017-11-15 22",0
"60

2017-11-15 22",0
"35

2017-11-15 22",0
"40

2017-11-15 22",0
"17

2017-11-15 22",0
"29

2017-11-15 22",0
"17

2017-11-15 23",0
"33

2017-11-15 23",0
"14

2017-11-15 23",0
"25

2017-11-15 23",0
"16

2017-11-15 23",0
"10

2017-11-15 23",0
"7

2017-11-16 00",0
"0

2017-11-16 00",0
"5

2017-11-16 00",0
"6

2017-11-16 00",0
"3

2017-11-16 00",0
"2

2017-11-16 00",0
"4

2017-11-16 01",0
"5

2017-11-16 01",0
"1

2017-11-16 01",0
"3

2017-11-16 01",0
"2

2017-11-16 02",0
"1

2017-11-16 02",0
"1

2017-11-16 03",0
"1

2017-11-16 05",0
"1

2017-11-16 06",0
"0

2017-11-16 06",0
"0

2017-11-16 07",0
"1

2017-11-16 07",0
"3

2017-11-16 07",0
"1

2017-11-16 08",0
"0

2017-11-16 08",0
"3

2017-11-16 08",0
"2

2017-11-16 09",0
"4

2017-11-16 09",0
"3

2017-11-16 09",0
"1

2017-11-16 09",0
"5

2017-11-16 09",0
"5

2017-11-16 10",0
"7

2017-11-16 10",0
"2

2017-11-16 10",0
"9

2017-11-16 10",0
"7

2017-11-16 11",0
"8

2017-11-16 11",0
"6

2017-11-16 11",0
"18

2017-11-16 11",0
"20

2017-11-16 11",0
"21

2017-11-16 11",0
"28

2017-11-16 12",0
"31

2017-11-16 12",0
"20

2017-11-16 12",0
"12

2017-11-16 12",0
"8

2017-11-16 12",0
"9

2017-11-16 13",0
"11

2017-11-16 13",0
"10

2017-11-16 13",0
"6

2017-11-16 13",0
"5

2017-11-16 14",0
"12

2017-11-16 14",0
"15

2017-11-16 14",0
"9

2017-11-16 14",0
"11

2017-11-16 15",0
"14

2017-11-16 15",0
"9

2017-11-16 15",0
"10

2017-11-16 15",0
"7

2017-11-16 15",0
"8

2017-11-16 15",0
"13

2017-11-16 16",0
"16

2017-11-16 16",0
"15

2017-11-16 16",0
"17

2017-11-16 16",0
"20

2017-11-16 16",0
"23

2017-11-16 17",0
"15

2017-11-16 17",0
"13

2017-11-16 17",0
"27

2017-11-16 17",0
"18

2017-11-16 17",0
"26

2017-11-16 18",0
"31

2017-11-16 18",0
"22

2017-11-16 18",0
"30

2017-11-16 18",0
"34

2017-11-16 19",0
"20

2017-11-16 19",0
~125,0
~130,0
=[,0
968734,0
[[[ 1,0
[ 1,0
86400,0
283,0
229*229*3,0
64*64*64,0
#8649,0
[22],0
[23],0
[24],0
[25],0
[26],0
2 -> [0,0
[100,0
1264,0
0 255,0
"0

-1",0
0 1,0
/= 255,0
3 3 3 32,0
3 3 20 32,0
965,0
962,0
10-Aug,0
1759,0
>1,0
]  `,0
01]`,0
0]]`,0
#3102,0
#3128,0
=4`,0
3540,0
#7365,0
7012,0
>90%,0
519168,0
3072,0
3072,0
4`,0
80],0
40000,0
243255,0
45],0
2017-10-30 21,0
2878,0
746142,0
746681,0
8557,0
3188,0
5565,0
5619,0
4296,0
3541,0
4305,0
4838,0
2417,0
3326,0
1444,0
2566,0
5520,0
2034,0
5741,0
960,0
1560,0
5891,0
40,0
1128,0
6050,0
9587,0
813,0
6189,0
9341,0
433,0
6313,0
8938,0
195,0
6400,0
8683,0
9888,0
6516,0
8347,0
9705,0
6588,0
8330,0
9455,0
6690,0
8244,0
9287,0
6740,0
7908,0
9139,0
6813,0
8031,0
8991,0
6880,0
7567,0
8868,0
6905,0
8761,0
6934,0
7289,0
8653,0
6986,0
7321,0
8527,0
7050,0
7400,0
7079,0
7091,0
8426,0
7092,0
7332,0
8372,0
7117,0
6867,0
8255,0
7159,0
8226,0
7144,0
7053,0
8205,0
7187,0
6784,0
8132,0
7204,0
8060,0
7226,0
6894,0
8061,0
7249,0
6987,0
8036,0
7250,0
7010,0
7989,0
7283,0
6628,0
7961,0
7286,0
6969,0
7900,0
7315,0
6636,0
7944,0
7314,0
6536,0
7904,0
7297,0
6438,0
7847,0
7339,0
6787,0
7871,0
7318,0
6713,0
7744,0
7344,0
6673,0
7758,0
7363,0
6600,0
7737,0
7349,0
6830,0
7729,0
7368,0
6429,0
7743,0
7372,0
6869,0
7655,0
7379,0
6340,0
7670,0
7380,0
6367,0
7712,0
7410,0
7676,0
7392,0
6780,0
7610,0
7427,0
6450,0
7657,0
7393,0
6563,0
7598,0
7415,0
6797,0
7662,0
7405,0
6411,0
7646,0
7421,0
6968,0
7595,0
7453,0
6506,0
7576,0
7469,0
6653,0
7553,0
7449,0
6436,0
7586,0
7448,0
7537,0
7468,0
6272,0
7528,0
7475,0
6597,0
7611,0
7460,0
6753,0
7504,0
7474,0
6046,0
7483,0
6361,0
7464,0
6198,0
7510,0
7482,0
6701,0
7535,0
7511,0
7526,0
7481,0
6442,0
7540,0
7495,0
6509,0
7491,0
6674,0
7489,0
6449,0
6556,0
7452,0
6332,0
7476,0
6541,0
6295,0
7484,0
6496,0
7518,0
6650,0
7618,0
7485,0
6168,0
7592,0
6904,0
7438,0
6371,0
7544,0
7470,0
6342,0
7604,0
7471,0
6426,0
7572,0
7486,0
6803,0
7599,0
7492,0
7558,0
6823,0
7497,0
6439,0
7532,0
7501,0
6811,0
7620,0
7477,0
6484,0
6406,0
7590,0
7493,0
6421,0
7635,0
7472,0
6409,0
7588,0
6949,0
7628,0
7629,0
7677,0
7467,0
6510,0
7631,0
6215,0
7647,0
7463,0
6739,0
7683,0
7436,0
6518,0
7740,0
7002,0
7741,0
7454,0
7054,0
7738,0
7803,0
7820,0
7418,0
6397,0
7772,0
6404,0
7450,0
6418,0
7782,0
7444,0
7073,0
7829,0
7417,0
7462,0
7815,0
7416,0
6238,0
7916,0
6790,0
7906,0
7395,0
6957,0
7949,0
6915,0
7924,0
7399,0
6852,0
7899,0
7419,0
6624,0
8010,0
7384,0
6683,0
8017,0
6843,0
7996,0
7401,0
7220,0
8083,0
7337,0
7954,0
8067,0
7364,0
7106,0
8062,0
7346,0
7587,0
8069,0
7356,0
8167,0
8147,0
6963,0
7319,0
8140,0
8210,0
7323,0
8179,0
7322,0
8207,0
8332,0
7290,0
7430,0
8264,0
6706,0
8361,0
7296,0
7280,0
8385,0
7298,0
7722,0
8410,0
7277,0
8182,0
8435,0
7270,0
8229,0
8536,0
8509,0
7259,0
7152,0
8497,0
7239,0
7108,0
8604,0
7222,0
7192,0
8597,0
7214,0
8238,0
8686,0
7197,0
8729,0
7178,0
7303,0
8688,0
7219,0
7791,0
8812,0
7161,0
8548,0
8830,0
7158,0
7812,0
8854,0
7126,0
7594,0
8943,0
7135,0
9536,0
9035,0
7107,0
8863,0
9137,0
7057,0
8745,0
9114,0
7310,0
9092,0
7069,0
8356,0
9162,0
7042,0
8215,0
9268,0
7052,0
7719,0
9248,0
7037,0
7891,0
9360,0
7217,0
9519,0
6979,0
8288,0
9637,0
6927,0
8973,0
9626,0
6937,0
8769,0
9738,0
6903,0
9126,0
9805,0
6875,0
8335,0
9735,0
6912,0
9096,0
9880,0
8867,0
9879,0
6839,0
8326,0
9938,0
6833,0
9362,0
9983,0
6828,0
9272,0
62,0
6804,0
1065,0
42,0
8979,0
148,0
6761,0
8948,0
6737,0
9391,0
259,0
9079,0
368,0
6700,0
9290,0
451,0
6669,0
9143,0
6725,0
138,0
6710,0
9595,0
607,0
6642,0
740,0
497,0
6655,0
8311,0
709,0
6613,0
500,0
811,0
6567,0
153,0
897,0
6553,0
9240,0
843,0
6560,0
8596,0
6513,0
231,0
1158,0
6480,0
9447,0
1304,0
9155,0
1263,0
1727,0
1296,0
734,0
1395,0
6393,0
25,0
1528,0
6374,0
2147,0
1552,0
6335,0
579,0
9685,0
1712,0
6312,0
642,0
6248,0
1962,0
6222,0
2253,0
1968,0
6245,0
2323,0
2122,0
6177,0
3162,0
2168,0
6182,0
820,0
2260,0
6108,0
2184,0
2384,0
6088,0
1571,0
2441,0
6077,0
312,0
2484,0
6075,0
2032,0
2483,0
6070,0
3187,0
2629,0
6036,0
3184,0
2821,0
5966,0
2724,0
5976,0
3151,0
2923,0
5955,0
1989,0
2876,0
5942,0
2071,0
6045,0
88,0
][0][0],0
][0],0
0 ],0
[ 4,0
62/15,0
[ 15,0
"57 

---> 58",0
342,0
6368,0
[#2271],0
5966,0
0] == 1,0
0] == 2,0
3026,0
//8,0
//256,0
"```

`",0
639,0
610,0
565,0
557,0
536,0
502,0
443,0
411,0
391,0
377,0
3605,0
977,0
3027,0
952,0
978,0
980,0
974,0
992,0
982,0
965,0
"1000

 9856/10000 [============================>",0
1E+16,0
[512,0
14 * 14],0
1,0
512],0
# 512,0
150528,0
150528],0
* 2,0
"```   

**",0
320,0
140,0
2488         #,0
2491         #,0
700,0
8652,0
6107,0
"1111    

 4/20 [=====>",0
6454,0
"0833 

 5/20 [======>",0
6483,0
"0667

 6/20 [========>",0
"0556

 7/20 [=========>",0
6230,0
"0952

 8/20 [===========>",0
6212,0
"0833

 9/20 [============>",0
6192,0
"1111

10/20 [==============>",0
6223,0
"1000

11/20 [===============>",0
6626,0
"0909

12/20 [=================>",0
"1111

13/20 [==================>",0
"1282

14/20 [====================>",0
6319,0
"1190

15/20 [=====================>",0
6343,0
102000,0
"

16/20 [=======================>",0
6310,0
"1042

17/20 [========================>",0
6207,0
"1176

18/20 [==========================>",0
6063,0
"1296

19/20 [===========================>",0
6056,0
1228,0
19/20,0
973,0
"```

[[ 0",0
"]

 [ 0",0
"```

[[ 3",0
"]

 [ 1",0
86138,0
86129,0
-->,0
~ 2,0
"```

60000/60000 [==============================]",0
3.02612E+15,0
2567,0
2142,0
"1733

```",0
"3026

60000/60000 [==============================]",0
2.56698E+15,0
"2566978931427002]

```",0
-1],0
100000,0
0-160,0
] > 0,0
928,0
10 38 20,0
2840,0
2798,0
2117,0
[64,0
[128,0
1024],0
2017-11-20 21,0
497760,0
497784,0
497790,0
497794,0
497798,0
759714,0
759743,0
"0 

2017-11-20 21",0
759750,0
986] 0,0
759759,0
6719,0
87316,0
9551,0
8317,0
6633,0
2400,0
6919,0
8856/8856 [==============================],0
3740,0
8316,0
1098,0
1892,0
4937/8856 [===============>,0
1261,0
3364,0
5985,0
6098,0
4681/8856 [==============>,0
6130,0
4384,0
5270,0
4463,0
4406,0
4422,0
4345,0
4363,0
4433,0
4453,0
4368,0
4415,0
2017-11-19 17,0
742339,0
276240,0
276809,0
982670,0
522351,0
522861,0
40980,0
/41991989/5161420,0
"```

2017-11-19 08",0
637,0
638409,0
760940,0
2017-11-19 08,0
761478,0
761506,0
135,0
3526,0
8920,0
818,0
"9755

```",0
715,0
716680,0
108295,0
108775,0
108815,0
552,0
3418,0
8949,0
769,0
"9772

```",0
20%,0
84906,0
9682,0
"`



`",0
`255/2`,0
` 103,0
68`,0
139,0
6994,0
5783,0
5301,0
4503,0
"3098

```",0
################,0
0001-0,0
-----------------------------------------------------------------------------------------------------,0
16825,0
334,0
752,0
376,0
214,0
6071,0
05  #,0
5968262962,0
9.85276E+11,0
10819295021,0
"03706740068



1",0
9.7986E+11,0
9.39839E+11,0
76873856,0
"979688630307



2",0
9.46858E+11,0
9.13536E+11,0
7.5018E+11,0
"825602595291



3",0
7.62938E+11,0
7.85929E+11,0
8659711466,0
"02602888577



4",0
5.01236E+11,0
5.8915E+11,0
1.32253E+11,0
"307935305328



5",0
2807936117,0
4.13879E+11,0
1.14726E+11,0
"292098902317



6",0
1.39581E+11,0
2.91962E+11,0
70717339354,0
"21767100456



7",0
1.14901E+11,0
2.63645E+11,0
7.06409E+11,0
"217224851168



8",0
1.01012E+11,0
2.45739E+11,0
4.68781E+11,0
"176116148001



9",0
9.97591E+11,0
2.44218E+11,0
8.69002E+11,0
"24957025293



10",0
9.57705E+11,0
2.38082E+11,0
7.93309E+11,0
"237788404863



11",0
9.17768E+11,0
2.32731E+11,0
3.56E+11,0
"154031230826



12",0
8.80096E+11,0
2.2736E+11,0
3.04725E+11,0
"140374521908



13",0
8.56908E+11,0
2.23671E+11,0
3.45248E+11,0
"150562275536



14",0
8.44832E+11,0
22217891928,0
3.60884E+11,0
"154798901412



15",0
8.44001E+11,0
2.2147E+11,0
30373785525,0
6.74995E+11,0
7.87532E+11,0
2.10298E+11,0
"401246211335



1",0
50003129797,0
6.40252E+11,0
1.86896E+11,0
"360440107238



2",0
8.64018E+11,0
23287392271,0
1.84036E+11,0
"112992629679



3",0
4.1547E+11,0
1.59679E+11,0
3.45239E+11,0
"166836664362



4",0
3.23593E+11,0
1.41382E+11,0
1.17207E+11,0
"0815250731591



5",0
2.55187E+11,0
1.2533E+11,0
7.88068E+11,0
"0707015042412



6",0
1.99053E+11,0
1.10094E+11,0
1.46587E+11,0
"0996316193543



7",0
1.94325E+11,0
1.08653E+11,0
22364237375,0
"12307138551



8",0
1.79297E+11,0
1.0396E+11,0
1.04152E+11,0
"0821187130446



9",0
1.5612E+11,0
9.65748E+11,0
7.53274E+11,0
"0676462595845

```",0
15,0
1219834391,0
9.58043E+11,0
3.23887E+11,0
"507626796452



1",0
9.87153E+11,0
9.47847E+11,0
9.91314E+11,0
"972727180805



2",0
9.13755E+11,0
8.95092E+11,0
9.60553E+11,0
"954757456198



3",0
8.87704E+11,0
8.77553E+11,0
3.1906E+11,0
"459220583437



4",0
42077836859,0
5.3465E+11,0
4.27964E+11,0
"602694774897



5",0
1.66043E+11,0
3.21682E+11,0
5.2072E+11,0
"188639527333



6",0
1.30638E+11,0
2.83328E+11,0
6.84812E+11,0
"21664535411



7",0
1.11097E+11,0
2.5938E+11,0
4.37812E+11,0
"170154755492



8",0
1.05542E+11,0
25173293699,0
4.3714E+11,0
"16746392877



9",0
9.906E+11,0
2.43373E+11,0
8.38071E+11,0
"238413533012



10",0
9.27037E+11,0
2.34349E+11,0
3.74346E+11,0
"158595657002



11",0
8.88212E+11,0
2.28354E+11,0
4.63573E+11,0
"176301127744



12",0
8.89626E+11,0
2.28435E+11,0
6.04751E+11,0
"202052195814



13",0
8.73379E+11,0
2.26244E+11,0
4.20134E+11,0
"164519093145



14",0
8.42049E+11,0
2.21496E+11,0
5.36445E+11,0
"186482944605



15",0
7.56697E+11,0
20801132382,0
4.32103E+11,0
"169859484031



16",0
7.57876E+11,0
2.0813E+11,0
3.26404E+11,0
"145170186645



17",0
75430783716,0
2.0745E+11,0
3.14801E+11,0
"143648955088



18",0
7.49894E+11,0
2.06845E+11,0
3.69722E+11,0
"154727127577

```",0
64000,0
1000]`,0
2048>,0
--------------------------------------,0
//16,0
-------------------------------------------------,0
"```

  128/60000 [",0
3093,0
"1094

  768/60000 [",0
1583,0
"2878

 1408/60000 [",0
9300,0
"4048

 2048/60000 [>",0
"4478

 2816/60000 [>",0
5987,0
"4993

 3584/60000 [>",0
4395,0
"5455

 4352/60000 [=>",0
3275,0
"5830

 5120/60000 [=>",0
2311,0
"6123

 5888/60000 [=>",0
1472,0
"6418

 6656/60000 [==>",0
838,0
"6618

 7296/60000 [==>",0
361,0
"6771

 7936/60000 [==>",0
9952,0
"6896

 8576/60000 [===>",0
9579,0
"7021

 9344/60000 [===>",0
9185,0
"7155

10112/60000 [====>",0
8848,0
"7264

10880/60000 [====>",0
8565,0
"7356

11648/60000 [====>",0
8269,0
"7443

12416/60000 [=====>",0
8035,0
"7517

13184/60000 [=====>",0
7790,0
"7596

13824/60000 [=====>",0
"7656

14464/60000 [======>",0
7381,0
"7722

15232/60000 [======>",0
"7782

16000/60000 [=======>",0
7020,0
"7836

16640/60000 [=======>",0
6888,0
"7874

17408/60000 [=======>",0
"7928

18176/60000 [========>",0
"7989



```",0
1-Mar,0
* 2 + 1],0
*/,0
39],0
524,0
"```





>",0
3608930,0
244,0
10%,0
15*55522=,0
821,0
"6141   67215272

735/55522 [",0
"6140   67233632

736/55522 [",0
7408,0
"6142   67253048

737/55522 [",0
"6144   67268764

738/55522 [",0
7397,0
6145   67285804,0
63948,0
80,0
64,0
= [ 0,0
] = 1,0
680,0
**2,0
8,0
00454924]],0
"`



````",0
1122,0
19 39 52,0
215499,0
2477,0
< 0,0
959,0
958,0
628,0
0```,0
392,0
16 13 53,0
6261 [],0
5797,0
161]= 4,0
#%--0,0
4249,0
### 1,0
### 2,0
### 3,0
"6

###",0
/127,0
2803 0,0
2530 0,0
0008 0,0
"1156

    -0",0
0847 0,0
1228 -0,0
0021 0,0
9764 1,0
4356 1,0
1471 0,0
"1074

    -0",0
4299 0,0
4199 -0,0
0062 0,0
"3002

    -0",0
1278 0,0
0862 -0,0
"0463

    0",0
0018 0,0
0287 0,0
0090 0,0
2814 0,0
3204 -0,0
0001 0,0
"0788

    -0",0
1228 0,0
1248 0,0
0069 0,0
7068 1,0
3278 1,0
0482 0,0
"1544

    -0",0
5822 0,0
2336 -0,0
1585 0,0
"1900

    -1",0
2246 0,0
7163 -0,0
1448 0,0
"4045

    0",0
5834 2,0
8951 1,0
2963 0,0
2887 0,0
2982 -0,0
0004 0,0
"0521

    -0",0
0009 -0,0
0000 0,0
1302 1,0
5769 1,0
3250 0,0
"1044

    -0",0
2698 0,0
2312 -0,0
0071 0,0
"0989

    -25",0
3391 21,0
4002 -0,0
9373 11,0
"4734

    68",0
2413 258,0
5824 136,0
4436 34,0
3922 0,0
3955 -0,0
0010 0,0
"2013

    -0",0
2217 0,0
2049 -0,0
0148 0,0
1292,0
```[],0
#6545,0
"0**

2",0
"8**

3",0
"4**

4",0
"```

*",0
9829,0
0**,0
3832,0
2329,0
"0}

0 {",0
592,0
40344,0
2104359,0
2104368,0
"0}

   20/46460 [",0
40341 {,0
"1}

1 {",0
44135,0
2056398,0
"1}

   40/46460 [",0
2080,0
42242 {,0
"2}

2 {",0
579,0
80609,0
1790438,0
1790428,0
"2}

   60/46460 [",0
1984,0
587,0
55033 {,0
"3}

3 {",0
474,0
20993,0
8361568,0
8361578,0
"3}

   80/46460 [",0
559,0
21524 {,0
"4}

4 {",0
340,0
86914,0
9213591,0
"4}

  100/46460 [",0
8705,0
515,0
5460  5 {,0
"5}

5 {",0
349,0
80087,0
2714424,0
2714429,0
"5}

  120/46460 [",0
6040,0
487,0
92186 {,0
"6}

6 {",0
359,0
6558,0
9727578,0
9727588,0
"6}

  140/46460 [",0
3710,0
469,0
51387 {,0
"7}

7 {",0
421,0
70245,0
9462433,0
9462428,0
"7}

  160/46460 [",0
1929,0
53748 {,0
"8}

8 {",0
385,0
3887,0
6696272,0
"8}

  180/46460 [",0
236,0
454,0
85429 {,0
"9}

9 {",0
72867,0
8643327,0
8643322,0
"9}

  200/46460 [",0
9077,0
453,0
941610 {,0
"10}

```",0
`2 ^ 9,0
2104359 == 592,0
403`,0
`2 ^ 6,0
8643327 == 116,0
445,0
72867`,0
11,0
50,0
3,0
][0][20]=0,0
][0][20],0
21896,0
2229,0
1623,0
1447,0
81,0
7843,0
5916,0
"1219

```",0
<=>,0
"`

3",0
] 4,0
] 5,0
] 6,0
46],0
2017-10-23 16,0
345428,0
345450,0
345455,0
345476,0
2543,0
1201,0
-1]],0
3,0
+1000],0
591,0
97,0
76%,0
477,0
476,0
"```



##",0
4661,0
490,0
14422,0
"```

[

[1",0
[7,0
"9]

] 

-> 

[

[0",0
20000,0
7000,0
8624,0
8000,0
"```



> 1000/1000 [==============================]",0
32*21*100,0
32*2,0
"```



1",0
[[0] * 600,0
[1] * 600,0
[2] * 600,0
[3] * 600,0
[4] * 600,0
[5] * 600,0
[6] * 600,0
[7] * 600,0
[8] * 600,0
[9] * 600],0
[[0] * 100,0
[1] * 100,0
[2] * 100,0
[3] * 100,0
[4] * 100,0
[5] * 100,0
[6] * 100,0
[7] * 100,0
[8] * 100,0
[9] * 100],0
1/375 [,0
375/375 [==============================],0
9712,0
1250,0
6000/6000 [==============================],0
9426,0
6666,0
7500,0
4603,0
8427,0
2814,0
6545,0
8750,0
3573,0
8798,0
1961,0
1804,0
9375,0
3017,0
9062,0
2160,0
1237,0
2462,0
9218,0
00      0,0
"00      6000

```",0
573,0
574,0
--> 575,0
576,0
577,0
394,0
203,0
356,0
64`,0
>>> [[1],0
5},0
90%,0
20 11 42,0
"```

###",0
}[,0
[[ 1,0
}}[,0
06],0
04],0
02]],0
[[-1,0
75],0
69],0
59]],0
03],0
01]]] #,0
94%,0
72%,0
/10,0
401,0
2440000,0
9-Jan,0
50000006,0
49999988,0
49999994,0
50000012,0
93],0
121,0
============================================,0
2-Mar,0
1-Jan,0
8659,0
1350,0
6-Jan,0
"0  

2",0
11],0
98,0
-1] #,0
27000,0
= {0,0
5.43561E+16,0
"2390227278685089}

`",0
1388,0
1389,0
1392,0
-> 1389,0
556,0
557%,0
560,0
"```

2017-09-28 20",0
115269,0
"0 

2017-09-28 20",0
115276,0
2017-09-28 20,0
115287,0
20001,0
7 +106,0
"`

10/10 [==============================]",0
=[[1,0
=[[4,0
/%,0
= %,0
7285,0
911,0
7284,0
910,0
846,0
7011,0
7056,0
685,0
6622,0
859,0
861,0
2473,0
1213,0
2555,0
1294,0
2538,0
1277,0
4352,0
3091,0
3083,0
1822,0
3818,0
2557,0
"9297



```",0
10~20%,0
[360],0
566,0
1076,0
[#],0
2**,0
[ 2,0
>`,0
3000,0
2536,0
################################################,0
35%,0
~93%,0
95%,0
"```

[   0",0
2020],0
0083],0
0004],0
0125],0
0046],0
9373],0
0029],0
0412],0
1569],0
1617],0
9631],0
9625],0
9087],0
9652],0
9863],0
9646],0
9638],0
9635],0
9592],0
9679],0
"```

1/1 [==============================]",0
83,0
"0 

```",0
12],0
/3600,0
/60,0
[8],0
[150528],0
][1,0
# **********************,0
24192,0
}`,0
>= 2,0
"150

```",0
[29],0
[30],0
352*480,0
#0,0
[-2],0
811817,0
2432,0
811855,0
"110

       9/14812565 [",0
5146,0
27432017-09-12 12,0
62317,0
438789,0
"474916

      19/14812565 [",0
9542,0
31332017-09-12 12,0
449876,0
362976,0
302632,0
4 * 8,0
~~~~,0
1555,0
-> 1557,0
1558,0
410,0
> 5,0
720,0
1280,0
"`



#",0
969,0
]  +,0
[#4365],0
700000,0
70000,0
6922,0
3 *,0
/></,0
"]

        

        #",0
3762,0
-------------------------------------------------------------------------------------------------------------------,0
3%,0
639,0
654,0
647,0
744,0
2]`,0
15 2017,0
0 --,0
323,0
--> 324,0
325,0
326,0
1029,0
1343,0
<= 0,0
"1345 

   1346",0
-96,0
[3000,0
200],0
[150,0
20*150=3000,0
3554,0
41467,0
3563,0
6589,0
4147,0
`2017-08-30 11,0
759137,0
"0 

2017-08-30 11",0
759323,0
971] 0,0
2017-08-30 11,0
759522,0
104755,0
359],0
105097,0
105436,0
326],0
105710,0
[123],0
[00002],0
18-4,0
8,0
*=,0
"]

    --> 257",0
258,0
[[[2,0
3]]],0
0]]],0
"][1]][1]





  [1]",0
505,0
48,0
4597,0
*2,0
"```

  1020/113526 [",0
"0080

  1021/113526 [",0
"0080

  1022/113526 [",0
"0080

  1023/113526 [",0
"0080

```",0
"0]

    ]



```",0
"```

    [[ 0",0
"]

     [ 1",0
`1618/1618 [==============================],0
7328,0
"5556

`",0
9900`,0
"```

7090/7090 [==============================]",0
5343,0
1117,0
956,0
9884,0
633,0
"9900

```",0
"0595971204911

```",0
218,0
150808,0
2693,0
41016,0
32*32,0
`{,0
[[[,0
{}],0
{}]]],0
2]],0
0]]},0
4976091,0
1253551,0
01763817],0
3164612,0
3651996,0
04976422],0
1229059,0
3835103,0
03466541]],0
03466541],0
03466541]]],0
-1,0
-1]]},0
2878,0
"0



{",0
# => 1,0
1337,0
124,0
#2228,0
#2743,0
#6737,0
129083,0
>= 3,0
"128

    1/60000 [",0
3394,0
"1172

    4/60000 [",0
8231,0
"4160 

    7/60000 [",0
"5045

   10/60000 [",0
3488,0
"5602

   13/60000 [",0
2442,0
"6010

   16/60000 [",0
1160,0
[  [0,0
#2673,0
#2637,0
56448/60000 [===========================>,0
3547,0
"8938

56960/60000 [===========================>",0
3529,0
"8942

57344/60000 [===========================>",0
3515,0
"8946

57856/60000 [===========================>",0
3497,0
"8952

58240/60000 [============================>",0
3484,0
"8954

58624/60000 [============================>",0
3468,0
"8960

59136/60000 [============================>",0
3449,0
"8965

59648/60000 [============================>",0
3436,0
"8969

60000/60000 [==============================]",0
3423,0
8972,0
793,0
927,0
"9766

  640/60000 [",0
1146,0
"9672

 1024/60000 [",0
1318,0
"9658

 1408/60000 [",0
1307,0
"9645

 1792/60000 [",0
1323,0
"9626

 2176/60000 [>",0
1248,0
"9637

 2688/60000 [>",0
1241,0
9643,0
`41`,0
`42`,0
7600,0
3480960,0
7252,0
960,0
`[64,0
128]`,0
"```

#%%",0
8895,0
1997,0
1093,0
1083,0
10358,0
1360,0
1240,0
138,0
"+

    139",0
#2436,0
2677,0
2328,0
3732,0
2399,0
305,0
306,0
"2448 

   2449",0
"2451 

   2452",0
2443,0
2444,0
2446,0
567,0
568,0
--> 569,0
570,0
571,0
389,0
393,0
319,0
--> 321,0
322,0
198,0
287,0
291,0
674,0
"739 

    740",0
"742 

    743",0
613,0
--> 614         %,0
40%-60%,0
2705,0
2663,0
3458,0
[*],0
339,0
492,0
[0] * 100,0
998,0
365,0
"32   

33",0
"{

34",0
"35     {

36",0
"47     

48",0
"55     }

56   }",0
"{

71",0
"134 

135 /*",0
170 #,0
[0] == 0,0
[1] == 0,0
"187   }

188 

189",0
== -1,0
191,0
"200 

201 

202",0
"203     {

204 

205       //",0
207       //,0
209       //,0
213,0
"214       {

215         //",0
"217       }

218",0
"232       }

233 

234       //",0
235       //,0
"264         }

265",0
"266         {

267           //",0
"269 

270           //",0
273,0
276,0
277,0
"279           }

280 

281           //",0
"290 

291",0
293,0
303,0
"309         }

310       }

311",0
"315       }

316     }

317",0
"320     }

321 

322",0
327,0
329,0
332,0
335,0
336,0
338,0
341,0
343 #,0
345,0
346,0
"350     }

351 

352     //",0
354     //,0
356     //,0
357     //,0
358     //,0
359     //,0
"374 

375",0
377,0
"393       {

394",0
"398         }

399       }

400",0
417,0
"429     }

430",0
432,0
437,0
"450   }

451",0
"{

485             //",0
486             //  1,0
491             //,0
493             //,0
549,0
551,0
553             },0
562,0
564,0
"566 }

567",0
569,0
"571 }

572",0
"576 }

577 

578",0
< 5,0
] = 0,0
# <--,0
9627,0
66032017-07-11 03,0
964542,0
964589,0
"]]

2017-07-11 03",0
970690,0
970735,0
972004,0
972026,0
[ /],0
1288,0
59587678  0,0
59662243  0,0
"67485453]

```",0
16614527  0,0
"16614527]

```",0
5287,0
543,0
+1`,0
[10],0
7442,0
4885],0
[17,0
3168],0
~75%,0
71802521,0
38354492],0
~25%,0
[20],0
6502,0
7682,0
9075,0
5621,0
7997,0
9073,0
7167,0
[0]`,0
"] 

```",0
>    2941,0
"+

>    2942",0
">    2944 

>    2945     #",0
92,0
6431,0
1821,0
3759,0
3832,0
9411,0
834,0
4141,0
2338,0
8380,0
5120,0
4135,0
6002,0
5550,0
389,0
3725,0
6117,0
1924,0
6443,0
2766,0
529,0
6993,0
9668,0
7928,0
7784,0
4821,0
6885,0
7342,0
6094,0
8213,0
5325,0
5345,0
8488,0
4800,0
8522,0
4357,0
8660,0
1004,0
"1172

```",0
6.18933E+15,0
"10309278350515463]

```",0
1.00412E+15,0
"11724137931034483]

```",0
1504,0
740,0
1 + 2 *,0
904,0
--> 121,0
122,0
"583 

    584             #",0
1680,0
1074,0
"667 

    668",0
"670 

    671",0
366,0
"%

--> 302",0
2867,0
2825,0
3789,0
6980,0
[784],0
> 97%,0
~92%,0
"]

  #         [2",0
==> 1,0
20%  108,0
65%  21,0
42%  19,0
97%  16,0
50%  8,0
08%  5,0
59%  2,0
33%  2,0
16%  300,0
06%  106,0
02%  44,0
01%  17,0
00%  1,0
00%  765,0
00%  748,0
00%  160,0
00%  32,0
00%  22,0
00%  13,0
00%  12,0
00%  10,0
00%  6,0
00%  3,0
49%  63,0
91%  30,0
05%  16,0
60%  8,0
42%  4,0
19%  2,0
46%  590,0
43%  558,0
12%  151,0
12%  148,0
10%  131,0
06%  76,0
02%  21,0
01%  18,0
01%  12,0
01%  7,0
01%  6,0
00%  380,0
00%  343,0
00%  228,0
00%  169,0
00%  42,0
00%  19,0
00%  16,0
00%  14,0
00%  11,0
00%  4,0
`6,0
5 =,0
5 * 0 + 0,0
5 * 2,0
* 0,0
5 + 0,0
5 * 4,0
0,0
5 * 8`,0
`2,0
33 = 0,0
5 * 0 +0,0
2 + 4 + 8,0
/ 3`,0
`7 = 0,0
`12,0
666 = 0,0
1 * + 0,0
9 *,0
2 + 4 +  8,0
[[[ 2,0
"]]



 [[ 4",0
"]]



 [[ 8",0
"]]]

```",0
[ 7,0
[ 3,0
1097,0
1831,0
632,0
212,0
313,0
40,0
3820,0
606,0
00 49 10,0
#6655,0
6211,0
7122,0
3385,0
5027,0
10080,0
9326,0
[[10,0
10]],0
"```

2017-05-04 12",0
601816,0
][0] <= 0,0
][0] > 0,0
80%,0
365/800=45%,0
#3849,0
#6245,0
[0]/,0
"87765867]

 [ 0",0
"87765765]

 [ 0",0
"87766296]

 [ 0",0
"87765878]

 [ 0",0
"87765783]

 [ 0",0
"87765902]

 [ 0",0
"87765855]

 [ 0",0
"87765938]

 [ 0",0
"87766141]

 [ 0",0
"87766016]]

```",0
1.25667E+16,0
0076035054909729212]`,0
2901,0
2839,0
"]

   2840",0
2842,0
7890,0
"15]

#",0
"]

]

```",0
=====,0
692,0
694,0
2851,0
1161,0
"{}

     74",0
765,0
768,0
963,0
966,0
1013,0
1016,0
1033,0
4-,0
255 0 0,0
199,0
882,0
"0625

  128/50000 [",0
3319,0
"0781

  192/50000 [",0
3233,0
"1042

  256/50000 [",0
3243,0
"1055

  384/50000 [",0
3267,0
"0990 

  512/50000 [",0
3213,0
"1094

  640/50000 [",0
"1109

  704/50000 [",0
"1080

  832/50000 [",0
3177,0
"1058

  960/50000 [",0
3176,0
"1031

 1088/50000 [",0
3146,0
"1048

```",0
#5559,0
[[[-145,0
"6569519]]]

[[[ 356",0
"71228027]]]

```",0
916] 0,0
128/60000 [,0
4688,0
4687,0
"4688

  384/60000 [",0
6981,0
4922,0
"4922 

  640/60000 [",0
6845,0
5609,0
"5609

 1024/60000 [",0
6654,0
6143,0
"6143

 1408/60000 [",0
6427,0
6456,0
"6456

 1792/60000 [",0
6226,0
6629,0
"6629

```",0
## [,0
"~~



## [",0
2016,0
````,0
[50],0
136] 0,0
60000/60000 [==============================],0
3829,0
8815,0
1336,0
9603,0
606,0
1041,0
9690,0
533,0
441,0
781,0
9763,0
409,0
702,0
9793,0
387,0
626,0
9815,0
379,0
605,0
9817,0
352,0
1056,0
9516,0
844,0
764,0
767,0
935,0
"938 

    939",0
"480 

    481",0
"64%

```",0
95},0
"5
2",0
2*,0
679,0
291,0
235,0
221,0
210,0
202,0
183,0
/#,0
"5] [0]
[2",0
"6] [0]
[3",0
"7] [0]
[4",0
8] [1] ->,0
9] [1] ->,0
"#
    #",0
= [ [123,0
5] ],0
= [ [0,0
2 ],0
1] ],0
"[
[0",0
"1]
]",0
"-1]
```",0
"]
```",0
]+=,0
]*,0
#%,0
*+,0
@[,0
}~,0
#439,0
2188,0
